{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "import psycopg2 as pg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from Player_rank import Player_ranker\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential, Model, Input\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "import tensorflow as tf\n",
    "import scipy.stats as scs\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nHere we're loading in all of the traditional Fantasy basketball stats into SQL, using window function to get a ranking by minutes\\n\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Here we're loading in all of the traditional Fantasy basketball stats into SQL, using window function to get a ranking by minutes\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"IF you have open connections run the following in the psql command prompt:\\n\\nSELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname = 'nba_capstone';\\n\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''IF you have open connections run the following in the psql command prompt:\n",
    "\n",
    "SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname = 'nba_capstone';\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pg2.connect(dbname = 'postgres',host='localhost')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.autocommit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Note for some reason you can not access the database if it is not all lowercase'''\n",
    "\n",
    "cur.execute('DROP DATABASE IF EXISTS nba_capstone;')  # Makes sure there is not already a class_example database and removes is if there is\n",
    "cur.execute('CREATE DATABASE nba_capstone;')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pg2.connect(dbname = 'nba_capstone',host='localhost')\n",
    "conn.autocommit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "        CREATE TABLE NBA_stats (\n",
    "            Season integer, \n",
    "            Player varchar(50), \n",
    "            Pos varchar(10),\n",
    "            Age int,\n",
    "            Tm varchar(15),\n",
    "            G int,\n",
    "            GS int,\n",
    "            MP float,\n",
    "            FG float,\n",
    "            FGA float,\n",
    "            FG_Percentage float,\n",
    "            Threes_Made float,\n",
    "            Threes_Attempted float,\n",
    "            Three_Percentage float,\n",
    "            Twos_Made float,\n",
    "            Twos_Attempted float,\n",
    "            Twos_Percentage float,\n",
    "            eff_FG_Percentage float,\n",
    "            FTM float,\n",
    "            FTA float,\n",
    "            FT_Percentage float,\n",
    "            ORB float,\n",
    "            DRB float,\n",
    "            Rebounds float,\n",
    "            AST float,\n",
    "            STL float,\n",
    "            BLK float,\n",
    "            TOV float,\n",
    "            Fouls float,\n",
    "            Points float\n",
    "        );\n",
    "        '''\n",
    "\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# current_directory_path = os.getcwd()\n",
    "# current_directory_path\n",
    "\n",
    "query = '''\n",
    "        COPY NBA_stats \n",
    "        FROM '/Users/rcheer/Desktop/Galvanize/Capstone/Fantasy-Basketball-Capstone-Project/NBA stats.csv' \n",
    "        DELIMITER ',' \n",
    "        CSV HEADER;\n",
    "        '''\n",
    "\n",
    "\n",
    "\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "        CREATE TABLE nba_advanced (\n",
    "            Season integer, \n",
    "            Player varchar(50), \n",
    "            Pos varchar(10),\n",
    "            Age int,\n",
    "            Tm varchar(15),\n",
    "            G int,\n",
    "            total_MP float,\n",
    "            PER float,\n",
    "            True_Shooting float,\n",
    "            Three_Attempt_Rate float,\n",
    "            FT_rate float,\n",
    "            ORB_Percentage float,\n",
    "            DRB_Percentage float,\n",
    "            Rebound_Percentage float,\n",
    "            Assist_Percentage float,\n",
    "            Steal_Percentage float,\n",
    "            Block_Percentage float,\n",
    "            Turnover_Percentage float,\n",
    "            Usage_Percentage float,\n",
    "            Offensive_WinShares float,\n",
    "            Defensive_WinShares float,\n",
    "            WinShares float,\n",
    "            WinShares_Per48 float,\n",
    "            Offensive_BoxPlusMinus float,\n",
    "            Defensive_BoxPlusMinus float,\n",
    "            BoxPlusMinus float,\n",
    "            Value_overReplacement float\n",
    "        );\n",
    "        '''\n",
    "\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "        COPY nba_advanced \n",
    "        FROM '/Users/rcheer/Desktop/Galvanize/Capstone/Fantasy-Basketball-Capstone-Project/NBA Advanced.csv' \n",
    "        DELIMITER ',' \n",
    "        CSV HEADER;\n",
    "        '''\n",
    "\n",
    "\n",
    "\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "save for later\n",
    "d.points,d.rebounds,d.ast,d.stl,d.blk,d.tov,d.fg_percentage,d.FT_percentage\n",
    "'''\n",
    "\n",
    "\n",
    "query1 = '''\n",
    "            update nba_stats set Tm = 'NOP' where Tm = 'NOH';\n",
    "            update nba_advanced set Tm = 'NOP' where Tm = 'NOH';\n",
    "            update nba_stats set Tm = 'CHA' where Tm = 'CHO';\n",
    "            update nba_advanced set Tm = 'CHA' where Tm = 'CHO';\n",
    "            \n",
    "            DROP TABLE IF EXISTS players;\n",
    "            CREATE TABLE players AS\n",
    "            select season,player,max(G) as Games from NBA_stats where Tm!='TOT' group by season,player;\n",
    "            \n",
    "            DROP TABLE IF EXISTS y_predictions;\n",
    "            CREATE TABLE y_predictions AS\n",
    "            select d.season,d.player,d.pos,d.age,MAX(case when p.player is not null then d.Tm else NULL end) as StartingTeam,SUM(G) as Games,SUM(GS) as GS,\n",
    "            max(MP) as minutes\n",
    "            from NBA_stats d\n",
    "            left join players p\n",
    "                on d.season = p.season\n",
    "                and d.player = p.player\n",
    "                and d.G = p.Games\n",
    "            where d.Tm!='TOT'\n",
    "            group by d.season,d.player,d.pos,d.age;\n",
    "            \n",
    "            update y_predictions set StartingTeam = 'NOP' where startingTeam = 'NOH';\n",
    "            update y_predictions set StartingTeam = 'CHA' where startingTeam = 'CHO';\n",
    "            \n",
    "            DROP TABLE IF EXISTS rank_by_minutes;\n",
    "            CREATE TABLE rank_by_minutes AS\n",
    "            select y.*,n.points,n.rebounds,n.ast,n.stl,n.blk,n.tov,n.threes_made,n.fg,n.fga,n.ftm,n.fta,\n",
    "            case when cast(y.GS as float)/y.Games >0.6 then 1 else 0 end as starter,\n",
    "            row_number() over(partition by n.season order by MP*G desc) as min_rank from NBA_stats n\n",
    "            inner join y_predictions y\n",
    "                ON n.player = y.player\n",
    "                and n.season = y.season\n",
    "                and n.Tm=y.startingTeam;\n",
    "            \n",
    "            select * from rank_by_minutes        \n",
    "                \n",
    "        '''\n",
    "cur.execute(query1)\n",
    "data = cur.fetchall()\n",
    "df = pd.DataFrame(np.array(data))\n",
    "df.columns = ['season','player','position','age','team','gamesPlayed','gamesStarted','minutes'\n",
    "              ,'points','rebounds','assists','steals','blocks','turnovers','threes_made','FGM','FGA','FTM','FTA','starter','min_rank']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['min_rank']=pd.to_numeric(df['min_rank'])\n",
    "df['points']=pd.to_numeric(df['points'])\n",
    "df['rebounds']=pd.to_numeric(df['rebounds'])\n",
    "df['assists']=pd.to_numeric(df['assists'])\n",
    "df['steals']=pd.to_numeric(df['steals'])\n",
    "df['blocks']=pd.to_numeric(df['blocks'])\n",
    "df['turnovers']=pd.to_numeric(df['turnovers'])\n",
    "df['threes_made']=pd.to_numeric(df['threes_made'])\n",
    "df['FGM']=pd.to_numeric(df['FGM'])\n",
    "df['FGA']=pd.to_numeric(df['FGA'])\n",
    "df['FTM']=pd.to_numeric(df['FTM'])\n",
    "df['FTA']=pd.to_numeric(df['FTA'])\n",
    "df['gamesPlayed']=pd.to_numeric(df['gamesPlayed'])\n",
    "df['gamesStarted']=pd.to_numeric(df['gamesStarted'])\n",
    "df['minutes']=pd.to_numeric(df['minutes'])\n",
    "df['age']=pd.to_numeric(df['age'])\n",
    "df['season']=pd.to_numeric(df['season'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>mean_points</th>\n",
       "      <th>mean_rebounds</th>\n",
       "      <th>mean_assists</th>\n",
       "      <th>mean_steals</th>\n",
       "      <th>mean_blocks</th>\n",
       "      <th>mean_turnovers</th>\n",
       "      <th>mean_threes_made</th>\n",
       "      <th>mean_fgm</th>\n",
       "      <th>mean_fga</th>\n",
       "      <th>mean_ftm</th>\n",
       "      <th>mean_fta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>13.3005</td>\n",
       "      <td>5.1235</td>\n",
       "      <td>2.7870</td>\n",
       "      <td>0.9150</td>\n",
       "      <td>0.5690</td>\n",
       "      <td>1.7035</td>\n",
       "      <td>0.8780</td>\n",
       "      <td>4.9095</td>\n",
       "      <td>10.5850</td>\n",
       "      <td>2.5990</td>\n",
       "      <td>3.3115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>12.9850</td>\n",
       "      <td>5.1080</td>\n",
       "      <td>2.8490</td>\n",
       "      <td>0.9120</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>1.6965</td>\n",
       "      <td>0.8265</td>\n",
       "      <td>4.8530</td>\n",
       "      <td>10.4370</td>\n",
       "      <td>2.4600</td>\n",
       "      <td>3.1825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>12.9225</td>\n",
       "      <td>5.0185</td>\n",
       "      <td>2.8135</td>\n",
       "      <td>0.9085</td>\n",
       "      <td>0.5685</td>\n",
       "      <td>1.6790</td>\n",
       "      <td>0.8380</td>\n",
       "      <td>4.7955</td>\n",
       "      <td>10.3525</td>\n",
       "      <td>2.4955</td>\n",
       "      <td>3.2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>12.1830</td>\n",
       "      <td>4.8915</td>\n",
       "      <td>2.6840</td>\n",
       "      <td>0.9225</td>\n",
       "      <td>0.5725</td>\n",
       "      <td>1.6805</td>\n",
       "      <td>0.8030</td>\n",
       "      <td>4.5925</td>\n",
       "      <td>10.1180</td>\n",
       "      <td>2.1955</td>\n",
       "      <td>2.8590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012</td>\n",
       "      <td>12.5550</td>\n",
       "      <td>5.0520</td>\n",
       "      <td>2.8840</td>\n",
       "      <td>0.9585</td>\n",
       "      <td>0.6125</td>\n",
       "      <td>1.7410</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>4.7285</td>\n",
       "      <td>10.3275</td>\n",
       "      <td>2.2150</td>\n",
       "      <td>2.8920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013</td>\n",
       "      <td>13.0510</td>\n",
       "      <td>5.1265</td>\n",
       "      <td>2.8310</td>\n",
       "      <td>0.9505</td>\n",
       "      <td>0.5420</td>\n",
       "      <td>1.7375</td>\n",
       "      <td>0.9715</td>\n",
       "      <td>4.8545</td>\n",
       "      <td>10.5425</td>\n",
       "      <td>2.3790</td>\n",
       "      <td>3.1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014</td>\n",
       "      <td>12.3805</td>\n",
       "      <td>4.9890</td>\n",
       "      <td>2.7145</td>\n",
       "      <td>0.9230</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>1.6315</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>4.6260</td>\n",
       "      <td>10.1940</td>\n",
       "      <td>2.1725</td>\n",
       "      <td>2.8505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015</td>\n",
       "      <td>12.8715</td>\n",
       "      <td>5.1935</td>\n",
       "      <td>2.7720</td>\n",
       "      <td>0.9530</td>\n",
       "      <td>0.5900</td>\n",
       "      <td>1.6785</td>\n",
       "      <td>1.0530</td>\n",
       "      <td>4.7645</td>\n",
       "      <td>10.4595</td>\n",
       "      <td>2.2840</td>\n",
       "      <td>2.9900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>13.3550</td>\n",
       "      <td>5.0420</td>\n",
       "      <td>2.8950</td>\n",
       "      <td>0.9230</td>\n",
       "      <td>0.5340</td>\n",
       "      <td>1.6195</td>\n",
       "      <td>1.2170</td>\n",
       "      <td>4.8980</td>\n",
       "      <td>10.6355</td>\n",
       "      <td>2.3385</td>\n",
       "      <td>2.9850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>13.2915</td>\n",
       "      <td>5.0950</td>\n",
       "      <td>2.9355</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.5585</td>\n",
       "      <td>1.6825</td>\n",
       "      <td>1.3200</td>\n",
       "      <td>4.9175</td>\n",
       "      <td>10.6135</td>\n",
       "      <td>2.1395</td>\n",
       "      <td>2.7465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  mean_points  mean_rebounds  mean_assists  mean_steals  mean_blocks  \\\n",
       "0    2008      13.3005         5.1235        2.7870       0.9150       0.5690   \n",
       "1    2009      12.9850         5.1080        2.8490       0.9120       0.5600   \n",
       "2    2010      12.9225         5.0185        2.8135       0.9085       0.5685   \n",
       "3    2011      12.1830         4.8915        2.6840       0.9225       0.5725   \n",
       "4    2012      12.5550         5.0520        2.8840       0.9585       0.6125   \n",
       "5    2013      13.0510         5.1265        2.8310       0.9505       0.5420   \n",
       "6    2014      12.3805         4.9890        2.7145       0.9230       0.5390   \n",
       "7    2015      12.8715         5.1935        2.7720       0.9530       0.5900   \n",
       "8    2016      13.3550         5.0420        2.8950       0.9230       0.5340   \n",
       "9    2017      13.2915         5.0950        2.9355       0.9240       0.5585   \n",
       "\n",
       "   mean_turnovers  mean_threes_made  mean_fgm  mean_fga  mean_ftm  mean_fta  \n",
       "0          1.7035            0.8780    4.9095   10.5850    2.5990    3.3115  \n",
       "1          1.6965            0.8265    4.8530   10.4370    2.4600    3.1825  \n",
       "2          1.6790            0.8380    4.7955   10.3525    2.4955    3.2005  \n",
       "3          1.6805            0.8030    4.5925   10.1180    2.1955    2.8590  \n",
       "4          1.7410            0.8800    4.7285   10.3275    2.2150    2.8920  \n",
       "5          1.7375            0.9715    4.8545   10.5425    2.3790    3.1020  \n",
       "6          1.6315            0.9600    4.6260   10.1940    2.1725    2.8505  \n",
       "7          1.6785            1.0530    4.7645   10.4595    2.2840    2.9900  \n",
       "8          1.6195            1.2170    4.8980   10.6355    2.3385    2.9850  \n",
       "9          1.6825            1.3200    4.9175   10.6135    2.1395    2.7465  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = Player_ranker(df)\n",
    "test.get_category_dist()\n",
    "test.cat_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.assign_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_copy = test.value.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>player</th>\n",
       "      <th>value_tot</th>\n",
       "      <th>value_points</th>\n",
       "      <th>value_rebounds</th>\n",
       "      <th>value_assists</th>\n",
       "      <th>value_blocks</th>\n",
       "      <th>value_steals</th>\n",
       "      <th>value_turnovers</th>\n",
       "      <th>value_threes</th>\n",
       "      <th>value_fg</th>\n",
       "      <th>value_ft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>Andre Iguodala</td>\n",
       "      <td>1.569149</td>\n",
       "      <td>1.022902</td>\n",
       "      <td>0.233549</td>\n",
       "      <td>1.209232</td>\n",
       "      <td>-0.313073</td>\n",
       "      <td>1.720216</td>\n",
       "      <td>-1.392654</td>\n",
       "      <td>0.164932</td>\n",
       "      <td>0.201353</td>\n",
       "      <td>-1.277308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>Joe Johnson</td>\n",
       "      <td>2.248938</td>\n",
       "      <td>1.506499</td>\n",
       "      <td>-0.293101</td>\n",
       "      <td>1.449827</td>\n",
       "      <td>-0.683573</td>\n",
       "      <td>0.464584</td>\n",
       "      <td>-1.113145</td>\n",
       "      <td>1.381647</td>\n",
       "      <td>-1.036752</td>\n",
       "      <td>0.572951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>O.J. Mayo</td>\n",
       "      <td>0.491912</td>\n",
       "      <td>0.967102</td>\n",
       "      <td>-0.536170</td>\n",
       "      <td>0.198732</td>\n",
       "      <td>-0.683573</td>\n",
       "      <td>0.464584</td>\n",
       "      <td>-1.532409</td>\n",
       "      <td>1.246456</td>\n",
       "      <td>-0.633993</td>\n",
       "      <td>1.001183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008</td>\n",
       "      <td>Antawn Jamison</td>\n",
       "      <td>3.459954</td>\n",
       "      <td>1.655298</td>\n",
       "      <td>1.529918</td>\n",
       "      <td>-0.426816</td>\n",
       "      <td>-0.498323</td>\n",
       "      <td>0.715710</td>\n",
       "      <td>0.284401</td>\n",
       "      <td>0.705694</td>\n",
       "      <td>0.083254</td>\n",
       "      <td>-0.589183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>Raymond Felton</td>\n",
       "      <td>-0.135656</td>\n",
       "      <td>0.167306</td>\n",
       "      <td>-0.536170</td>\n",
       "      <td>1.882899</td>\n",
       "      <td>-0.313073</td>\n",
       "      <td>1.469090</td>\n",
       "      <td>-1.532409</td>\n",
       "      <td>-0.240639</td>\n",
       "      <td>-1.364914</td>\n",
       "      <td>0.332253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season          player  value_tot  value_points  value_rebounds  \\\n",
       "0    2008  Andre Iguodala   1.569149      1.022902        0.233549   \n",
       "1    2008     Joe Johnson   2.248938      1.506499       -0.293101   \n",
       "2    2008       O.J. Mayo   0.491912      0.967102       -0.536170   \n",
       "3    2008  Antawn Jamison   3.459954      1.655298        1.529918   \n",
       "4    2008  Raymond Felton  -0.135656      0.167306       -0.536170   \n",
       "\n",
       "   value_assists  value_blocks  value_steals  value_turnovers  value_threes  \\\n",
       "0       1.209232     -0.313073      1.720216        -1.392654      0.164932   \n",
       "1       1.449827     -0.683573      0.464584        -1.113145      1.381647   \n",
       "2       0.198732     -0.683573      0.464584        -1.532409      1.246456   \n",
       "3      -0.426816     -0.498323      0.715710         0.284401      0.705694   \n",
       "4       1.882899     -0.313073      1.469090        -1.532409     -0.240639   \n",
       "\n",
       "   value_fg  value_ft  \n",
       "0  0.201353 -1.277308  \n",
       "1 -1.036752  0.572951  \n",
       "2 -0.633993  1.001183  \n",
       "3  0.083254 -0.589183  \n",
       "4 -1.364914  0.332253  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy value data back into SQL\n",
    "engine = create_engine(\"postgresql://@localhost/nba_capstone\")\n",
    "\n",
    "value_copy.to_sql(name='value', con=engine, if_exists = 'replace', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "        DROP TABLE IF EXISTS player_value;\n",
    "        CREATE TABLE player_value AS\n",
    "        select ROW_NUMBER() OVER(PARTITION BY season ORDER BY value_tot DESC),* from value;\n",
    "        \n",
    "        DROP TABLE IF EXISTS value;\n",
    "        \n",
    "        select * from player_value;\n",
    "        \n",
    "        '''\n",
    "\n",
    "\n",
    "cur.execute(query)\n",
    "ranking_data = cur.fetchall()\n",
    "df_2 = pd.DataFrame(np.array(ranking_data))\n",
    "cols_value = ['playerrank']\n",
    "for item in (list(value_copy.columns)):\n",
    "    cols_value.append(item)\n",
    "cols_value\n",
    "df_2.columns=cols_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_2.columns:\n",
    "    if i!='player':\n",
    "        df_2[i]=pd.to_numeric(df_2[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_2.columns:\n",
    "    if i!='player':\n",
    "        df_2[i]=pd.to_numeric(df_2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playerrank</th>\n",
       "      <th>season</th>\n",
       "      <th>player</th>\n",
       "      <th>value_tot</th>\n",
       "      <th>value_points</th>\n",
       "      <th>value_rebounds</th>\n",
       "      <th>value_assists</th>\n",
       "      <th>value_blocks</th>\n",
       "      <th>value_steals</th>\n",
       "      <th>value_turnovers</th>\n",
       "      <th>value_threes</th>\n",
       "      <th>value_fg</th>\n",
       "      <th>value_ft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>Chris Paul</td>\n",
       "      <td>10.649584</td>\n",
       "      <td>1.766898</td>\n",
       "      <td>0.152526</td>\n",
       "      <td>3.952019</td>\n",
       "      <td>-0.868823</td>\n",
       "      <td>4.733733</td>\n",
       "      <td>-1.811918</td>\n",
       "      <td>-0.105449</td>\n",
       "      <td>1.195183</td>\n",
       "      <td>1.635414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>LeBron James</td>\n",
       "      <td>8.708530</td>\n",
       "      <td>2.808492</td>\n",
       "      <td>1.003268</td>\n",
       "      <td>2.123494</td>\n",
       "      <td>0.983678</td>\n",
       "      <td>1.971343</td>\n",
       "      <td>-1.811918</td>\n",
       "      <td>0.976075</td>\n",
       "      <td>0.888138</td>\n",
       "      <td>-0.234041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2008</td>\n",
       "      <td>Dwyane Wade</td>\n",
       "      <td>8.419529</td>\n",
       "      <td>3.143291</td>\n",
       "      <td>-0.050032</td>\n",
       "      <td>2.267852</td>\n",
       "      <td>1.354178</td>\n",
       "      <td>3.226975</td>\n",
       "      <td>-2.370936</td>\n",
       "      <td>0.300123</td>\n",
       "      <td>1.126183</td>\n",
       "      <td>-0.578103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "      <td>Danny Granger</td>\n",
       "      <td>6.463654</td>\n",
       "      <td>2.324895</td>\n",
       "      <td>-0.009520</td>\n",
       "      <td>-0.041864</td>\n",
       "      <td>1.539428</td>\n",
       "      <td>0.213457</td>\n",
       "      <td>-1.113145</td>\n",
       "      <td>2.463170</td>\n",
       "      <td>-0.678128</td>\n",
       "      <td>1.765360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2008</td>\n",
       "      <td>Dirk Nowitzki</td>\n",
       "      <td>6.094625</td>\n",
       "      <td>2.343495</td>\n",
       "      <td>1.327360</td>\n",
       "      <td>-0.186221</td>\n",
       "      <td>0.427928</td>\n",
       "      <td>-0.288795</td>\n",
       "      <td>-0.274618</td>\n",
       "      <td>-0.105449</td>\n",
       "      <td>0.611555</td>\n",
       "      <td>2.239370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   playerrank  season         player  value_tot  value_points  value_rebounds  \\\n",
       "0           1    2008     Chris Paul  10.649584      1.766898        0.152526   \n",
       "1           2    2008   LeBron James   8.708530      2.808492        1.003268   \n",
       "2           3    2008    Dwyane Wade   8.419529      3.143291       -0.050032   \n",
       "3           4    2008  Danny Granger   6.463654      2.324895       -0.009520   \n",
       "4           5    2008  Dirk Nowitzki   6.094625      2.343495        1.327360   \n",
       "\n",
       "   value_assists  value_blocks  value_steals  value_turnovers  value_threes  \\\n",
       "0       3.952019     -0.868823      4.733733        -1.811918     -0.105449   \n",
       "1       2.123494      0.983678      1.971343        -1.811918      0.976075   \n",
       "2       2.267852      1.354178      3.226975        -2.370936      0.300123   \n",
       "3      -0.041864      1.539428      0.213457        -1.113145      2.463170   \n",
       "4      -0.186221      0.427928     -0.288795        -0.274618     -0.105449   \n",
       "\n",
       "   value_fg  value_ft  \n",
       "0  1.195183  1.635414  \n",
       "1  0.888138 -0.234041  \n",
       "2  1.126183 -0.578103  \n",
       "3 -0.678128  1.765360  \n",
       "4  0.611555  2.239370  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playerrank</th>\n",
       "      <th>season</th>\n",
       "      <th>player</th>\n",
       "      <th>value_tot</th>\n",
       "      <th>value_points</th>\n",
       "      <th>value_rebounds</th>\n",
       "      <th>value_assists</th>\n",
       "      <th>value_blocks</th>\n",
       "      <th>value_steals</th>\n",
       "      <th>value_turnovers</th>\n",
       "      <th>value_threes</th>\n",
       "      <th>value_fg</th>\n",
       "      <th>value_ft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4219</th>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>Anthony Davis</td>\n",
       "      <td>13.069292</td>\n",
       "      <td>2.728406</td>\n",
       "      <td>2.327843</td>\n",
       "      <td>-0.323373</td>\n",
       "      <td>4.382346</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>-0.642579</td>\n",
       "      <td>-0.719758</td>\n",
       "      <td>2.572502</td>\n",
       "      <td>1.340136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4220</th>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>Stephen Curry</td>\n",
       "      <td>10.977767</td>\n",
       "      <td>2.415188</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>1.610250</td>\n",
       "      <td>-0.769567</td>\n",
       "      <td>1.647478</td>\n",
       "      <td>-1.635937</td>\n",
       "      <td>3.343394</td>\n",
       "      <td>1.073741</td>\n",
       "      <td>3.291282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4221</th>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>Kevin Durant</td>\n",
       "      <td>10.555627</td>\n",
       "      <td>2.415188</td>\n",
       "      <td>0.660945</td>\n",
       "      <td>1.254056</td>\n",
       "      <td>2.665042</td>\n",
       "      <td>-0.545910</td>\n",
       "      <td>-1.635937</td>\n",
       "      <td>1.369863</td>\n",
       "      <td>1.809299</td>\n",
       "      <td>2.563082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4222</th>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>James Harden</td>\n",
       "      <td>10.522310</td>\n",
       "      <td>3.152171</td>\n",
       "      <td>0.118234</td>\n",
       "      <td>2.984140</td>\n",
       "      <td>0.303748</td>\n",
       "      <td>2.134898</td>\n",
       "      <td>-3.374314</td>\n",
       "      <td>2.762944</td>\n",
       "      <td>-0.589500</td>\n",
       "      <td>3.029989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4223</th>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "      <td>Karl-Anthony Towns</td>\n",
       "      <td>9.046572</td>\n",
       "      <td>1.475533</td>\n",
       "      <td>2.793024</td>\n",
       "      <td>-0.272488</td>\n",
       "      <td>1.806390</td>\n",
       "      <td>-0.302200</td>\n",
       "      <td>-0.270069</td>\n",
       "      <td>0.208962</td>\n",
       "      <td>2.213129</td>\n",
       "      <td>1.394291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4224</th>\n",
       "      <td>6</td>\n",
       "      <td>2017</td>\n",
       "      <td>LeBron James</td>\n",
       "      <td>8.050018</td>\n",
       "      <td>2.617858</td>\n",
       "      <td>1.358716</td>\n",
       "      <td>3.136795</td>\n",
       "      <td>0.733074</td>\n",
       "      <td>1.160059</td>\n",
       "      <td>-3.125975</td>\n",
       "      <td>0.557232</td>\n",
       "      <td>2.935558</td>\n",
       "      <td>-1.323300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4225</th>\n",
       "      <td>7</td>\n",
       "      <td>2017</td>\n",
       "      <td>Giannis Antetokounmpo</td>\n",
       "      <td>7.982516</td>\n",
       "      <td>2.507311</td>\n",
       "      <td>1.901427</td>\n",
       "      <td>0.948747</td>\n",
       "      <td>1.806390</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>-1.635937</td>\n",
       "      <td>-0.835849</td>\n",
       "      <td>2.328774</td>\n",
       "      <td>-0.442116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4226</th>\n",
       "      <td>8</td>\n",
       "      <td>2017</td>\n",
       "      <td>Damian Lillard</td>\n",
       "      <td>7.758411</td>\n",
       "      <td>2.507311</td>\n",
       "      <td>-0.230652</td>\n",
       "      <td>1.864674</td>\n",
       "      <td>-0.340241</td>\n",
       "      <td>0.428929</td>\n",
       "      <td>-1.387598</td>\n",
       "      <td>2.066403</td>\n",
       "      <td>-0.920536</td>\n",
       "      <td>3.770119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4227</th>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "      <td>Chris Paul</td>\n",
       "      <td>7.259998</td>\n",
       "      <td>0.978069</td>\n",
       "      <td>0.118234</td>\n",
       "      <td>2.526177</td>\n",
       "      <td>-0.769567</td>\n",
       "      <td>1.891188</td>\n",
       "      <td>-0.642579</td>\n",
       "      <td>1.369863</td>\n",
       "      <td>-0.176916</td>\n",
       "      <td>1.965529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4228</th>\n",
       "      <td>10</td>\n",
       "      <td>2017</td>\n",
       "      <td>Jimmy Butler</td>\n",
       "      <td>7.194467</td>\n",
       "      <td>1.641355</td>\n",
       "      <td>0.079468</td>\n",
       "      <td>0.999632</td>\n",
       "      <td>-0.340241</td>\n",
       "      <td>2.622318</td>\n",
       "      <td>-0.145900</td>\n",
       "      <td>-0.139308</td>\n",
       "      <td>0.324360</td>\n",
       "      <td>2.152782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4229</th>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>Victor Oladipo</td>\n",
       "      <td>6.742591</td>\n",
       "      <td>1.807176</td>\n",
       "      <td>0.040703</td>\n",
       "      <td>0.694323</td>\n",
       "      <td>0.518411</td>\n",
       "      <td>3.597157</td>\n",
       "      <td>-1.511767</td>\n",
       "      <td>0.905503</td>\n",
       "      <td>0.389094</td>\n",
       "      <td>0.301991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4230</th>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>DeMarcus Cousins</td>\n",
       "      <td>6.513379</td>\n",
       "      <td>2.194092</td>\n",
       "      <td>3.025615</td>\n",
       "      <td>1.254056</td>\n",
       "      <td>2.235716</td>\n",
       "      <td>1.647478</td>\n",
       "      <td>-4.119333</td>\n",
       "      <td>1.021593</td>\n",
       "      <td>0.301785</td>\n",
       "      <td>-1.047624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4231</th>\n",
       "      <td>13</td>\n",
       "      <td>2017</td>\n",
       "      <td>Nikola Jokic</td>\n",
       "      <td>6.424866</td>\n",
       "      <td>0.959645</td>\n",
       "      <td>2.172783</td>\n",
       "      <td>1.610250</td>\n",
       "      <td>0.518411</td>\n",
       "      <td>0.672639</td>\n",
       "      <td>-1.387598</td>\n",
       "      <td>0.208962</td>\n",
       "      <td>0.838766</td>\n",
       "      <td>0.831007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4232</th>\n",
       "      <td>14</td>\n",
       "      <td>2017</td>\n",
       "      <td>Kyrie Irving</td>\n",
       "      <td>6.159878</td>\n",
       "      <td>2.046696</td>\n",
       "      <td>-0.502008</td>\n",
       "      <td>1.101402</td>\n",
       "      <td>-0.554904</td>\n",
       "      <td>0.428929</td>\n",
       "      <td>-0.766749</td>\n",
       "      <td>1.718133</td>\n",
       "      <td>0.968233</td>\n",
       "      <td>1.720144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4233</th>\n",
       "      <td>15</td>\n",
       "      <td>2017</td>\n",
       "      <td>Andre Ingram</td>\n",
       "      <td>5.581832</td>\n",
       "      <td>-0.237954</td>\n",
       "      <td>-0.812129</td>\n",
       "      <td>0.287245</td>\n",
       "      <td>2.021053</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>0.226610</td>\n",
       "      <td>1.369863</td>\n",
       "      <td>0.116338</td>\n",
       "      <td>1.207037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234</th>\n",
       "      <td>16</td>\n",
       "      <td>2017</td>\n",
       "      <td>LaMarcus Aldridge</td>\n",
       "      <td>5.370052</td>\n",
       "      <td>1.807176</td>\n",
       "      <td>1.319951</td>\n",
       "      <td>-0.476027</td>\n",
       "      <td>1.377064</td>\n",
       "      <td>-0.789620</td>\n",
       "      <td>0.226610</td>\n",
       "      <td>-1.068029</td>\n",
       "      <td>1.620860</td>\n",
       "      <td>1.352068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4235</th>\n",
       "      <td>17</td>\n",
       "      <td>2017</td>\n",
       "      <td>MarShon Brooks</td>\n",
       "      <td>5.131062</td>\n",
       "      <td>1.254438</td>\n",
       "      <td>-0.812129</td>\n",
       "      <td>0.338130</td>\n",
       "      <td>-0.340241</td>\n",
       "      <td>1.647478</td>\n",
       "      <td>-0.766749</td>\n",
       "      <td>1.602043</td>\n",
       "      <td>1.009007</td>\n",
       "      <td>1.199083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4236</th>\n",
       "      <td>18</td>\n",
       "      <td>2017</td>\n",
       "      <td>Paul George</td>\n",
       "      <td>5.126899</td>\n",
       "      <td>1.586081</td>\n",
       "      <td>0.234529</td>\n",
       "      <td>0.185475</td>\n",
       "      <td>-0.125578</td>\n",
       "      <td>2.622318</td>\n",
       "      <td>-1.263428</td>\n",
       "      <td>2.066403</td>\n",
       "      <td>-1.086400</td>\n",
       "      <td>0.907499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4237</th>\n",
       "      <td>19</td>\n",
       "      <td>2017</td>\n",
       "      <td>Kristaps Porzingis</td>\n",
       "      <td>4.816889</td>\n",
       "      <td>1.733478</td>\n",
       "      <td>0.583415</td>\n",
       "      <td>-0.883106</td>\n",
       "      <td>3.953020</td>\n",
       "      <td>-0.302200</td>\n",
       "      <td>-0.270069</td>\n",
       "      <td>0.673322</td>\n",
       "      <td>-0.888515</td>\n",
       "      <td>0.217545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4238</th>\n",
       "      <td>20</td>\n",
       "      <td>2017</td>\n",
       "      <td>Jrue Holiday</td>\n",
       "      <td>4.397228</td>\n",
       "      <td>1.051768</td>\n",
       "      <td>-0.230652</td>\n",
       "      <td>1.559365</td>\n",
       "      <td>0.518411</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>-1.139258</td>\n",
       "      <td>0.208962</td>\n",
       "      <td>0.875856</td>\n",
       "      <td>0.149007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4239</th>\n",
       "      <td>21</td>\n",
       "      <td>2017</td>\n",
       "      <td>Khris Middleton</td>\n",
       "      <td>4.231094</td>\n",
       "      <td>1.254438</td>\n",
       "      <td>0.040703</td>\n",
       "      <td>0.541669</td>\n",
       "      <td>-0.554904</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>-0.766749</td>\n",
       "      <td>0.557232</td>\n",
       "      <td>0.034790</td>\n",
       "      <td>1.720144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4240</th>\n",
       "      <td>22</td>\n",
       "      <td>2017</td>\n",
       "      <td>Nikola Vucevic</td>\n",
       "      <td>4.156660</td>\n",
       "      <td>0.591153</td>\n",
       "      <td>1.591307</td>\n",
       "      <td>0.236360</td>\n",
       "      <td>1.162400</td>\n",
       "      <td>0.185219</td>\n",
       "      <td>-0.270069</td>\n",
       "      <td>-0.255398</td>\n",
       "      <td>0.356381</td>\n",
       "      <td>0.559307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4241</th>\n",
       "      <td>23</td>\n",
       "      <td>2017</td>\n",
       "      <td>Kyle Lowry</td>\n",
       "      <td>4.141570</td>\n",
       "      <td>0.535879</td>\n",
       "      <td>0.195764</td>\n",
       "      <td>2.017329</td>\n",
       "      <td>-0.769567</td>\n",
       "      <td>0.428929</td>\n",
       "      <td>-0.766749</td>\n",
       "      <td>2.066403</td>\n",
       "      <td>-0.765502</td>\n",
       "      <td>1.199083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4242</th>\n",
       "      <td>24</td>\n",
       "      <td>2017</td>\n",
       "      <td>Otto Porter</td>\n",
       "      <td>4.136911</td>\n",
       "      <td>0.259510</td>\n",
       "      <td>0.505884</td>\n",
       "      <td>-0.476027</td>\n",
       "      <td>-0.125578</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>0.847459</td>\n",
       "      <td>0.557232</td>\n",
       "      <td>0.888985</td>\n",
       "      <td>0.275676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4243</th>\n",
       "      <td>25</td>\n",
       "      <td>2017</td>\n",
       "      <td>Kawhi Leonard</td>\n",
       "      <td>4.001655</td>\n",
       "      <td>0.535879</td>\n",
       "      <td>-0.153122</td>\n",
       "      <td>-0.323373</td>\n",
       "      <td>0.947737</td>\n",
       "      <td>2.622318</td>\n",
       "      <td>-0.145900</td>\n",
       "      <td>-0.139308</td>\n",
       "      <td>0.190517</td>\n",
       "      <td>0.466907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4244</th>\n",
       "      <td>26</td>\n",
       "      <td>2017</td>\n",
       "      <td>Kevin Love</td>\n",
       "      <td>3.988737</td>\n",
       "      <td>0.793824</td>\n",
       "      <td>1.630072</td>\n",
       "      <td>-0.628682</td>\n",
       "      <td>-0.340241</td>\n",
       "      <td>-0.545910</td>\n",
       "      <td>0.226610</td>\n",
       "      <td>1.137683</td>\n",
       "      <td>-0.085231</td>\n",
       "      <td>1.800614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4245</th>\n",
       "      <td>27</td>\n",
       "      <td>2017</td>\n",
       "      <td>Andre Drummond</td>\n",
       "      <td>3.805188</td>\n",
       "      <td>0.314784</td>\n",
       "      <td>4.227332</td>\n",
       "      <td>0.032821</td>\n",
       "      <td>2.235716</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>-1.139258</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>1.440481</td>\n",
       "      <td>-3.178068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4246</th>\n",
       "      <td>28</td>\n",
       "      <td>2017</td>\n",
       "      <td>Russell Westbrook</td>\n",
       "      <td>3.763264</td>\n",
       "      <td>2.230942</td>\n",
       "      <td>1.940192</td>\n",
       "      <td>3.747412</td>\n",
       "      <td>-0.554904</td>\n",
       "      <td>2.134898</td>\n",
       "      <td>-3.870994</td>\n",
       "      <td>-0.139308</td>\n",
       "      <td>-0.520390</td>\n",
       "      <td>-1.204585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4247</th>\n",
       "      <td>29</td>\n",
       "      <td>2017</td>\n",
       "      <td>Kemba Walker</td>\n",
       "      <td>3.725170</td>\n",
       "      <td>1.622930</td>\n",
       "      <td>-0.773363</td>\n",
       "      <td>1.355826</td>\n",
       "      <td>-0.554904</td>\n",
       "      <td>0.428929</td>\n",
       "      <td>-0.642579</td>\n",
       "      <td>1.834223</td>\n",
       "      <td>-0.897960</td>\n",
       "      <td>1.352068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4248</th>\n",
       "      <td>30</td>\n",
       "      <td>2017</td>\n",
       "      <td>Eric Bledsoe</td>\n",
       "      <td>3.653643</td>\n",
       "      <td>0.830673</td>\n",
       "      <td>-0.463243</td>\n",
       "      <td>1.101402</td>\n",
       "      <td>0.089085</td>\n",
       "      <td>2.622318</td>\n",
       "      <td>-1.511767</td>\n",
       "      <td>0.441142</td>\n",
       "      <td>0.360757</td>\n",
       "      <td>0.183276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4729</th>\n",
       "      <td>511</td>\n",
       "      <td>2017</td>\n",
       "      <td>Darrun Hilliard</td>\n",
       "      <td>-8.567256</td>\n",
       "      <td>-2.246234</td>\n",
       "      <td>-1.781256</td>\n",
       "      <td>-1.086645</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.008169</td>\n",
       "      <td>1.716648</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.468564</td>\n",
       "      <td>0.038246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4730</th>\n",
       "      <td>512</td>\n",
       "      <td>2017</td>\n",
       "      <td>Tim Quarterman</td>\n",
       "      <td>-8.645561</td>\n",
       "      <td>-2.209385</td>\n",
       "      <td>-1.587430</td>\n",
       "      <td>-1.341069</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>1.219968</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.307768</td>\n",
       "      <td>0.563284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4731</th>\n",
       "      <td>513</td>\n",
       "      <td>2017</td>\n",
       "      <td>Demetrius Jackson</td>\n",
       "      <td>-8.660268</td>\n",
       "      <td>-2.319932</td>\n",
       "      <td>-1.626195</td>\n",
       "      <td>-1.290185</td>\n",
       "      <td>-0.984230</td>\n",
       "      <td>-1.520749</td>\n",
       "      <td>1.095798</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.482386</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4732</th>\n",
       "      <td>514</td>\n",
       "      <td>2017</td>\n",
       "      <td>Markel Brown</td>\n",
       "      <td>-8.715761</td>\n",
       "      <td>-2.209385</td>\n",
       "      <td>-1.471135</td>\n",
       "      <td>-1.239300</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>1.468308</td>\n",
       "      <td>-1.184119</td>\n",
       "      <td>-0.629359</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4733</th>\n",
       "      <td>515</td>\n",
       "      <td>2017</td>\n",
       "      <td>Josh Smith</td>\n",
       "      <td>-8.748490</td>\n",
       "      <td>-2.319932</td>\n",
       "      <td>-1.471135</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.569694</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4734</th>\n",
       "      <td>516</td>\n",
       "      <td>2017</td>\n",
       "      <td>Erik McCree</td>\n",
       "      <td>-8.773341</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.858786</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-1.520749</td>\n",
       "      <td>1.716648</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.436543</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4735</th>\n",
       "      <td>517</td>\n",
       "      <td>2017</td>\n",
       "      <td>Xavier Munford</td>\n",
       "      <td>-8.789856</td>\n",
       "      <td>-2.356782</td>\n",
       "      <td>-1.897551</td>\n",
       "      <td>-1.137530</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-1.764459</td>\n",
       "      <td>1.716648</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.496208</td>\n",
       "      <td>-0.122692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4736</th>\n",
       "      <td>518</td>\n",
       "      <td>2017</td>\n",
       "      <td>Tyler Lydon</td>\n",
       "      <td>-8.811713</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.975081</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4737</th>\n",
       "      <td>519</td>\n",
       "      <td>2017</td>\n",
       "      <td>Trey McKinney-Jones</td>\n",
       "      <td>-8.811713</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.975081</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4738</th>\n",
       "      <td>520</td>\n",
       "      <td>2017</td>\n",
       "      <td>Xavier Rathan-Mayes</td>\n",
       "      <td>-8.814577</td>\n",
       "      <td>-1.380278</td>\n",
       "      <td>-1.587430</td>\n",
       "      <td>0.338130</td>\n",
       "      <td>0.089085</td>\n",
       "      <td>0.672639</td>\n",
       "      <td>-0.642579</td>\n",
       "      <td>-1.300209</td>\n",
       "      <td>-2.811382</td>\n",
       "      <td>-2.192553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4739</th>\n",
       "      <td>521</td>\n",
       "      <td>2017</td>\n",
       "      <td>Matt Williams</td>\n",
       "      <td>-8.833537</td>\n",
       "      <td>-2.135687</td>\n",
       "      <td>-1.858786</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>1.716648</td>\n",
       "      <td>-1.184119</td>\n",
       "      <td>-0.427098</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4740</th>\n",
       "      <td>522</td>\n",
       "      <td>2017</td>\n",
       "      <td>Cole Aldrich</td>\n",
       "      <td>-8.856290</td>\n",
       "      <td>-2.338357</td>\n",
       "      <td>-1.703725</td>\n",
       "      <td>-1.442839</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.008169</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.234282</td>\n",
       "      <td>-0.486792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4741</th>\n",
       "      <td>523</td>\n",
       "      <td>2017</td>\n",
       "      <td>Nicolas Brussino</td>\n",
       "      <td>-8.938136</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.664960</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.436543</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4742</th>\n",
       "      <td>524</td>\n",
       "      <td>2017</td>\n",
       "      <td>PJ Dozier</td>\n",
       "      <td>-8.985381</td>\n",
       "      <td>-2.264659</td>\n",
       "      <td>-1.781256</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>1.468308</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>0.069110</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4743</th>\n",
       "      <td>525</td>\n",
       "      <td>2017</td>\n",
       "      <td>Omer Asik</td>\n",
       "      <td>-9.030298</td>\n",
       "      <td>-2.209385</td>\n",
       "      <td>-0.967189</td>\n",
       "      <td>-1.442839</td>\n",
       "      <td>-0.984230</td>\n",
       "      <td>-2.008169</td>\n",
       "      <td>1.592478</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.018199</td>\n",
       "      <td>-1.460376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4744</th>\n",
       "      <td>526</td>\n",
       "      <td>2017</td>\n",
       "      <td>London Perrantes</td>\n",
       "      <td>-9.069214</td>\n",
       "      <td>-2.356782</td>\n",
       "      <td>-1.858786</td>\n",
       "      <td>-1.290185</td>\n",
       "      <td>-0.984230</td>\n",
       "      <td>-2.008169</td>\n",
       "      <td>1.964987</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.597338</td>\n",
       "      <td>-0.406323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4745</th>\n",
       "      <td>527</td>\n",
       "      <td>2017</td>\n",
       "      <td>Jacob Pullen</td>\n",
       "      <td>-9.101093</td>\n",
       "      <td>-2.319932</td>\n",
       "      <td>-1.975081</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>1.716648</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.045843</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4746</th>\n",
       "      <td>528</td>\n",
       "      <td>2017</td>\n",
       "      <td>Charles Cooke</td>\n",
       "      <td>-9.142223</td>\n",
       "      <td>-2.356782</td>\n",
       "      <td>-1.897551</td>\n",
       "      <td>-1.442839</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.008169</td>\n",
       "      <td>1.964987</td>\n",
       "      <td>-1.416299</td>\n",
       "      <td>-0.583516</td>\n",
       "      <td>-0.203161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4747</th>\n",
       "      <td>529</td>\n",
       "      <td>2017</td>\n",
       "      <td>Nate Wolters</td>\n",
       "      <td>-9.152010</td>\n",
       "      <td>-2.375206</td>\n",
       "      <td>-1.820021</td>\n",
       "      <td>-1.391954</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.670825</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4748</th>\n",
       "      <td>530</td>\n",
       "      <td>2017</td>\n",
       "      <td>Derrick Williams</td>\n",
       "      <td>-9.237618</td>\n",
       "      <td>-2.264659</td>\n",
       "      <td>-1.781256</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.803976</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4749</th>\n",
       "      <td>531</td>\n",
       "      <td>2017</td>\n",
       "      <td>Josh McRoberts</td>\n",
       "      <td>-9.248257</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.975081</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.436543</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4750</th>\n",
       "      <td>532</td>\n",
       "      <td>2017</td>\n",
       "      <td>Nick Collison</td>\n",
       "      <td>-9.288480</td>\n",
       "      <td>-2.061988</td>\n",
       "      <td>-1.471135</td>\n",
       "      <td>-1.341069</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>1.468308</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>0.560941</td>\n",
       "      <td>-1.460376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4751</th>\n",
       "      <td>533</td>\n",
       "      <td>2017</td>\n",
       "      <td>Chris Boucher</td>\n",
       "      <td>-9.297149</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.587430</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.873086</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4752</th>\n",
       "      <td>534</td>\n",
       "      <td>2017</td>\n",
       "      <td>Kyle Singler</td>\n",
       "      <td>-9.322633</td>\n",
       "      <td>-2.098837</td>\n",
       "      <td>-1.664960</td>\n",
       "      <td>-1.391954</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.008169</td>\n",
       "      <td>1.716648</td>\n",
       "      <td>-1.300209</td>\n",
       "      <td>-0.440920</td>\n",
       "      <td>-0.935338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4753</th>\n",
       "      <td>535</td>\n",
       "      <td>2017</td>\n",
       "      <td>Vander Blue</td>\n",
       "      <td>-9.478457</td>\n",
       "      <td>-2.338357</td>\n",
       "      <td>-1.897551</td>\n",
       "      <td>-1.188415</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-1.764459</td>\n",
       "      <td>1.344138</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.496208</td>\n",
       "      <td>-0.406323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4754</th>\n",
       "      <td>536</td>\n",
       "      <td>2017</td>\n",
       "      <td>Aaron Jackson</td>\n",
       "      <td>-9.982955</td>\n",
       "      <td>-0.974937</td>\n",
       "      <td>-0.812129</td>\n",
       "      <td>-0.984876</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>0.847459</td>\n",
       "      <td>-0.371488</td>\n",
       "      <td>-2.204598</td>\n",
       "      <td>-2.031614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4755</th>\n",
       "      <td>537</td>\n",
       "      <td>2017</td>\n",
       "      <td>Luis Montero</td>\n",
       "      <td>-10.102304</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.587430</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>0.847459</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.436543</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4756</th>\n",
       "      <td>538</td>\n",
       "      <td>2017</td>\n",
       "      <td>Chinanu Onuaku</td>\n",
       "      <td>-10.337018</td>\n",
       "      <td>-1.711921</td>\n",
       "      <td>-0.424478</td>\n",
       "      <td>-0.984876</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>-1.635937</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.596646</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4757</th>\n",
       "      <td>539</td>\n",
       "      <td>2017</td>\n",
       "      <td>Mindaugas Kuzminskas</td>\n",
       "      <td>-10.557886</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.975081</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-1.746172</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4758</th>\n",
       "      <td>540</td>\n",
       "      <td>2017</td>\n",
       "      <td>Scotty Hopson</td>\n",
       "      <td>-12.265018</td>\n",
       "      <td>-2.264659</td>\n",
       "      <td>-1.975081</td>\n",
       "      <td>-0.984876</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>0.847459</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.873086</td>\n",
       "      <td>-2.031614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      playerrank  season                 player  value_tot  value_points  \\\n",
       "4219           1    2017          Anthony Davis  13.069292      2.728406   \n",
       "4220           2    2017          Stephen Curry  10.977767      2.415188   \n",
       "4221           3    2017           Kevin Durant  10.555627      2.415188   \n",
       "4222           4    2017           James Harden  10.522310      3.152171   \n",
       "4223           5    2017     Karl-Anthony Towns   9.046572      1.475533   \n",
       "4224           6    2017           LeBron James   8.050018      2.617858   \n",
       "4225           7    2017  Giannis Antetokounmpo   7.982516      2.507311   \n",
       "4226           8    2017         Damian Lillard   7.758411      2.507311   \n",
       "4227           9    2017             Chris Paul   7.259998      0.978069   \n",
       "4228          10    2017           Jimmy Butler   7.194467      1.641355   \n",
       "4229          11    2017         Victor Oladipo   6.742591      1.807176   \n",
       "4230          12    2017       DeMarcus Cousins   6.513379      2.194092   \n",
       "4231          13    2017           Nikola Jokic   6.424866      0.959645   \n",
       "4232          14    2017           Kyrie Irving   6.159878      2.046696   \n",
       "4233          15    2017           Andre Ingram   5.581832     -0.237954   \n",
       "4234          16    2017      LaMarcus Aldridge   5.370052      1.807176   \n",
       "4235          17    2017         MarShon Brooks   5.131062      1.254438   \n",
       "4236          18    2017            Paul George   5.126899      1.586081   \n",
       "4237          19    2017     Kristaps Porzingis   4.816889      1.733478   \n",
       "4238          20    2017           Jrue Holiday   4.397228      1.051768   \n",
       "4239          21    2017        Khris Middleton   4.231094      1.254438   \n",
       "4240          22    2017         Nikola Vucevic   4.156660      0.591153   \n",
       "4241          23    2017             Kyle Lowry   4.141570      0.535879   \n",
       "4242          24    2017            Otto Porter   4.136911      0.259510   \n",
       "4243          25    2017          Kawhi Leonard   4.001655      0.535879   \n",
       "4244          26    2017             Kevin Love   3.988737      0.793824   \n",
       "4245          27    2017         Andre Drummond   3.805188      0.314784   \n",
       "4246          28    2017      Russell Westbrook   3.763264      2.230942   \n",
       "4247          29    2017           Kemba Walker   3.725170      1.622930   \n",
       "4248          30    2017           Eric Bledsoe   3.653643      0.830673   \n",
       "...          ...     ...                    ...        ...           ...   \n",
       "4729         511    2017        Darrun Hilliard  -8.567256     -2.246234   \n",
       "4730         512    2017         Tim Quarterman  -8.645561     -2.209385   \n",
       "4731         513    2017      Demetrius Jackson  -8.660268     -2.319932   \n",
       "4732         514    2017           Markel Brown  -8.715761     -2.209385   \n",
       "4733         515    2017             Josh Smith  -8.748490     -2.319932   \n",
       "4734         516    2017            Erik McCree  -8.773341     -2.448905   \n",
       "4735         517    2017         Xavier Munford  -8.789856     -2.356782   \n",
       "4736         518    2017            Tyler Lydon  -8.811713     -2.448905   \n",
       "4737         519    2017    Trey McKinney-Jones  -8.811713     -2.448905   \n",
       "4738         520    2017    Xavier Rathan-Mayes  -8.814577     -1.380278   \n",
       "4739         521    2017          Matt Williams  -8.833537     -2.135687   \n",
       "4740         522    2017           Cole Aldrich  -8.856290     -2.338357   \n",
       "4741         523    2017       Nicolas Brussino  -8.938136     -2.448905   \n",
       "4742         524    2017              PJ Dozier  -8.985381     -2.264659   \n",
       "4743         525    2017              Omer Asik  -9.030298     -2.209385   \n",
       "4744         526    2017       London Perrantes  -9.069214     -2.356782   \n",
       "4745         527    2017           Jacob Pullen  -9.101093     -2.319932   \n",
       "4746         528    2017          Charles Cooke  -9.142223     -2.356782   \n",
       "4747         529    2017           Nate Wolters  -9.152010     -2.375206   \n",
       "4748         530    2017       Derrick Williams  -9.237618     -2.264659   \n",
       "4749         531    2017         Josh McRoberts  -9.248257     -2.448905   \n",
       "4750         532    2017          Nick Collison  -9.288480     -2.061988   \n",
       "4751         533    2017          Chris Boucher  -9.297149     -2.448905   \n",
       "4752         534    2017           Kyle Singler  -9.322633     -2.098837   \n",
       "4753         535    2017            Vander Blue  -9.478457     -2.338357   \n",
       "4754         536    2017          Aaron Jackson  -9.982955     -0.974937   \n",
       "4755         537    2017           Luis Montero -10.102304     -2.448905   \n",
       "4756         538    2017         Chinanu Onuaku -10.337018     -1.711921   \n",
       "4757         539    2017   Mindaugas Kuzminskas -10.557886     -2.448905   \n",
       "4758         540    2017          Scotty Hopson -12.265018     -2.264659   \n",
       "\n",
       "      value_rebounds  value_assists  value_blocks  value_steals  \\\n",
       "4219        2.327843      -0.323373      4.382346      1.403769   \n",
       "4220        0.001938       1.610250     -0.769567      1.647478   \n",
       "4221        0.660945       1.254056      2.665042     -0.545910   \n",
       "4222        0.118234       2.984140      0.303748      2.134898   \n",
       "4223        2.793024      -0.272488      1.806390     -0.302200   \n",
       "4224        1.358716       3.136795      0.733074      1.160059   \n",
       "4225        1.901427       0.948747      1.806390      1.403769   \n",
       "4226       -0.230652       1.864674     -0.340241      0.428929   \n",
       "4227        0.118234       2.526177     -0.769567      1.891188   \n",
       "4228        0.079468       0.999632     -0.340241      2.622318   \n",
       "4229        0.040703       0.694323      0.518411      3.597157   \n",
       "4230        3.025615       1.254056      2.235716      1.647478   \n",
       "4231        2.172783       1.610250      0.518411      0.672639   \n",
       "4232       -0.502008       1.101402     -0.554904      0.428929   \n",
       "4233       -0.812129       0.287245      2.021053      1.403769   \n",
       "4234        1.319951      -0.476027      1.377064     -0.789620   \n",
       "4235       -0.812129       0.338130     -0.340241      1.647478   \n",
       "4236        0.234529       0.185475     -0.125578      2.622318   \n",
       "4237        0.583415      -0.883106      3.953020     -0.302200   \n",
       "4238       -0.230652       1.559365      0.518411      1.403769   \n",
       "4239        0.040703       0.541669     -0.554904      1.403769   \n",
       "4240        1.591307       0.236360      1.162400      0.185219   \n",
       "4241        0.195764       2.017329     -0.769567      0.428929   \n",
       "4242        0.505884      -0.476027     -0.125578      1.403769   \n",
       "4243       -0.153122      -0.323373      0.947737      2.622318   \n",
       "4244        1.630072      -0.628682     -0.340241     -0.545910   \n",
       "4245        4.227332       0.032821      2.235716      1.403769   \n",
       "4246        1.940192       3.747412     -0.554904      2.134898   \n",
       "4247       -0.773363       1.355826     -0.554904      0.428929   \n",
       "4248       -0.463243       1.101402      0.089085      2.622318   \n",
       "...              ...            ...           ...           ...   \n",
       "4729       -1.781256      -1.086645     -1.198893     -2.008169   \n",
       "4730       -1.587430      -1.341069     -1.198893     -2.251879   \n",
       "4731       -1.626195      -1.290185     -0.984230     -1.520749   \n",
       "4732       -1.471135      -1.239300     -1.198893     -2.251879   \n",
       "4733       -1.471135      -1.493724     -1.198893     -2.251879   \n",
       "4734       -1.858786      -1.493724     -1.198893     -1.520749   \n",
       "4735       -1.897551      -1.137530     -1.198893     -1.764459   \n",
       "4736       -1.975081      -1.493724     -1.198893     -2.251879   \n",
       "4737       -1.975081      -1.493724     -1.198893     -2.251879   \n",
       "4738       -1.587430       0.338130      0.089085      0.672639   \n",
       "4739       -1.858786      -1.493724     -1.198893     -2.251879   \n",
       "4740       -1.703725      -1.442839     -1.198893     -2.008169   \n",
       "4741       -1.664960      -1.493724     -1.198893     -2.251879   \n",
       "4742       -1.781256      -1.493724     -1.198893     -2.251879   \n",
       "4743       -0.967189      -1.442839     -0.984230     -2.008169   \n",
       "4744       -1.858786      -1.290185     -0.984230     -2.008169   \n",
       "4745       -1.975081      -1.493724     -1.198893     -2.251879   \n",
       "4746       -1.897551      -1.442839     -1.198893     -2.008169   \n",
       "4747       -1.820021      -1.391954     -1.198893     -2.251879   \n",
       "4748       -1.781256      -1.493724     -1.198893     -2.251879   \n",
       "4749       -1.975081      -1.493724     -1.198893     -2.251879   \n",
       "4750       -1.471135      -1.341069     -1.198893     -2.251879   \n",
       "4751       -1.587430      -1.493724     -1.198893     -2.251879   \n",
       "4752       -1.664960      -1.391954     -1.198893     -2.008169   \n",
       "4753       -1.897551      -1.188415     -1.198893     -1.764459   \n",
       "4754       -0.812129      -0.984876     -1.198893     -2.251879   \n",
       "4755       -1.587430      -1.493724     -1.198893     -2.251879   \n",
       "4756       -0.424478      -0.984876     -1.198893     -2.251879   \n",
       "4757       -1.975081      -1.493724     -1.198893     -2.251879   \n",
       "4758       -1.975081      -0.984876     -1.198893     -2.251879   \n",
       "\n",
       "      value_turnovers  value_threes  value_fg  value_ft  \n",
       "4219        -0.642579     -0.719758  2.572502  1.340136  \n",
       "4220        -1.635937      3.343394  1.073741  3.291282  \n",
       "4221        -1.635937      1.369863  1.809299  2.563082  \n",
       "4222        -3.374314      2.762944 -0.589500  3.029989  \n",
       "4223        -0.270069      0.208962  2.213129  1.394291  \n",
       "4224        -3.125975      0.557232  2.935558 -1.323300  \n",
       "4225        -1.635937     -0.835849  2.328774 -0.442116  \n",
       "4226        -1.387598      2.066403 -0.920536  3.770119  \n",
       "4227        -0.642579      1.369863 -0.176916  1.965529  \n",
       "4228        -0.145900     -0.139308  0.324360  2.152782  \n",
       "4229        -1.511767      0.905503  0.389094  0.301991  \n",
       "4230        -4.119333      1.021593  0.301785 -1.047624  \n",
       "4231        -1.387598      0.208962  0.838766  0.831007  \n",
       "4232        -0.766749      1.718133  0.968233  1.720144  \n",
       "4233         0.226610      1.369863  0.116338  1.207037  \n",
       "4234         0.226610     -1.068029  1.620860  1.352068  \n",
       "4235        -0.766749      1.602043  1.009007  1.199083  \n",
       "4236        -1.263428      2.066403 -1.086400  0.907499  \n",
       "4237        -0.270069      0.673322 -0.888515  0.217545  \n",
       "4238        -1.139258      0.208962  0.875856  0.149007  \n",
       "4239        -0.766749      0.557232  0.034790  1.720144  \n",
       "4240        -0.270069     -0.255398  0.356381  0.559307  \n",
       "4241        -0.766749      2.066403 -0.765502  1.199083  \n",
       "4242         0.847459      0.557232  0.888985  0.275676  \n",
       "4243        -0.145900     -0.139308  0.190517  0.466907  \n",
       "4244         0.226610      1.137683 -0.085231  1.800614  \n",
       "4245        -1.139258     -1.532389  1.440481 -3.178068  \n",
       "4246        -3.870994     -0.139308 -0.520390 -1.204585  \n",
       "4247        -0.642579      1.834223 -0.897960  1.352068  \n",
       "4248        -1.511767      0.441142  0.360757  0.183276  \n",
       "...               ...           ...       ...       ...  \n",
       "4729         1.716648     -1.532389 -0.468564  0.038246  \n",
       "4730         1.219968     -1.532389 -0.307768  0.563284  \n",
       "4731         1.095798     -1.532389 -0.482386  0.000000  \n",
       "4732         1.468308     -1.184119 -0.629359  0.000000  \n",
       "4733         2.089157     -1.532389 -0.569694  0.000000  \n",
       "4734         1.716648     -1.532389 -0.436543  0.000000  \n",
       "4735         1.716648     -1.532389 -0.496208 -0.122692  \n",
       "4736         2.089157     -1.532389  0.000000  0.000000  \n",
       "4737         2.089157     -1.532389  0.000000  0.000000  \n",
       "4738        -0.642579     -1.300209 -2.811382 -2.192553  \n",
       "4739         1.716648     -1.184119 -0.427098  0.000000  \n",
       "4740         2.089157     -1.532389 -0.234282 -0.486792  \n",
       "4741         2.089157     -1.532389 -0.436543  0.000000  \n",
       "4742         1.468308     -1.532389  0.069110  0.000000  \n",
       "4743         1.592478     -1.532389 -0.018199 -1.460376  \n",
       "4744         1.964987     -1.532389 -0.597338 -0.406323  \n",
       "4745         1.716648     -1.532389 -0.045843  0.000000  \n",
       "4746         1.964987     -1.416299 -0.583516 -0.203161  \n",
       "4747         2.089157     -1.532389 -0.670825  0.000000  \n",
       "4748         2.089157     -1.532389 -0.803976  0.000000  \n",
       "4749         2.089157     -1.532389 -0.436543  0.000000  \n",
       "4750         1.468308     -1.532389  0.560941 -1.460376  \n",
       "4751         2.089157     -1.532389 -0.873086  0.000000  \n",
       "4752         1.716648     -1.300209 -0.440920 -0.935338  \n",
       "4753         1.344138     -1.532389 -0.496208 -0.406323  \n",
       "4754         0.847459     -0.371488 -2.204598 -2.031614  \n",
       "4755         0.847459     -1.532389 -0.436543  0.000000  \n",
       "4756        -1.635937     -1.532389 -0.596646  0.000000  \n",
       "4757         2.089157     -1.532389 -1.746172  0.000000  \n",
       "4758         0.847459     -1.532389 -0.873086 -2.031614  \n",
       "\n",
       "[540 rows x 13 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2[df_2['season']==2017].sort_values(by='playerrank', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Creating all teammate based changes\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "query = '''\n",
    "        DROP TABLE IF EXISTS adv_top10min;\n",
    "        CREATE TEMPORARY TABLE adv_top10min as \n",
    "        select a.*,usage_percentage*total_MP/G as usage_withMins,row_number() over(partition by a.season,tm order by usage_percentage*total_MP/G desc) as usage_rank\n",
    "        from(select *,row_number() over(partition by season,tm order by total_MP desc) as min_rank from nba_advanced) a\n",
    "        inner join y_predictions y\n",
    "                ON a.player = y.player\n",
    "                and a.season = y.season\n",
    "                and a.Tm=y.startingTeam\n",
    "        where min_rank<=10;\n",
    "        \n",
    "        DROP TABLE IF EXISTS Change_Teams;\n",
    "        CREATE TABLE Change_Teams AS\n",
    "        select na.tm as old_team,na2.tm as new_team,na2.player,na2.pos,p.season,na.usage_withMins,\n",
    "        n.points,n.rebounds,n.ast,n.threes_made,na.usage_rank \n",
    "        from player_value p\n",
    "        inner join adv_top10min na\n",
    "            on p.player = na.player\n",
    "            and p.season = na.season+1\n",
    "        inner join adv_top10min na2\n",
    "            on na2.player = na.player\n",
    "            and na2.season = p.season\n",
    "            and na2.tm != na.tm\n",
    "        inner join rank_by_minutes n\n",
    "            ON N.player = na.player\n",
    "            and n.season = na.season;\n",
    "        \n",
    "        \n",
    "        \n",
    "        DROP TABLE IF EXISTS incoming_by_team;\n",
    "        CREATE TABLE incoming_by_team AS\n",
    "        select new_team,season,SUM(case when usage_withmins >1000 then 1 else 0 end) as high_usageplayer_added,\n",
    "        SUM(usage_withmins) as usagemin_added, MAX(usage_withmins) as max_usageadded,\n",
    "        SUM(points) as points_added, MAX(points) as max_pointsadded,SUM(rebounds) as rebounds_added,\n",
    "        MAX(rebounds) as max_reboundsadded, SUM(ast) as ast_added, MAX(ast) as max_astadded,\n",
    "        SUM(threes_made) as threes_added, MAX(threes_made) as max_threesadded \n",
    "        from change_teams\n",
    "        group by new_team,season;\n",
    "        \n",
    "        DROP TABLE IF EXISTS outgoing_by_team;\n",
    "        CREATE TABLE outgoing_by_team AS\n",
    "        select old_team,season,SUM(case when usage_withmins >1000 then 1 else 0 end) as high_usageplayer_dropped,\n",
    "        SUM(usage_withmins) as usagemin_dropped, MAX(usage_withmins) as max_usagedropped,\n",
    "        SUM(points) as points_dropped, MAX(points) as max_pointsdropped,SUM(rebounds) as rebounds_dropped,\n",
    "        MAX(rebounds) as max_reboundsdropped, SUM(ast) as ast_dropped, MAX(ast) as max_astdropped,\n",
    "        SUM(threes_made) as threes_dropped, MAX(threes_made) as max_threesdropped\n",
    "        from change_teams\n",
    "        group by old_team,season;\n",
    "        \n",
    "        DROP TABLE IF EXISTS Team_Changes;\n",
    "        CREATE TABLE Team_Changes AS\n",
    "        select c.new_team as team, c.season,c.high_usageplayer_added,o.usagemin_dropped-c.usagemin_added as usagemin_opened,\n",
    "        c.max_usageadded,o.high_usageplayer_dropped,o.max_usagedropped,\n",
    "        o.points_dropped-c.points_added as points_opened,max_pointsdropped,max_pointsadded,\n",
    "        o.rebounds_dropped-c.rebounds_added as rebounds_opened,max_reboundsdropped,max_reboundsadded,\n",
    "        o.ast_dropped-c.ast_added as ast_opened,max_astdropped,max_astadded,\n",
    "        o.threes_dropped-c.threes_added as threes_opened,max_threesdropped,max_threesadded\n",
    "        from incoming_by_team c\n",
    "        inner join outgoing_by_team o\n",
    "            ON o.old_team = c.new_team\n",
    "            and o.season = c.season;\n",
    "            \n",
    "        DROP TABLE IF EXISTS Team_maxes;\n",
    "        CREATE TABLE Team_maxes AS\n",
    "        select R.season,R.startingTeam,MAX(R2.points) as pts, max(r2.rebounds) as reb, max(r2.ast) as ast,\n",
    "        MAX(R2.Tov) as TO,MAX(r2.FGA) as shot_attempts, cast(NULL as float) as max_usage \n",
    "        from rank_by_minutes R\n",
    "        inner join rank_by_minutes R2\n",
    "            ON R2.startingTeam = R.startingTeam\n",
    "            and R2.season+1 = R.season\n",
    "        group by R.season,R.startingTeam;\n",
    "        \n",
    "        \n",
    "        update Team_maxes T\n",
    "        set max_usage = usage\n",
    "        from\n",
    "        (select T.season,T.startingTeam,T.pts,t.reb,t.ast,t.TO,MAX(a.usage_percentage) as usage from Team_maxes T\n",
    "        inner join adv_top10min a\n",
    "            ON a.season+1 = t.season\n",
    "            and a.tm = t.startingteam\n",
    "        group by T.season,T.startingTeam,T.pts,t.reb,t.ast,t.TO) A\n",
    "        WHERE A.season = T.season and  A.startingTeam = T.startingTeam;\n",
    "        \n",
    "        \n",
    "        \n",
    "        '''\n",
    "\n",
    "\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Get player based data\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "query = '''\n",
    "        DROP TABLE IF EXISTS player_stats;\n",
    "        CREATE TABLE player_stats AS\n",
    "        select r.*,r2.starter as starter_ly,r3.points-r2.points as change_points_ly,r2.points as points_ly\n",
    "        ,r3.rebounds-r2.rebounds as change_reb_ly, r2.rebounds as rebounds_ly,\n",
    "        r3.ast-r2.ast as change_ast_ly, r2.ast as ast_ly,r3.stl-r2.stl as change_stl_ly,r2.stl as stl_ly,\n",
    "        r3.blk-r2.blk as change_blk_ly, r2.blk as blk_ly,r3.tov-r2.tov as change_tov_ly,r2.tov as tov_ly,\n",
    "        r2.threes_made as threes_ly,r3.threes_made-r2.threes_made as change_threes,r2.fg as fg_ly, r2.fga as fga_ly,\n",
    "        r2.ftm as ftm_ly,r2.fta as fta_ly\n",
    "        from rank_by_minutes r\n",
    "        left join rank_by_minutes r2\n",
    "            on r.player = r2.player\n",
    "            and r.season = r2.season+1\n",
    "        left join rank_by_minutes r3\n",
    "            ON r3.player = r2.player\n",
    "            and r3.season+1 = r2.season;\n",
    "        \n",
    "        DROP TABLE IF EXISTS player_advstats;\n",
    "        CREATE TABLE player_advstats AS\n",
    "        select y.player,y.season,y.startingteam,a.per as per_ly, a2.per-a.per as change_per,a.three_attempt_rate as threeAR_ly,\n",
    "        a2.three_attempt_rate-a.three_attempt_rate as change_3AR, a.rebound_percentage as reb_perc_ly, a2.rebound_percentage-a.rebound_percentage as change_reb_perc\n",
    "        ,a.assist_percentage as ast_perc_ly, a2.assist_percentage-a.assist_percentage as change_assist_perc\n",
    "        ,a.steal_percentage as stl_perc_ly, a2.steal_percentage-a.steal_percentage as change_stl_perc_ly\n",
    "        ,a.block_percentage as blk_perc_ly, a2.block_percentage-a.block_percentage as change_blk_perc_ly\n",
    "        ,a.turnover_percentage as TO_perc_ly, a2.turnover_percentage-a.turnover_percentage as change_turnover_perc_ly,\n",
    "        rank() over(partition by y.season,y.startingTeam order by a.usage_percentage) as usagerank,\n",
    "        rank() over(partition by y.season,a.tm order by a.usage_percentage) as usagerank_ly,\n",
    "        a.offensive_winshares,\n",
    "        a.defensive_winshares,a.winshares,a.winshares_per48,a.offensive_boxplusminus,a.defensive_boxplusminus,\n",
    "        a.boxplusminus,a.value_overreplacement        \n",
    "        from y_predictions y\n",
    "        left join nba_advanced a\n",
    "            ON a.player = y.player\n",
    "            and a.season+1 = y.season\n",
    "        left join nba_advanced a2\n",
    "            ON a2.player = a.player\n",
    "            and a2.season+1 = a.season;\n",
    "    \n",
    "        \n",
    "        DROP TABLE IF EXISTS player_careerstats;\n",
    "        CREATE TABLE player_careerstats AS\n",
    "        select r.player,r.season,SUM(case when r2.player is not null then 1 else 0 end) as YearsPro, avg(r2.points) as career_points\n",
    "        ,avg(r2.rebounds) as career_rebounds,avg(r2.ast) as career_ast, avg(r2.stl) as career_stl, avg(r2.blk) as career_blk\n",
    "        ,avg(r2.tov) as career_TO, avg(r2.threes_made) as career_threesmade,avg(r2.ftm) as career_ftm,avg(r2.fta) as career_fta\n",
    "        ,avg(r2.fga) as career_fga, avg(r2.fg) as career_fgm\n",
    "        from rank_by_minutes r\n",
    "        inner join rank_by_minutes r2\n",
    "            ON r.player = r2.player\n",
    "            and r.season > r2.season\n",
    "        group by r.player,r.season;\n",
    "       \n",
    "        '''\n",
    "\n",
    "\n",
    "cur.execute(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>player</th>\n",
       "      <th>position</th>\n",
       "      <th>age</th>\n",
       "      <th>team</th>\n",
       "      <th>gamesPlayed</th>\n",
       "      <th>gamesStarted</th>\n",
       "      <th>minutes</th>\n",
       "      <th>points</th>\n",
       "      <th>rebounds</th>\n",
       "      <th>...</th>\n",
       "      <th>steals</th>\n",
       "      <th>blocks</th>\n",
       "      <th>turnovers</th>\n",
       "      <th>threes_made</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>starter</th>\n",
       "      <th>min_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>LeBron James</td>\n",
       "      <td>PF</td>\n",
       "      <td>33</td>\n",
       "      <td>CLE</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>36.9</td>\n",
       "      <td>27.5</td>\n",
       "      <td>8.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>10.5</td>\n",
       "      <td>19.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>Khris Middleton</td>\n",
       "      <td>SF</td>\n",
       "      <td>26</td>\n",
       "      <td>MIL</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>36.4</td>\n",
       "      <td>20.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>7.2</td>\n",
       "      <td>15.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>Bradley Beal</td>\n",
       "      <td>SG</td>\n",
       "      <td>24</td>\n",
       "      <td>WAS</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>36.3</td>\n",
       "      <td>22.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>8.3</td>\n",
       "      <td>18.1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>Andrew Wiggins</td>\n",
       "      <td>SF</td>\n",
       "      <td>22</td>\n",
       "      <td>MIN</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>36.3</td>\n",
       "      <td>17.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>6.9</td>\n",
       "      <td>15.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>CJ McCollum</td>\n",
       "      <td>SG</td>\n",
       "      <td>26</td>\n",
       "      <td>POR</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>36.1</td>\n",
       "      <td>21.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>8.2</td>\n",
       "      <td>18.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   season           player position  age team  gamesPlayed  gamesStarted  \\\n",
       "0    2017     LeBron James       PF   33  CLE           82            82   \n",
       "1    2017  Khris Middleton       SF   26  MIL           82            82   \n",
       "2    2017     Bradley Beal       SG   24  WAS           82            82   \n",
       "3    2017   Andrew Wiggins       SF   22  MIN           82            82   \n",
       "4    2017      CJ McCollum       SG   26  POR           81            81   \n",
       "\n",
       "   minutes  points  rebounds    ...     steals  blocks  turnovers  \\\n",
       "0     36.9    27.5       8.6    ...        1.4     0.9        4.2   \n",
       "1     36.4    20.1       5.2    ...        1.5     0.3        2.3   \n",
       "2     36.3    22.6       4.4    ...        1.2     0.4        2.6   \n",
       "3     36.3    17.7       4.4    ...        1.1     0.6        1.7   \n",
       "4     36.1    21.4       4.0    ...        1.0     0.4        1.9   \n",
       "\n",
       "   threes_made   FGM   FGA  FTM  FTA  starter  min_rank  \n",
       "0          1.8  10.5  19.3  4.7  6.5        1         1  \n",
       "1          1.8   7.2  15.5  3.9  4.4        1         2  \n",
       "2          2.4   8.3  18.1  3.6  4.5        1         3  \n",
       "3          1.4   6.9  15.9  2.5  3.8        1         4  \n",
       "4          2.3   8.2  18.6  2.6  3.1        1         5  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''testing leaving out 2017 and inputting predicted stats (Will later do this on 2018, but validating on 2017 first)'''\n",
    "query = '''\n",
    "        select * from rank_by_minutes where season = 2017;    \n",
    "                \n",
    "        '''\n",
    "cur.execute(query)\n",
    "data = cur.fetchall()\n",
    "df_2017 = pd.DataFrame(np.array(data))\n",
    "df_2017.columns = ['season','player','position','age','team','gamesPlayed','gamesStarted','minutes'\n",
    "              ,'points','rebounds','assists','steals','blocks','turnovers','threes_made','FGM','FGA','FTM','FTA','starter','min_rank']\n",
    "\n",
    "for i in df_2017.columns:\n",
    "    if i not in(['player','position','team']):\n",
    "        df_2017[i]=pd.to_numeric(df_2017[i])\n",
    "\n",
    "rank_2017 = Player_ranker(df_2017)\n",
    "rank_2017.get_category_dist()\n",
    "rank_2017.assign_values()\n",
    "rank_2017.value.head()\n",
    "df_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [],
   "source": [
    " query= '''\n",
    "        \n",
    "        DROP TABLE IF EXISTS points_pred;\n",
    "        CREATE TABLE points_pred(\n",
    "        season int, --these come from player_stats\n",
    "        player varchar(50),\n",
    "        Age int,\n",
    "        team varchar(50),\n",
    "        points float, -- these come from player_stats\n",
    "        points_ly float,\n",
    "        change_points_ly float,\n",
    "        starter_change int,\n",
    "        Games int,\n",
    "        C_PF int,\n",
    "        PG int,\n",
    "        SG_SF int,\n",
    "        \n",
    "         -- these come from team_changes\n",
    "        high_usageplayer_added int,\n",
    "        usagemin_opened float,\n",
    "        maxusage_added float,\n",
    "        high_usageplayer_dropped int,\n",
    "        points_opened float,\n",
    "        max_pointsdropped float,\n",
    "        max_pointsadded float,\n",
    "        \n",
    "        three_ar_ly float, -- from player_advstats\n",
    "        change_3ar float,\n",
    "        per_ly float,\n",
    "        change_per float,\n",
    "        usagerank float,\n",
    "        usagerank_ly float,\n",
    "        offensive_winshares float,\n",
    "        offensive_boxplusminus float,\n",
    "        boxplusminus float,\n",
    "        value_overreplacement float,\n",
    "        \n",
    "        career_points float,\n",
    "        yearspro int\n",
    "        );\n",
    "        \n",
    "        INSERT INTO points_pred(season,player,age,team,points,points_ly,change_points_ly,starter_change,Games,C_PF,PG,SG_SF)\n",
    "        SELECT season,player,age,startingteam,points,points_ly,change_points_ly,starter-starter_ly,Games,\n",
    "        case when pos in ('C','PF') then 1 else 0 end,case when pos='PG' then 1 else 0 end,case when pos in('SG','SF') then 1 else 0 end from player_stats;\n",
    "        \n",
    "        update points_pred pp\n",
    "        set high_usageplayer_added = tc.high_usageplayer_added,usagemin_opened=tc.usagemin_opened,\n",
    "        maxusage_added=tc.max_usageadded,high_usageplayer_dropped=tc.high_usageplayer_dropped,points_opened=tc.points_opened,\n",
    "        max_pointsdropped=tc.max_pointsdropped,max_pointsadded=tc.max_pointsadded\n",
    "        from team_changes tc\n",
    "        where tc.team = pp.team and pp.season=tc.season;\n",
    "        \n",
    "        update points_pred pp\n",
    "        set three_ar_ly = pa.threear_ly,change_3ar=pa.change_3ar,per_ly=pa.per_ly,change_per=pa.change_per,\n",
    "        usagerank=pa.usagerank,usagerank_ly=pa.usagerank_ly,offensive_winshares=pa.offensive_winshares,\n",
    "        offensive_boxplusminus=pa.offensive_boxplusminus,boxplusminus=pa.boxplusminus,value_overreplacement=pa.value_overreplacement\n",
    "        from player_advstats pa\n",
    "        where pp.player = pa.player and pp.season = pa.season and pp.team = pa.startingteam;\n",
    "        \n",
    "        update points_pred pp\n",
    "        set career_points = pc.career_points, yearspro = pc.yearspro\n",
    "        from player_careerstats pc\n",
    "        where pp.player = pc.player and pp.season = pc.season;\n",
    "        \n",
    "        \n",
    "        select * from points_pred where season>2009\n",
    "        '''\n",
    "\n",
    "\n",
    "cur.execute(query)\n",
    "data = cur.fetchall()\n",
    "points_df = pd.DataFrame(np.array(data))\n",
    "points_df.columns = ['season','player','age','team','points','points_ly','change_points_ly','starter_change','Games','C_PF','PG','SG_SF','high_usageplayer_added','usagemin_opened','maxusage_added','high_usageplayer_dropped','points_opened','max_pointsdropped',\n",
    "                    'max_pointsadded','three_ar_ly','change_3ar','per_ly','change_per','usagerank','usagerank_ly','offensive_winshares','offensive_boxplusminus','boxplusminus','value_overreplacement','career_points','yearspro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rookies = points_df[points_df['points_ly'].isna()]\n",
    "rookies.sort_values(by='points',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "points = points_df[points_df['points_ly'].notna()]\n",
    "for i in points.columns:\n",
    "    if i not in(['player','team']):\n",
    "        points[i]=pd.to_numeric(points[i])\n",
    "points = points.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = points[(points['season']!=2017) & (points['Games']>30)]['points']\n",
    "X = points[(points['season']!=2017) & (points['Games']>30)].drop(['points','player','season','team','Games'],axis=1)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression r2: 0.7746187096528391\n",
      "GradientBoost r2: 0.7715932876985157\n",
      "RandomForest r2: 0.6962466937101812\n"
     ]
    }
   ],
   "source": [
    "r2_lr = np.mean(cross_val_score(LinearRegression(),X_train,y_train,cv=10,n_jobs=-1))\n",
    "print('Linear Regression r2: {}'.format(r2_lr))\n",
    "\n",
    "r2_gb = np.mean(cross_val_score(GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.5),X_train,y_train,cv=5,n_jobs=-1))\n",
    "print('GradientBoost r2: {}'.format(r2_gb))\n",
    "\n",
    "r2_rf = np.mean(cross_val_score(RandomForestRegressor(n_estimators=1000,max_depth = 3,max_features=0.5),X_train,y_train,cv=5,n_jobs=-1))\n",
    "print('RandomForest r2: {}'.format(r2_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7495924120019375, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7476594944544669, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7943399658158287, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7190431458804185, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7222216933630867, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7627053638805009, total=   0.6s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7502206778411044, total=   0.6s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000, score=0.8045909017875303, total=   0.6s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7293798119305249, total=   0.6s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7300588658432952, total=   0.6s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7724619977012069, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7526974885743176, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000, score=0.810172956048633, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7464345262995764, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7359319991432365, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000, score=0.7714118315177116, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000, score=0.7484088434769929, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000, score=0.809351530051144, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000, score=0.7396221339062757, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000, score=0.7360800496568037, total=   1.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7782412972206614, total=   0.7s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7534142959553877, total=   0.7s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000, score=0.8076397951828361, total=   0.7s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7526210846094401, total=   0.8s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000, score=0.739283943797602, total=   0.8s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000, score=0.7718861303857902, total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000, score=0.7502934336936846, total=   1.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000, score=0.8069350259476348, total=   1.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000, score=0.7376255382516397, total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000, score=0.737654204563374, total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7626771339183323, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7465049831143591, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000, score=0.8018587343434184, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7303094382099727, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7286900382983863, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7601056582996399, total=   1.0s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7428013575185071, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000, score=0.8003830497626752, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7290513105397022, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7293391964796927, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7770393060223986, total=   1.0s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7515317599698752, total=   1.0s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000, score=0.8057791616339796, total=   1.2s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7403035333377772, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7380020790437171, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7661440685290489, total=   1.7s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7396205227844399, total=   1.7s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000, score=0.802302081648347, total=   1.7s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7295044347022633, total=   1.8s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7316890912641884, total=   1.8s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7715801807194493, total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7457471806092637, total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000, score=0.8033399817639613, total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000, score=0.744422152544153, total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7393631477275849, total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7603685317760063, total=   2.7s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7374521750249801, total=   2.7s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7991477867900119, total=   2.8s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7310660946972016, total=   2.7s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000, score=0.73103055543112, total=   2.7s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7562111426304283, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7480430230577373, total=   0.8s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7967011623928267, total=   0.8s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7257278038368107, total=   0.8s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7256501733403956, total=   0.8s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7461836284262331, total=   1.5s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7426505957356664, total=   1.5s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7943318467730048, total=   1.5s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7163064966131981, total=   1.5s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7268958591275507, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7642667464108575, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7472279720786172, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000, score=0.8051508686829824, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000, score=0.730024428630686, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7321632082347167, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7570609920410137, total=   3.2s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7422406018737014, total=   3.1s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000, score=0.8025975188997343, total=   3.1s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7321555092651384, total=   3.1s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7271797914893012, total=   3.1s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7624550271802718, total=   2.8s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7422698693042158, total=   2.8s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000, score=0.80269818476494, total=   2.6s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7366475381642718, total=   2.7s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7304025880552752, total=   2.6s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7579714310310804, total=   5.0s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7381936611530922, total=   5.0s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7997123433740743, total=   4.9s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000, score=0.729932346775635, total=   4.9s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000, score=0.721586215979279, total=   4.9s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000, score=0.737095505582872, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7391002109576411, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7821762588610093, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7153281788280829, total=   1.8s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7123294115378661, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7394600909167903, total=   3.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7397868483744654, total=   3.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7868843929850418, total=   3.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7230768853387237, total=   3.1s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7163275204374132, total=   3.1s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7546220342493819, total=   3.9s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7452179324783312, total=   3.9s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7971776444927601, total=   3.9s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7299268435231488, total=   3.9s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000, score=0.721997645297602, total=   3.8s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7537602466103849, total=   6.7s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7453613935960759, total=   6.9s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7963422967116403, total=   7.3s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000, score=0.731775920024456, total=   7.0s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7192168588867147, total=   7.3s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7521194216181062, total=   6.8s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000, score=0.73591294700449, total=   6.6s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000, score=0.8000873197537989, total=   6.5s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7281733634094683, total=   6.7s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7275044178926261, total=   6.4s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7545468244722808, total=  11.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7373252340416532, total=  11.3s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000, score=0.8003975458072936, total=  11.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7251717171625662, total=  11.6s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7249564186650879, total=  11.5s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000, score=0.752286846835078, total=   0.3s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7344522867350258, total=   0.3s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000, score=0.8002626878951357, total=   0.3s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000, score=0.703864233587904, total=   0.3s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7235337227035721, total=   0.3s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7393922487573352, total=   0.6s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7125520140158332, total=   0.6s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000, score=0.79302259406663, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7073971620006783, total=   0.6s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7119012948136328, total=   0.6s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7559099138338337, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7319007998160488, total=   0.4s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7992056979535583, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7203937644737937, total=   0.4s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000, score=0.721137441584053, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000, score=0.7385908644620797, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000, score=0.7092442173441982, total=   0.9s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000, score=0.7851112072120722, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000, score=0.6894879510843741, total=   0.9s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000, score=0.7074554670306207, total=   0.9s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7466439072911673, total=   0.7s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7257824680827822, total=   0.7s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000, score=0.8005423190440591, total=   0.7s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7147742701837227, total=   0.7s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7219265556585865, total=   0.7s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000, score=0.729322513231452, total=   1.4s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000, score=0.7082251376147489, total=   1.4s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000, score=0.786368296727049, total=   1.4s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000, score=0.6927225064421316, total=   1.4s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000, score=0.7021674528402333, total=   1.4s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000, score=0.735987099698128, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7163199673523517, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7837932451898368, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7048473971269863, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7286024372293955, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7434888704202895, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7199128185929571, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7876007854609404, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000, score=0.6945420460139555, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7055204482159698, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7510237368472615, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7303682814183251, total=   0.9s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7875888975676699, total=   0.9s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7086265574189083, total=   0.9s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7244035036909662, total=   0.9s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7393223717485395, total=   1.8s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7229888788680818, total=   1.8s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7914514342873987, total=   1.9s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7119477121686841, total=   1.8s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7131420118957748, total=   1.8s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7483604041973191, total=   1.4s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000, score=0.722014021511503, total=   1.4s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7873754260611263, total=   1.5s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7146158970835647, total=   1.4s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7223065561849062, total=   1.4s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7445193304153469, total=   2.9s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7268449941649757, total=   2.9s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7910472172522893, total=   2.8s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7076979390667831, total=   2.9s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7155123783998669, total=   3.1s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7508683171448276, total=   0.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7369347684284189, total=   0.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7868665407329936, total=   0.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7051506815535404, total=   0.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7168202672140183, total=   0.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7403865965978269, total=   1.5s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7394960864825679, total=   1.5s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7866143604997458, total=   1.5s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000, score=0.70787989008121, total=   1.5s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000, score=0.708104263057199, total=   1.5s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7527646705276453, total=   1.6s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7306964803031681, total=   1.6s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7968111012770279, total=   1.6s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7207640091874379, total=   1.6s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7215776096779543, total=   1.6s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7532871973495969, total=   2.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7300993993125191, total=   2.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7962722790974893, total=   2.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7249697944914697, total=   2.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7245997112925274, total=   2.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7450880758859164, total=   2.4s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7219047273998561, total=   2.4s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7968425632753985, total=   2.5s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7228328199892681, total=   2.5s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7210661583696008, total=   2.5s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7490806201728469, total=   4.3s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7251426220404611, total=   4.4s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7987682411300973, total=   4.4s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7209759908921514, total=   4.6s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7279667359080849, total=   4.7s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7177709865279249, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7284447966563368, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7781155952166244, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7134790895649794, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7022702697577334, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7278511082439557, total=   1.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7282186855102353, total=   1.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000, score=0.771979995001921, total=   1.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7168075035305853, total=   1.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7107626870256414, total=   1.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7485030109277822, total=   2.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7434980023515272, total=   2.0s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7896427314684267, total=   2.0s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7194799449885727, total=   2.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7233966325426893, total=   2.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7397012993381731, total=   2.2s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7369431862597071, total=   2.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7890744709242321, total=   2.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7174973044650194, total=   2.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7198864632305905, total=   2.2s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7494867760789095, total=   3.3s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7325835434169372, total=   3.4s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7991469983980578, total=   3.3s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7226740586690906, total=   3.4s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7216717811919983, total=   3.4s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7487770435984751, total=   3.5s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7330375830969063, total=   3.5s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7975796905296982, total=   3.4s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7222503677852579, total=   3.4s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7095453234854497, total=   3.5s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7400927184551788, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7051763260749899, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7863782256378044, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000, score=0.6903610883360561, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000, score=0.709880163506944, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7238648057886273, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7015505815972904, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000, score=0.771189774211563, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000, score=0.6774645909887353, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000, score=0.6983061932376536, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7346831372833165, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000, score=0.6977042165981303, total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7876122507583366, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000, score=0.690826704359533, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7044378218776257, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000, score=0.7191456328307622, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000, score=0.6950523653128976, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000, score=0.770112856119971, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000, score=0.6671644457002963, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000, score=0.6967486575476491, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7239935260934496, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000, score=0.6968332954089733, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7912071424581322, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000, score=0.6787669355629476, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7036425895595, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000, score=0.7107280285375973, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000, score=0.6906934320836046, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000, score=0.7684853436032557, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000, score=0.6733068186415727, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000, score=0.6881659954174325, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000, score=0.73062496919834, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7112315806878475, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7889885476586568, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000, score=0.6938845522487078, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7078837587072513, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7355003080703729, total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7127437181038732, total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7818553463982422, total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000, score=0.6858339349017537, total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7021546186806401, total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7417695496650021, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7099484489978046, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7923173090695046, total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000, score=0.6985217244130694, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7017796878802254, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7366849469695127, total=   1.8s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000, score=0.710631893814357, total=   1.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7701324326286275, total=   1.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000, score=0.6971844661677287, total=   1.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000, score=0.710067350050307, total=   1.8s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7378688585097068, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000, score=0.723908544033475, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7861375811253967, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7083898379004534, total=   1.5s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7020346355186942, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7436745379932068, total=   3.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000, score=0.721390374669193, total=   3.1s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7899364619877614, total=   2.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7023376993387401, total=   2.8s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7078778010172415, total=   2.9s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7332085221187111, total=   0.8s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7260121075747383, total=   0.8s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7757299189069455, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7071261929320487, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7061625505249256, total=   0.8s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7394025958553498, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7376728682711406, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7813160199839769, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000, score=0.699058564582554, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7095696708273942, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7501109680043165, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7320737587546198, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7871169906244867, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7234201757710497, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7194652481909605, total=   1.5s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7418655595748486, total=   1.5s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7244626202046608, total=   1.5s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7834005945928676, total=   1.5s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7241832829411852, total=   1.5s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7227272210830801, total=   1.5s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7453695426305416, total=   2.2s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7308966989776801, total=   2.3s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7894149280812881, total=   2.2s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7252913188700597, total=   2.2s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7107156873553534, total=   2.3s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7499877423621176, total=   2.3s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7295974357531997, total=   2.4s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000, score=0.8033482037577244, total=   2.4s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000, score=0.708724944503413, total=   2.4s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7096245120460201, total=   2.3s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7245899828276123, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7213787716744793, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000, score=0.771114043249621, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000, score=0.6951395793983591, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000, score=0.6866123757502176, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7083380746262937, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7218458017159783, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7729539221198265, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000, score=0.6786220787087511, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000, score=0.6924059206715347, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7461429399331911, total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7335854835740997, total=   1.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7882061664132022, total=   1.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000, score=0.715496985489933, total=   1.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7125187406617058, total=   1.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7351299096149566, total=   1.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7332982267329171, total=   1.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7847242825214382, total=   1.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7182262515857962, total=   1.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7061579918019316, total=   1.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7342673085994973, total=   1.8s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7324242118013593, total=   1.8s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7848016999949579, total=   1.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7116218347626846, total=   1.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7100725360014587, total=   1.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7420754701332148, total=   1.8s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7149834059138893, total=   1.8s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7906294839563833, total=   1.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7086771799125724, total=   1.8s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7012909195205025, total=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed: 11.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'learning_rate': [0.01, 0.05, 0.1], 'n_estimators': [1000, 2000], 'max_depth': [3, 5, 7, 10], 'max_features': [0.1, 0.3, 0.5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'learning_rate':[0.01,0.05,0.1], 'n_estimators':[1000,2000],'max_depth':[3,5,7,10],'max_features':[0.1,0.3,0.5]}\n",
    "\n",
    "clf = GridSearchCV(GradientBoostingRegressor(), parameters, cv=5,verbose=3)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.01, loss='ls', max_depth=3, max_features=0.5,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=1000, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>points_ly</th>\n",
       "      <th>change_points_ly</th>\n",
       "      <th>starter_change</th>\n",
       "      <th>C_PF</th>\n",
       "      <th>PG</th>\n",
       "      <th>SG_SF</th>\n",
       "      <th>high_usageplayer_added</th>\n",
       "      <th>usagemin_opened</th>\n",
       "      <th>maxusage_added</th>\n",
       "      <th>...</th>\n",
       "      <th>per_ly</th>\n",
       "      <th>change_per</th>\n",
       "      <th>usagerank</th>\n",
       "      <th>usagerank_ly</th>\n",
       "      <th>offensive_winshares</th>\n",
       "      <th>offensive_boxplusminus</th>\n",
       "      <th>boxplusminus</th>\n",
       "      <th>value_overreplacement</th>\n",
       "      <th>career_points</th>\n",
       "      <th>yearspro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>24</td>\n",
       "      <td>16.4</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>868.379858</td>\n",
       "      <td>673.950617</td>\n",
       "      <td>...</td>\n",
       "      <td>14.6</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>15.366667</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>26</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-152.301781</td>\n",
       "      <td>993.128302</td>\n",
       "      <td>...</td>\n",
       "      <td>17.8</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>22</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-98.010991</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>16.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>25</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-6.7</td>\n",
       "      <td>-7.7</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3157</th>\n",
       "      <td>35</td>\n",
       "      <td>3.7</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-290.057346</td>\n",
       "      <td>1068.484507</td>\n",
       "      <td>...</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.742857</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  points_ly  change_points_ly  starter_change  C_PF  PG  SG_SF  \\\n",
       "1879   24       16.4              -1.1               0     0   0      1   \n",
       "1626   26       10.0              -1.9               1     1   0      0   \n",
       "1705   22        6.3               0.0               0     1   0      0   \n",
       "1194   25        0.6               0.0               0     1   0      0   \n",
       "3157   35        3.7              -0.5               0     1   0      0   \n",
       "\n",
       "      high_usageplayer_added  usagemin_opened  maxusage_added    ...     \\\n",
       "1879                     0.0       868.379858      673.950617    ...      \n",
       "1626                     0.0      -152.301781      993.128302    ...      \n",
       "1705                     0.0       -98.010991      428.000000    ...      \n",
       "1194                     0.0         0.000000        0.000000    ...      \n",
       "3157                     1.0      -290.057346     1068.484507    ...      \n",
       "\n",
       "      per_ly  change_per  usagerank  usagerank_ly  offensive_winshares  \\\n",
       "1879    14.6        -0.9       18.0          51.0                  2.1   \n",
       "1626    17.8        -2.7       13.0           6.0                  2.7   \n",
       "1705    16.7         0.0        1.0          10.0                  1.7   \n",
       "1194     2.1         0.0        2.0           3.0                 -0.1   \n",
       "3157    10.1         1.1        1.0           1.0                  1.3   \n",
       "\n",
       "      offensive_boxplusminus  boxplusminus  value_overreplacement  \\\n",
       "1879                    -0.1          -0.5                    0.9   \n",
       "1626                    -1.5           0.0                    1.0   \n",
       "1705                     0.0           0.5                    0.5   \n",
       "1194                    -6.7          -7.7                   -0.1   \n",
       "3157                    -0.2          -0.9                    0.3   \n",
       "\n",
       "      career_points  yearspro  \n",
       "1879      15.366667         3  \n",
       "1626       7.333333         3  \n",
       "1705       6.300000         1  \n",
       "1194       0.600000         1  \n",
       "3157       5.742857         7  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1564/1564 [==============================] - 4s 3ms/step - loss: 11878.8637\n",
      "Epoch 2/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 4343.9099\n",
      "Epoch 3/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1921.8235\n",
      "Epoch 4/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 855.8726\n",
      "Epoch 5/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 454.2457\n",
      "Epoch 6/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 296.9264\n",
      "Epoch 7/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 222.7534\n",
      "Epoch 8/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 185.8451\n",
      "Epoch 9/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 158.7572\n",
      "Epoch 10/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 139.0554\n",
      "Epoch 11/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 122.6291\n",
      "Epoch 12/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 110.4425\n",
      "Epoch 13/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 99.8389\n",
      "Epoch 14/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 92.6563\n",
      "Epoch 15/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 86.6604\n",
      "Epoch 16/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 81.8472\n",
      "Epoch 17/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 77.8150\n",
      "Epoch 18/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 74.9545\n",
      "Epoch 19/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 71.6594\n",
      "Epoch 20/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 68.9425\n",
      "Epoch 21/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 66.9222\n",
      "Epoch 22/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 64.8553\n",
      "Epoch 23/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 63.0489\n",
      "Epoch 24/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 60.6908\n",
      "Epoch 25/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 58.4902\n",
      "Epoch 26/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 56.7222\n",
      "Epoch 27/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 54.8835\n",
      "Epoch 28/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 53.2408\n",
      "Epoch 29/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 51.7178\n",
      "Epoch 30/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 50.2482\n",
      "Epoch 31/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 48.9953\n",
      "Epoch 32/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 47.6237\n",
      "Epoch 33/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 46.8052\n",
      "Epoch 34/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 45.5641\n",
      "Epoch 35/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 44.4269\n",
      "Epoch 36/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 43.5009\n",
      "Epoch 37/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 42.4576\n",
      "Epoch 38/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 41.7709\n",
      "Epoch 39/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 40.7875\n",
      "Epoch 40/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 40.2304\n",
      "Epoch 41/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 39.4250\n",
      "Epoch 42/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 38.8373\n",
      "Epoch 43/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 38.1037\n",
      "Epoch 44/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 37.4823\n",
      "Epoch 45/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 37.0542\n",
      "Epoch 46/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 36.3804\n",
      "Epoch 47/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 35.8134\n",
      "Epoch 48/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 35.3125\n",
      "Epoch 49/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 34.8114\n",
      "Epoch 50/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 34.4247\n",
      "Epoch 51/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 34.1619\n",
      "Epoch 52/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 33.7585\n",
      "Epoch 53/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 33.0670\n",
      "Epoch 54/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 32.6726\n",
      "Epoch 55/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 32.3926\n",
      "Epoch 56/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 32.1094\n",
      "Epoch 57/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 31.7368\n",
      "Epoch 58/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 31.5429\n",
      "Epoch 59/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 31.0793\n",
      "Epoch 60/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 30.8593\n",
      "Epoch 61/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 30.6546\n",
      "Epoch 62/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 30.4437\n",
      "Epoch 63/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 30.5780\n",
      "Epoch 64/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 30.2253\n",
      "Epoch 65/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 29.7165\n",
      "Epoch 66/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 29.4312\n",
      "Epoch 67/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 29.1026\n",
      "Epoch 68/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 29.0320\n",
      "Epoch 69/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 28.8611\n",
      "Epoch 70/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 28.5733\n",
      "Epoch 71/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 28.4761\n",
      "Epoch 72/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 28.1385\n",
      "Epoch 73/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 28.0300\n",
      "Epoch 74/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 27.7585\n",
      "Epoch 75/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 27.5716\n",
      "Epoch 76/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 27.3340\n",
      "Epoch 77/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 27.1113\n",
      "Epoch 78/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 27.0187\n",
      "Epoch 79/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 26.9311\n",
      "Epoch 80/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 26.6645\n",
      "Epoch 81/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 26.4257\n",
      "Epoch 82/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 26.0756\n",
      "Epoch 83/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 25.8669\n",
      "Epoch 84/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 25.5733\n",
      "Epoch 85/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 25.4060\n",
      "Epoch 86/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 25.1576\n",
      "Epoch 87/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 24.9862\n",
      "Epoch 88/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 24.7534\n",
      "Epoch 89/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 24.4408\n",
      "Epoch 90/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 24.4055\n",
      "Epoch 91/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 24.0846\n",
      "Epoch 92/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 23.9064\n",
      "Epoch 93/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 23.7031\n",
      "Epoch 94/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 23.4661\n",
      "Epoch 95/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 23.2305\n",
      "Epoch 96/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 23.0653\n",
      "Epoch 97/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 22.7495\n",
      "Epoch 98/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 22.6917\n",
      "Epoch 99/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 22.4478\n",
      "Epoch 100/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 22.3305\n",
      "Epoch 101/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 22.2251\n",
      "Epoch 102/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 22.2414\n",
      "Epoch 103/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 22.2642\n",
      "Epoch 104/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 21.9678\n",
      "Epoch 105/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 21.9730\n",
      "Epoch 106/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 21.5836\n",
      "Epoch 107/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 21.2061\n",
      "Epoch 108/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 21.1700\n",
      "Epoch 109/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 20.9480\n",
      "Epoch 110/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 20.7193\n",
      "Epoch 111/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 20.6905\n",
      "Epoch 112/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 20.5595\n",
      "Epoch 113/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 20.3158\n",
      "Epoch 114/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 20.3959\n",
      "Epoch 115/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 20.7255\n",
      "Epoch 116/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 20.1692\n",
      "Epoch 117/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 20.0561\n",
      "Epoch 118/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 19.7226\n",
      "Epoch 119/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 19.5576\n",
      "Epoch 120/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 19.5563\n",
      "Epoch 121/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 19.2832\n",
      "Epoch 122/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 19.2309\n",
      "Epoch 123/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 19.0208\n",
      "Epoch 124/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 18.9602\n",
      "Epoch 125/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 18.8115\n",
      "Epoch 126/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 18.7827\n",
      "Epoch 127/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 18.6500\n",
      "Epoch 128/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 18.4789\n",
      "Epoch 129/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 18.3386\n",
      "Epoch 130/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 18.3086\n",
      "Epoch 131/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 18.1803\n",
      "Epoch 132/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 18.0732\n",
      "Epoch 133/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 18.3197\n",
      "Epoch 134/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 18.0147\n",
      "Epoch 135/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 17.8161\n",
      "Epoch 136/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 17.7409\n",
      "Epoch 137/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 17.4233\n",
      "Epoch 138/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 17.6140\n",
      "Epoch 139/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 17.5275\n",
      "Epoch 140/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 17.3956\n",
      "Epoch 141/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 17.0990\n",
      "Epoch 142/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 17.1859\n",
      "Epoch 143/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 16.9419\n",
      "Epoch 144/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 16.7954\n",
      "Epoch 145/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 16.6810\n",
      "Epoch 146/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 16.6604\n",
      "Epoch 147/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 16.4757\n",
      "Epoch 148/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 16.4014\n",
      "Epoch 149/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 16.2116\n",
      "Epoch 150/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 16.1047\n",
      "Epoch 151/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 15.9661\n",
      "Epoch 152/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 16.0567\n",
      "Epoch 153/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 15.8124\n",
      "Epoch 154/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 15.7205\n",
      "Epoch 155/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 15.6580\n",
      "Epoch 156/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 15.7743\n",
      "Epoch 157/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 15.6057\n",
      "Epoch 158/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 15.4918\n",
      "Epoch 159/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 15.1910\n",
      "Epoch 160/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 15.2782\n",
      "Epoch 161/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 15.1127\n",
      "Epoch 162/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 14.9919\n",
      "Epoch 163/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 14.8950\n",
      "Epoch 164/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 14.8675\n",
      "Epoch 165/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 14.8491\n",
      "Epoch 166/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 14.7477\n",
      "Epoch 167/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 14.5408\n",
      "Epoch 168/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 14.4126\n",
      "Epoch 169/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 14.3726\n",
      "Epoch 170/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 14.4891\n",
      "Epoch 171/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 14.1528\n",
      "Epoch 172/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 14.0083\n",
      "Epoch 173/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 14.0275\n",
      "Epoch 174/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 14.0021\n",
      "Epoch 175/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 13.8339\n",
      "Epoch 176/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 13.6979\n",
      "Epoch 177/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 13.7654\n",
      "Epoch 178/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 13.6756\n",
      "Epoch 179/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 13.5235\n",
      "Epoch 180/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 13.5282\n",
      "Epoch 181/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 13.4628\n",
      "Epoch 182/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 13.3670\n",
      "Epoch 183/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 13.7669\n",
      "Epoch 184/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 13.4859\n",
      "Epoch 185/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 13.3684\n",
      "Epoch 186/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 13.2933\n",
      "Epoch 187/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 13.0907\n",
      "Epoch 188/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 12.9837\n",
      "Epoch 189/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 12.8726\n",
      "Epoch 190/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 12.9335\n",
      "Epoch 191/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 12.6998\n",
      "Epoch 192/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 12.8046\n",
      "Epoch 193/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 12.4050\n",
      "Epoch 194/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 12.3551\n",
      "Epoch 195/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 12.2695\n",
      "Epoch 196/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 12.3573\n",
      "Epoch 197/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 12.1296\n",
      "Epoch 198/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 12.0537\n",
      "Epoch 199/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 12.1041\n",
      "Epoch 200/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 12.0667\n",
      "Epoch 201/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 11.8880\n",
      "Epoch 202/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 11.9272\n",
      "Epoch 203/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 11.8871\n",
      "Epoch 204/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 11.9234\n",
      "Epoch 205/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 11.8410\n",
      "Epoch 206/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 11.6128\n",
      "Epoch 207/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 11.6500\n",
      "Epoch 208/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 11.5434\n",
      "Epoch 209/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 12.1760\n",
      "Epoch 210/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 11.9368\n",
      "Epoch 211/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 11.4566\n",
      "Epoch 212/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 11.3975\n",
      "Epoch 213/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 11.7355\n",
      "Epoch 214/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 11.4319\n",
      "Epoch 215/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 11.3864\n",
      "Epoch 216/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 11.7433\n",
      "Epoch 217/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 11.6107\n",
      "Epoch 218/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 11.3968\n",
      "Epoch 219/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 11.2328\n",
      "Epoch 220/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 11.4873\n",
      "Epoch 221/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 11.1634\n",
      "Epoch 222/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 11.0816\n",
      "Epoch 223/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 11.1058\n",
      "Epoch 224/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 10.9605\n",
      "Epoch 225/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 10.9610\n",
      "Epoch 226/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 11.0453\n",
      "Epoch 227/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 10.9548\n",
      "Epoch 228/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 10.7620\n",
      "Epoch 229/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 10.7627\n",
      "Epoch 230/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 10.7822\n",
      "Epoch 231/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 10.8823\n",
      "Epoch 232/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 10.7467\n",
      "Epoch 233/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 10.7003\n",
      "Epoch 234/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 10.6425\n",
      "Epoch 235/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 10.6568\n",
      "Epoch 236/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 10.5492\n",
      "Epoch 237/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 10.6224\n",
      "Epoch 238/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 10.5096\n",
      "Epoch 239/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 10.7145\n",
      "Epoch 240/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 10.4770\n",
      "Epoch 241/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 10.4619\n",
      "Epoch 242/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 10.6229\n",
      "Epoch 243/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 10.6142\n",
      "Epoch 244/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 10.6432\n",
      "Epoch 245/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 10.4163\n",
      "Epoch 246/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 10.4642\n",
      "Epoch 247/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 10.4399\n",
      "Epoch 248/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 10.3863\n",
      "Epoch 249/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 10.6419\n",
      "Epoch 250/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 10.8127\n",
      "Epoch 251/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 10.4517\n",
      "Epoch 252/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 10.2913\n",
      "Epoch 253/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 10.3323\n",
      "Epoch 254/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 10.2501\n",
      "Epoch 255/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 10.3306\n",
      "Epoch 256/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 10.0917\n",
      "Epoch 257/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 10.0890\n",
      "Epoch 258/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 10.0427\n",
      "Epoch 259/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 10.2897\n",
      "Epoch 260/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 10.2971\n",
      "Epoch 261/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 10.1104\n",
      "Epoch 262/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 10.1139\n",
      "Epoch 263/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 10.0765\n",
      "Epoch 264/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 10.3084\n",
      "Epoch 265/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 10.2718\n",
      "Epoch 266/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 9.9459\n",
      "Epoch 267/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 9.9941\n",
      "Epoch 268/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 9.9842\n",
      "Epoch 269/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 10.2124\n",
      "Epoch 270/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 10.0276\n",
      "Epoch 271/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 10.1652\n",
      "Epoch 272/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 9.9973\n",
      "Epoch 273/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 10.0055\n",
      "Epoch 274/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 10.0007\n",
      "Epoch 275/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 9.7853\n",
      "Epoch 276/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 9.7821\n",
      "Epoch 277/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 9.8414\n",
      "Epoch 278/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 9.9579\n",
      "Epoch 279/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 9.6240\n",
      "Epoch 280/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 9.5367\n",
      "Epoch 281/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 9.7201\n",
      "Epoch 282/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 9.5451\n",
      "Epoch 283/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 9.9246\n",
      "Epoch 284/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 9.6014\n",
      "Epoch 285/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 9.5476\n",
      "Epoch 286/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 9.6253\n",
      "Epoch 287/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 9.3918\n",
      "Epoch 288/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 9.5421\n",
      "Epoch 289/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 9.7656\n",
      "Epoch 290/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 9.6810\n",
      "Epoch 291/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 9.3351\n",
      "Epoch 292/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 9.4692\n",
      "Epoch 293/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 9.2303\n",
      "Epoch 294/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 9.2724\n",
      "Epoch 295/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 9.3052\n",
      "Epoch 296/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 9.2686\n",
      "Epoch 297/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 9.2485\n",
      "Epoch 298/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 9.3209\n",
      "Epoch 299/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 9.1832\n",
      "Epoch 300/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 9.1606\n",
      "Epoch 301/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 9.2026\n",
      "Epoch 302/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 9.4027\n",
      "Epoch 303/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 9.7179\n",
      "Epoch 304/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 9.8043\n",
      "Epoch 305/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 9.6116\n",
      "Epoch 306/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 10.0564\n",
      "Epoch 307/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 9.2839\n",
      "Epoch 308/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 9.2095\n",
      "Epoch 309/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 9.8578\n",
      "Epoch 310/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 9.3519\n",
      "Epoch 311/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 9.3059\n",
      "Epoch 312/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 9.1973\n",
      "Epoch 313/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 9.0869\n",
      "Epoch 314/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 9.0031\n",
      "Epoch 315/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 9.0743\n",
      "Epoch 316/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 9.2479\n",
      "Epoch 317/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 9.2374\n",
      "Epoch 318/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 9.6095\n",
      "Epoch 319/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 9.0048\n",
      "Epoch 320/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 9.1073\n",
      "Epoch 321/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 9.1001\n",
      "Epoch 322/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 9.0712\n",
      "Epoch 323/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 8.7910\n",
      "Epoch 324/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 8.8574\n",
      "Epoch 325/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 9.0407\n",
      "Epoch 326/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 8.8438\n",
      "Epoch 327/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.8604\n",
      "Epoch 328/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.9016\n",
      "Epoch 329/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 8.9671\n",
      "Epoch 330/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 9.3637\n",
      "Epoch 331/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 8.8948\n",
      "Epoch 332/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 8.8713\n",
      "Epoch 333/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 8.8781\n",
      "Epoch 334/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 8.8275\n",
      "Epoch 335/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 8.7592\n",
      "Epoch 336/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 8.6403\n",
      "Epoch 337/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 8.7379\n",
      "Epoch 338/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 8.9018\n",
      "Epoch 339/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.6229\n",
      "Epoch 340/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 8.7267\n",
      "Epoch 341/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 8.6518\n",
      "Epoch 342/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 8.7349\n",
      "Epoch 343/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 8.6210\n",
      "Epoch 344/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 8.7876\n",
      "Epoch 345/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 9.2301\n",
      "Epoch 346/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 8.4897\n",
      "Epoch 347/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 8.6337\n",
      "Epoch 348/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 8.5742\n",
      "Epoch 349/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 8.5423\n",
      "Epoch 350/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 8.4815\n",
      "Epoch 351/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 9.1230\n",
      "Epoch 352/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 8.5827\n",
      "Epoch 353/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 8.6498\n",
      "Epoch 354/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 8.5629\n",
      "Epoch 355/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.6484\n",
      "Epoch 356/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 8.5291\n",
      "Epoch 357/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 8.4001\n",
      "Epoch 358/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 8.3758\n",
      "Epoch 359/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 8.5962\n",
      "Epoch 360/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.5224\n",
      "Epoch 361/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 8.4874\n",
      "Epoch 362/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 8.3698\n",
      "Epoch 363/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 8.3260\n",
      "Epoch 364/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 8.3625\n",
      "Epoch 365/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 8.5160\n",
      "Epoch 366/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 8.5619\n",
      "Epoch 367/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 8.3404\n",
      "Epoch 368/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 8.3765\n",
      "Epoch 369/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.3582\n",
      "Epoch 370/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.7203\n",
      "Epoch 371/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.4424\n",
      "Epoch 372/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.4682\n",
      "Epoch 373/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 8.4747\n",
      "Epoch 374/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.5079\n",
      "Epoch 375/1000\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 8.4030\n",
      "Epoch 376/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 8.3774\n",
      "Epoch 377/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.5001\n",
      "Epoch 378/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 8.4760\n",
      "Epoch 379/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.3465\n",
      "Epoch 380/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 8.2605\n",
      "Epoch 381/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 8.3749\n",
      "Epoch 382/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 8.4036\n",
      "Epoch 383/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 8.2077\n",
      "Epoch 384/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 8.2127\n",
      "Epoch 385/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 8.2681\n",
      "Epoch 386/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 8.3895\n",
      "Epoch 387/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 8.2818\n",
      "Epoch 388/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 8.1926\n",
      "Epoch 389/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 8.2591\n",
      "Epoch 390/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.1567\n",
      "Epoch 391/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.2491\n",
      "Epoch 392/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 8.4586\n",
      "Epoch 393/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 8.2509\n",
      "Epoch 394/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 8.3188\n",
      "Epoch 395/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 8.5342\n",
      "Epoch 396/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 8.5558\n",
      "Epoch 397/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.2545\n",
      "Epoch 398/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 8.1030\n",
      "Epoch 399/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 8.8809\n",
      "Epoch 400/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 8.6183\n",
      "Epoch 401/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 8.2602\n",
      "Epoch 402/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 8.1941\n",
      "Epoch 403/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 8.8316\n",
      "Epoch 404/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.5319\n",
      "Epoch 405/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.2169\n",
      "Epoch 406/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 8.3790\n",
      "Epoch 407/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 8.4173\n",
      "Epoch 408/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 9.0970\n",
      "Epoch 409/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 8.3643\n",
      "Epoch 410/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.9631\n",
      "Epoch 411/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 8.3676\n",
      "Epoch 412/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 8.3657\n",
      "Epoch 413/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 8.2189\n",
      "Epoch 414/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.4843\n",
      "Epoch 415/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 8.1464\n",
      "Epoch 416/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 8.2880\n",
      "Epoch 417/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.9215\n",
      "Epoch 418/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 8.1219\n",
      "Epoch 419/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 8.6262\n",
      "Epoch 420/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 8.1069\n",
      "Epoch 421/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 8.9793\n",
      "Epoch 422/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 8.2031\n",
      "Epoch 423/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.8814\n",
      "Epoch 424/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 8.0541\n",
      "Epoch 425/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.9862\n",
      "Epoch 426/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.8084\n",
      "Epoch 427/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.9248\n",
      "Epoch 428/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.8905\n",
      "Epoch 429/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.8767\n",
      "Epoch 430/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.8385\n",
      "Epoch 431/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 8.0040\n",
      "Epoch 432/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 8.1297\n",
      "Epoch 433/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 8.3315\n",
      "Epoch 434/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.0372\n",
      "Epoch 435/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.9250\n",
      "Epoch 436/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.8119\n",
      "Epoch 437/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.7046\n",
      "Epoch 438/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.8530\n",
      "Epoch 439/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 8.0953\n",
      "Epoch 440/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.0645\n",
      "Epoch 441/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.8567\n",
      "Epoch 442/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.7557\n",
      "Epoch 443/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.9642\n",
      "Epoch 444/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.8708\n",
      "Epoch 445/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.2829\n",
      "Epoch 446/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 8.1721\n",
      "Epoch 447/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.6701\n",
      "Epoch 448/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 8.0370\n",
      "Epoch 449/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.6486\n",
      "Epoch 450/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.8655\n",
      "Epoch 451/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.7548\n",
      "Epoch 452/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.7350\n",
      "Epoch 453/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.6661\n",
      "Epoch 454/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.9186\n",
      "Epoch 455/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 8.1885\n",
      "Epoch 456/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.5898\n",
      "Epoch 457/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.6209\n",
      "Epoch 458/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 8.0628\n",
      "Epoch 459/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 7.5265\n",
      "Epoch 460/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.9188\n",
      "Epoch 461/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.9973\n",
      "Epoch 462/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 7.8418\n",
      "Epoch 463/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.8465\n",
      "Epoch 464/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.5378\n",
      "Epoch 465/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 7.6600\n",
      "Epoch 466/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.7960\n",
      "Epoch 467/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.8675\n",
      "Epoch 468/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 7.6771\n",
      "Epoch 469/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.9336\n",
      "Epoch 470/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.6409\n",
      "Epoch 471/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.5059\n",
      "Epoch 472/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.5254\n",
      "Epoch 473/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.7355\n",
      "Epoch 474/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.8961\n",
      "Epoch 475/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.6348\n",
      "Epoch 476/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.8332\n",
      "Epoch 477/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.8775\n",
      "Epoch 478/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.8251\n",
      "Epoch 479/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.6106\n",
      "Epoch 480/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.6922\n",
      "Epoch 481/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.8237\n",
      "Epoch 482/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.6123\n",
      "Epoch 483/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.5664\n",
      "Epoch 484/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.6337\n",
      "Epoch 485/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.6304\n",
      "Epoch 486/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.4453\n",
      "Epoch 487/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.8837\n",
      "Epoch 488/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.6031\n",
      "Epoch 489/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.4904\n",
      "Epoch 490/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.5853\n",
      "Epoch 491/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.7684\n",
      "Epoch 492/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.7858\n",
      "Epoch 493/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.5838\n",
      "Epoch 494/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.5598\n",
      "Epoch 495/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.5340\n",
      "Epoch 496/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.4348\n",
      "Epoch 497/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.4732\n",
      "Epoch 498/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.5223\n",
      "Epoch 499/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.3782\n",
      "Epoch 500/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.6360\n",
      "Epoch 501/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 8.0758\n",
      "Epoch 502/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.7319\n",
      "Epoch 503/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.4805\n",
      "Epoch 504/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.4216\n",
      "Epoch 505/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.5146\n",
      "Epoch 506/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.4990\n",
      "Epoch 507/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.4040\n",
      "Epoch 508/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.5814\n",
      "Epoch 509/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.3461\n",
      "Epoch 510/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.1981\n",
      "Epoch 511/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.3524\n",
      "Epoch 512/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.3220\n",
      "Epoch 513/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.5962\n",
      "Epoch 514/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.6507\n",
      "Epoch 515/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.6677\n",
      "Epoch 516/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.7129\n",
      "Epoch 517/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 8.1643\n",
      "Epoch 518/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.6321\n",
      "Epoch 519/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.5128\n",
      "Epoch 520/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.3975\n",
      "Epoch 521/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.5093\n",
      "Epoch 522/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.3623\n",
      "Epoch 523/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.4891\n",
      "Epoch 524/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.8995\n",
      "Epoch 525/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.4013\n",
      "Epoch 526/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.6672\n",
      "Epoch 527/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.5840\n",
      "Epoch 528/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.2398\n",
      "Epoch 529/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.4622\n",
      "Epoch 530/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.2746\n",
      "Epoch 531/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.3715\n",
      "Epoch 532/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 8.0451\n",
      "Epoch 533/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.9532\n",
      "Epoch 534/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.7038\n",
      "Epoch 535/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.9102\n",
      "Epoch 536/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.0151\n",
      "Epoch 537/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.5427\n",
      "Epoch 538/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.2229\n",
      "Epoch 539/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.2649\n",
      "Epoch 540/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.2322\n",
      "Epoch 541/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.5729\n",
      "Epoch 542/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.3687\n",
      "Epoch 543/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.2054\n",
      "Epoch 544/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.4632\n",
      "Epoch 545/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 8.1508\n",
      "Epoch 546/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.5308\n",
      "Epoch 547/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.4321\n",
      "Epoch 548/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.3129\n",
      "Epoch 549/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.3433\n",
      "Epoch 550/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.3122\n",
      "Epoch 551/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.2877\n",
      "Epoch 552/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.1622\n",
      "Epoch 553/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.3958\n",
      "Epoch 554/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.4159\n",
      "Epoch 555/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 7.3424\n",
      "Epoch 556/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.2542\n",
      "Epoch 557/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.2950\n",
      "Epoch 558/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.3038\n",
      "Epoch 559/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.2602\n",
      "Epoch 560/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.1626\n",
      "Epoch 561/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.1585\n",
      "Epoch 562/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.1269\n",
      "Epoch 563/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.1451\n",
      "Epoch 564/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.0270\n",
      "Epoch 565/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.1607\n",
      "Epoch 566/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 7.0963\n",
      "Epoch 567/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.2184\n",
      "Epoch 568/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.4877\n",
      "Epoch 569/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 7.1361\n",
      "Epoch 570/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.2669\n",
      "Epoch 571/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.4494\n",
      "Epoch 572/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.3434\n",
      "Epoch 573/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.1137\n",
      "Epoch 574/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.6710\n",
      "Epoch 575/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.5801\n",
      "Epoch 576/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.6140\n",
      "Epoch 577/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.3920\n",
      "Epoch 578/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.3716\n",
      "Epoch 579/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.1978\n",
      "Epoch 580/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.0599\n",
      "Epoch 581/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.0672\n",
      "Epoch 582/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.0913\n",
      "Epoch 583/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.9778\n",
      "Epoch 584/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.0618\n",
      "Epoch 585/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.4043\n",
      "Epoch 586/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 8.0091\n",
      "Epoch 587/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.4224\n",
      "Epoch 588/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.0354\n",
      "Epoch 589/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.0599\n",
      "Epoch 590/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.2221\n",
      "Epoch 591/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.0579\n",
      "Epoch 592/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.9751\n",
      "Epoch 593/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.0407\n",
      "Epoch 594/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.2814\n",
      "Epoch 595/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.1122\n",
      "Epoch 596/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 8.0447\n",
      "Epoch 597/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.8006\n",
      "Epoch 598/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.3888\n",
      "Epoch 599/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.4314\n",
      "Epoch 600/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.7784\n",
      "Epoch 601/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.2482\n",
      "Epoch 602/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 7.0723\n",
      "Epoch 603/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.0404\n",
      "Epoch 604/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.7351\n",
      "Epoch 605/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.2663\n",
      "Epoch 606/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 7.0490\n",
      "Epoch 607/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.5756\n",
      "Epoch 608/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.0058\n",
      "Epoch 609/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.1380\n",
      "Epoch 610/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.5235\n",
      "Epoch 611/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.5229\n",
      "Epoch 612/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.1716\n",
      "Epoch 613/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.1590\n",
      "Epoch 614/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.2581\n",
      "Epoch 615/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 8.0536\n",
      "Epoch 616/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.8391\n",
      "Epoch 617/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.4521\n",
      "Epoch 618/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.1888\n",
      "Epoch 619/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.1072\n",
      "Epoch 620/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.0290\n",
      "Epoch 621/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.0710\n",
      "Epoch 622/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.2240\n",
      "Epoch 623/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.1546\n",
      "Epoch 624/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.3024\n",
      "Epoch 625/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.3749\n",
      "Epoch 626/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.9531\n",
      "Epoch 627/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.9818\n",
      "Epoch 628/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.0570\n",
      "Epoch 629/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.1549\n",
      "Epoch 630/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.0132\n",
      "Epoch 631/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.0521\n",
      "Epoch 632/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.4091\n",
      "Epoch 633/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.4816\n",
      "Epoch 634/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.0853\n",
      "Epoch 635/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.9550\n",
      "Epoch 636/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.3361\n",
      "Epoch 637/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.3858\n",
      "Epoch 638/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.9065\n",
      "Epoch 639/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.2913\n",
      "Epoch 640/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.9386\n",
      "Epoch 641/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.9158\n",
      "Epoch 642/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.1171\n",
      "Epoch 643/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 7.0255\n",
      "Epoch 644/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.7715\n",
      "Epoch 645/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.3164\n",
      "Epoch 646/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.0977\n",
      "Epoch 647/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.1951\n",
      "Epoch 648/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.9938\n",
      "Epoch 649/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.2494\n",
      "Epoch 650/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.0585\n",
      "Epoch 651/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.8783\n",
      "Epoch 652/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.0383\n",
      "Epoch 653/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.9863\n",
      "Epoch 654/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.2118\n",
      "Epoch 655/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.9984\n",
      "Epoch 656/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.5311\n",
      "Epoch 657/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.2231\n",
      "Epoch 658/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.8195\n",
      "Epoch 659/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.8774\n",
      "Epoch 660/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.9031\n",
      "Epoch 661/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.8922\n",
      "Epoch 662/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.8362\n",
      "Epoch 663/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.0253\n",
      "Epoch 664/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.3564\n",
      "Epoch 665/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.8653\n",
      "Epoch 666/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.0885\n",
      "Epoch 667/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.1956\n",
      "Epoch 668/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.6008\n",
      "Epoch 669/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.2242\n",
      "Epoch 670/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.0746\n",
      "Epoch 671/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.7640\n",
      "Epoch 672/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.8988\n",
      "Epoch 673/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.9653\n",
      "Epoch 674/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.0292\n",
      "Epoch 675/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.0586\n",
      "Epoch 676/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.1704\n",
      "Epoch 677/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.9373\n",
      "Epoch 678/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.0169\n",
      "Epoch 679/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.8869\n",
      "Epoch 680/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.2610\n",
      "Epoch 681/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.0039\n",
      "Epoch 682/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.7921\n",
      "Epoch 683/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.1215\n",
      "Epoch 684/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.8354\n",
      "Epoch 685/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.7841\n",
      "Epoch 686/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.1502\n",
      "Epoch 687/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.8432\n",
      "Epoch 688/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.7717\n",
      "Epoch 689/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.9702\n",
      "Epoch 690/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.7662\n",
      "Epoch 691/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.7658\n",
      "Epoch 692/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.1098\n",
      "Epoch 693/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.8904\n",
      "Epoch 694/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.8419\n",
      "Epoch 695/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.2095\n",
      "Epoch 696/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.9434\n",
      "Epoch 697/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.1343\n",
      "Epoch 698/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.3346\n",
      "Epoch 699/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.2350\n",
      "Epoch 700/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.7161\n",
      "Epoch 701/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.9654\n",
      "Epoch 702/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.1110\n",
      "Epoch 703/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.0473\n",
      "Epoch 704/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.0622\n",
      "Epoch 705/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.3595\n",
      "Epoch 706/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.8927\n",
      "Epoch 707/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.7511\n",
      "Epoch 708/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.7276\n",
      "Epoch 709/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.5043\n",
      "Epoch 710/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.9121\n",
      "Epoch 711/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.1147\n",
      "Epoch 712/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.0783\n",
      "Epoch 713/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.8446\n",
      "Epoch 714/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.7941\n",
      "Epoch 715/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.8405\n",
      "Epoch 716/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.6417\n",
      "Epoch 717/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.9254\n",
      "Epoch 718/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.7418\n",
      "Epoch 719/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.1289\n",
      "Epoch 720/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.7623\n",
      "Epoch 721/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.8548\n",
      "Epoch 722/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.9111\n",
      "Epoch 723/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.7681\n",
      "Epoch 724/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.7064\n",
      "Epoch 725/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 8.5627\n",
      "Epoch 726/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 7.2933\n",
      "Epoch 727/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 7.1776\n",
      "Epoch 728/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.1047\n",
      "Epoch 729/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.9237\n",
      "Epoch 730/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.7266\n",
      "Epoch 731/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.8396\n",
      "Epoch 732/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 7.0488\n",
      "Epoch 733/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.6296\n",
      "Epoch 734/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 6.7713\n",
      "Epoch 735/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.8169\n",
      "Epoch 736/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.9274\n",
      "Epoch 737/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.8441\n",
      "Epoch 738/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.7873\n",
      "Epoch 739/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.7559\n",
      "Epoch 740/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.8591\n",
      "Epoch 741/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.0470\n",
      "Epoch 742/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.8456\n",
      "Epoch 743/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.8671\n",
      "Epoch 744/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.8440\n",
      "Epoch 745/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 6.7130\n",
      "Epoch 746/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.7936\n",
      "Epoch 747/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.1951\n",
      "Epoch 748/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.8577\n",
      "Epoch 749/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.7786\n",
      "Epoch 750/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.7937\n",
      "Epoch 751/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.0217\n",
      "Epoch 752/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.8259\n",
      "Epoch 753/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.2870\n",
      "Epoch 754/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.7790\n",
      "Epoch 755/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.8966\n",
      "Epoch 756/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.6758\n",
      "Epoch 757/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.7383\n",
      "Epoch 758/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.7663\n",
      "Epoch 759/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.0729\n",
      "Epoch 760/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.8650\n",
      "Epoch 761/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.7709\n",
      "Epoch 762/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.0060\n",
      "Epoch 763/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.9915\n",
      "Epoch 764/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.3133\n",
      "Epoch 765/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.1976\n",
      "Epoch 766/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.8939\n",
      "Epoch 767/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.7624\n",
      "Epoch 768/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.8126\n",
      "Epoch 769/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.8457\n",
      "Epoch 770/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.2378\n",
      "Epoch 771/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.9573\n",
      "Epoch 772/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.6037\n",
      "Epoch 773/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.7809\n",
      "Epoch 774/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.7865\n",
      "Epoch 775/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.7807\n",
      "Epoch 776/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 7.1433\n",
      "Epoch 777/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.8579\n",
      "Epoch 778/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.7549\n",
      "Epoch 779/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.0023\n",
      "Epoch 780/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.9996\n",
      "Epoch 781/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.7671\n",
      "Epoch 782/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.2734\n",
      "Epoch 783/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.6034\n",
      "Epoch 784/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.0142\n",
      "Epoch 785/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.9142\n",
      "Epoch 786/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.7555\n",
      "Epoch 787/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.8350\n",
      "Epoch 788/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.2423\n",
      "Epoch 789/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.9636\n",
      "Epoch 790/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.7067\n",
      "Epoch 791/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.8337\n",
      "Epoch 792/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.8834\n",
      "Epoch 793/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.5834\n",
      "Epoch 794/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.7092\n",
      "Epoch 795/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.7254\n",
      "Epoch 796/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.6741\n",
      "Epoch 797/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.8937\n",
      "Epoch 798/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.2518\n",
      "Epoch 799/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.3640\n",
      "Epoch 800/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 6.5838\n",
      "Epoch 801/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.4919\n",
      "Epoch 802/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.5383\n",
      "Epoch 803/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.6760\n",
      "Epoch 804/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.8574\n",
      "Epoch 805/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.9396\n",
      "Epoch 806/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.8902\n",
      "Epoch 807/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.7618\n",
      "Epoch 808/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.6327\n",
      "Epoch 809/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.6117\n",
      "Epoch 810/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.5770\n",
      "Epoch 811/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.7094\n",
      "Epoch 812/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.8447\n",
      "Epoch 813/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.5712\n",
      "Epoch 814/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.7192\n",
      "Epoch 815/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.8436\n",
      "Epoch 816/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.4999\n",
      "Epoch 817/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.0955\n",
      "Epoch 818/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.6696\n",
      "Epoch 819/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.6635\n",
      "Epoch 820/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.9028\n",
      "Epoch 821/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.1963\n",
      "Epoch 822/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.5537\n",
      "Epoch 823/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.7242\n",
      "Epoch 824/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.5783\n",
      "Epoch 825/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.7740\n",
      "Epoch 826/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.7947\n",
      "Epoch 827/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.6086\n",
      "Epoch 828/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.6255\n",
      "Epoch 829/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.6466\n",
      "Epoch 830/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.6171\n",
      "Epoch 831/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.5180\n",
      "Epoch 832/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.5496\n",
      "Epoch 833/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.5128\n",
      "Epoch 834/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.5782\n",
      "Epoch 835/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.4763\n",
      "Epoch 836/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.6764\n",
      "Epoch 837/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.8573\n",
      "Epoch 838/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.7067\n",
      "Epoch 839/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.6950\n",
      "Epoch 840/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.3533\n",
      "Epoch 841/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.7045\n",
      "Epoch 842/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.9443\n",
      "Epoch 843/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.9590\n",
      "Epoch 844/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 7.1298\n",
      "Epoch 845/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.7991\n",
      "Epoch 846/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.5958\n",
      "Epoch 847/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.5941\n",
      "Epoch 848/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.5165\n",
      "Epoch 849/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.0423\n",
      "Epoch 850/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.8364\n",
      "Epoch 851/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.5314\n",
      "Epoch 852/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.5518\n",
      "Epoch 853/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.5073\n",
      "Epoch 854/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.8936\n",
      "Epoch 855/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.6200\n",
      "Epoch 856/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.6512\n",
      "Epoch 857/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.8307\n",
      "Epoch 858/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.6367\n",
      "Epoch 859/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.6572\n",
      "Epoch 860/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.4770\n",
      "Epoch 861/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.9955\n",
      "Epoch 862/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.6640\n",
      "Epoch 863/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.9518\n",
      "Epoch 864/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.7471\n",
      "Epoch 865/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.5997\n",
      "Epoch 866/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.8189\n",
      "Epoch 867/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.5790\n",
      "Epoch 868/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.9972\n",
      "Epoch 869/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.3916\n",
      "Epoch 870/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.6439\n",
      "Epoch 871/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.4652\n",
      "Epoch 872/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.5703\n",
      "Epoch 873/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.4651\n",
      "Epoch 874/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.6749\n",
      "Epoch 875/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.4925\n",
      "Epoch 876/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.5681\n",
      "Epoch 877/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.7019\n",
      "Epoch 878/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.7746\n",
      "Epoch 879/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.9227\n",
      "Epoch 880/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.5368\n",
      "Epoch 881/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.2265\n",
      "Epoch 882/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.0383\n",
      "Epoch 883/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.9586\n",
      "Epoch 884/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.1347\n",
      "Epoch 885/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.8386\n",
      "Epoch 886/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.5790\n",
      "Epoch 887/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 6.6218\n",
      "Epoch 888/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.5120\n",
      "Epoch 889/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.6832\n",
      "Epoch 890/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.8518\n",
      "Epoch 891/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.5513\n",
      "Epoch 892/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.6015\n",
      "Epoch 893/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.9358\n",
      "Epoch 894/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.4403\n",
      "Epoch 895/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 6.6916\n",
      "Epoch 896/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.9598\n",
      "Epoch 897/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.8931\n",
      "Epoch 898/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.8027\n",
      "Epoch 899/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.7624\n",
      "Epoch 900/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.2542\n",
      "Epoch 901/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.9435\n",
      "Epoch 902/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.6968\n",
      "Epoch 903/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.5107\n",
      "Epoch 904/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.0648\n",
      "Epoch 905/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.0965\n",
      "Epoch 906/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.7254\n",
      "Epoch 907/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.0976\n",
      "Epoch 908/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.8673\n",
      "Epoch 909/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.8893\n",
      "Epoch 910/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.5576\n",
      "Epoch 911/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.7095\n",
      "Epoch 912/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.9376\n",
      "Epoch 913/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.7095\n",
      "Epoch 914/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.7015\n",
      "Epoch 915/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.8875\n",
      "Epoch 916/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.3306\n",
      "Epoch 917/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.3401\n",
      "Epoch 918/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.6742\n",
      "Epoch 919/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.0792\n",
      "Epoch 920/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.6392\n",
      "Epoch 921/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.6204\n",
      "Epoch 922/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.9256\n",
      "Epoch 923/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.9735\n",
      "Epoch 924/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 7.0008\n",
      "Epoch 925/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.4876\n",
      "Epoch 926/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.3367\n",
      "Epoch 927/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.4450\n",
      "Epoch 928/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.3845\n",
      "Epoch 929/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.7294\n",
      "Epoch 930/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.7621\n",
      "Epoch 931/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.5535\n",
      "Epoch 932/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.4105\n",
      "Epoch 933/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.4846\n",
      "Epoch 934/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.2847\n",
      "Epoch 935/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.0207\n",
      "Epoch 936/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.8031\n",
      "Epoch 937/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.6648\n",
      "Epoch 938/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.6084\n",
      "Epoch 939/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.3894\n",
      "Epoch 940/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.5627\n",
      "Epoch 941/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.4919\n",
      "Epoch 942/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.3775\n",
      "Epoch 943/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.4116\n",
      "Epoch 944/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.4568\n",
      "Epoch 945/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.9463\n",
      "Epoch 946/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.7519\n",
      "Epoch 947/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.9082\n",
      "Epoch 948/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.3975\n",
      "Epoch 949/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.3965\n",
      "Epoch 950/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.3892\n",
      "Epoch 951/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.5122\n",
      "Epoch 952/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.7417\n",
      "Epoch 953/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.0300\n",
      "Epoch 954/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.6909\n",
      "Epoch 955/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.3783\n",
      "Epoch 956/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.3296\n",
      "Epoch 957/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.6095\n",
      "Epoch 958/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.5268\n",
      "Epoch 959/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.7445\n",
      "Epoch 960/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.5673\n",
      "Epoch 961/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.7383\n",
      "Epoch 962/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.5160\n",
      "Epoch 963/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.7156\n",
      "Epoch 964/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.4607\n",
      "Epoch 965/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.3084\n",
      "Epoch 966/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.5394\n",
      "Epoch 967/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.6434\n",
      "Epoch 968/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.6093\n",
      "Epoch 969/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.6819\n",
      "Epoch 970/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.3692\n",
      "Epoch 971/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.6143\n",
      "Epoch 972/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.4881\n",
      "Epoch 973/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.5136\n",
      "Epoch 974/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.3583\n",
      "Epoch 975/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.7203\n",
      "Epoch 976/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.3862\n",
      "Epoch 977/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.4922\n",
      "Epoch 978/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 6.5861\n",
      "Epoch 979/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.3325\n",
      "Epoch 980/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.5719\n",
      "Epoch 981/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.5337\n",
      "Epoch 982/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.4741\n",
      "Epoch 983/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.4799\n",
      "Epoch 984/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.5871\n",
      "Epoch 985/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.2025\n",
      "Epoch 986/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.9810\n",
      "Epoch 987/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.6268\n",
      "Epoch 988/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.6074\n",
      "Epoch 989/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.6892\n",
      "Epoch 990/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.4314\n",
      "Epoch 991/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.4636\n",
      "Epoch 992/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.7030\n",
      "Epoch 993/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.6852\n",
      "Epoch 994/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.5179\n",
      "Epoch 995/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.4519\n",
      "Epoch 996/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.2129\n",
      "Epoch 997/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.4555\n",
      "Epoch 998/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.5833\n",
      "Epoch 999/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.6951\n",
      "Epoch 1000/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.3890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a4c0929b0>"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=16,input_dim= X_train.shape[1],activation='relu'))\n",
    "#model.add(Dense(units=8, activation='relu'))\n",
    "#model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(units=8, activation='relu'))\n",
    "#model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(units=4, activation='relu'))\n",
    "#model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(units=1,activation='linear'))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(np.array(X_train), np.array(y_train), epochs=1000,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.5)\n",
    "gbr.fit(X_train,y_train)\n",
    "gbr_predictions = gbr.predict(X_test)\n",
    "LR = LinearRegression(fit_intercept=True).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = pd.DataFrame(predictions)\n",
    "testing.columns=['NN_predictions']\n",
    "testing['actual'] = y_test.reset_index()['points']\n",
    "testing['GBR_predictions']=gbr_predictions\n",
    "testing['LY_scoring']=X_test['points_ly'].reset_index()['points_ly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2017points = points[points['season']==2017].drop(['season','team','player','points','Games'],axis=1)\n",
    "points_2017 = model.predict(pred_2017points)\n",
    "test_2 =pd.DataFrame(points_2017)\n",
    "gbr_pts_2017 = pd.DataFrame(gbr.predict(pred_2017points))\n",
    "LR_pts_2017 = pd.DataFrame(LR.predict(pred_2017points))\n",
    "test_3 = pd.merge(points,pred_2017points,left_index=True,right_index=True).reset_index()\n",
    "test_3['predictions']=test_2[0]\n",
    "test_3['gbr_pred'] = gbr_pts_2017[0]\n",
    "test_3['LR_pred'] = LR_pts_2017[0]\n",
    "test_3['mean_pred'] = (test_3['predictions']+test_3['gbr_pred']+test_3['LR_pred'])/3\n",
    "test_3 = test_3[test_3['Games']>30]\n",
    "test_3[['player','points','points_ly_x','predictions','gbr_pred','LR_pred','mean_pred']].sort_values(by='points_ly_x',ascending=False)\n",
    "\n",
    "points_pred = test_3[['player','LR_pred']]\n",
    "points_pred.columns = ['player','point_prediction1']\n",
    "\n",
    "df_2017 = pd.merge(df_2017,points_pred,how = 'left',left_on = 'player',right_on='player')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09999954, 0.18079444, 0.05630521, 0.068424  , 0.00065053,\n",
       "       0.02123672, 0.02468731, 0.00082807, 0.02697013, 0.02809122,\n",
       "       0.02346993, 0.03004118, 0.04160092, 0.0432922 , 0.0426422 ,\n",
       "       0.02623327, 0.04604534, 0.03923624, 0.02557597, 0.03005844,\n",
       "       0.05530913, 0.0830102 , 0.00549783])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''next is rebounds'''\n",
    "\n",
    "\n",
    "query= '''\n",
    "        \n",
    "        DROP TABLE IF EXISTS rebounds_pred;\n",
    "        CREATE TABLE rebounds_pred(\n",
    "        season int, --these come from player_stats\n",
    "        player varchar(50),\n",
    "        Age int,\n",
    "        team varchar(50),\n",
    "        rebounds float, -- these come from player_stats\n",
    "        rebounds_ly float,\n",
    "        change_rebounds_ly float,\n",
    "        Games int,\n",
    "        C_PF int,\n",
    "        PG int,\n",
    "        SG_SF int,\n",
    "        starter_change int, \n",
    "        \n",
    "        -- these come from team_changes\n",
    "        high_usageplayer_added int,\n",
    "        usagemin_opened float,\n",
    "        maxusage_added float,\n",
    "        high_usageplayer_dropped int,\n",
    "        rebounds_opened float,\n",
    "        max_reboundsdropped float,\n",
    "        max_reboundsadded float,\n",
    "        \n",
    "        -- from player_advstats\n",
    "        per_ly float,\n",
    "        change_per float,\n",
    "        usagerank float,\n",
    "        usagerank_ly float,\n",
    "        reb_perc_ly float,\n",
    "        change_reb_perc float,\n",
    "        defensive_winshares float,\n",
    "        defensive_boxplusminus float,\n",
    "        boxplusminus float,\n",
    "        value_overreplacement float,\n",
    "        \n",
    "        career_rebounds float,\n",
    "        yearspro int\n",
    "        );\n",
    "        \n",
    "        INSERT INTO rebounds_pred(season,player,age,team,rebounds,rebounds_ly,change_rebounds_ly,Games,starter_change,C_PF,PG,SG_SF)\n",
    "        SELECT season,player,age,startingteam,rebounds,rebounds_ly,change_reb_ly,Games,starter-starter_ly,\n",
    "        case when pos in ('C','PF') then 1 else 0 end,case when pos='PG' then 1 else 0 end,case when pos in('SG','SF') then 1 else 0 end from player_stats;\n",
    "        \n",
    "        update rebounds_pred rp\n",
    "        set high_usageplayer_added = tc.high_usageplayer_added,usagemin_opened=tc.usagemin_opened,\n",
    "        maxusage_added=tc.max_usageadded,high_usageplayer_dropped=tc.high_usageplayer_dropped,rebounds_opened=tc.rebounds_opened,\n",
    "        max_reboundsdropped=tc.max_reboundsdropped,max_reboundsadded=tc.max_reboundsadded\n",
    "        from team_changes tc\n",
    "        where tc.team = rp.team and rp.season=tc.season;\n",
    "        \n",
    "        update rebounds_pred rp\n",
    "        set per_ly=pa.per_ly,change_per=pa.change_per,usagerank=pa.usagerank,usagerank_ly=pa.usagerank_ly\n",
    "        ,reb_perc_ly = pa.reb_perc_ly,change_reb_perc = pa.change_reb_perc,defensive_winshares=pa.defensive_winshares,\n",
    "        defensive_boxplusminus=pa.defensive_boxplusminus,boxplusminus=pa.boxplusminus,value_overreplacement=pa.value_overreplacement\n",
    "        from player_advstats pa\n",
    "        where rp.player = pa.player and rp.season = pa.season and rp.team = pa.startingteam;\n",
    "        \n",
    "        update rebounds_pred rp\n",
    "        set career_rebounds = pc.career_rebounds, yearspro = pc.yearspro\n",
    "        from player_careerstats pc\n",
    "        where rp.player = pc.player and rp.season = pc.season;\n",
    "        \n",
    "        \n",
    "        select * from rebounds_pred where season>2009\n",
    "        '''\n",
    "\n",
    "\n",
    "cur.execute(query)\n",
    "data = cur.fetchall()\n",
    "rebounds_df = pd.DataFrame(np.array(data))\n",
    "rebounds_df.columns = ['season','player','age','team','rebounds','rebounds_ly','change_rebounds_ly','Games','C_PF','PG','SG_SF','starter_change','high_usageplayer_added','usagemin_opened','maxusage_added','high_usageplayer_dropped','rebounds_opened','max_reboundsdropped',\n",
    "                    'max_reboundsadded','per_ly','change_per','usagerank','usagerank_ly','reb_perc_ly','change_reb_perc','defensive_winshares','defensive_boxplusminus','boxplusminus','value_overreplacement','career_rebounds','yearspro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>player</th>\n",
       "      <th>age</th>\n",
       "      <th>team</th>\n",
       "      <th>rebounds</th>\n",
       "      <th>rebounds_ly</th>\n",
       "      <th>change_rebounds_ly</th>\n",
       "      <th>Games</th>\n",
       "      <th>C_PF</th>\n",
       "      <th>PG</th>\n",
       "      <th>...</th>\n",
       "      <th>usagerank_ly</th>\n",
       "      <th>reb_perc_ly</th>\n",
       "      <th>change_reb_perc</th>\n",
       "      <th>defensive_winshares</th>\n",
       "      <th>defensive_boxplusminus</th>\n",
       "      <th>boxplusminus</th>\n",
       "      <th>value_overreplacement</th>\n",
       "      <th>career_rebounds</th>\n",
       "      <th>yearspro</th>\n",
       "      <th>age_squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>Greg Monroe</td>\n",
       "      <td>20</td>\n",
       "      <td>DET</td>\n",
       "      <td>7.5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>Gary Neal</td>\n",
       "      <td>26</td>\n",
       "      <td>SAS</td>\n",
       "      <td>2.5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>Lance Stephenson</td>\n",
       "      <td>20</td>\n",
       "      <td>IND</td>\n",
       "      <td>1.5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>Greivis Vasquez</td>\n",
       "      <td>24</td>\n",
       "      <td>MEM</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>Gary Forbes</td>\n",
       "      <td>25</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1.8</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  season            player age team rebounds rebounds_ly change_rebounds_ly  \\\n",
       "0   2010       Greg Monroe  20  DET      7.5        None               None   \n",
       "1   2010         Gary Neal  26  SAS      2.5        None               None   \n",
       "2   2010  Lance Stephenson  20  IND      1.5        None               None   \n",
       "3   2010   Greivis Vasquez  24  MEM        1        None               None   \n",
       "4   2010       Gary Forbes  25  DEN      1.8        None               None   \n",
       "\n",
       "  Games C_PF PG     ...     usagerank_ly reb_perc_ly change_reb_perc  \\\n",
       "0    80    1  0     ...                1        None            None   \n",
       "1    80    0  0     ...                1        None            None   \n",
       "2    12    0  0     ...                1        None            None   \n",
       "3    70    0  0     ...                1        None            None   \n",
       "4    63    0  0     ...                1        None            None   \n",
       "\n",
       "  defensive_winshares defensive_boxplusminus boxplusminus  \\\n",
       "0                None                   None         None   \n",
       "1                None                   None         None   \n",
       "2                None                   None         None   \n",
       "3                None                   None         None   \n",
       "4                None                   None         None   \n",
       "\n",
       "  value_overreplacement career_rebounds yearspro age_squared  \n",
       "0                  None            None     None         400  \n",
       "1                  None            None     None         676  \n",
       "2                  None            None     None         400  \n",
       "3                  None            None     None         576  \n",
       "4                  None            None     None         625  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 651,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rebounds_df['age_squared']=rebounds_df['age']*rebounds_df['age']\n",
    "rebounds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "rebounds = rebounds_df[rebounds_df['rebounds_ly'].notna()]\n",
    "for i in rebounds.columns:\n",
    "    if i not in(['player','team']):\n",
    "        rebounds[i]=pd.to_numeric(rebounds[i])\n",
    "rebounds = rebounds.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rebounds[(rebounds['season']!=2017) & (rebounds['Games']>30)].drop(['player','team','rebounds','Games'],axis=1)\n",
    "y = rebounds[(rebounds['season']!=2017) & (rebounds['Games']>30)]['rebounds']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1564/1564 [==============================] - 3s 2ms/step - loss: 299580.4897\n",
      "Epoch 2/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 175521.9756\n",
      "Epoch 3/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 93471.9222\n",
      "Epoch 4/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 39492.5703\n",
      "Epoch 5/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 12758.4211\n",
      "Epoch 6/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 4703.9037\n",
      "Epoch 7/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 2574.6948\n",
      "Epoch 8/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 1660.2999\n",
      "Epoch 9/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1059.4220\n",
      "Epoch 10/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 674.6345\n",
      "Epoch 11/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 427.3835\n",
      "Epoch 12/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 267.5788\n",
      "Epoch 13/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 168.9353\n",
      "Epoch 14/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 109.4596\n",
      "Epoch 15/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 75.3411\n",
      "Epoch 16/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 55.5611\n",
      "Epoch 17/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 41.9404\n",
      "Epoch 18/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 33.7443\n",
      "Epoch 19/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 28.1452\n",
      "Epoch 20/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 24.4077\n",
      "Epoch 21/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 21.8165\n",
      "Epoch 22/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 19.7279\n",
      "Epoch 23/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 17.8114\n",
      "Epoch 24/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 16.5056\n",
      "Epoch 25/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 15.4716\n",
      "Epoch 26/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 14.5995\n",
      "Epoch 27/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 13.9979\n",
      "Epoch 28/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 13.4464\n",
      "Epoch 29/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 13.0442\n",
      "Epoch 30/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 12.6814\n",
      "Epoch 31/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 12.3366\n",
      "Epoch 32/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 12.0480\n",
      "Epoch 33/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 11.7792\n",
      "Epoch 34/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 11.5746\n",
      "Epoch 35/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 11.3761\n",
      "Epoch 36/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 11.2227\n",
      "Epoch 37/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 11.0773\n",
      "Epoch 38/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 10.9405\n",
      "Epoch 39/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 10.8459\n",
      "Epoch 40/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 10.7252\n",
      "Epoch 41/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 10.6404\n",
      "Epoch 42/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 10.5537\n",
      "Epoch 43/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 10.4744\n",
      "Epoch 44/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 10.4013\n",
      "Epoch 45/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 10.3244\n",
      "Epoch 46/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 10.2663\n",
      "Epoch 47/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 10.2071\n",
      "Epoch 48/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 10.1521\n",
      "Epoch 49/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 10.1167\n",
      "Epoch 50/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 10.0731\n",
      "Epoch 51/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 10.0261\n",
      "Epoch 52/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 9.9931\n",
      "Epoch 53/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 9.9480\n",
      "Epoch 54/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 9.9217\n",
      "Epoch 55/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 9.8712\n",
      "Epoch 56/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 9.8361\n",
      "Epoch 57/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 9.8088\n",
      "Epoch 58/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 9.7774\n",
      "Epoch 59/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 9.7442\n",
      "Epoch 60/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 9.7086\n",
      "Epoch 61/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 9.6778\n",
      "Epoch 62/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 9.6458\n",
      "Epoch 63/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 9.6220\n",
      "Epoch 64/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 9.5947\n",
      "Epoch 65/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 9.5707\n",
      "Epoch 66/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 9.5476\n",
      "Epoch 67/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 9.5223\n",
      "Epoch 68/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 9.5032\n",
      "Epoch 69/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 9.4804\n",
      "Epoch 70/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 9.4545\n",
      "Epoch 71/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 9.4353\n",
      "Epoch 72/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 9.4209\n",
      "Epoch 73/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 9.3975\n",
      "Epoch 74/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 9.3821\n",
      "Epoch 75/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 9.3582\n",
      "Epoch 76/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 9.3416\n",
      "Epoch 77/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 9.3249\n",
      "Epoch 78/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 9.3142\n",
      "Epoch 79/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 9.2896\n",
      "Epoch 80/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 9.2769\n",
      "Epoch 81/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 9.2613\n",
      "Epoch 82/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 9.2399\n",
      "Epoch 83/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 9.2289\n",
      "Epoch 84/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 9.2100\n",
      "Epoch 85/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 9.1930\n",
      "Epoch 86/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 9.1832\n",
      "Epoch 87/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 9.1626\n",
      "Epoch 88/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 9.1501\n",
      "Epoch 89/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 9.1326\n",
      "Epoch 90/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 9.1210\n",
      "Epoch 91/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 9.1026\n",
      "Epoch 92/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 9.1012\n",
      "Epoch 93/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 9.0762\n",
      "Epoch 94/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 9.0795\n",
      "Epoch 95/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 9.0527\n",
      "Epoch 96/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 9.0386\n",
      "Epoch 97/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 9.0209\n",
      "Epoch 98/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 9.0170\n",
      "Epoch 99/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 8.9977\n",
      "Epoch 100/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 8.9819\n",
      "Epoch 101/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 8.9694\n",
      "Epoch 102/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 8.9537\n",
      "Epoch 103/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 8.9433\n",
      "Epoch 104/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 8.9362\n",
      "Epoch 105/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 8.9272\n",
      "Epoch 106/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 8.9022\n",
      "Epoch 107/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 8.8941\n",
      "Epoch 108/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 8.8933\n",
      "Epoch 109/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 8.8659\n",
      "Epoch 110/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 8.8705\n",
      "Epoch 111/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 8.8549\n",
      "Epoch 112/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.8358\n",
      "Epoch 113/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 8.8273\n",
      "Epoch 114/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 8.8108\n",
      "Epoch 115/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 8.7986\n",
      "Epoch 116/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 8.7823\n",
      "Epoch 117/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 8.7710\n",
      "Epoch 118/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 8.7631\n",
      "Epoch 119/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 8.7568\n",
      "Epoch 120/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 8.7444\n",
      "Epoch 121/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 8.7279\n",
      "Epoch 122/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 8.7117\n",
      "Epoch 123/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 8.7064\n",
      "Epoch 124/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 8.6929\n",
      "Epoch 125/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 8.6910\n",
      "Epoch 126/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 8.6745\n",
      "Epoch 127/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 8.6709\n",
      "Epoch 128/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 8.6581\n",
      "Epoch 129/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 8.6497\n",
      "Epoch 130/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 8.6489\n",
      "Epoch 131/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 8.6425\n",
      "Epoch 132/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 8.6239\n",
      "Epoch 133/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 8.6061\n",
      "Epoch 134/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 8.5922\n",
      "Epoch 135/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 8.5833\n",
      "Epoch 136/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 8.5835\n",
      "Epoch 137/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 8.5596\n",
      "Epoch 138/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 8.5551\n",
      "Epoch 139/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 8.5405\n",
      "Epoch 140/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 8.5344\n",
      "Epoch 141/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 8.5234\n",
      "Epoch 142/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 8.5202\n",
      "Epoch 143/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 8.5036\n",
      "Epoch 144/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 8.5061\n",
      "Epoch 145/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 8.4781\n",
      "Epoch 146/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 8.4845\n",
      "Epoch 147/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 8.4703\n",
      "Epoch 148/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 8.4660\n",
      "Epoch 149/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 8.4509\n",
      "Epoch 150/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 8.4459\n",
      "Epoch 151/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 8.4361\n",
      "Epoch 152/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 8.4421\n",
      "Epoch 153/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 8.4175\n",
      "Epoch 154/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 8.4123\n",
      "Epoch 155/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 8.4066\n",
      "Epoch 156/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 8.4068\n",
      "Epoch 157/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 8.3861\n",
      "Epoch 158/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 8.3813\n",
      "Epoch 159/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 8.3782\n",
      "Epoch 160/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 8.3871\n",
      "Epoch 161/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 8.3611\n",
      "Epoch 162/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 8.3382\n",
      "Epoch 163/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 8.3438\n",
      "Epoch 164/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 8.3291\n",
      "Epoch 165/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 8.3259\n",
      "Epoch 166/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 8.3254\n",
      "Epoch 167/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 8.3429\n",
      "Epoch 168/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 8.2998\n",
      "Epoch 169/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.2971\n",
      "Epoch 170/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 8.2901\n",
      "Epoch 171/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 8.2844\n",
      "Epoch 172/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.2721\n",
      "Epoch 173/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 8.2685\n",
      "Epoch 174/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.2579\n",
      "Epoch 175/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 8.2699\n",
      "Epoch 176/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 8.2562\n",
      "Epoch 177/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 8.2510\n",
      "Epoch 178/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 8.2354\n",
      "Epoch 179/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 8.2320\n",
      "Epoch 180/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 8.2254\n",
      "Epoch 181/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 8.2120\n",
      "Epoch 182/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 8.2105\n",
      "Epoch 183/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 8.1967\n",
      "Epoch 184/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 8.2079\n",
      "Epoch 185/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 8.1968\n",
      "Epoch 186/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 8.1956\n",
      "Epoch 187/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 8.1747\n",
      "Epoch 188/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 8.1968\n",
      "Epoch 189/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 8.1755\n",
      "Epoch 190/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 8.1520\n",
      "Epoch 191/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.1614\n",
      "Epoch 192/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 8.1582\n",
      "Epoch 193/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 8.1472\n",
      "Epoch 194/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 8.1463\n",
      "Epoch 195/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 8.1354\n",
      "Epoch 196/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 8.1258\n",
      "Epoch 197/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 8.1202\n",
      "Epoch 198/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 8.1117\n",
      "Epoch 199/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 8.1058\n",
      "Epoch 200/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 8.1107\n",
      "Epoch 201/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 8.1005\n",
      "Epoch 202/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 8.0941\n",
      "Epoch 203/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 8.0912\n",
      "Epoch 204/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 8.0833\n",
      "Epoch 205/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 8.0876\n",
      "Epoch 206/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 8.0732\n",
      "Epoch 207/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 8.0747\n",
      "Epoch 208/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 8.0743\n",
      "Epoch 209/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 8.0767\n",
      "Epoch 210/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 8.0573\n",
      "Epoch 211/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 8.0524\n",
      "Epoch 212/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 8.0441\n",
      "Epoch 213/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.0376\n",
      "Epoch 214/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 8.0375\n",
      "Epoch 215/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 8.0585\n",
      "Epoch 216/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 8.0242\n",
      "Epoch 217/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 8.0266\n",
      "Epoch 218/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 8.0299\n",
      "Epoch 219/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 8.0077\n",
      "Epoch 220/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 8.0050\n",
      "Epoch 221/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 8.0055\n",
      "Epoch 222/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 8.0083\n",
      "Epoch 223/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.9965\n",
      "Epoch 224/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 8.0014\n",
      "Epoch 225/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.9836\n",
      "Epoch 226/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.9820\n",
      "Epoch 227/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.9836\n",
      "Epoch 228/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.9706\n",
      "Epoch 229/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.9758\n",
      "Epoch 230/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.9699\n",
      "Epoch 231/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.9939\n",
      "Epoch 232/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.9933\n",
      "Epoch 233/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.9710\n",
      "Epoch 234/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 8.0070\n",
      "Epoch 235/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.9420\n",
      "Epoch 236/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.9396\n",
      "Epoch 237/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.9493\n",
      "Epoch 238/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.9356\n",
      "Epoch 239/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.9250\n",
      "Epoch 240/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.9356\n",
      "Epoch 241/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.9223\n",
      "Epoch 242/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.9191\n",
      "Epoch 243/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.9248\n",
      "Epoch 244/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.9255\n",
      "Epoch 245/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.9087\n",
      "Epoch 246/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.9109\n",
      "Epoch 247/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.9893\n",
      "Epoch 248/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.9353\n",
      "Epoch 249/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.8959\n",
      "Epoch 250/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.9035\n",
      "Epoch 251/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.9156\n",
      "Epoch 252/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.9025\n",
      "Epoch 253/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.8817\n",
      "Epoch 254/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.8751\n",
      "Epoch 255/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.8837\n",
      "Epoch 256/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.8749\n",
      "Epoch 257/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.8818\n",
      "Epoch 258/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.8733\n",
      "Epoch 259/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.8646\n",
      "Epoch 260/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.8648\n",
      "Epoch 261/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.8687\n",
      "Epoch 262/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.8520\n",
      "Epoch 263/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.8576\n",
      "Epoch 264/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.8707\n",
      "Epoch 265/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.8460\n",
      "Epoch 266/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.8405\n",
      "Epoch 267/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.8531\n",
      "Epoch 268/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.8427\n",
      "Epoch 269/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.8345\n",
      "Epoch 270/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.8473\n",
      "Epoch 271/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.8244\n",
      "Epoch 272/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.8270\n",
      "Epoch 273/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.8372\n",
      "Epoch 274/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.8169\n",
      "Epoch 275/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.8141\n",
      "Epoch 276/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.8206\n",
      "Epoch 277/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.8407\n",
      "Epoch 278/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.8730\n",
      "Epoch 279/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.8296\n",
      "Epoch 280/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.8025\n",
      "Epoch 281/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 7.8144\n",
      "Epoch 282/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.8077\n",
      "Epoch 283/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.7967\n",
      "Epoch 284/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.7928\n",
      "Epoch 285/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.7957\n",
      "Epoch 286/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.7946\n",
      "Epoch 287/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.7827\n",
      "Epoch 288/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.7812\n",
      "Epoch 289/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.7785\n",
      "Epoch 290/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.7852\n",
      "Epoch 291/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.7779\n",
      "Epoch 292/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.7627\n",
      "Epoch 293/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.8179\n",
      "Epoch 294/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.7647\n",
      "Epoch 295/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.7713\n",
      "Epoch 296/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.7518\n",
      "Epoch 297/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.7582\n",
      "Epoch 298/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.7653\n",
      "Epoch 299/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.7726\n",
      "Epoch 300/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.7525\n",
      "Epoch 301/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.7454\n",
      "Epoch 302/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.7431\n",
      "Epoch 303/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.7418\n",
      "Epoch 304/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.7467\n",
      "Epoch 305/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.7509\n",
      "Epoch 306/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.7394\n",
      "Epoch 307/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.7596\n",
      "Epoch 308/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.7273\n",
      "Epoch 309/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.7511\n",
      "Epoch 310/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.7216\n",
      "Epoch 311/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.7107\n",
      "Epoch 312/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.7260\n",
      "Epoch 313/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.7301\n",
      "Epoch 314/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.7101\n",
      "Epoch 315/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.7332\n",
      "Epoch 316/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.7916\n",
      "Epoch 317/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.6968\n",
      "Epoch 318/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.6980\n",
      "Epoch 319/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.6971\n",
      "Epoch 320/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.7371\n",
      "Epoch 321/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.7974\n",
      "Epoch 322/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.7042\n",
      "Epoch 323/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.6827\n",
      "Epoch 324/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 7.6961\n",
      "Epoch 325/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.7060\n",
      "Epoch 326/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.6838\n",
      "Epoch 327/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.6800\n",
      "Epoch 328/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.6837\n",
      "Epoch 329/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.6697\n",
      "Epoch 330/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.6682\n",
      "Epoch 331/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.6631\n",
      "Epoch 332/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.6725\n",
      "Epoch 333/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.7035\n",
      "Epoch 334/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.6680\n",
      "Epoch 335/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.6724\n",
      "Epoch 336/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.6592\n",
      "Epoch 337/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.6450\n",
      "Epoch 338/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.6368\n",
      "Epoch 339/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.6372\n",
      "Epoch 340/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.6355\n",
      "Epoch 341/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.6628\n",
      "Epoch 342/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.6377\n",
      "Epoch 343/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.6272\n",
      "Epoch 344/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.6269\n",
      "Epoch 345/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.6266\n",
      "Epoch 346/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.6368\n",
      "Epoch 347/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.6281\n",
      "Epoch 348/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.6204\n",
      "Epoch 349/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.6237\n",
      "Epoch 350/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.6287\n",
      "Epoch 351/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.6163\n",
      "Epoch 352/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.6290\n",
      "Epoch 353/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.6261\n",
      "Epoch 354/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.6298\n",
      "Epoch 355/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.5915\n",
      "Epoch 356/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.6111\n",
      "Epoch 357/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.5878\n",
      "Epoch 358/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.5868\n",
      "Epoch 359/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.5898\n",
      "Epoch 360/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.5892\n",
      "Epoch 361/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.5832\n",
      "Epoch 362/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.6402\n",
      "Epoch 363/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.5755\n",
      "Epoch 364/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.6767\n",
      "Epoch 365/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.5808\n",
      "Epoch 366/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.6061\n",
      "Epoch 367/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.5961\n",
      "Epoch 368/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.6403\n",
      "Epoch 369/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.7165\n",
      "Epoch 370/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.5607\n",
      "Epoch 371/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.5519\n",
      "Epoch 372/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.5499\n",
      "Epoch 373/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.5929\n",
      "Epoch 374/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.6015\n",
      "Epoch 375/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.5874\n",
      "Epoch 376/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.5902\n",
      "Epoch 377/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.5273\n",
      "Epoch 378/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.5209\n",
      "Epoch 379/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.5397\n",
      "Epoch 380/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.5381\n",
      "Epoch 381/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.5371\n",
      "Epoch 382/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.5901\n",
      "Epoch 383/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.5121\n",
      "Epoch 384/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.5313\n",
      "Epoch 385/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.5046\n",
      "Epoch 386/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.5104\n",
      "Epoch 387/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.4984\n",
      "Epoch 388/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.4994\n",
      "Epoch 389/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.5005\n",
      "Epoch 390/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.5337\n",
      "Epoch 391/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.5105\n",
      "Epoch 392/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.4816\n",
      "Epoch 393/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.5269\n",
      "Epoch 394/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.5155\n",
      "Epoch 395/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.4863\n",
      "Epoch 396/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.5669\n",
      "Epoch 397/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.4750\n",
      "Epoch 398/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.4710\n",
      "Epoch 399/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.4823\n",
      "Epoch 400/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.4660\n",
      "Epoch 401/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.4535\n",
      "Epoch 402/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.4572\n",
      "Epoch 403/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.4830\n",
      "Epoch 404/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.4506\n",
      "Epoch 405/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.4580\n",
      "Epoch 406/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.4516\n",
      "Epoch 407/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.4727\n",
      "Epoch 408/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.4401\n",
      "Epoch 409/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.4316\n",
      "Epoch 410/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.4284\n",
      "Epoch 411/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.4214\n",
      "Epoch 412/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.4191\n",
      "Epoch 413/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.4361\n",
      "Epoch 414/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.4322\n",
      "Epoch 415/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.4203\n",
      "Epoch 416/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.4157\n",
      "Epoch 417/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.4124\n",
      "Epoch 418/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.4228\n",
      "Epoch 419/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.5539\n",
      "Epoch 420/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.5334\n",
      "Epoch 421/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.5032\n",
      "Epoch 422/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.5465\n",
      "Epoch 423/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.4279\n",
      "Epoch 424/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.3688\n",
      "Epoch 425/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.4573\n",
      "Epoch 426/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.3929\n",
      "Epoch 427/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 7.3762\n",
      "Epoch 428/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.3636\n",
      "Epoch 429/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.3433\n",
      "Epoch 430/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 7.3681\n",
      "Epoch 431/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.3949\n",
      "Epoch 432/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.4118\n",
      "Epoch 433/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.3994\n",
      "Epoch 434/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.4534\n",
      "Epoch 435/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.3345\n",
      "Epoch 436/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.3208\n",
      "Epoch 437/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.3152\n",
      "Epoch 438/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.3135\n",
      "Epoch 439/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.3381\n",
      "Epoch 440/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.2971\n",
      "Epoch 441/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.3596\n",
      "Epoch 442/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.2921\n",
      "Epoch 443/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.3407\n",
      "Epoch 444/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.3289\n",
      "Epoch 445/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.3318\n",
      "Epoch 446/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.4330\n",
      "Epoch 447/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.3247\n",
      "Epoch 448/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.2887\n",
      "Epoch 449/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.2672\n",
      "Epoch 450/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.3262\n",
      "Epoch 451/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.2589\n",
      "Epoch 452/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.2809\n",
      "Epoch 453/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.3049\n",
      "Epoch 454/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.3109\n",
      "Epoch 455/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.2646\n",
      "Epoch 456/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.2601\n",
      "Epoch 457/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.2398\n",
      "Epoch 458/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.2473\n",
      "Epoch 459/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.2641\n",
      "Epoch 460/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.2479\n",
      "Epoch 461/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.2224\n",
      "Epoch 462/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.2243\n",
      "Epoch 463/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.2250\n",
      "Epoch 464/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.2258\n",
      "Epoch 465/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.2270\n",
      "Epoch 466/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.2437\n",
      "Epoch 467/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.2500\n",
      "Epoch 468/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.3501\n",
      "Epoch 469/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.1844\n",
      "Epoch 470/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.1775\n",
      "Epoch 471/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.2341\n",
      "Epoch 472/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.3909\n",
      "Epoch 473/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.2331\n",
      "Epoch 474/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.1962\n",
      "Epoch 475/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.2211\n",
      "Epoch 476/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.2114\n",
      "Epoch 477/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 7.2052\n",
      "Epoch 478/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.2074\n",
      "Epoch 479/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.1412\n",
      "Epoch 480/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.2228\n",
      "Epoch 481/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.1706\n",
      "Epoch 482/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.1508\n",
      "Epoch 483/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.1774\n",
      "Epoch 484/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.1510\n",
      "Epoch 485/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.1410\n",
      "Epoch 486/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.1621\n",
      "Epoch 487/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.1379\n",
      "Epoch 488/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.1315\n",
      "Epoch 489/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.1138\n",
      "Epoch 490/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.1416\n",
      "Epoch 491/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.1250\n",
      "Epoch 492/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.1246\n",
      "Epoch 493/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.1623\n",
      "Epoch 494/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.1067\n",
      "Epoch 495/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.1191\n",
      "Epoch 496/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.1304\n",
      "Epoch 497/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.0918\n",
      "Epoch 498/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.0858\n",
      "Epoch 499/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.1222\n",
      "Epoch 500/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.0744\n",
      "Epoch 501/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.0922\n",
      "Epoch 502/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.0775\n",
      "Epoch 503/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.1344\n",
      "Epoch 504/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.0573\n",
      "Epoch 505/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.0714\n",
      "Epoch 506/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.0601\n",
      "Epoch 507/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.0856\n",
      "Epoch 508/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.1226\n",
      "Epoch 509/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.1309\n",
      "Epoch 510/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.1149\n",
      "Epoch 511/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.0400\n",
      "Epoch 512/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.0530\n",
      "Epoch 513/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.0637\n",
      "Epoch 514/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.0609\n",
      "Epoch 515/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.0157\n",
      "Epoch 516/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.0193\n",
      "Epoch 517/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.0808\n",
      "Epoch 518/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.0104\n",
      "Epoch 519/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.2097\n",
      "Epoch 520/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.1496\n",
      "Epoch 521/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.9982\n",
      "Epoch 522/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.9948\n",
      "Epoch 523/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.9889\n",
      "Epoch 524/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.0139\n",
      "Epoch 525/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.9899\n",
      "Epoch 526/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.0696\n",
      "Epoch 527/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.0338\n",
      "Epoch 528/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.9582\n",
      "Epoch 529/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.0206\n",
      "Epoch 530/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.9847\n",
      "Epoch 531/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.9735\n",
      "Epoch 532/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.9876\n",
      "Epoch 533/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.9915\n",
      "Epoch 534/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.0562\n",
      "Epoch 535/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.9909\n",
      "Epoch 536/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.9235\n",
      "Epoch 537/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.9329\n",
      "Epoch 538/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 7.0175\n",
      "Epoch 539/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.9191\n",
      "Epoch 540/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.9759\n",
      "Epoch 541/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.9253\n",
      "Epoch 542/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.9729\n",
      "Epoch 543/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.9800\n",
      "Epoch 544/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.9365\n",
      "Epoch 545/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.9531\n",
      "Epoch 546/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.8813\n",
      "Epoch 547/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.9400\n",
      "Epoch 548/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.8971\n",
      "Epoch 549/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.8955\n",
      "Epoch 550/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.9456\n",
      "Epoch 551/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 6.9961\n",
      "Epoch 552/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.9391\n",
      "Epoch 553/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.9135\n",
      "Epoch 554/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.8903\n",
      "Epoch 555/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.8601\n",
      "Epoch 556/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.8814\n",
      "Epoch 557/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.8567\n",
      "Epoch 558/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.8387\n",
      "Epoch 559/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.8369\n",
      "Epoch 560/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.8685\n",
      "Epoch 561/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.8372\n",
      "Epoch 562/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.8176\n",
      "Epoch 563/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.8184\n",
      "Epoch 564/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.8121\n",
      "Epoch 565/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.8153\n",
      "Epoch 566/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.8636\n",
      "Epoch 567/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.7968\n",
      "Epoch 568/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.8926\n",
      "Epoch 569/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.7982\n",
      "Epoch 570/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.8083\n",
      "Epoch 571/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.8229\n",
      "Epoch 572/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.8939\n",
      "Epoch 573/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 6.8051\n",
      "Epoch 574/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.8064\n",
      "Epoch 575/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.8536\n",
      "Epoch 576/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.8893\n",
      "Epoch 577/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 6.8201\n",
      "Epoch 578/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.7357\n",
      "Epoch 579/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.9600\n",
      "Epoch 580/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.7702\n",
      "Epoch 581/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 6.7597\n",
      "Epoch 582/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.7086\n",
      "Epoch 583/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.7965\n",
      "Epoch 584/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.7497\n",
      "Epoch 585/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.7490\n",
      "Epoch 586/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.7204\n",
      "Epoch 587/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.7058\n",
      "Epoch 588/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.7779\n",
      "Epoch 589/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.7992\n",
      "Epoch 590/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.7015\n",
      "Epoch 591/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 6.6629\n",
      "Epoch 592/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.7115\n",
      "Epoch 593/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.6991\n",
      "Epoch 594/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 6.7982\n",
      "Epoch 595/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.7960\n",
      "Epoch 596/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.7029\n",
      "Epoch 597/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.6482\n",
      "Epoch 598/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.6785\n",
      "Epoch 599/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.6797\n",
      "Epoch 600/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.7145\n",
      "Epoch 601/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.6366\n",
      "Epoch 602/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.6608\n",
      "Epoch 603/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.6502\n",
      "Epoch 604/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.6970\n",
      "Epoch 605/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.5731\n",
      "Epoch 606/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 6.6674\n",
      "Epoch 607/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.5759\n",
      "Epoch 608/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.6036\n",
      "Epoch 609/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.5869\n",
      "Epoch 610/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.5584\n",
      "Epoch 611/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.5617\n",
      "Epoch 612/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.5469\n",
      "Epoch 613/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.6466\n",
      "Epoch 614/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 6.5418\n",
      "Epoch 615/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.5869\n",
      "Epoch 616/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.5439\n",
      "Epoch 617/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.5526\n",
      "Epoch 618/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.5219\n",
      "Epoch 619/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.5315\n",
      "Epoch 620/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.5110\n",
      "Epoch 621/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.6066\n",
      "Epoch 622/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.5098\n",
      "Epoch 623/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.5884\n",
      "Epoch 624/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.4843\n",
      "Epoch 625/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.4708\n",
      "Epoch 626/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 6.5059\n",
      "Epoch 627/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.4655\n",
      "Epoch 628/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.4415\n",
      "Epoch 629/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.4613\n",
      "Epoch 630/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.4301\n",
      "Epoch 631/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.4434\n",
      "Epoch 632/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.4362\n",
      "Epoch 633/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.4586\n",
      "Epoch 634/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.4327\n",
      "Epoch 635/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 6.4085\n",
      "Epoch 636/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.3502\n",
      "Epoch 637/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.3893\n",
      "Epoch 638/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.4382\n",
      "Epoch 639/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.3175\n",
      "Epoch 640/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.3186\n",
      "Epoch 641/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.4033\n",
      "Epoch 642/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.3375\n",
      "Epoch 643/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.3248\n",
      "Epoch 644/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.2838\n",
      "Epoch 645/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.3025\n",
      "Epoch 646/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.2814\n",
      "Epoch 647/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.2437\n",
      "Epoch 648/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.2331\n",
      "Epoch 649/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.2252\n",
      "Epoch 650/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.1881\n",
      "Epoch 651/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.1670\n",
      "Epoch 652/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.2262\n",
      "Epoch 653/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.1949\n",
      "Epoch 654/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.1347\n",
      "Epoch 655/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.1710\n",
      "Epoch 656/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.1251\n",
      "Epoch 657/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.1249\n",
      "Epoch 658/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.1175\n",
      "Epoch 659/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.1571\n",
      "Epoch 660/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.0860\n",
      "Epoch 661/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.0741\n",
      "Epoch 662/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.1432\n",
      "Epoch 663/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.1270\n",
      "Epoch 664/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.1473\n",
      "Epoch 665/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.0303\n",
      "Epoch 666/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 5.9947\n",
      "Epoch 667/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 5.9433\n",
      "Epoch 668/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 5.9376\n",
      "Epoch 669/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 5.9574\n",
      "Epoch 670/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.0161\n",
      "Epoch 671/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.8936\n",
      "Epoch 672/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.8660\n",
      "Epoch 673/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.8728\n",
      "Epoch 674/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.8223\n",
      "Epoch 675/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 5.7935\n",
      "Epoch 676/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.7193\n",
      "Epoch 677/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.6714\n",
      "Epoch 678/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 5.6101\n",
      "Epoch 679/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 5.6536\n",
      "Epoch 680/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 5.4903\n",
      "Epoch 681/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 5.4569\n",
      "Epoch 682/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 5.4257\n",
      "Epoch 683/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 5.3715\n",
      "Epoch 684/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 5.2801\n",
      "Epoch 685/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 5.1944\n",
      "Epoch 686/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 5.2965\n",
      "Epoch 687/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 5.1758\n",
      "Epoch 688/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 5.4286\n",
      "Epoch 689/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 5.0757\n",
      "Epoch 690/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 5.1265\n",
      "Epoch 691/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 4.7152\n",
      "Epoch 692/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 4.6319\n",
      "Epoch 693/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 4.5177\n",
      "Epoch 694/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 4.3999\n",
      "Epoch 695/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 4.2858\n",
      "Epoch 696/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 4.1440\n",
      "Epoch 697/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 4.0517\n",
      "Epoch 698/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 3.8936\n",
      "Epoch 699/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 3.8620\n",
      "Epoch 700/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 3.7221\n",
      "Epoch 701/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 3.5457\n",
      "Epoch 702/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 3.3601\n",
      "Epoch 703/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 3.2853\n",
      "Epoch 704/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 3.1376\n",
      "Epoch 705/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 2.9347\n",
      "Epoch 706/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 2.8167\n",
      "Epoch 707/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 2.6881\n",
      "Epoch 708/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 2.6005\n",
      "Epoch 709/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.4918\n",
      "Epoch 710/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.4670\n",
      "Epoch 711/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.5070\n",
      "Epoch 712/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 2.3158\n",
      "Epoch 713/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 2.3477\n",
      "Epoch 714/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.3094\n",
      "Epoch 715/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 2.2227\n",
      "Epoch 716/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 2.1601\n",
      "Epoch 717/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 2.1198\n",
      "Epoch 718/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 2.0696\n",
      "Epoch 719/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 2.0682\n",
      "Epoch 720/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 2.0007\n",
      "Epoch 721/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 2.0106\n",
      "Epoch 722/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.9561\n",
      "Epoch 723/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.9352\n",
      "Epoch 724/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.9326\n",
      "Epoch 725/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.9414\n",
      "Epoch 726/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.8795\n",
      "Epoch 727/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.8733\n",
      "Epoch 728/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.8884\n",
      "Epoch 729/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.8486\n",
      "Epoch 730/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.8244\n",
      "Epoch 731/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.8110\n",
      "Epoch 732/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.7937\n",
      "Epoch 733/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.9138\n",
      "Epoch 734/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.9712\n",
      "Epoch 735/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.9063\n",
      "Epoch 736/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.7987\n",
      "Epoch 737/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.7430\n",
      "Epoch 738/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.7503\n",
      "Epoch 739/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.8563\n",
      "Epoch 740/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.7977\n",
      "Epoch 741/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.7406\n",
      "Epoch 742/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.6970\n",
      "Epoch 743/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.8215\n",
      "Epoch 744/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.8339\n",
      "Epoch 745/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.7683\n",
      "Epoch 746/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.6888\n",
      "Epoch 747/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.6683\n",
      "Epoch 748/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.6612\n",
      "Epoch 749/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.6450\n",
      "Epoch 750/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.6671\n",
      "Epoch 751/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.6409\n",
      "Epoch 752/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.6280\n",
      "Epoch 753/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.6098\n",
      "Epoch 754/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.6224\n",
      "Epoch 755/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.6457\n",
      "Epoch 756/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.6043\n",
      "Epoch 757/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.5971\n",
      "Epoch 758/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.5949\n",
      "Epoch 759/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.6535\n",
      "Epoch 760/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.6675\n",
      "Epoch 761/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.5989\n",
      "Epoch 762/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.5866\n",
      "Epoch 763/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.5645\n",
      "Epoch 764/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.5817\n",
      "Epoch 765/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.5875\n",
      "Epoch 766/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.5860\n",
      "Epoch 767/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.5706\n",
      "Epoch 768/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.6239\n",
      "Epoch 769/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.5317\n",
      "Epoch 770/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.5327\n",
      "Epoch 771/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.5238\n",
      "Epoch 772/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.5372\n",
      "Epoch 773/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.5319\n",
      "Epoch 774/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.5144\n",
      "Epoch 775/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.5040\n",
      "Epoch 776/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.5015\n",
      "Epoch 777/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.5030\n",
      "Epoch 778/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.4873\n",
      "Epoch 779/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.5086\n",
      "Epoch 780/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.4861\n",
      "Epoch 781/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.4830\n",
      "Epoch 782/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.4782\n",
      "Epoch 783/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.4893\n",
      "Epoch 784/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.4811\n",
      "Epoch 785/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.4969\n",
      "Epoch 786/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.4845\n",
      "Epoch 787/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.4625\n",
      "Epoch 788/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.4725\n",
      "Epoch 789/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.5010\n",
      "Epoch 790/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.4982\n",
      "Epoch 791/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.4905\n",
      "Epoch 792/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.4576\n",
      "Epoch 793/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.4533\n",
      "Epoch 794/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.4540\n",
      "Epoch 795/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.4864\n",
      "Epoch 796/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.4378\n",
      "Epoch 797/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.4263\n",
      "Epoch 798/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.4594\n",
      "Epoch 799/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.4490\n",
      "Epoch 800/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.4425\n",
      "Epoch 801/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.4927\n",
      "Epoch 802/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.4785\n",
      "Epoch 803/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.4280\n",
      "Epoch 804/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.4826\n",
      "Epoch 805/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.4523\n",
      "Epoch 806/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.4983\n",
      "Epoch 807/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.4778\n",
      "Epoch 808/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.4913\n",
      "Epoch 809/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.4325\n",
      "Epoch 810/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.5294\n",
      "Epoch 811/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.4376\n",
      "Epoch 812/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.4624\n",
      "Epoch 813/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.3968\n",
      "Epoch 814/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.4096\n",
      "Epoch 815/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.3944\n",
      "Epoch 816/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.3874\n",
      "Epoch 817/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.3853\n",
      "Epoch 818/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.4114\n",
      "Epoch 819/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.4146\n",
      "Epoch 820/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.4168\n",
      "Epoch 821/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.4336\n",
      "Epoch 822/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.4099\n",
      "Epoch 823/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.3706\n",
      "Epoch 824/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.3772\n",
      "Epoch 825/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.4223\n",
      "Epoch 826/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.3822\n",
      "Epoch 827/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.3779\n",
      "Epoch 828/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.3992\n",
      "Epoch 829/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.3607\n",
      "Epoch 830/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.3754\n",
      "Epoch 831/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.3724\n",
      "Epoch 832/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.3707\n",
      "Epoch 833/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.4156\n",
      "Epoch 834/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.4123\n",
      "Epoch 835/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.4428\n",
      "Epoch 836/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.5130\n",
      "Epoch 837/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.3740\n",
      "Epoch 838/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.3864\n",
      "Epoch 839/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.3930\n",
      "Epoch 840/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.4118\n",
      "Epoch 841/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.3876\n",
      "Epoch 842/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.3540\n",
      "Epoch 843/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.3559\n",
      "Epoch 844/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.3452\n",
      "Epoch 845/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.3437\n",
      "Epoch 846/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.3508\n",
      "Epoch 847/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.3690\n",
      "Epoch 848/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.3855\n",
      "Epoch 849/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.3672\n",
      "Epoch 850/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.3787\n",
      "Epoch 851/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.4076\n",
      "Epoch 852/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.3476\n",
      "Epoch 853/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.3497\n",
      "Epoch 854/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.3354\n",
      "Epoch 855/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.3431\n",
      "Epoch 856/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.3926\n",
      "Epoch 857/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.4105\n",
      "Epoch 858/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.3507\n",
      "Epoch 859/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.3276\n",
      "Epoch 860/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.3258\n",
      "Epoch 861/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.4331\n",
      "Epoch 862/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.3559\n",
      "Epoch 863/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.3646\n",
      "Epoch 864/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.3312\n",
      "Epoch 865/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.3292\n",
      "Epoch 866/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.3284\n",
      "Epoch 867/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.3641\n",
      "Epoch 868/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.3437\n",
      "Epoch 869/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.3084\n",
      "Epoch 870/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.3341\n",
      "Epoch 871/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.3154\n",
      "Epoch 872/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.3444\n",
      "Epoch 873/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.3067\n",
      "Epoch 874/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.3070\n",
      "Epoch 875/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.3740\n",
      "Epoch 876/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.3876\n",
      "Epoch 877/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.3726\n",
      "Epoch 878/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.3730\n",
      "Epoch 879/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.3202\n",
      "Epoch 880/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.3289\n",
      "Epoch 881/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.3287\n",
      "Epoch 882/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.3519\n",
      "Epoch 883/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.3080\n",
      "Epoch 884/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.3352\n",
      "Epoch 885/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.3877\n",
      "Epoch 886/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.3997\n",
      "Epoch 887/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.2929\n",
      "Epoch 888/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.3003\n",
      "Epoch 889/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.3022\n",
      "Epoch 890/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.3575\n",
      "Epoch 891/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2941\n",
      "Epoch 892/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2931\n",
      "Epoch 893/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2904\n",
      "Epoch 894/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.3133\n",
      "Epoch 895/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.2891\n",
      "Epoch 896/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.2934\n",
      "Epoch 897/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.3200\n",
      "Epoch 898/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.3424\n",
      "Epoch 899/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.3169\n",
      "Epoch 900/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2771\n",
      "Epoch 901/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2815\n",
      "Epoch 902/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2966\n",
      "Epoch 903/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2981\n",
      "Epoch 904/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.3566\n",
      "Epoch 905/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.2851\n",
      "Epoch 906/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.3066\n",
      "Epoch 907/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2923\n",
      "Epoch 908/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2915\n",
      "Epoch 909/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.3305\n",
      "Epoch 910/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2818\n",
      "Epoch 911/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.3065\n",
      "Epoch 912/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2901\n",
      "Epoch 913/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2805\n",
      "Epoch 914/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.2874\n",
      "Epoch 915/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2964\n",
      "Epoch 916/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2863\n",
      "Epoch 917/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.3023\n",
      "Epoch 918/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.2960\n",
      "Epoch 919/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2863\n",
      "Epoch 920/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2688\n",
      "Epoch 921/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.2596\n",
      "Epoch 922/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.3114\n",
      "Epoch 923/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2769\n",
      "Epoch 924/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.3380\n",
      "Epoch 925/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.3054\n",
      "Epoch 926/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2728\n",
      "Epoch 927/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2565\n",
      "Epoch 928/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2684\n",
      "Epoch 929/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2621\n",
      "Epoch 930/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2613\n",
      "Epoch 931/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2861\n",
      "Epoch 932/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.2663\n",
      "Epoch 933/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2637\n",
      "Epoch 934/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.3049\n",
      "Epoch 935/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.2674\n",
      "Epoch 936/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.2607\n",
      "Epoch 937/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.2768\n",
      "Epoch 938/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2587\n",
      "Epoch 939/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.2606\n",
      "Epoch 940/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2914\n",
      "Epoch 941/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2793\n",
      "Epoch 942/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2950\n",
      "Epoch 943/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2563\n",
      "Epoch 944/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.2791\n",
      "Epoch 945/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2460\n",
      "Epoch 946/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2785\n",
      "Epoch 947/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2666\n",
      "Epoch 948/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2642\n",
      "Epoch 949/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2397\n",
      "Epoch 950/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2614\n",
      "Epoch 951/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2483\n",
      "Epoch 952/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.2479\n",
      "Epoch 953/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.2368\n",
      "Epoch 954/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2457\n",
      "Epoch 955/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2474\n",
      "Epoch 956/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.2628\n",
      "Epoch 957/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2476\n",
      "Epoch 958/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2807\n",
      "Epoch 959/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2629\n",
      "Epoch 960/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.3234\n",
      "Epoch 961/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2568\n",
      "Epoch 962/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.2585\n",
      "Epoch 963/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2728\n",
      "Epoch 964/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2336\n",
      "Epoch 965/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2658\n",
      "Epoch 966/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2991\n",
      "Epoch 967/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2438\n",
      "Epoch 968/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2317\n",
      "Epoch 969/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2933\n",
      "Epoch 970/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2344\n",
      "Epoch 971/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2319\n",
      "Epoch 972/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.2283\n",
      "Epoch 973/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.2224\n",
      "Epoch 974/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2993\n",
      "Epoch 975/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.2626\n",
      "Epoch 976/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2921\n",
      "Epoch 977/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2862\n",
      "Epoch 978/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2313\n",
      "Epoch 979/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2294\n",
      "Epoch 980/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2471\n",
      "Epoch 981/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2174\n",
      "Epoch 982/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2284\n",
      "Epoch 983/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2232\n",
      "Epoch 984/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.3014\n",
      "Epoch 985/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2457\n",
      "Epoch 986/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.2447\n",
      "Epoch 987/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.2273\n",
      "Epoch 988/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.2563\n",
      "Epoch 989/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2645\n",
      "Epoch 990/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2430\n",
      "Epoch 991/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2354\n",
      "Epoch 992/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2389\n",
      "Epoch 993/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.2477\n",
      "Epoch 994/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2305\n",
      "Epoch 995/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.2200\n",
      "Epoch 996/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.2707\n",
      "Epoch 997/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.2670\n",
      "Epoch 998/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2270\n",
      "Epoch 999/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2214\n",
      "Epoch 1000/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.3115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a4db17160>"
      ]
     },
     "execution_count": 670,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model = Sequential()\n",
    "NN_model.add(Dense(units=16,input_dim= X_train.shape[1],activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_model.add(Dense(units=8, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_model.add(Dense(units=4, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_model.add(Dense(units=1,activation='linear'))\n",
    "NN_model.compile(loss='mse', optimizer='adam')\n",
    "NN_model.fit(np.array(X_train), np.array(y_train), epochs=1000,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a4db00c18>"
      ]
     },
     "execution_count": 671,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_predictions = NN_model.predict(X_train)\n",
    "training = pd.DataFrame(training_predictions)\n",
    "training['actual'] = y_train.reset_index()['rebounds']\n",
    "plt.scatter(training_predictions,training[0]-training['actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = NN_model.predict(X_test)\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.5)\n",
    "gbr.fit(X_train,y_train)\n",
    "gbr_predictions = gbr.predict(X_test)\n",
    "LR = LinearRegression(fit_intercept=True).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = pd.DataFrame(predictions)\n",
    "testing.columns=['NN_predictions']\n",
    "testing['actual'] = y_test.reset_index()['rebounds']\n",
    "testing['GBR_predictions']=gbr_predictions\n",
    "testing['LY_rebounding']=X_test['rebounds_ly'].reset_index()['rebounds_ly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a38ecf588>]"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6IAAAHVCAYAAADrQEbXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3VmMJEl6J/a/mblHREZWVdbZ3dMXekhwhuQ0lqvZxoLSgwQsRYECBO0+ipAEAiIwbxJWgCCtsA96EwRQgCBAgLQD8dgFuIRWhMRDF5bLfaAeqAWaPSSnm90zvd3TU9XVV1ZVXpUZEe5uZnowNw+PyDg8Ijz8iPj/gEJWZWZVeuXh7n//PvtMWGtBREREREREVBVZ9wEQERERERHRfmEQJSIiIiIiokoxiBIREREREVGlGESJiIiIiIioUgyiREREREREVCkGUSIiIiIiIqoUgygRERERERFVikGUiIiIiIiIKsUgSkRERERERJUKqvxg9+/ft2+88UaVH5KIiIiIiIgq8md/9mdPrLUPlr1fpUH0jTfewNtvv13lhyQiIiIiIqKKCCF+XOT92JpLRERERERElWIQJSIiIiIiokoxiBIREREREVGlGESJiIiIiIioUgyiREREREREVCkGUSIiIiIiIqoUgygRERERERFVikGUiIiIiIiIKrU0iAohfkMI8ZUQ4t0Zb/vPhBBWCHF/O4dHREREREREu6ZIRfS3APzS9CuFEK8B+EUAD0s+JiIiIiIiItphS4OotfZPADyb8ab/DsB/DsCWfVBERERERES0u9ZaIyqE+HcBPLbW/kXJx0NEREREREQ7Llj1Lwgh+gD+PoB/q+D7fwfAdwDg9ddfX/XDERERERER0Y5ZpyL6kwC+DuAvhBCfAHgVwDtCiJdmvbO19rvW2restW89ePBg/SMlIiIiIiKinbByRdRa+30AL/g/p2H0LWvtkxKPi4iIiIiIiHZUke1bfgfAnwL4phDiUyHEr27/sIiIiIiIiGhXLa2IWmt/ecnb3yjtaIiIiIiIiGjnrTU1l4iIGuQf/SPgT/6k7qMgIiIiKmzlNaJERNQwX30F3LhR91EQERERFcaKKBFR22ntfhERERG1BIMoEVHbJYn7RURERNQSDKJERG3HiigRERG1DIMoEVGbWQsYwyBKRERErcIgSkTUZj6AMogSERFRizCIEhG1mV8byiBKRERELcIgSkTUZqyIEhERUQsxiBIRtRmDKBEREbUQgygRUZv51lxu30JEREQtwiBKRNRmrIgSERFRCzGIEhG1GYMoERERtRCDKBFRm3FqLhEREbUQgygRUZuxIkpEREQtxCBKRNRmDKJERETUQgyiRERt5gOoMe4XERERUQswiBIRtVl+2xZWRYmIiKglGESJiNosHz4ZRImIiKglGESJiNqMQZSIiIhaiEGUiKjN2JpLRERELcQgSkTUZqyIEhERUQsxiBIRtRmDKBEREbUQgygRUZvlW3PzvyciIiJqMAZRIqI2Y0WUiIiIWohBlIiozRhEiYiIqIUYRImI2oxTc4mIiKiFGESJiNqMFVEiIiJqIQZRIqI2YxAlIiKiFmIQJSJqs3z45NRcIiIiagkGUSKiNksSQAj3e1ZEiYiIqCUYRImI2kxr/CA8w2e4YBAlIiKi1mAQJSJqM60xCgRGSBhEiYiIqDUYRImI2ixJYDohDCyDKBEREbUGgygRUZtpDRsGsOnviYiIiNqAQZSIqM20hgkCWFhOzSUiIqLWYBAlImoxG8dAyNZcIiIiahcGUSKiFjM6AZSClZJBlIiIiFqDQZSIqMWsToBAwSgGUSIiImoPBlEiohYzSQxIyYooERERtQqDKBFRi1mtAalglGAQJSIiotZgECUiajG3RpQVUSIiImoXBlEiohaz6bAioyS3byEiIqLWYBAlImoxo2NAcmouERERtQuDKBFRWxkDay2gJNeIEhERUaswiBIRtZXWMLCAUq4qytZcIiIiagkGUSKitkoSWACQyg0s0gyiRERE1A4MokREbZVVRCUgpZugS0RERNQCDKJERG2lNaxvzVUBW3OJiIioNRhEiYjaKklcRTRtzTU6rvuIiIiIiAphECUiaiut3RrRtDXXcmouERERtcTSICqE+A0hxFdCiHdzr/s1IcQHQoi/FEL870KI29s9TCIiumZqai7XiBIREVFbFKmI/haAX5p63R8BeNNa+9cA/BDAf1nycRER0TJJ4taIcmouERERtczSIGqt/RMAz6Ze90+ttf6O5/8D8OoWjo2IiBaZmJqrYNiaS0RERC1RxhrR/wjA/13Cv0NERKvwa0RZESUiIqKW2SiICiH+PoAEwG8veJ/vCCHeFkK8fXx8vMmHIyKivPwaUaVgEk7NJSIionZYO4gKIX4FwL8D4N+31tp572et/a619i1r7VsPHjxY98MREdE0v0Y0bc21RgPzT8dEREREjRGs85eEEL8E4L8A8G9Ya6/KPSQiIirEV0T9PqKwgDGuQkpERETUYEW2b/kdAH8K4JtCiE+FEL8K4H8AcBPAHwkh/lwI8T9t+TiJiGhaukZUhR23j2j6OiIiIqKmW1oRtdb+8oxX//oWjoWIiFaRJDCwUCqElspVRBlEiYiIqAXKmJpLRER10BoWFioI3dRcBlEiIiJqCQZRIqK2SteIqrDjpubCAgm3cCEiIqLmYxAlImqrJIEFIIPQTc0FWBElIiKiVmAQJSJqq7QiKmUAqQKuESUiIqLWYBAlImorrWGVhJQKQimuESUiIqLWYBAlImorrWGkhBCCFVEiIiJqFQZRIqK2ShJXERUSQgVcI0pEREStwSBKRNRWWsNIAQEBGYRszSUiIqLWYBAlImorrWGVSiui3L6FiIiI2oNBlIiorZIERgkIIdJhRWBFlIiIiFqBQZSIqKVskgDSVUSlCjmsiIiIiFqDQZSIqKWMTgClICC4fQsRERG1CoMoEVFL2SQG0qm5MmBFlIiIiNqDQZSIqKWMdq25XCNKREREbcMgSkTUUjZtzXUV0Q6n5hIREVFrMIgSEbWUSVtzuUaUiIiI2oZBlIiopazW46m5XCNKRERELcIgSkRUt6urtf6am5or3RpRqWAFGESJiIioFRhEiYjq9NlnwK/9GvDkycp/dWKNqJAwUjKIEhERUSswiBIR1ensDLAWuLhY+a+aJHZTcyEghIBlECUiIqKWYBAlIqpTFLmXa0y7tVqP9xEVEggUbByXfIBERERE5WMQJSKqkw+OawRIk7bmCiEgIAApYTSDKBERETUfgygRUZ3WrYha69aIyvEaUUjlqqREREREDccgSkRUJ18JXTWIGuO2a/H7iAoBKOmqpEREREQNxyBKRFQnXxFdtTVXa1hgYmoupIJdY60pERERUdUYRImI6rRua26SuIqozK0RZUWUiIiIWoJBlIioTusOK9IaNm3NzSqiSrl1o0REREQNxyBKRFSndSuiWsPAQqgAANwaUanc3qJEREREDccgSkRUp3WHFSUJLAChFABkrbmcmktERERtwCBKRFSnDYYVGVjItCLqhhVxjSgRERG1A4MoEVGd1q2IpmtEp1tzuUaUiIiI2oBBlIioThuuEZVBCCCtiHJqLhEREbUEgygRUZ3WnZrr14jK3BpRqbhGlIiIiFqBQZSIqE4bV0Rza0SVgtGcmktERETNxyBKRFSnDYYVWViIILdGlFNziYiIqCUYRImI6mIM4IPjGtu3uKm5uTWiUnGNKBEREbUCgygRUV18NRRYc2ousu1buI8oERERtQmDKBFRXfLtuGvuIyrSqblCCAipYKx2lVYiIiKiBmMQJSKqi6+Idjprteba3LAiABBKwQIMokRERNR4DKJERHXxVdB+f/2KqBoHURmEsLDjdadEREREDcUgSkRUF18R7fc3XiMKuD1FDezq/xYRERFRxRhEiYjqkg+iesW1nenUXL9GFACEClxrLiuiRERE1HAMokREdfHtuAcH7uUqlUytYcVkRVSqwFVEGUSJiIio4RhEiYjqkq+IAisHUSMFhBDZq9ywIgZRIiIiaj4GUSKiuviK6OGhe7lCELVJAqgAUoxP46yIEhERUVswiBIR1WW6IrrC5FyTRICSEMhVRAOuESUiIqJ2YBAlIqrLBmtErdaAlFMV0ZBTc4mIiKgVGESJiOoSRUAQAJ2O+/NKFdEYUAHXiBIREVErMYgSEdUljoEwdGEUWGON6HRFlGtEiYiIqB0YRImI6hJFrhoapnuBrhBEjU4AObVGlPuIEhERUUswiBIR1SWKJiuiK7TmWj1jam7AiigRERG1w9IgKoT4DSHEV0KId3OvuyuE+CMhxIfpyzvbPUwioh0Ux64iukZrrlsjKqfWiAZcI0pEREStUKQi+lsAfmnqdX8PwB9ba38KwB+nfyYiolVs0Jo7c2puELIiSkRERK2wNIhaa/8EwLOpV/9tAP8w/f0/BPB3Sj4uIqLdNz2saJWpuToBpJq9RpTbtxAREbXPYAAMh3UfRWXWXSP6orX2cwBIX74w7x2FEN8RQrwthHj7+Ph4zQ9HRLSDNqqIJkCgrq0RZWsuERFRS/3u7wJ/8Ad1H0Vltj6syFr7XWvtW9batx48eLDtD0dE1B6bVEST2E3NnVojmr2NiIiI2uX5c+DkpO6jqMy6QfRLIcTXACB9+VV5h0REtCd8RVRK92vlNaLTFdEwfRtbc4mIiFonjoGrq7qPojLrBtE/APAr6e9/BcDvl3M4RER7xG/fAriXq0zNNa41d3qNKAAYrhElIiJqnzgGLi8Ba+s+kkoU2b7ldwD8KYBvCiE+FUL8KoD/BsAvCiE+BPCL6Z+JiKgoY9xazk7H/TkIVttHNEmuT82VCpCKFVEiIqI2ShL3a4X7gTYLlr2DtfaX57zpF0o+FiKi/RFF7mU+iK5SEfVTc/NrRIUAlOQaUSIiojbyAfTqanx/sMO2PqyIiIhm8BebNVtzrdbXp+YKt9aUFVEiIqKWsXZ8H3B5We+xVIRBlIioDrMqokVbcayFMQmEVBOvFhCAVFwjSkRE1Db5a/eeDCxiECUiqsMmFVGtYQEINRVE09ZcVkSJiIhaJv8wmkGUiIi2ZpOKqNYwsJBqcpm/a81Vbv0oERERtUf+HoCtuUREtDXTFdFVhhUlCSxstl2LJyAApdz6USIiImoPVkSJiKgS0xXRFVtz51ZEOTWXiIiofbhGlIiIKuGDaL4iukJrrlsjOlURFYL7iBIREbURK6JERFQJf8FZZx9RXxENwolXZxVRBlEiIqJ28fcFSnGNKBERbdGs1tyiFdF0jeh0a67bvkVyjSgREVHb+IfRt26xIkpERFu0ybCitCI6vX0Lp+YSERG1lL8vODpiECUioi2KIhc+ZXoa9sOKrF3+d9M1otOtudxHlIiIqKXyQXQwAPagu4lBlIioDnE8roYCLpQCxaqiSZJWRGdNzVWwZvcvXkRERDvFX/+PjtzLwaC+Y6kIgygRUR2iaLw+FFgtiGrt1ogGwbU3Cam4fQsREVHb5CuiwF605zKIEhHVIYomK6L+9wWDqIGFmGrNBdyWLhxWRERE1DLTQXQPJucyiBIR1SGOZ1dEi0zOTRK3RlRdr4hKxWFFRERErZMkgBDAzZvuz6yIEhHRVmzYmjtrjSiQVkS5RpSIiKhd/OyIft/9mUGUiIi2YnpYkf99kYrogjWiUioYtuYSERG1C4MoERFVYpOKqJ+aO2uNaBDAmoLbwBAR0VZpo/HBkw8wiHd/AiptKEncvYBSQK/HNaJERLQl8yqiBYKoTd9n9hrRAMZawJhSDpOIiNYX6QiX0SWeR8/rPhRquvx9Qb/PiigREW3JvIpogdZco937zF0jCrsXG2ETETWdse6hYGI4RI6WyAfRw0MGUSIi2pLpiugKrblZRXRGa65UAQyDKBFRI/ggGhvu70xL+NZcwFVE2ZpLRESlM8ZdcPIV0RVac00SA0JCKHXtbUIpWIBBlIioAbIgqhlEaQm25hIR0dZFkXs5qyJaoDXX6gRQElJcP4WzIkpE1BxszaXCZrXm7vjgQQZRIqKq+bC5bkVUJ4BSEBDX3iaCkGtEiYgagq25VNh0a67WwGhU7zFtGYMoEVHVfEV0zWFFNkkAqVgRJSJqOOsWS7AiSstNt+YCO9+eyyBKRFQ1HzbzrblSAkIUXyOqJISYURH1a0SL7EdKRERb5Sui2ujs90QzMYgSEdHWzaqICuEuQEWm5mq9oCIasiJKRNQQ+fDJqigtlG/NPTx0L3d8ci6DKBFR1WZVRAF3ASqyj2gSz18jqhTXiBIRNUQ+iHJyLs1lLSuiRERUgVkVUcAF0UIV0QVTcwNWRImImoIVUSpEaxdGGUSJiGirZm3f4v9cdGquVHPXiALpQCMiIqrVREW0rsm5xgBffFHPx6Zi/DXbt+Z2Ou73DKJERFSqWdu3AIVbc63WgJqzRjTopO/DIEpEVDdjDQLpwkVtFdH33wf+wT8Azs/r+fi03PSSHSFcVZRrRImIqFTzWnOLVkT91Nw5a0QBwMTRxodJRESb8UFUSVXfGtGnT13b545X11pt1uyIfn/nv2YMokREVdtwWJHVC/YRDcLx+xARUa2stRBPnyAQqr6KqK+EFri+UE2mW3MBNzmXQZSIiEoVRe5iI6dOwQWHFRmTuKm5M9eIuouY4RpRIqLambNTyP/lf0X4ox/Xt0aUQbT55lVE2ZpLRESlyo9ozyu6j2gyf2puNqyIFVEiotqZwSUkBIJnp/VXRCMu2WgstuYSEVElouj6+lCg+D6iOoGQaubbfGuuYRAlIqqdiSJICISnF/WtEWVFtPnmteaORoUeULcVgygRUdXmVUQL7yOqIfIXqxzBNaJERI1h4pGriJ5dIDEJrLXVHkAcj6tqDKLNNa8iCux0VZRBlIioavMqomFYuCIq1ewgmlVEecNBRFQ7E6cV0ZMzwNrq23MvLsa/53WhuRhEiYioEotacwtVROe35gopASFYEd2CxCT1tdYRUSv51twgSoDhsPogmt87dJtB9Px8MvTSatJrv1VqXDVnECUiotItG1a0pHXLaD2/IioVICXXiG7Bo7NH+Pjk47oPg4haxMYRBIAQCjg7q35ybj6IbnNY0e//PvCHf7i9f3/XpQ8JPrp8hI9OPnKvOzx0LxlEiYioNIsqotYCWs//u8bAWjN/jSgEIBUrolsQm7i+7ReIqJWy1lxI4Pys+q4KH0Sl3G5F9PISODvb3r+/69KvTSQMzoZnGCbDcUV0h7dwYRAlIqraomFFwOL2XK1hYOdXRIUEFCui22CsgbGm7sMgopaw1sLGMaSQCEQAnJ3X05rb6wEHB9sNolEEDAbb+/d3XXrd19LtD358eey+ZkKwIkpERCVaNKwIWBpE7YIgKoQAlIJdVFWltRhroA0/r0RUjLEGSGLIoAN15y5EXa25t265a842g2gcM4huIo6BIICGe9j5dPAURsCFUQZRIiIqzbKK6KKbhbQiKhZVRNmauxXWWhhrqt9+gYhayQXRBLLTAe7dQ3h+WU9F9NYtd83Z5hrROHa/dnjPy61K7wuMNbjZvQltNJ5ePXXtuWzNJSKiUhh3YzJ3jSiw+EKeJLAYb9MyTUC41tyEaxnL5tty2Z5LREUYa4A4hgy7wN27CM8uECdbDIOz5IPotltzAVZF15UkMErCWotb3Vvoh30cXx27IMqKKBERlcJfrOdNzQUKVkRnb98yroiyhbRsPoBqy88tES1nYdMg2gHu3kUQaySX58v/Ylm0Bp4/334Q1do9ZAV2OjRtVRzDhO5htBIKDw4fYBAP8PxA7fTnlEGUiKhK/kYgrYgO4gG+9/n3EOmo8LAiCzu/IioEhxVtCSuiRLSKa625kIifPanuAPy+ntteI5pv+WVFdD1xDB26B8xSSNw9uAslFb4KI7bmEhFRSfwF2wfRZABjjRvVXmRYUZIsXCMKAIJrRLciq4hyYBERFeBacxOIjmvNDSCRnD6r7gD81i3bXiOaD7gMoutJEmjlYpmSClJI3O/fx2moEV89X7q/eFsxiBIRVclfsNPQ6QdXaKMLDyuywNypuUjfZtiaW6p8FZStuURURFYRDTvA7dsIRQB7dlrdwKLpILqtiiiD6OZyrblSuHj2oP8AttfDE/scGA7rPLqtYRAlIqrSVEXUb26urV5pH1ERLKiIKlZEy5YPomzNJaIismFFnS4gJYLbd6vdS7SqIJqvtO7wesatimPowLXmKuFedoMubt28h2NcwT5/XufRbQ2DKBFRlRZVRAu25rp9RGevEQV8RZRBtEwTFVG25hJRAdk+oqF78BjeewCcn2UPILfu/Nw99Ox2WRFtuiSBCcatud4Lt19FDI3T0y/qOrKt2iiICiH+UyHEe0KId4UQvyOE6JV1YEREO2m6ImpmVEQ3mJoLcI3oNuT3DmVrbv0uo90d3kG7YzysqAsACO7eB87PkVQZRG/dAoQYDyvaxlrDOMYphjjDkEF0XbmKqG/NBYBbRy+gA4Xj00/rOrKtWjuICiFeAfCfAHjLWvsmAAXg3yvrwIiIdtKciqixplBrrk3fNm9qLsA1otvA1tzmOB2e4oMnH7gBX0QNZox2rbldV6cJ770AxDHii9NqDsAHUaDY9mDriiJ8gef4QlwyiK4rjqF9RVSMHzSLGzfwAIe4uHiGQbx7n9tNW3MDAAdCiABAH8Bnmx8SEdEOm7dGNN+au+BGwaSboS9dI1rVGqQ9wdbc5hglIwCobp0d0Zps7M7XvjU3uP8CBASSp8fVHEBVQTSOYWCh+z0G0XUlCYy6XhFFv4/76EMMBzi+quj7pkJrB1Fr7WMA/y2AhwA+B3Bmrf2n0+8nhPiOEOJtIcTbx8e79wkkIlrJVBDN1ohaDSjlWqiKVESXrhFlWCoTp+Y2R6TdzxAfCFDTmfR8L9LWXL+FSyV7iRrj9hGtqCKqYZDcOOSwonWlFVEppNsP3AtDBGEXd+MQT6+e7tx5b5PW3DsA/jaArwN4GcChEOI/mH4/a+13rbVvWWvfevDgwfpHSkS0C3Ktucaayb0phXDtuQuCqB9CtLgiGsAyiJaKrbnNkQVRPhCghjPREAICopsG0aMjBDJA/KyCwszzdO9JH0TTh59brYgeHrAiug5jAK2hAzkxqChzeIgHSQfGGjwdPK3++LZok9bcfxPAj6y1x9baGMD/BuBfK+ewiIh2VBS5sCnlxOTE7KY6CBbeKBReI8q2xVLtTWuuMcCPf1z3USzEiii1hYlGkBDjaqSUCI/uIDl9tv0Pnt+6BRgfQ36rlbKkQdQc9mGvrrYzEGmXpdd1o+RkW67X7+NwoHHYOcTx5W51l24SRB8C+HkhRF+4GvIvAHi/nMMiItpRcXxtUJEUcnxTvawimriQurQiumgLGFqZD6KhCne7IvrDHwK/+ZvAxx/XfSRzsSJKbWGiyAVRX40EENy5h/i0gqrWvCC6pdZcIyVw0IfW8eItyOi69GuilZwYVJTp94GrKzzoP8AwGeJidFHxAW7PJmtE/wWA3wXwDoDvp//Wd0s6LiKi3RRF19aH9oLe+KZ6yV5vfluWpWtEreFT6RL58BnIYLcD0JN07dr3v1/vccxhrJmcNE3UYFlFNBdEw9v3kJyfbv/8XGEQNdHIPUTtdpHAcJ3oqtKviQnU7IrooVt7e+fgDgIZ7NTQoo2m5lpr/ytr7U9ba9+01v6H1tpRWQdGRLSTchVRv4doN+gWr4gWWiOqYGGBstaJWgs8fFjOv9VSWUVUhrvdEnqabivx/vvlff+UyFdDAbbmUurRo0Z+rwKAiadacwGE9x7AJDH02Za3cDk/d9eTg4P0A285iIYB0OtBw3Cd6KrSa76WYvYa0X4fuLyEFBL3+/dxGV3uzIO4TbdvISKiVcyoiHZVF8YaWGvdzcKiqblxDEgFOetilZIqgCkziH7yCfAbvwF8/nk5/14LWbjqRSCDnbkBmOnkxE1vHg6Bjz6q+2iumQiiu1yZpmJOToBf/3XgBz+o+0hmsnEMAUy25t69DwBInny53Q/ut27xE1j9MWxhjaj2FdFeFxqWQXRVWWuumN+aG8dAHOOlGy/hzRfenF05baHd+F8QEbVFviKqYyipEKZtttrqpcOKjE4AJSEg5r6PCEIXm8oKor7N6vKynH+vhfamNffkBPipn3JVlHffrftorvFBVEnFiii5ybBAY1tBZ7bm3nsBABBvey/R83Pg6Gj8521WROMoa81lRXQNRVpzAeDqCkqqye1dWo5BlIioSlMV0UAG2RNQbfTS1lyrE0DOmayXKr0i6m9chsNy/r0WMtZACrlRALqKr/DO5+9MVPUaxRjg7Ay4fx/4mZ8BPvhgO4NNNhDpCEKIyXXVtL98AG3Y96k3qzU3uH0XUApJFUHUrw8FKmjNDcdrRBlEV+Nbc9WC1lygsQ9cNsEgSkRUpVwQjU2MUIbZhcdYs7Q11yQxoIKFT0SzNaJlTS70Ny6j/R0D4IOofwCwTnvuMBnCWotR0tDP48WFe3hx5w7w5pvue/XDD+s+qgmRjhDKcPdbpKkYH3i2sSVJCUwcX6+Iqg5w6xbiZ0+294GtrTaIZhXRnmvN3cHAtFVxDAsLIxdMzQV2siuJQZSIahPreP/a66a2bwlkkIWbIq25Vmtg3l5jKb/HaGlbuLAiOq6I5qvXK/J/J2nqHq8nJ+7l7dvAG2+4drD33qv1kKZFOkJHdSa3PKL95YNoUyui0QhSBm7ddSqQAXB0hORki0H08tJ1OOSDqJRLry/r0tHQ/dtBAB0oVkRXle7DiiCYu48ogJ0M+AyiRFSbD599iMcXj+s+jGpt2JprdAzIJWtE05sev+foxlgRnWjN9X9elW8lbWxLqZ+Ye+eOu2n92Z91+4o2qNrkg6gSqrmfR6pO04NoHEGGk1ttCSEQHN1BfPpse1u4TG/d4oXhVn6eTRyNH7D2QgbRVSWJqyQHwezW3Nwa0V3DIEpEtYl0hFg38wZia6aGFYVq3JqrrV6+j2iSAGrOU9OUUG5rF7/naCnHDLAimmvNXScE+UpooyuiQowHnLz5pvvaN2QiqbV2HEQ5rIiAFrTmRpAVftRdAAAgAElEQVRh59rrgzv3kOh4HBjLdnbmXqZBNNIRHp49hN1SRdQkcVbN070ug+iqsoronGFFvZ57OMjWXCKi8mij92udlzGu2tnpZGFk9YpoOjV3wRpRmQZRVkTLU2ZrbmMD1MmJu3H1bYSvv+7+3JDpuYlJYK3NKqLZlke0vxo/rCiCDLvXXh/euYcYGnj6dDsfeKoiejo8xfHlMUah2N6woiBER3Wgu+FOVu62Ko7dtOEgmL1GVAg3yXwHP68Moqt49Givb8SIypTdlO9Te52/AQjDrBKcH1aUVUQXTs3VS6fmCr9GtOyK6B6f/8oYVuS/1xtbET09dW25nhDAt74F/Mt/OVENr+v4/bRhXxEF1vs60A5peEXUJgnEVGsuAAR37iOGAZ49284HPj93D5TStYXDxP386nALFVFrYRI3rChUIZJehxXRVcWxa81VanZrLuDacxlE91iSAL/1W8A/+2dz3+XHpz/GV5dfVXdMRC3mb8r36kbS3yxNVUSlcBXOrCJqzNytV4xOstbbeWTgK6JszS2LtXZijeg6D1Aa//Dl5GQyiAKuPVdrt5ULXAj9/pffx+nwtPLDywfRTVqkaYc0eI2osQaIY8jOjIrorTtIArndiuitW+5hEpBN6jahKj+0aw1tDUQYIJQhdJdBdGVJAiMAyDmtuYB7qMDW3D02GLiL8fe/P/OE99XlV3hy9QRnw7MaDo6ofRrfprgNc4IogPHwlTREzquKWp1kw4jmydaIltWa6497zyuiQojNWnObXBGNY7d9y+3bk69/+WUXTtP23GEyhLGmli1oJiqiG3wdaIc0PYgm8ew1oiqEvnkD5umWJudObd0y0j6IbqEiGkUwsJBh163d7qbDitg2X1wcu2o1MLs1F3BBlBXRPeZPdsMh8Fd/NfmmeIBPzz8F4PYFJKLl9rIimm/NTc8VoXJtW9nwFd/GNSeIGp1ka0Dn8du3mLIGQbEiWk5rbpMfvuQn5ub59tyPPwaurrIwWEclMtIRlFTZr7qOgxrE35g3sDXXBdFkZhANVQjcPkLy9Hg7HzwXRPN7F+tAlR9E00E7MkynWXdCV7hp4MOBxopjV60G2JpLc/gbMCGAd97JXm2txY9OfwQlFG73bjfzSTdRAzW+TXEbVqmIzrmIW62XtuaOK6IlfW65RvTa9i1rteY2uSI6L4gCrj3XGOCv/mocRGsI0yM9Qke5m3pfNdirB1k0SevxObWBoWdRa24gA+DWLcQnT93PVpmsnQii/mcWAMw2gmhWEe0gkAFst+sG7+xgaNqaJIFWLpItbM0dDMr/fqkZg2hRviL6Mz8D/PjHwBPXTvH44jEG8QBv3H4DvaDXzBsMogbyN+XW2v2ZfDk1rMhXQ4FcRXRJa65J4gIV0XSN6DYqovvytZrigyjgbhQ2qog28eHLyYl7Od2aCwAvvgjcvw+8917tFdEsiEq25u49f18mRHMrovHs1txQhsDRbSQmHm+1UparKxfS0yDqBxUBaWtu2Z+rdNCOSltz0eu5wTtcJ1pcHEMHCkKIxUHU7t7nlUG0KF8R/fmfd3v5fO97uBhd4MvnX+LB4QMc9Y4QqhDW2q2F0UhH+Msv/3LipELUVvkbyL2pakxVRH01FHDhJpuaC8yviBq9NIiOp+aWXBH128/soXwQXWcPS2ttts5UG928hy8nJ+4hyI0b19/m23M/+QTRmZvyWUcAzAdRDiui7Ib8xo1GVkStta41d9awIhUCR7e2Mzl3ausWvz4UqKY1F74iumOBaavS1txF0/BxeOhe7lilmUG0KP8D9eAB8I1vQH/vHXzy7CP0gh5evfUqgHGL3baC6CAeINYxruLd+iak/ZS/gdybm8mpNaL5IOr3RVxaEdUJxLw1JCm5re1bgL1cJ+oflGRB1LdRr8C/vw9Sjfue91u3zNuf9s03AWsRfeim51Z9/NpoaKOvteayIrrH/H3Z0ZE7RzXs4Y7RCaA1xLzW3KMjJFUE0WQEJV21bautuZ2u+3/1uqyIriptzZ07qAjItuJhEN1X/geq2wW+/W38+OozxD/6CF+/8/Xs5iSU7uYvLqsdboofbsL2X9oFrIgm2TkDKD6syOokC5rz+DWipqwbjjh2m2kDe7lOdDqIrtOa67/fu8rdlDbuPH5yMrst13vwAHjxRUQ/fB9A9QHQX/+uteY2LdBTdfwN+dGRC6EN69YwkXtoJzvXW3OlkJD9G4jDLWzhMhVEh8kQXdV1XTeBXLg92FryFVHpKqIJK6KriWPoYPH+4FkQ3bEtXBhEixoOgV4PkBJPX76Dk0OJlz/8Av2wn73LtiuiPuBuK+gSVSl/A7k3QTRXEZ1uzS06rMgU2L5lKxXRmzfd7/ewIurbaDdpzfXf793ABdFGVfKsnb2H6BT9rZ+B/vJz4PnzygNgfusWT0m1P+cOus4HHb9NScPac03kHtrNas0FgDDoILl9azsVUSmzVs6RHqEbdF3XTbj4+rKWXEV0ojW3jZW7y0vg88+r/7hxDBOo+RNzAVZE995gAPR6GCUjPHr+GDd+9q/jxU+OJxaZbzuI+n+XW8TQLsjfiDfqpnyb0oqoCQNoo68NK7LWwqST82Y+3be24BpRP6yohHORXxfq1w6yIrpea66ZbM1tVEV0OHRf1yVBNPrpnwIAqB/9qPKfWb/9RD6ISiH359xB1+Vbc4HmBdGRD6K9mW8PZYj41o3tVERv3gSkhLUWkY7QC3quk8NfX8ocWBTH0DBQnXRYkQrcnphtrIj+8R8Dv/3b1X9ctubSUsMhbK+HT04/AQB8/ef/bQgI4Hvfy97FB9FtBUW25tIu2cuKaBQBQeDaloBrFVEA2Qj3eUHUWJsFzXmkVICQ5Qwr8sfhK6IMouu15trJ1txGtZT6ibnLguitG8CDBzj46GEtFVEhxGQ7+xoPBGiHDAau8ucfkjVscu64Inq9NRdw5//k6Kb7+StzS46prVustegqFxJ1kF5fygzt08OKACS9TjuD6KNH9Rx3WhFd2JobBG55IFtz99RggC/CEZ5Hz/H60evo3HsB+ImfcEE0PYEIIdyJZdsVUbbm0g7IVwT35mYyjrO2XGAqiPo1b0qM33daksDCLq+IQgCBKmf7Fn8c/mZvD1tzfegUcF+bdVpz/de8kRXRRVu35EQ6An7yJ3Hw1Qns2WmlD5AiHSGUIURumNI6XwfaIVdXbu36kknjdTHxkoqoSiuixoz38S1DLoj6ibndoJtWRNOK25Zac4UQ7ueyjUF0NHJbM2pd7hraIuLYVUSXDCJEv8+K6L6ygwE+Dwa4c3AHdw/uuld++9uuNffjj7P3C2SwvWFFfo0oW3NpB2irs+rGXlVEO53sZ3m6ugMAWqY32rMqolrDwGbDiOYRQri2rDIupv6GhRXRiYrouq25jVwj6m+Cl1VEdQTxxtfRQwA8/qzS/0N+6xaPFdE9Nxi4G3NfcWxYRdSmxyO7s4NoIAMkNw9hYctbJ2rtRBD12/35YUUmLD+ImmgEKJU9IFVCQXc77QtMn302nrxc9UONJIFWYnFrLuDW/bbt87oEg2hByeASttvBzc7N8Su/+U13EnznnexVoQq3XhFt1JN0ojXlt2LYmyBapCK6qHVKa1hg6dRcAJAygElKrIgeHrqtPfa4IppfI2qtXWkvUB+YlHADKRp1Hj85cdey7uyhKl6kI4S3biOABIbDSkPgzCDKiuh+GwyaXRFNW3PFnNbcUIbA7XQLl7LWiQ6H7vOQ27pFColQhS4gbmGNqIlGQBhmIUpJBX3QbV9F9PHj8e+rfKhhrWvNVUum5gLuPM3W3P2UDK+AbnfixhFBAPzczwE/+EH2jbGt1lxrLRIdI/j0MawxzbqJIVqDtrnW3H25mfQV0bSrYWJYUZGKaJKkFdElT00BCKXKqYjmtpxBp7PfFdGzM+D4eK2tQ7TR2V5+javkLdu6JRXpCJ1OHyrsuiBa0c+ttRaxiWdWRPfmIRZd1/QgGkeQEOOK7RS35+YBkjAoryI6vYeoHqEXuIrsxLCiEj9XOhoBQZCFqEAGSLphu4Nold9L6XXdBgFbc2mOOEaiI6AzFUQB156rNfAXfwEgnYK2hdbZxCTA8Vc4+L/+CPjkE64TpVaz1kIbjUAGbpPtfbmZzFVEpZh8+pmFGxj3kGtOa26RNaKAG1hUytRcf0HudNwWVvtcEf1n/xz4vd/Lvm6rfN9qq7OHDducJbCW09OlbbnAuCqpDvqVVkRjE8Naey2IrtMiTTvEB9GGtuaaaLQwiIYqBIRAfPdoa0F0mAyz5QDbCqImjiaCaNaaOxiMW13b4PHjcVdIld9LaRCFWjKsCBi35rbp87oEg2gRw6FrnejNCKIPHgCvvebac61FIN22DKu0bBURmxi4vMIBAuCLL5p1E0O0In8Dr4RqXnVom3JrRKfPJVlF1KR7ic5pzS2yRhTwFdESg2gYuov0PldEh0Pg4mLya1WQr4gCDWsp9YNSlgTRfFVS9Q8rrYjO2kMUaNjnkap3deUqRE2tiPogGs5eSpFt+XfnqLzW3FwQ9Vu3+EndSuZac0tdIzoEwnByn+VO6M4tDXs4MNfFhfvcvf66+3OV30vp9jcIguVrRPt995C6Yd/rm2AQLWIwgIYFut3ZZfNvf9tN2nr0aGt7iSYmAYZDHCAEvvySA4uo1XzwDGSw1lYYhVkLfPhhc54epkE0MclEWy6AySrbnIqoTS8+hdaIqqDcimgY7m1F1MJ9/8goAQaD9Vpzm1oRvbhwXT1LWnMTk2RVSdW/AYxGlT1AmhtE13ggQDvC34w3uSLqW3PnBFE/rC6+fdM9DCpjKcX5uVvLf+NGtnVLvjUXYeCqb2WuEZ2qiGatuUB72kg/+8y9/PrX3cvKg6h1QbRIay6wU+tEGUSLGAxcRXRWay4AfOtbrlLwzjvZzWXZQTHWMTAcoo8QePIE8bAlP9xEM/gbRyXVdoPoBx+4zak//XQ7//6qcq250+cSIcS41TAMZ14I/fChYhXRALaMG3RWRMcV0djd/EptJl5fxERFtEldACtMzAXQuIoosEfDzmjMrz88OHAP7oDGVYlMNHIPDeXsW22/Zjw+ulneFi7n526rLaUmtm4B0iAapEG01IpoNBGilFAw3dA9wGvLOtHHj93X6bXX3J/raM1dto8o4FpzgfYE/AIYRItIW3Nl72D2N0mnA7z5JvDeewii7Uy29RXRLhSEMUg+f7z8LxE1lP/58BNEt3ZD+/Che3lxsZ1/f1W5YUX5rVu87HMxryKaVjhlUGCN6DYqot3uXlZEs31E08+FGrqblJVac5taEfV7iK4URG9UukY00hGUVNeqBVlFtCmhnqqTD6JSzl/OUCOTxJDB7PWhXihDJLfSPZrLWCea30M0SYOob80VCpAKWpQbRHU8AoLJ1lx0e67K16Yg+sIL44pjk1tzAQbRvZNWRINef/77fPvbQBwjfP+HAFD6MKHYxJCjEVSvjxAS8eOHpf77RFXKtrLYdkX00SP3sikn7QUVUSBXKZsTRE3swoAo0JorpIKdNfBonWMGxq25e1oRlUJmT8nVcJS9vqjpNaLW2mZU8k5OXCvf0dHCd5uoSvb7UFEMXcb2QAXM2roFGLezszV3D/lz+sGBC1ydTuNac20UQcxpy/UCGSA+SoNoGetEp/YQ9Vu3AOnPixAwJYf2Wa256HZduGpDELXWBdFXXqmnzTuO04ooW3NpnrQiqg4WBNGXXwbu30fw4UcAyq+IxjpGMIyBu3cR3r6H+LNHpf77RFXKWnO3OawojoHPP3e/b0IQNcZtWh26EDK9RhTIVUTntOb67VgKTc1VAQxbc0uRBVG/RjcNopusEQUasif06am7cV2yJdBEVbLfh4KAHlRzMzQviK6zVpd2RBpwom6Ad796F6dB8wa4mDiCnDMx1wtViKQTugBUVmtubusW35YL5OYQdGZfX9Zl4mhyWJFQQK/rlrQ14dq7zLNnrtPnlVfqGXyVJK56XGRqLiuie2owgF5WERUCePFFqGcnEEJspTU3HEZAv4/g5Vdda25TBrAQraiSiuhnn42HPzThpJ1e2GLl9gldqyKadlqIAq25pU7NldIFlV7PHVcZldYWMdZAWmT/71Vbc401sNZOrKFa5e9v1cnJSlu3AEiDqIS+er7lg5vxsXMa9XmkaqVBdOBzQygbVxE1SbS0NTeQAWKbuBbjTZc9jEbuV6411w8qAnIPbkK11WFFrjW3257WXL9/aI0V0cKtud2uuxY34Z6mJAyiRQyHSDohgiUnFNy9C5yeutbZsocVmRhBGkTDl19zw4rK2ndq31gL/PCHDPI1mqiIbmuNqG/L7fWacdJOL2xJOFkVy5uoiM5aI5r4NaJLzkXwa0RLqoj6p8R+j7U9q4oaa7IBRQAghsOV9r/139/+a96oiujJydKJucBUGDw4cBXRq+1XRLXR0EYvrIjW0eL85OoJ3j9+v/KPSylfEe2k3wNNXCMaRZBhgTWiJg2im4a2qa1bRnqUrQ8FchXRQJX3ubIWOrm+jyj8Fi5tCaKdjtuO0T90rXiNqG/NXVoRFcJVRdmau2cGAyTdYPbE3Lx79wBjEFwOtloRDV993bU8POQ60bU8fAj8438MfPxx3Ueyt7TVkEJmk2K3ciP56BFw/757QNSEIOorooE77c4cVpSviC6cmrvkqSlc1bS0qbk+iPbSp+t7NrDIWAOZ5D6Xg8FKLeVZB4AYrxHNv742SeIGeRWoiI706HpFtILp7fMm5gL1Diu6iq9wFV+Vvmc4FTQYuMmwwl07dCCbF0TjCLLTXfg+oQphrXXbnWx6Xs0FUb91S7411/+8mLDE0J6GKJX7f2YP2nqd9gTRr31tPN246vXGaWuuDEIIIZa/f7/fjHuakjCIFjEcIumGy4Po3bsAgODseflBNBoijLRrzb3/Amy3g+ThJ6V+jL3hnySxolyb/OAWH0RLvaGz1gXR115rzknbV0QXteYWnppb8T6irIhC5qvLV1crVfKzKdGyYWtEC27dcq0q6deIVlARXRRE6xxW5L92tT9M2FdXV25QUfr9YTpBM1tzl1RESw1tuSCabd0yoyJaamhPg2j+mpQ9aGtDENXazZJ45ZXx6+bMaNiatDVXhYsfWmQOD5txT1MSBtEC9NUl0Oku791Og2h4/rzUqbmJSWBHQwSQriKqOsALLyJ+9ElpH2Ov+BOj37aAKpcf3JI9pS2zKvr0qTtRNzCIxsHiNaLGGti5FVF381t4am7ZQZQVUWcwWKmSn29Fz7+sfW1jwa1b/FKTaxXRQb0V0Ym9dyuWBdG6v4b7ajAA+v0scOky201LYuJ4+bCitDMmLrMievNmtnVLfo1o1pobhuWF9ihyQbQzGXiFENAH3WZcexf58ksXRtMgGusYz0Nby9TcZQ8tMk25pykJg2gByfAS6HaXV0QPD937nV2U+qQ71jEwHCLMgmgIvPQS4idfNf9pUxP5kz2DaG2mK6JAyUHUrw9tUhBNb5ISJRDIYGYLTrbmLZBz1oimU1sLVkRtGWtEo2jvK6LWWogyWnNz27dsY6jdynxFdMka0WthMAyhVFjJ1NxIRxBCzGxlB7DdfYgX8A+bWRGtyWAAHBxk35smKHcAz6asdXt1igLDigAg6ZWwnvL83N2HBgFGejSxdQuwpTWic0KUEgq624KKaH5QEYBPzz/FR+K0+qm5wkIVmP0AgGtE91EyuAJ6BYKoEMDduwhOz2GsKe3GOjEJMBxXRAMZAC+96NaJfvppKR9jr/gTYxmj0mktExXRbQwcefTIDX+4f9+dtKOo/kmvvjU3kHPPJVnrlJodRH2rbbGpuSVu3+Kf6u9zRTROvx5KZRXRogFouiLqf197iDk5cW3gN24sfLdZVUl10IcdDbc+KCjSEUI5f+2U7yKomn+I0Ii9YPfRYICk18l+tppWETVGA0lSaI0oAMSdtAtmk+vU1B6i+fWhQK6DoOTWXA0LNRVEAxm0Y43o48cuvKf7KF9EF6VPFV4qjmGUgly2h6j3t/4W8Hf/7naPqUIMostYi2R4BXQ6y4MoANy7h/DEtUeU1Z4bG18Rdfu3hTIEHryAWFgOLFpHGRXRzz5jRXUDsyqipd6U+/WhfsIcUH9V1A8rkrP3EAVyLZuBcu1CZvImN1sjWmQfUT+saNO1t1wjOtmae+tWtka0cGvuVEXU/772iqjfumXJgIxZVUnVPwSGw61XI+dt3eLV1ZrrPyZbc2tydYWoN/5+LLXKVwKTxIA1S4NoVhHtpv+XTR7y5fcQTSYn5npSyHI/VzNac4G0U6GbVnmbPNDr8WNXDRUCg3iAWMewgYKJKrzGxTF0ICeuDwv1euOHwjuAQXSZJEGiI6DbKxZE795FcH4BGF3aTcZ0RVRJBRGGiF+4N25BpOL8E7rhcP2ndf/knwC/93vlHdOeyVdES2/NHQyA42MXRIHmBNFsWNH8img25CEdaDT9dNwkMaAUxLIR73AVUVi7eVV0VhDdx4poPoiu2pprdFaN8AIZ1B9iTk8Lb90yXZVUvb4LolsOgcuCaB2tudrobLha7VXtfTUYYNRz59GO6owrog0JPWbkzpFF1v2FKkScbkOzUQUxDaJ+65b8+lBPCumm5pZV8VvYmhu6r0dTrxejEfDkSdaWexFduNcHYbVBNEmglVw+h2ZHMYguMxi4TXm7nWJPK+7dQ2glcH5R2l6isY4hhiMXRA8OAKR7T33tRfc0p4x1YPskf1Jcpz03jt3fe/hwPByAVpKviJY+uCW/PhRoThDNV0TnrXfLV0SBa0HUag1ItXyvMaRBFOO9R9eWD6JSujbdfayI+tbco6PVhxXlHrx4gQyaUxFdYlYYVP0bW6+IWmsRm3hxEK2hxTl/ba/9YcI+SltYR2l4OwgP3Lp6/7YGMLE7Ry6riALpuaCTPpxcN7TFsQuxt24hNvG1rVs8JZVrzU2SckL7nIpoIAMk3fTntqntuZ995j4HPoiOfBANoOOKW3ODYtf1XbSf/+tVDIduLWaRYUWAq4hCAudnpd1kxCZGMIpdKT7dPzBUIeKXXnAnny+/LOXj7I3BALh50/1+nfZa/3esBd57r7zj2hPWWhhrtlcRffTIBSY/jr0pQTSKYGGhF6wRvVYRnbqpMjoBlCy015hM15H6vUfXlg+igKuK7mMQ9RXRoyMgSaC0WWmN6PSDzNrXiA4G7qZ37SB6CIxGW/0/+BvqplVE89d2VkRrkAabUUchkAFCGbp19UBzgqiviHaXB9FQhojDDSuiua1bhon72Atbc4FyPlfzKqJSQXfS60ZTg6gfVPTyy7DW4iK6cNfmsOKKaBxDB6p4a+6OYRBdZjBAAoOg1y/2/j6Inp2X2pobDuPxDTXSE9eL990f2J67muHQbV4MrBdEnz51L7tdBtE1zJogCpQcRF96aRyeDg/dywYE0URJQCwIomJxa65NW3NXq4iWHER7vea2Wm2B/77MKqLpGiw1iifevkgjK6IFJ+Zaa+dXREcj6E2/vxZYtHVLdhw1BPqJIMqKaPXSYBN1FLpBd9xuCjRmcq5Nj6NIa24gg3EQXffcmt9DNN26ZWZFVKhyQ7vfA7Mz2QashIL2Vd4mB9G7d4F+H1fxFbTROOodpRXR6oKojWMYtubSXGlFNOgdFnv/fh+ydwB1flHesCIdIxhFE0E0kAGSfs89nefAotUMBu7m6+BgvdbcZ8/cy7/5N93UYg4tWsn0BNFShxVp7S4ur78+fl3azl57EI1jxKH7v84dVpRVRGffKBidQBR8auoHGm1UEU23INjniqhfCygT7TpS0gcbMr1hLBJEZlZE00qerWtNW8E9RBOTzKxKqv4hYO1Wt3DxQXTWDbW3Sot0WVgRrVl6Lh+FAl3VdT9Lc7pI6uIrarKzfKhMqEIkm64RzQfRdOuWWQ9wSq+ILhhWZLtdGNhmB9Gp9aG3e7eBMEiHTVVzbjZxBAQBW3NpjrQiqnoHxd7fb+Fy/rzciuhgMoiGKnTTvV59lRXRVfiF872euwFbtyLa7wN/42+4P7MqupLpimiprblffukurn59KODadA8O6g+iUZStA1q0fYsQYn5FVGsIVSyIZhVRvcF5yH98VkRdRbTTyc7DviJaJIjMq4gW/ftbUTCIzqtKqkO35UsVQXTemmogveFN2/2r4q/tgQy4fUsdBgNYWEQdhY7quGtIGLrQ05CKqA+iokBrbiADmE56/CVVROc9vJkIoiV8rrLAPWP7FvR6bmlb3dfeWS4u3Ocstz70IDxw7cxBAA1T2UMNHY+AIGBrLs0xHELDIOgv3mdtwr17CE7PyxtWZGKEw+haay4A6Fdfdj9MZ2elfKydNxq5MHpw4Kqi6wTRZ8+Ae/fc33/1VeDdd8s/zh02qyIqhCinxc13B+SDKOB+duq+GMYx4nSgxsIb63zr1PTUXJ1AzqmmTitljai/EO9xRfRaEE0r7GoUTbx9kcQkM9eIAqu3dh5fHuN59HylvzPTyYn7vyy5UZ4fRN06e31VwrEs+NhKLl47VfqwswISk0AKiVCFbM2tw2CAGAa220E36LrvgYrDwzLzAtosoQwBId1eoutWDy8u3EPCMHR7iM5YHwqknRgltuaayIWo6T0wlVBAt+O+Jk2siH72mXv5yisw1uB59Bw3OzfducY/1Kjoe8mssORmF+3n/3oVq64RBYC7dxE+v0ISbV418K1bweB6ay4AxK+max1ZFS3GnxB9RfT0dPX2i2fP3LoCAHjzTeCLL9wIcCrEV4DyVcHS2usePXLt6uk6vkwTgmgUIUnXAS0afLaozcwmCWTRimjgwqPdZKr2rCC6pxVRkSTu85AGUTl0N5pFW3Onv+bZ/oErds58ev4pji+PV/o7M52eFh5UBMxYp9nvQ0FCX263IrpofSiQa2evsLKcmASBDOofOEwD55kAACAASURBVLWvBgOMkADdHrrKrRFFEFQaHpbJgmh3eWtudj/XC9c/t15dZfeII72kIlp2EA3Dax0fSipASOhup5lB9PFj1y310ku4jC5hrMGt7q3se0lXWF3PKqJcI0ozDYdIOiGCYPlTrcy9ewisQHL6bOMPHxs3pjxMzLXWXACI7991N0cMosX4k/zBgbsJ09o9SSwqjl0F+t499+ef/VnXjs323MKyimjuCWopN3TWup+D6Woo0IwgGsdIAlf9XVThkUJCyzn7iFa9RpQV0XFFNJqqiA7SILrk+3Z6SrS3ToDSRsNYk4XDjaywdcvMquTBARTE1ltzlwZRUfKwswISkyAYRVCffc6KaB2urjBSAIIAHZVurReElYaHZVYJov5+LultENrSIBrpCNbamXuIAr41t7wg6kPUdDUvW3pw0G1uEH3xRSAMcRFdQAiBG50bWXW9yocaOl0jytZcmslcXcJ0O8W2bvHu3kUIhfj06cYfPzEJMBy6SbwzWnNjq117KAcWFZOviPppkau05/pBRb4ieuuWG4zz7ruN2Ui76XwFKH9jXkpF9Pzc/coPKvKaEESjCHEoF7blAr41d84aUaOzgLlMKVNz/d6nCvj45GN3093tutfvyf7FWRD1FdH0l6+ILvu+nV4T7a1TEfUBdOMgaq2riC6ZmOs/1sww6CuiWw6i81oMvSzQV9yaG/zF96F+/w+h694Ldh8NBogOOhBCjNeINq0imu5DWWQf0ex+rrtBa+5gAPT744m581pzhSp1Pa1rzQ2vBVF/fU96nfqvvdOsnRhUdD46Rz/sQ0kFIQREmLYUV/RQwyQxwH1EaR49vAK6ndVK5vfupXuJbr6FS6xjYDhEOBVEJ25iXnvNDWlpyJPARpuuiAKrTc71W7f4iijg2nOPj4GvvirnGHecvzHPn3RLCaK+K2BRRbTOhwVxjCRUSx9qKanmtk6ZJIYIigVRWUZrbnpOuZQaJ4MTXMVX7iEOsDdV0WsVUcBVAwu25k6vifbWWdvo5w5sPH/g4sI9SFhzD1EAQKcDJQPowXZuMrXR0EYvrYiWOnW7oMQkCK6Gbi/Z0f60qTfGYIBRz1VDhRBZuKoyPCxjohEgROHtW4A0tG3SmntwMN5DdEFrbpnraedNfM0eEPUaWBF99sx9nl9+GdpoXMVXuNm5mb1Zhp16KqJszaVZksEl0O2uVhE9OHBrSk/PNg6iExXRw/EWMkq6pyexSSeEGjPenJfm8yfEgwO3llCIzSqigGvPlZJDiwryW1kIIbLXlbIp/cOHLii8+OL1t/X7rrpY59PyKEKs5m/d4imhoP2nZsbU3OIV0bRlsYSKqB9ukZhkPNxmT9aJXquIAi6IFmzNnVcR9X9epyJqrd1se7CCE3P9x5wZBoWAOuhvrSJaZA9RoL5hRcFgBAkBPWpYtWcfDAYYdYPse6OJFVEbR26dfu46N49frpFsMqwobc0d6VFWKZ6l7M9VNqxoTkW0kUHU3yu/8gqeR89hrcWt7niuhOp0q2vz1hrGarbmrksIcVsI8btCiA+EEO8LIf7Vsg6sKZLBJdBZMYgCCO/cB87PNt5LNDbxzNZcIN0EWee2quA60eX8zXOvBwQBcPPmakH06VP3QCA/afLwEPj61yfac794/gV+dPKjEg98d8zayqK0iugrr7iHAtP8z06dLUJRhCQoVhGdu4+oWWGNaFYR3eBhWPrx/ZqixCSsiALAwUHx1tw5FVEppFsPvEIlL3892ag9t2AQNdYgMcncm1rVO9haRbRwEK14WJG11g2fuhpBQcCORvXtBbuvBgOMOiprP1VSAUpBi+YEURNH2Tm4CCWUG+yzzgO+OHa/0tbcRe3sbj1tOoynrIpoGF4LUVm47obNDKKdDvDgQbY+9LAzLvRUWhFNEve14NTctf33AP4fa+1PA/g5AO9vfkjNkgyvgN7qQTS4dx8427wiGusYwSiGgLgWREMVjm8MX3iBQbSIwcBtSu8rG6vuJeq3bpn25pvu3/n8cwDA2fAs2yCZJvmKaN7Gw4qiyLWnz2rLBZoRROMYsVo8MRdIPxf+zDxdEU2Swjc3fmquKSGIzqyI7kkQtXAhQ0bxREUUV1eFKvnzKqL+detURKd/v7LTU1epOToq9PHmBtGDQ3eN3IJVK6JVDSvK9hC9GkJBAqOIk3MrZi6fI+kGWfupFBIQAiYIGtSaGxVqy/UCGbiKaBxfO+8v5YNeWhGdN6gImKqIlvC50nNac4H0WubbjU2D9tt9/Bj42tcAKXE+OseNzo2J41edXnVt3nEMDQMxY53tvlj7fy2EuAXgXwfw6wBgrY2stSsstmsBa5EMroDOisOKAIT3XgAuLzfewiUxCcJR7G4aepMnl1CG47VCr73mgiifzC42HLrPo2+X8Vu4FPX06WRbrvfTP+0CbtqeO9KjjR9C7KqtVEQfP3YXulmDioD6g6gx0EkEGwbLhxVJBSsEjBTXp+aaJGu5XabMiqieVRHdt9bcOFcR7feBwaDQ9+28iijgbj5XXSPqg9lG60RPTtygtSXfS0WCqBlup9oR6QhCiKXXXiFEefsQF5CYBLA2DaICiEacnFslazEaPAd6vXFF1LeBhqpBFdERZKd4EFUyrYgCq59b/XXt4MBVROesDwV8aE+3cClt+5Y5QVQq6G7o7kubcr3Q2m2598orSEyCQTyYaMsFKq6IxjEM7EoPLXbNJvH7JwAcA/hNIcT3hBD/sxDicPqdhBDfEUK8LYR4+/i4hL3PqpQkbiJet7dy77a69wCwFvGzzf7PsXEVUfT719YaZK25gAuiw6EbmkPzDQbZ9gsA3NTIi4tiTyCjCHj+fHZF9OAA+MmfBN57D8ZoxDrOtm2gSbMqohsHUd8N8Oqrs99edxCNYyQwQBAUqogCgA6u31SttEY0HWpkNrmY+tZclVvPuGcVUWMNYA2k1hOtuRgM3NTYNdeIAu5rvWpF9CA8gBRy89bcTfYQTamDPuxwsJXznF+bKgqssatyP8/EJEAcITDWVUQjVkQrFccYmQjodrPvS/8wwgSqORXROIJcYds/15qbPqRctZU1va5F3QDGmsWtuSWHdjfxdXYQDWSAxIfrprTnfvmlu9975RVcjFzXWn5QEQCobq+6NaJpa65aoY1712wSRAMA3wbwP1pr/xUAlwD+3vQ7WWu/a619y1r71oMHDzb4cDUYDJDAQHZ7K5fMRTo5N3n2ZKNDSEyCcBhfa8sFxq251lquEy1qMJisLN+5M97KYJlZg4ry3nwTODvD6JOPslfxSfl1syqiGw8revjQtaf35rQk1R1EowgxDBCGy4cV+TVvgZy9j2jBIFrK1NysNdeFgb2tiCaJWx6Rb83VGsqYtafmAmlFdMU1oh3VQajCzVtzC27dAmBuFV/1D4HhCHqTqvuCj72sLTc7jjKGnRWUHyCoINz/n+f56gwGiKCBbm+i8qeEgg6DBlVEV2vNVTI9fmD1c2sa8kZd9/eXtuYCMCV9ruZNzQU2DNfbkhtUdD46h5IK/XDy/lqqEKaq9cZpay4rouv5FMCn1tp/kf75d+GC6e4YDpHAIDi4HgKXSoNovGEQjXWMYDiaHUTTm4PEJC4cHR4yiC4zHE5WRFfZwmXW1i153/wmEAQYvfvn2avYnnvdvIoosOY6L2uBTz+dvz4UGLdjt6kiOuOJtdW6+AAMpSAgYDYZmBa7ZQFGuiCqrd7LiqhM0qCRr4gCkMOo0D6iUsiZlb1V1ohmg4Mef4HOxdX6QTRJXBfIChNz51UlVf8GYI3b5qxkKwXRqiuig0EaRCUQjdj5UqWrK4yQQPZ6E+dSKaSriDYliEbRSq252RpRYO2K6KjjrqOLWnP9tbeUIGoMtI6hwjl7lkoFve7/aVseP3b3ykdHuIgucKNz49r5TakAuqr1xmlr7rzP4T5YO4haa78A8EgI8c30Vb8A4K9KOaqmSCuiQW+NINrrIewdIjl9uvaHN9bAWINwEM2tiALphVGI8TpRmm+6IuqrAkUGFi2riHa7wDe+gdEP3gPSGxO2bF03syK6ycCR42P3gGFREBVivJdoHaIIMTQQhIXWiALpgKB8RdRaGKMLT811QbSEimgYQqdfl8Qk42Ffe1QRlUn6fekroun5WEXx8tbcGQ9evFXWiPplGOEf/B/o/MH/iXjd8Hd66h7ebLJ1Syro3wAA6MtyB7NZayfWwy6jpKp2WNHAVUQlBFtzqzYYYASN7uHkoK2sotiQ1lybxNnAuCKUUDCdwA1HW3ON6Ch0D7wWXWOyfXfLaGNesr5RCQXdCSeOsXbHx8BLLyEyMUbJ6Nr6UKDihxpZay4rouv6jwH8thDiLwH8dQD/9eaH1CBpRVStE0QBBLfvIjldYSLrlOzGYzg7iPqngRMDi54+BS63s6/bTpiuiN686bZxKRJEnz5177/oKee3voXR5Xk2PZcV0UnGGlhr51ZE12px8w9fFgVRoPYgmqStucXXiE4FUWNgYSHDgjc3QQAJsfnU3DDMbrSz7+dulxVRAGoUF5qaO2+jciVU9sBxmUhHQDRCZxijc/Yc0Z/+v+ttG+K7Pwq25i4Kg6rvxkLoy+erH8cCsXFr7IsGUSlkpa25ajiCgICSgZuay9bc6qStud3+1ICZplVE4wiyU7zKpaQC/NrEdSqi3S6GNkZXdReuqx635pbwuYoiF0Tn3BMFMoDuhi5cN6UienkJHB7OXR8KpOflMICt4hrnw/wK1fNds1EQtdb+ebr+869Za/+OtXb91NVEgwE0TPbUd1XhnfuIN6iIjqfzLW7NnRhYBLAqOo+f3JaviArhbsiKrhGdVw31vvENjEKB4KNPAHCN6LRFeyoCa1ZEHz1yrTbLvjZ1BtG0NVeFy4evZK1TwVTrVJLAwBaviKYDPDaemhuG2ddFG+3CT7e7XxVRX1XOrxEFIEfLW3MTkyysiALFzhOxiYHnzxFCoXP3AfDee4g//KDg/yKn4B6iQJEg6q6NSckV0aJbt2THUXFrbjB0x6fu3HVTc1kRrc5ggBESdA8ng6gSyj28a1IQXaHdUgkFdDtu25BVQ9tgkG3dsqgt13OhvYTWXB+i5lTzlFRAp+P2d21KEL26Avr/P3vv9iNJdp8HfuecuGVmXbq7uofd0zM9nBlqBuCQNEFRNM2FYVs2IMhrLGTDDzKwL35ZP+7bAvtf7PNiHwV7AZnwCtLC1gKW9UCTokWZpDTD0UjsufcMp7uqu6sqM24nTpx9+MWJvMXlRGRWZnZ1fQDRnKqsjLxEnDjf7/t+32+Is+QMDncwcAdLDylH3MjNjW+5suZeoRplj+hSGLAVnOtHUJNz6J72B5lLIJNwc7RbcwHgxRdJ3fvgg17Hu/RIEiKjg4WF59o1e0W0jey4LpIvv4zh+58AubpSRBdQlyC60lD6jz+mIkxbuubWrbk5XL/dXTG1Ts0rorr4/9Y9ooyBc2c9iugMUSoDi64UUQiLGZIqb1BEO5z3qUoLIsrh/tZvA9euIf3D/6dbQeD8HPiv/5WcHXvNBVaT/N1IREekJqhovS6czkR0w2FFTpwCQQC+fwB2pYhuFHJyjhwa3qhCEd0Va67WyDNp715BsRYwTlbWPtbc4RBJ1jxDdPZYayHtFtZcMA7l+7tBRLOMzo/RCOfpOfb9ZTUUKL4L14Facfyi7WtS0BBXYUVXqIIOQ2RM9yeiRzcBANnxw15/P5vOV0VEOePgjE+tuY5DI0Tee+9qnmgVzEK4SESvX28noklClo66oKICWmukr72CYaKABw+2Wil/NHmEs+Rsa8evwtoV0cmElOo2Wy6wE4qoY2HVqrPm5hld57ZzRAGAcVES2F6YUUSNeleOcHmeiKisIaJRAq11o0VWaVVrx577TFsglYSY0MgY79Yd4B/9JuT4DPiP/9HujcQx8Hu/R9fAv/pXrYUbGzIo9goiGm6ZiG5QEZW5hBMl5MIIAog0u1JEN4h0cgY4Dnx/fl8muKC++l1QREu7pb3KVa4FgdfLmisDt3V0i8HaSHuaEonyqslv6fgY7AgRLe7/sS8glazsDwWKe/AGFVEi81eK6BUqoKIJ4HpwWsYt1MG9QeNq5Ek/IiqVBOIYbg0RBUgVlbOpmG+8QTbTh/2OealhqoyLIz6uX6ffNS2UbUFFBVKVQr90F74/gvP+h1tVRB+cP8CjyW7Nla1VRPuGFdn2hwJTIrqNIk0RVuT4yzagRTDGqOdtYVOlCyJqrYgC4EKspoimKVmrtCpJgdKKrqHnxJqrtQYzZN4oHI4DeB54QhuVJiLSFlZkHtOGVKVwJxEgBLzDG8CtW0i/+23g5z8H3n23+Y+lBP7dvwOOj4Hf/V1yz1gcD2gmgzwYgDG+diL6NH5azku1geCitSCwLtBItbQkojy5Gt+ySSThGRAESxZUIlc7MkfU9E52Gd9iCpCB10sRjQNam+ytuWvoEW1TRIt1Lwu83QgrKl7DuUvrRFV/KFAUxl23nyKqNfDOO4BlSGCeJtDQEB2KFpcNV0S0AVk0AXy/1lbVBufmC/Q8J/3IQJZnEElK8+tqiKjDnXmy88Yb9O977/U65qVGkyIKNPeJto1uKZCoBBAOgtfegPj8i61tUKSiEJVdq9S3KaKdPy9TcLlzp/2xwyGQ59tR8gpF1LUgooCp7rMaRdRujqh57KqpudpxoLUuNzjPpSK6aM0FgMEAIqbPoOm8bQsrAiwV0VzCG8fAwQGEoLl96W/8Op37f/RH9SF1eQ78+39PFvZ/8S+A115rPRZgqUoyBh4MoOL1EdFQhpikE9wc3rT+m3L92MB6l+UZ5TaUiqi8Gt+yQSTROeD7S+elYIUiqhSd81uETlMKlusaVgRA+T0U0ShCErTPEC2PxdakHpdhRTXjWwy5HgQ7pYieOVRYrSPtgq+giD58CPz+7wN/bde/b45xNUf0CpVQ0QTwvdaUyzq4gz1gMIB83I+IylzCjYsNSp0iyt2pNReg3p+7d4G/+Ztex7zUqFNEbUa4WCqiSUYbU390CJHIrSmiUUaL/q5V6tt6RDtv6KKIyIFNL465hrZQmdVJQtZcix5RwARvzFesTegQd+zXI85XVESlpHmmmBKSskf0OVFE54jo7Hk2GIAXRLTuvK1LiTYoFVHLHlH3fFKuV57wkEIB//yfU1HgD/9wWe3Xmn7+3nvAb/828NZbNBrFYrZsqlIILmpfe/kegiHUGq+p4/AYnHEcDZqLfrMoN7wXvN6ZsC4niuetuavM6r1CJyTRGG4wWlLLOePQjqCE1i3bc3VK60InItpXEVUKSBIkvmgd3WIwp4iu4iKwVERVH7vxRSAMoaFx7mS1tlxgRhHtQ0TN+xzbJYkrmQBcQPR0Xl4GXBHRBmQxRWL3JaIOd4DDQ2SPj3v9vVQSTmH9srbmAsCbbwKffmp9ITw3WFURPThoJTyJSsAZhzsYwUkl1JaIaJzRjWzXwpJaFdGuikYULX+fddgiEc3SGBACroVtCqhRRIubYpfZdMxxoFfZnEtJhBgoe49KRTRNt648bALUI1p8D0uKaLM1t+58Nyitay3XqSGP3nkIHNL8RE94VIR84QXgN3+TKvA///n8H/7n/wz89KfAP/gHwHe+AwD4YvIF3n74dlk0q0NbYm75HgbDtYUV5TrH4+gxrg+uNxPgLAP+6q/KTfRKYWcdQEn2+XyPKDhUsgOb7CqcnwPvv7/tV7FWpNEYfrActEUBMy6NP9myPTdP6P7LulhzORHJzqStuJ9Jn0aDtaWym2MpR9D6vaJjRiGvtZWWfa++uzNENEIG5Xm1QUXATI9o2sP1Y5xClmMUVZoAjtNa8LvMuCKiDciiEPD6E1HBBdjBIbInj/sdP8/gJsUA+YY5TVmezffGvPkm/Xulis7DLISLimgQEJlpU0TbEnNBiqgnPNqgaIZsSxuUSBaK6K5Zc2sU0d5hRc8MEY0Ax7FeSwQTUHyeiBqLLe9QOV1Ham5eKKIOJztoqYgCz4U9l8a35LQO85lb5nAIEdGGs06JqzvfZ2GT+CpzCeSKekRniKixz+K73wVeeYWCi05P6Wc/+hHwgx8A3/428A//YflcoQyR6xyfnn3aeExrIhoMoaL1XFOPo8dQuWq35f7sZ8D3vw/86lf0GjakiFKAYAJHsxkiyqDiHeh/q8KPfgT82397qcILk3gMryJAshy5sQOKaN5DEQXoPM66puYW+xoV2Lv3SBEt1rJVPqsWay5nfEqu43j7hcswxBkSIPBr+0OB6bmkZNr92ulIRPNMAkJY98NfRjy/79wCWRICQX8iCgDutRuQk7NeFTqZS4qJHw5rEw6NDWOuov7CC2TfuuoTnUdMqlSlqtk2wsVmdAtIEQ2cAAgCOFuslBtFdOesuQ3BLb1GMCzOhW3CFomoTCLAdcuRS20o4/WzrLwR9krNFaun5hpFVHAx7Un3i43H80JEZbZcDBwMwKNma26bIgpU9PlXQCoJTEJ4ms8rosWIFXAO/M7v0LnyB39Ayugf/zHw1a8C//Sfzt0/4iwGYwxP46c4jU9rj9lJEU3Wc00dh8cInAB7Xsvs7vv36d/C9dPb2t8RREQjSrIfjUgVB4eKd0DtqcL5+XRkxSWAznOkcQh/uGyrJBXLpTmc21ZE+xJRLqB8l8ih7bpd3M+yDm1kpTUXWImI2rxPwQRUUPx+26poGGLsMwTusPFeTD2iLnKtuivGpohgq4jKQhHtmUVzGXBFROugNbIoBPP8lSRz5/oRMuTTHkPrw2uoXFE6X40tF5jOEp3rE2WMVNH797deGdwpRBGRlipS3zTCJY5psW8JKgJIEfUdf6ZSviVFNItKi84ukdEsz2oXXM745VVEi5tNZ0UUKDckZY9oB7sXFytYczUpC2bDwhmH4GJeEX0O+kSbiKiIYkDremuujSLKRCsRpRmi53Ahyh5Rs/aXquj168Bv/RZZMf/DfwBefZXCiWZUXK014izGreEtBE6AT84+qUyazXWOLM8siegIKopWVt0iGWGSTnBrdKv5gXk+tZsWm71NhRVleQZEM0TUrPNrUoTXDrMZ3jYBWBPSaAzovJKI7pQiWlhz+yiiyisIku3aWtzPlG9PZsqwImB1IspYY5J7Sa6B7Z+HYYgkcDFwm/cMpSLa51zqqojK9Mqau+0XsLPIMqg8gwjswkXq4Fw/goTqTEQNsXSjZiJaO4fuzTdpA3vJ+kNWQhzXk5br16lHtGozZRJzWxRRqeR0jlehiOotRPubxNyBQ+91l/pEla5XRC+ciHoeKeLbIKKFImpNRI0iCpRENJd9UnNXCCtSikiWUUTZ86eIGpLGM7XspBgMIDSArD411VYRbSNQMpfAeAwPYk4RLX9n8K1vAW+9Bdy7R2NaFoKtUpVCa42BO8DLhy8jyRJ8Mfli6Xhd5niKwZB64VdUoR6Fj8AYw41Bi/PkwYOlzd5GrbkLRJSDQafJRkbHdIZZ67ZNANaE5JyKxf6oQhEtkk57kYc1o0xC7auIAvbfmVFEPfv7C2ccWqwe7JSnCeC44A0kyuEO2Y2B7Z+HYYg0cO0CnTyPihpd17WuPaKZBJwra+4VqhBFlHIZWG5ya+Bev0mKqCEzljDkwYmSZkW0uKCWAoteeYU2i1f23CmMIlqFa9do431+vvw7U0SwGd2CYo6X70OAA2my8T5Nk5hr7G271CeqclV7s+w1lL4LEWVsOkt0w5AyAXO6bRRyzuc2Cr1Sc1dRRIvjGkJsrLkqV1MieskVUUMweSqrrblgQByv3CNqo4iy8YQI0AFtwg1JLBVRgM7xf/kvgX/9r6ff0QyMZT9wAhz4B7gWXMPn55/PPwc6EtHhHtkhV7iuypCi4Hr7NXL/Pr1PIaZEdINhRSyKaW2fCStCku7UOlvikimiyeQMAOANl/v7TNJpL/KwZpSWVd+ybaSAwx1kbnH+235nxeMyz95xs67PqlTzGgptgu2OIppPxsgDz6pFRrg+rWsXrIheWXOviGg94piIaEVTfBc4gxGyQdBdEVV2imilNRegm/Sv/RoFFu1ipXYbaFNEgWp7rvnuzGNqUI5umVFEkW5+hIvZbJZEdIesuU0zFTsroqaPxrZHFNgaEc3SGI7bMcrfEbRRMIpoQUS7zhHtrYgWN+BZa26piD4nYUUlEa1SRIdDMDDwRPZOzQUwJfcNkErCmxQjQ4rXUUlEASJpNZkCs0QUAF46eAkaGg/OHsw9rhsRpXukmvRPaX8SPYHKVbstFyAievcusLc3Z81ljG1EEXWSlD7fwaC05iLdvPOlFVpfOiKahmdgYPD2ry39ziSd9iIPa4buq4gyAeUV63sHa27uOtCifdRSeRwzJ3NFRVSlMeC6jWqe4DN24y3ce2chwzEQBHaKqLuiIpokVn2+hsxfKaJXWIZRRFckoi53kV87QH7cbZZoGRMfNyuinPFpkuUi3nyTwhwePFj+3fOIJkW0aYTLyQnZ4SxGtzDGpqm5W9qgxFkMhzvlZnOXKvVrDSsyN2pbRRTYniKaJXA8e8JcZTPTRVhRlx5RJpwybbczFhXRGWuuNurgc0JEmaxWRAGAp2m9NdeyR7TtGqUZouF05jGmPbtLRLQBiUrg8Kly4js+bu/dxuPoMc6TqRvEPKfNhk0Mi4LXpMJNYolH4SO7kKI4ptFkr79OpHxGdehl7e+ILM/gRDMBgp4HwXZUEZ1NKb0kRDSZnMGHqFzzSeVzdkcR5aJT0RAwpK2jIhqGyAZEeDspomuwMduQKIc7yPyO7+kioDVkeE5E1EYR9fzVekQBK1VUyRTcca3G7lxWXBHROhREdOUeUe4ABweQHWeJylwCSQpX80YiCtTMEgWAr3yFgiqu7LmEJkX08JA2FnWKaIfRLYyxqSKapBtXRCMZIXAC6xmFm8RaFdG6ubBN6EFEkyxZ+TPM0hhuV0VUCKrup8FnuwAAIABJREFUG0U0666IGmtur/41o4gKmm/HGCs3OqXV6nmx5srqHlEAEImst+Y2FF4MHO6U4XR1kLmEN57OEDUwybm2iLOYWgdmcHvvNjzhzQUXmcRcq5mERbFWhf0UURNS1DqyBQA++ICUvgoi2sva3xFZnlGS/agoUDMG4Q93UxGd3QRfFiIanVOfdMWav1M9omkCuN1VLsEEcs+jlowOiqgaUpGzKxFdVRHNixmYjYooK2aWMrbd81BKKrBZK6L+aoooYEdEM9lpJNtlxBURrUMcQ63Dmssd4OAQ2eSsk3qQ5Rl4klAPUhsR5e6yNRegxfqVV66IKECblyYi6jjA/j7iky/w4OwB3n749nS0wcmJXWKuSsiWWzyfEO7WekQDJ9hYgEcXNG3Md5GIaq3x13/1J3jw0dv2x6iAlD0UUSFoU7WYmtuQULgIJgSgFG1sumJGETXnUhmOxkH2/+dEEeUNiqhI6625TSnRBjb9jWmWkCJaQUS7KKJxFpdOCQPOOF4+fBmRjPAoJOeO7egWABAjo4j2I6LH4TEYYzgatq+xuH+fel/v3l0mon3GP3UEKaLJlIiCwpqQ7qAiehmJ6OQMPpx6RXRXUnN72i0d7gC+R+t+hx5Ro4h2Sc2F66w86iaXaSvhFlxAA8gDf7vnYRhScGgnRbSHzTuOOyX051kK0cHldBlxRURrkIcT5NCrW3OFC1w7hOw4wkUqCTctbmwtRLRxDt2bbwIPHzbPyHwekCRERiusuSYo42/2Erxz/At8MfkCqUrxJH5CC2cUWSuis2qD4w+AdLOKaJmY6w42FuBhi7Z+uc6Khrmpde0RjSLrwdqnySmy/++Pkf7ZD+yPUYEsS+C6HYhoRb9TOUe0xSI+Cy4cQOX9LIvFBiWfSfSbS+kOgitFFACPk0ZrbptKUZt8XiDLM+g4hpfplYioyhWkkktEFACuBddw4B/gs/PPkOVZNyI6GAGMQUV24RyzyHWOk+jELqRIa+CXv6SxNEJMiWih4m5MEY3iOSLKgwHQcA5sDZeMiKpcQSURfHdA338FhONBMeyGNbeld7IKgguAcWSe00kR7WvNXblH1GL0SOmiGQTb7RENQ0jkYMHA6nMSXtBfETX7RStF9IqIXhHRGmTRBGAMzrClZ6UFxprbdZaozCWcpFgg+lpzAeCNN+jf510VrVDPIhnhk9NP8Jdf/CU+ePIB0v0B7p4zfP2Fr+PQP8Q4HVuPblG5QpZnU0UUAB8MwdJ6295FYDGMpLFIsWG09ct1VkT79ohqe9vTyZPPgCiEjFdIBFUZcpX1UESdBUWUPr9uiqgDrGjNVQ4vv7M5ld33nx9FtCo1VwhKx17RmtvmXJBKAufncMGXiKjLXWR5ZnXdLK4Ni3j58GXkOseDswfdiKjjAr4PFXYnop1Cih4/ph7+11+n/x6NKOm8OAcvWhHVWk97RGcV0WCw29bc0ehSENFEJUCcwGvYk3EukLti+4poXyJq1oJBB/UwDKF8ula3Ys1tCysq3lM23A1F1K1IXK4C97z+PaIdiGieZZ3u6ZcRV0S0Blk4BlwPzore7dKa23GES5ZncG2JaLEZqdxs3rgB3Lp1RURn1DOVK7x3/B5+8egXeBQ+wqF/iDeO3sDX7nwTtycMrmYYeSPqDTx+SH/XZXSLQRA02vYuAmZ0i5khugm7mi1aFVEuoLW2J019rbmAVWU2yzOcPvqE/v8KRNSQWNezf51zimiZmiupZ4/bL9vccYG8pyJqiKiosOY+T4qozsGVWiaiAI1wievt90090QZtimiq0ukM0WvzaaHlLFGLPtE2Iho4AV4YvYDj8Bhaa3siykRvInocHtuFFAFkywXmiSgwN0v0IlVJpRWgMioQzxHRHbfmHh1dCiKaqhRIEviDeiJR9iNum4hKCdYjgKZ0Mfme3dqa5zThwVhzu6TmcgHFLj6sqHxPO2HNzeGO7Iio8ILu1mWtiYgeHFC7VxsR1RpKSYgO+RGXEVdEtAYqjqjaveJsH844hB9AjgadrblObEdE2zYyePNN4KOPLv2msREz6tlpcopxOsaL+y/iG1/6Bl69/ir2/X1KztUaOD0tN0bj48+oyb7L6BaDIICTZhtVJOMshuCi7IHYhF3NFjaK6OzjWhFF9N1UzEusRQci+iR6Av30Ka4hgEzC3gPrs4SO5fgdiOhsj2iZmpt1DjWgHtF8pR7RXPBqa+5zoIjqQpHmYNWp2YMBRNKQmmujiLZY6GUugfEYLkSlNReoGOFSAZPqPbdGLeDO3p1y7bAmolxQga+jNTeSEcbp2C6kCCAiev36VG1YIKKc8Qtd67I8A+KYQuhmrbmDIViS7kzBr8RkQkW6y6KIZgkQx41ElDOO3HW2bs3VMu3UQmFQ2lhtSZuZIeq75QQFG3DGAcaQu+5qPaKZtAorAgAVeDtARLsoon53xVgp+p/vL/WwV0JKKOgra+62X8CuIosmgO9ZWx2a4HAH2bUDa0XUWIDcRNLmp2VBq50lavDmm1Q5++UvO73uS4UZRTSUIRhjuL13e/77nZklOnSHYIxhcvwZbf6c5vOgUhH1fVJEN7hBiWRUqqHAjllzWxRRczOzVjXMOJ4uVecORPQkOsFgHOMA/krpx1lCRZAu1lzOONiSIpqBWVa8y+dxXCBXyPucg6UiyqbWXE4JuiURveTFrVxTjy4Hq1VERVxvy1ynIuo6/pL634WIxlkMX/iNKo3gAi8dvATGWK1yugjOOFgwgIq6uQY6hRQpRYm5Rg0FpmSwuJYv2v2R5RkQLRPRbThfrDCZ0OscDC4HEVUJRJKWc2urIPiOKKJp0mnMlkFpY/Vdu7W1OPdV4FmrobPHyVf8rGzeZ7m++TtARFkO17LdTnCH7MtJh3ucKczaEtEsQw59Zc3d9gvYVWRxCPj+2oioPNyzVkTNhsSN01Y1FJjOequ1Z5mEwefZnjujiIYyxMAZLG/IjO3tyRNwxjF0hxg/+cIqqCjOYrhioVciCOAkm1dEyw3khx9CPHm6M5X6SkX0ww+BYxpt1DnltykFuQ6WRDTOYkzSCY7OVTGGJ0HWYUzGLGRMNyO3gyIK0LzQOUVUKfCakI46sOLx2mKw9hIqFFFgprgRBJdeEc113qyIDofg8WqKKGccjLHGHlF3EoFdu7ZUdDFFSGsi6rS7B24MbuCbt79p9VgDMRh2UkQ7hRQBNDs0TauJ6II1t69zoQ1ERKNlIjoYQGQ5lNyxa+GyEdEsgZ9krXPVc1dsXRHNMwnu9CCivKN6WNzHMt/ttFc147jUKv20SlGhrcVWOveekoSKSltAPhlDBT5cS6dHOWs17XBdm31mJ0U0v7LmbvsF7CqyeAJ46yGiLneRHe7TSWlR5TLEpRyc3YJWay7nFFr0t3+7tUVg65hRRCMZYehWfK77+6R8Pn0KABg5Q4RPHkHbJuYuWt42XCnPciK9JRH9/vchfvznO1Opr1REv/994E//FEBPRfSCiOjjiIpGN85SskTmCjLtt5nL0kIR7TiTWLjesiLacUA6Lx5vRr90glFEOZv7zkoi+hwpoqxFEQWWCyhtDoBZNDkXUpXCG0dL/aEAXTMOd+rdMAW01pWjW+rQOWQlGHZSRE1IUSdbLueUmGtgrmVDRIsN70X1iZI1t4KIBgE4WDflZBOYJaJZtnWVcFWkhog2rPk70yOaJuBV60ULyqKU53a25nbdq3LGkTtO/88qTUnNa1FEp9bcYn+0paKInJwDQdCt5cB1KZDJFqYwGwRWRFRbfoaXHVdEtAZZHIEHQedm8yo43EF2UNgBLFRRs6lwo8ROEW2z5gJkz41j4OOP21/wZUQcA0Ig5WR7riSijNFmrxh1s5cL5GmM6Fr7CJ9EJcsKQhDAyXJkG6qUR7IIKnIH9H7Pz+FMwt2x5i4qomkKnJ/330j2IaLG6t5CRE/CExz4B3Afn04LPWG/OYkyCSHAwb1uVU/heMgZm5sjyjsSUUNczeiXTpDUGqB0Xq+Ipmk5PuMyolURNURU66WCT1tP9CyaerllLitniBrYjHBJVQqttTUR7QoxGEIpab2pfRI/ge/41Jtvg/v3ydkzO6rJcei/ZxRR4OLGVdUqokEAAdbZmnzhmCWiwDOviibROXwtGtd8Ilc7QERl2ptcCCZIPcyycu2vhbHm+l7nPJOVPysprUgUY4z6t/1i/dwWEQ3PrWeIAjOKaJf9W5U1t+H+mEtat696RK+wDK2h4hBOsNoMUQNXuJD7BfGxIKJTRdSOiHJG4xUakxNfe41u3M+rPbfoJwyLVNlKIgrMEdHRGVW4xwfNm7dc55BKViui4BR8tQHMpWIW/chiEkFrvRMz7lSuypsSgOls2+Jm2iusqIWIqlzhs/PP5tWq4bCRiJ4n50hViiNGM0fd23cBFDeyHpBJRKM3OlbIqbrPpxbZvj2i6K+I5s60N3T2dZWKqO4xZ+0ZQq5z8Kw4d+pSczUD5LI9d22KaDKBFyW1RNQVbisRbUvMXRViMCL13nJOYJIl9WvwIqII+Owz4CtfWf7djOpQrh8X1IqQ5Rl4lNA1NXsulOv8DhFRpehzuyRENFUpdBxRcnSTIsqLNXOba1KeI89VbyLqcIfmiALt35mx5npOZ0VUMEHW3L6flSURBYr3tHUiOiYiyu2IKCXXuyVZtMIiEc2yxs9XFW6pK2vuFZaRkcXRCTqqLTXoOsLFEEo3tCOi5hiNypfnERl9771LrWDUougnDCUt3AO35ru9fr205nqnNDJhste80JaJuYuKqO9T9XxDM+aiLILggqwnpu9yHFJhZQf6RJeCW0xRZkHRsCbNcTyvkFTgJDrB5+ef49OzT6c/bCGij6PH4IzjWkivQ7z0MhgYZMdUUAOZxmTv7ZiiKLiAEouKaMceUccoov2IqHLp7xetuUqr6Wd/ie25rUR0OIQAA+J42ZrbRRGtCdrJdQ51flaZmGtgo4hePBEdUj+zJRHtMqcU779P96zZ/lCDGSLalj68KrI8gxMXM0RnnVJGEd1QwdEK5nu4REQUSQIfzu4roqXdsh+5EFyQNRdoX1vDEHAcZNx+hqjByp9VmkJBW1mQBRdTRdRyjVg3ZDTup4imK4QVAY32XENyu7qlLhuuiGgVoggZ8rUpok6RvpXtj6wVUZbnEIldjyhAfahtfUJ4801SoR49snrOS4VCPYtkhMAJ6nugrl+nx8YxcHKCEfMwHjRvJMvE3EpFlAGp3Ig9dq4HzCiiKgfkbsy4WwpumVVEte6maGhtpYg+iegYx+ExzpNC0WwgornO8SR+guuD6+CPi9f34otwwSlJuwdkGq6giE43CnnWp0d0RUXUpe+r0pprxuZc4sAiIqJFYaTOmluEWV2EIpqqFDivniFq4AkPKleNBZxEJXB4d9XEFl0UUakkcp03jpGZw/37VPR48cXl380S0a5hZx1BI9WSeVsusHHnixXM5veSEFEa3ZLAh2jcEwlW9PVts193xb4/wQSUrSIaRcgHATTsZ4garMuaa6PmCSZoNiqwnfNQa8hwDBYMrNdAwWmW90qKKNBIRI3t98qae4VlGCI66BYuUocy1fbGoZ0imku4sthU2BJR4bYPNX/jDfr3ebTnFupZKMNmS9hMci4eP8bewS2kWjV+trWKaLFBQVo/8H6dmBvdUpxnDjiwI32itYpongNJ0i2sKKG+vCYiKpXEOB3j9t5t+I6Pj04/ouduIKJPY0oZPhoc0etjrCCigiqqPbCaIsqnimiuuveIFtbavj2ipSLK5xVRrbV91f4ZBhHR4tqps+aCAfHyNW7+22bjU9cjKpWZIcobFVGgOTnXNjG3L8RwjxRRi02meZ1WiqjWRERfe43CihZRoYheZFiRG6U1RJRBJTtE9C4bEVUJkCSt1txpX98We9elhIYG6xFWBCyohxaKaDak4nNnay6fb/3ojA6Eu5Pd+CKQJJA6gzuwG90CFOeS63ZLzS2I6KmOoRfC1KqQF7Zd0WG022XEFRGtQhwjQw4xWKMiCiC7cZ0sky0LpFQSTlosDuuy5gKUCvulLwEffWT1nJcKUYQsIAtbIxGdmSWKx48xunEbADBO60lIohIILpZvBEFQWHP7z6C0xVJi7vExzTEFA6JwN6y5dYooAEwm3XpEzc2sYVPyJKbnPxoe4ZXDV5BkCT47/6yRiJ6EJ/CERyEqJye0+d/bgwNOI506QuUKeZr0V0RnrLmUmtux6m0U0Z7W3LwgoouKKABkXvFanntFlAHJsv2+VEQtlAqHO1C5Who9YmaIesyh9bsCtkT0omy5ACBGe9aKqHGQWBHRkxPg9LTalgsQ0QpDIM83ElbkRBWKaFGM0ElyYaNjOuOSEdFUpfDSjNKrW3pE4TjItaIC5zZgCFpPuyUpopb9lGFYptH2sua6zuo9ohbvsyyqcr6d8zAMIaGsZ4gCpke0oyIax4iExi/PPsQTp/g7C0X0KjX3CkvQYQiFvPO4hTqUqba3blCFa3YDXoEsz+AmxcaxgzU3y7P2G+GtW1aq7KVDFCH0qK/Hiog+fQqcnGB48w4YY5jI+sWkcnQLMLXmJumFE0HTAzZwB1ToePwYeOUVUmQn4U5Yc7M8W1ZEzaYiDMsgIytFw1SKG3pEn0RPMHAHCJwA+/4+bo1u4YvxF5j41NO3OMpIKomz5AxHw6Pp67txg/pKwCF7EFGZSyBJ4PrDakWnAYILaMcp4+N1lnUefF2m5vaZgZqmZA3Gco8ogGmF+xIrolprMKMYNCqi8dJ5a4pPNtbcuv5GmReK6N4hUFOEMI6bOiKqcnJ0XCgRLYq2atIe6GVep5VCe/8+/fvaa9W/H41Km/6FhxUpCSeMl4mo40AId2POFyvM9oi6Lp07zzARTbIEflpcX62KqEvq/LYCi1a05jrcQeYW9wobRXRA11HX1FwqdK6giJZhRZbWXOTbm2kbhpDI4Q4tU7phFNHuqbnSp/tibL5DK2vuVY/oFRZgBnM7HaonTTALRHar2OB+/nnj42Uu4STdFFGrES4AcPMmkaw+CsmzCq2BJEFUENHaoCKAiE0Q0AD1JAE7OsLIHbUqopWbqpmwootWRM3olsAJSEGQEvjyl+n4fRXRyQR45521vUalZxRRpeh13qVE2tnkXCsi2qKIGlvu9eB6+bO7+3fhCQ8f4RS6wkZYzg4d3KBz5uQEODoCOIfrBr0UUakKItrDXSGYAISAymhDleerpOb2+P6lpFRFLFtzASBznxNFVOW0ka8qJJQ9onGlNdfMBWxD3SzoVKUQ4wn49fpZxkZZrGsfuOigIgAQjgt4PtSk3b6eqhQOd+xmld6/T9fg9evVv5/pw7rIsKJc58hlAkfpZSIKQASDSlV8a5hM6HwNAmov2BYBWBMSlcBLi4C0hoJeqWJBby+wqINSWAXBBbTn0Xuw6BE1RLR3WFGW9VOP0xQKOYTfvq6YMDYdBNsJKzKK6MieiDLGwBwXeZfzKElKNTtGNjdeqgpXYUWEKyJaATMv0FmTNZcxRlWuG9doEW0hoqSIdrfmmr9twoNhhk/1KfKTY6vnvRSIY0BrhA5t2loX7OvXKakRAI6OMPJGCGVYSZC01khVWq2I+j4E40AqL7xSHmcxOOO0KTWK94svQjhe/x7Rv/gL4Pd/f21EQ+Vq+tmfntLN76WX6L+Lm1NdeugSWoioseVeH0w3sIIL3Du8h8hj+BXGSzfEk+gEI29EG3YTWHWDCIATDKGT7gUFmUsgjjv1psy+XjgOVNHfqVWPHtHCTtq3R9SMb6m05ha/u8yKaK5zcJnV26o5Bw8GYBWuhyUregPqgnakkvDGUW1/KED3l6YRLhshokwAQVAWcZuQZImdLTfLgA8+qLflAkuBINbrR0fUzhAtIPwBOV92RRE1M0RNEeQZJqLleLREtYbTlX19yLeviK5gzQXjRGia1tY8B6IIyiiifcKKRLGu9xAmjFPHtkcUANQw2Mp5qCcTZMg7EVEAEJ5P85FtiXqSIDOKaBbT/r1JES0+Qxsyf5lxRUQrkMUhwNjaFFGgCBNiGnjhhUYiauy1blxsHFsW3vL5TSBSgwXvND7FrwKFLzDGL97/caPKd6lQLOah22LLNbh+fXoDuHEDe94etNbl6JdZmEHxlYooY+D+AHwDqblRFk2V3mJ0C46OwA4OwKOo3wbp9LR48tVvHGaWaWkfMvZ0Q0RnZgGuQxGdteXO4jA4xI2D2/gcY0Rn0wTrSEaIZEQhRcCUzB/Rf7vBCEiT9kCwBUglgTjpZAkyoOq+KO07ucrAOlpzIQQYWH9F1OHT12Ke0ihPTtHzc9kV0Uw1B00NBuBJxRzRxXCuBtQqolnSSkQBWv/riGiiEjDG7FNqe0DwgoiG7UQ0VamdLffTT0nVaiKiC4EgdaFPq6KViAbDjY3psoIhogbPMBEtrdxJ1rofKntEt6iIdiFoVSjX14Hf/J0VBXYzn7NPWJF2HXIH9SDtJpnYqkfUFNqClvd0QZCTMwCAOzro9HfC9budS7OKaFYEFjUR0SyllqSOBebLhisiWgEVTgDXg1hj1H0ZJnTnDhHRml5OsxFx4pQioB2719Bmzc11jk/OPkFw9CX8Go6Ap0/x3vF7+OT0kwtLGdwZRBFyaMSOJRE1ybmcA9euYeTSDX2SLi8otaNbDIIAIpUb6RGdG93i+8DeHrC3BxEuzzi0wtlZ8eSrK15LMxVNYu4LL9Am3yiithtJczOr6BGtsuXO4uVbr0OA4aPjX5Y91SfRCRhjUwXVvL5SESXrXR9FlCcpxLCHNZeTNTdfQRGFEOBg/XpEpUTuNIQVaUXn2fOsiAJkz02WXQ+dFNG6HtHxKdwcrUS0aZZonMXwhW9lEe4LwQTg+9ZE1EoRvX+f1uAvf7n+MQuKqHUhqyOIiMYNRHRHFVGDZ5iIGkXfj6SdIuo41CO6JSKqDRHtqXKV6mHgNX9nxT0zCzxwxu2s7jNY9bPKZQpwYZVbYE2uLwhycgZwQQXlDuCu101dT5KyZUVrjXTot1hzJX1+F7g2Pwu4IqIVyOKQ+vsuioiG4XSTvwCjuLiR/QxR8/xAvTX3V+NfIckS3Lv5Og4ObuGr0R5ujW7h4eQhfvHoF5dbHY1jRJCA7zf3hxqYfqRr1wAh4AoXvuNXfka1o1sMfB8izS5UEc3yDFLJ6eiW42NS8hgD9vfhhHG/45tzdA03jqWZio8fU5Flf38uxbZTWJHjVCpVVbbcWTh7B3gZh5hMnuDh5CG01ngcPcahfzi95s3oluJccAd7QJK292AvQCpJNntLZ8Ms5kYRoOgR7ZiaS4po/9Rc5fDKPsdyPQuCy6+IthHR4RA8rkjNXVER1VpDnj5unCFq4Amv9ty86NEtwIwi2mLNNTNErYnoyy9P59VWYTCg63ST1tyK+7JRRHemqFsQ0ePwGO8+eveZJaJaa3x2/hlc4WIQWyiiTABuoYhuyZqbF+th7/EtJlMk8JqLfMX3qXyvsy0XmN5f+qrHuUwBx67XuyTXA38rPaJyck6hg07H5HrX70bUk2Qa4gcgHrqN71fJhNqnnnNcEdEKZNEECNZLRF3u0kbhzh36QY09t1REo6QTEeWMQ3BRaR2Msxi/Gv8KNwY3aCzF0RH44ye4d3gPbxy9Aa013jt+D5+efbo7N9J1IooQQgK+Z2/NBUo1DABG7qgyOdfY3mo3VkEA54J7RJd6wE5OKJQKKBTRntbci1REnzyhz5mxuT6KTtbcjrbcEsMhbmCAQynw2flnOA6PIZWcpuUC9BkWhQgAFDbUx5qbJXDT9g1UFWbDirTWQJ6voIh2JKKKxh/kjqjcaJRE1PcvPxG1sOaKKmvuij2iZWIuhJUiqnK1RMK01hc+ugWY7RFt3mSWNss2m/BkQvfIJlsuQIrpzPpxodbcuN6aywdDCm/ZMWvuJJ0glGG7uraj+Hz8OSIZ4ZXDV8Dj9j3RVOXLt2fNLUdy9A8rAohgWimivtNrr7pqsJNKYsB17FLBS3Lt07E2/N3IcExElHdrbeEmNMq2qBHHUJ5b7gfjwKFrscYBmWeyHLH2POOKiFYgS0Iwz+9VZapDOSfuhRdo811DRE1V2+1IRIEZsruAT04/AWccLx0U/Xg3b5bzTPf9fXz11lfL0RbvPnq30oL6TCOOEULCGYzsKvGGiB5Nicmetwep5JL9rXZ0i0EQXLgiOje6JU2pt9O89v19iDSDSjuSyTSd3gTXQUSrFFFD9M0sQHQMK6ogd222XDoI2Qjv5ftgjOHj04/hcAeH/sxmf/b1gcZTsD7W3GgMV1erKG0gay6FFeU6BzK1Qo9ox/Ov2CgowSvXwTlF9MqaCxEv2zK7KKKMMQgu5s6vcoaoJREt/2YGpof9womoUURl0hh8Yl5f6zr8wQe0eWsjogCtHxtSRIUXVLbLiMEQiBOoC84CsEKa0v9Go/KclL5LP+vTK74lRDIqC+iH3j6tMy0FvTLpdNuKqOOA99w/lkUpv0URLYmo24uIrkrauyiiJbkOiuu+wa56EZARKaKd+2hd3/7zKaYzZK6A7/hwhUtEVNenHyuZQjQVOZ8TXBHRCmRRSD0fa4Tp4cwcTkSwQRFljHVWRIGZzeEMnkRPcJac4cX9F8vXgKMjWuBmNv9GHVVa4cOnH3Z7c7uOQhEdjprtbSWuXSPlemZ23cijKviiPbd2dItBEMBJswutlEcymibmmt7GGUXUAUd2Xm0Fr8X5zDzAdVhzZxVRraeKKNDPmhtFlf2hbbbcEsMhvFiWxZnrg+tT++ns6BaDwQCuzCFlN9IlwzFc8P6KqOOQIporQPdQRB2HFNGu1lxDRB1eSaaeB0XU9A9bhRWl6ZLq3EURBZbVPKkKRdQfNttTMb2/LBLRTSTmAnTdsiCgTVuDFc301LcS0Z/9jHrcjYOoCbNE9AIVUSdOwfaqAwz5YAimdfeC30U0hecEAAAgAElEQVRgZoao2Q/IoDh/nxFVVGuND59+CMEEXj58uQzmsVlHhR9stUc0TxPAdTv3bBpMFVG3+fuateZ2nCEKTBOG+5L2PE36WXOBjdtzZTiBOxh17pPnnm//+RRjcJQrIJhA4ASI/eJ7qSHeKkuvrLm4IqKVUHEIx++uYDTBXIgyl8CLL9YrokrSY8OwuyIq3DnroMoVPjn7BEN3iFvDW9MHGpJyPD/CZd/fx9HgqNwsXBboKELEcwwGlolpQgD/5t8Ab75Z/mjgDMAZX1KLrRTRCw6xmLPezSTmAiBFFMxq0PwcZnuY162Ijse0STCKYx9rXU11vNWWa1CQ35vDm7h3eA939mY2vGFI5GpGEUUQEKHvMEs01zlUHJK1sgcRZYyBF2ESJqGwd49o10JIsYmrs+aW6t0lVkRNQYSlsl0R1Qxq5txYSom2wGIhMVUpcD6Gd1g/Q9SgnCW64Igxa/lFE1GAVEHVMvvQzBBtJOhffAH88pfAd77TODOyxAwRvciwIidKK225AGidB2u1Jm8EZtM7S0T9Z4uIfjH5AqEMce/wHu2HWlLSZ8Fdb7upuR2UwiqY4KHMd4nc1BURwxAQAplg/ay5ZjzYKj2iloTb5AxkwZaIaDTuN0LN69AjWhRkM1fA4Q4RUa+ZiOaZtAp7uuy4IqKL0BpZEsEJLoaIloFF5+e0IV9AlmdwclAFZkVr7ufjzyGVxL3De/OVoKOFERULr1NrvTu9LmtAHJ5C+z6GXv+5sIwxjLzRnCJqgjcaFVHfJ0VUZaXCsm7MjW5ZGDuCvT0I8O0T0VlF1IxuMYroaETne5aBMw6tdftnVWHNtbLlGsyosLdGt6ZuAWD5MwSovwSCek0sIZUEkqS3IgpMrUG62Ih1HgnQNzW3tOayZmvus6SIag389KfWmyBDaHiWNSuiw+ESCVnqibbAoq1U5hJ8PIG43k5ETe9TlSLq8H49ZF0hBqN2RdRmhugPf0if92/8ht2BN2TNdeI2IsrnihFbQwURTc2G+BkoGsVZjM/PP8e14NrU2dKBiAov2OocUVIK+yuiQHEetxUPwhAYDKB0vtWwoi598KU1d5NENM8hkxBuj3GM3AvsFdEKIpoFLjLkV4poC66I6CIkzXxcNxGdm/PZEFgkcwk3LW6kPay5KlfQWiOSER5OHuLm8GZpKy1xeEh9LguKKNA+BuZZRDg5tQ8qasCet4coi8oNauvoFoA2KJoB2cUEFqlcQSo5r4geHk43zvv7FLAxCbtt0AwR3d9ff2ruwmiU8jwPw/Km1qpqVBBRa1uuOWbdzXDx9QFkzQWHjDoQ0VwCcdxbEQUA4biFIkrfQT9FlHVPzTWKqKgPK9JaI/c9ugFfUJFlrfjkE+AP/gB4+22rh5dENG3vEeVgyOPpdbLUE22BKkXUHYet/aEAFcpcsTxLdBOJuQalItqwyWydIXp2BvzVXwHf+pb9NTMa0TmYZZWhT+sAKaJxIxHlYFDxDiiOZtM7HJafgzRE9BlQRD96+hEYY7h3eG/6Q/O6LfZEQrjIOd/u+JYVrLlAQdqKeZS1xYMwRD4IkOt8pR7R3mFFstv7JHK9hR7ROIbUqhcRFZ4PDQ1tSURzaGiXyHngBEAwQIysnojKFKJnqNVlwhURXUQcI0MOZ9BfPavCnCJ6+zb9sIqIKgknKRaFHtZcgDbAH59+DMEE7h7cXX4g57TJrlBE5wjzJUEYn4H7g5UHuo/cEbTWpT23dXQLUFo6kaQXElgUZXSDLke3zCbmAmQb5A4Qhd2Of3ZG59/+/toU0XIMyJMnFNhlRlLMEFFzU2sk7UpRhXKhR/RJ9ASBE9jZENuIaDFDtkQPa65UEogLRbRHWBEACIfmmOniO+icsMcYqcxdQ0qKG29TjygAiqrPt5dQ2QmGgHZRRHUOrlS7NRccOolL8tpLEV3sEY0m8FJlRUSB6lmim0jMNRDDdkW0dYboj39MRY3vftf+wIYczhSy1l30y5Sk3IYWa26+Q0Q0Hw7K81GakRI7TkQfTh5inI7x8sHL8y6VLtZcxqGc7RHRVa25wAJpq/vOogjZkK7t/qm5bm/1uOv7FEzQjE3ON6qI6skEEgrucL/z33KP9nYqsbhuCu4AzysVUQQ+YlZPRHOVXVlzcUVElxFFyJCvPaxIcEEeeWNnOzqqJKJZntHcQaCXNRegmaHjdIy7B3frF6ijo2oiehkV0egMg2Bv5YHuRlk2Y1ysFVEwIF2eM7gOzIWRVIXsMAaxt0+KaJfN2dkZcHBAZG9Nimi5KX/8mDbXRt0z5/lkUt7UGhVRQ4xnNiXGlntj0G5jLI+ZptWblYXRLQBKa65O7Geyyryw5jLRGjZTBzPHLC9sn6wisbMNTIju41ssUnMBTGem7brlL8+Bd96h/295PlNScQYO1j6+BQyIp3MkzbXeZYO4pIienlARowMRXcwImHNLXDDEYK+xR7R1hmiSAD/5CfDWW1Pbvg0MOZxMyqLJuvtEs2gMR7N6IloUI3ZGEXVdCkYsIN3dV0RTleLB2QMc+Afzo7SAKXGxseZygdx1tmfNlSngOivtNxzuEGkDGhVRNaBru3dYkSM2MkcUKBx7yJuLwBeAbELuLnfUnYgKjz7fXNopomqGiHrCA+cO4sCtJKK5zqEzCdG13eYS4oqILiCPQmhoOD1k/DbM9XDeubNERFWukOu8NxE1m55Hk0cYeSPcHN6sf/DNm0QIFpSSy6iIRvEYQ9ugogaYKpfpEzX9To03nAtWROMsBmecVNnxmDZzN+e/dzHaB6Ie1tyDA7rxr0kRLW+Ws4m5wLyiYWOtq6iOd7LlAtNrq2pj9vjxPJkvjuWAA6n99yiVBEsSOMHILnSlAsItFNGi/6RP9ZQLp7siWlpzea01F5ghorveJ/rhh9PNQBciKiUR0SZFdDikx8Rxed6ac6TLBlFwUYYcAYA8fUKjW67ZpX0vKqKbSsw1EK4H5Tq1m8zWGaJ/8Rd0Hn3ve90OPEtE+fqtuSpX0GH9DFEA07CiXekRnekP5YwjFSAXyg4T0Y+efgQAeOXaK8u/jCJ6/RVJ6YsgRVQ8s6m5QOGOsOgRzYo05D6KKGMMjAvkot9nlcu0U2ZB2b89E064CcixIaLd94DccQHGoVKL+1uSlIqoWfcDJ0A8rCeiyLLuuQ+XEFdEdAFZEeqybmsusFDxvnMHePp0bpExv3Pi1ay5APDKYcViPoujI1IJnj6d+7FRbi+LIppkCVQSr4WIAqSKltbcttEtAOD7EOCkiF5Aj2gko+lGsypkB4CzfwhMelhzjSK6ptTcOUV0tv+ywprbqGhUEdEuttyFY87BqMo3FpTVICB1Kk6sizTU75317g8F6EaooEvLX+ceUQBMOMi7FkGkpOquUz2wvCSibVX7XcE77xCZfOGFbtZcG0XU9yEYp4p4cY33sebOtm9IJaHH59Rf3EERzXVeXucbJ6ImjKSFiFYqokoBf/ZnwKuvUqp8F8wQUStrf0dkeQbELUS0WOetLHwXjYKIGjI+cAeQuliHdpSIHofHOEvO8NLBS9XnhxnXZVHQE2wHFNF1WHObVOxiNmVWjEPpG0YmWHGcrkRUa6gsBe8QtFO2HszMDd8EpFFE97rvAQUXNOKmCxF1vfL7CJygVhFVuQKUugorwhURXUIW0QlzEYqowx2kKqUNTkVgkSF/blwsoB03sC53IbjAl/a+NE1RrUPNCBfzPBeh3m0DYToBZGo/Q7QFe94esjxDnMXto1uAqSKaygtTRGtHtxQQe4Uiars5y4qehllr7ophNKUimiR0E5pVRAcDqnbPKBpWRLSojpdpubZqKFBPRCcT2sAsElHXhSs8IE2sizRSSbix7N0fCsyk5hZEtMuN36CvIppD126onilFVCngF7+gcUwHB+tXRDkH9wfAbI9oj7CiWTeAzGmGqMddmqdpgcXk3EQlYIyt3BtvC8GJiOoataNxhujbb1Pxq6saClRac9epiGZ5BkQtRFQIUoR3iIia+83AGUBrjSzwdpKISiXx6dmn2PP2cGt0q/pBFeF0ddiJHtF1KKJuQ9tDktDMymIcSp/UXKAYd+SI7qQ9y2g8VQc1rxRiNmzNlYW45O7ZFfRmYQKdlLQjogoa8Nzy+wicAEngIB8vTy1QOY3mEd5VWNEVEV3ARRJR3/ERyQg//fyn+CtxjL/FCT754Gd4NHmE8+S8rGA7UUKLbkc7H2MMX3vha3jp4KX2BzeMcFmcR/osIxw/BtNAMFyTIurSRuQsOUOWZ+1qwwX2iKpcIVXp/OgW111SUMTBIdkGbfocABotBEytuUrVzzLr8FoFr0jMBYiEFjcnK0VjoUf0aUyqvtXYFoOZvtQ51KjKAChJu4s1N5dwk9UUUVHMxCvniG6wR1QVRLRqk1Nu+N1ngIi+/z5tZL/2tU6qkIa2U0RBibFIptf4qopoqlJgPIZ7cI2uDwuUs0SLtTvO4vbWgTVCMAEEQdnPvIjaGaJa08iWF14AvvKV7gf2PEqBn7XmrlsRbSOiAIQ/gE6SCxvTZY1FIlrcH+RgN4now8lD5DrHl699uf5BxagSGwguoB1hl3S6bmiNXCYr2y0d7kAzhtxzq7+zgshlxTiUvoooZ5zU466kvShU8g4kqmw9GASbteaG54DjwPW7F4QFE4Dr2CuiggFczCmiGAyQTM6WHp5nEtD6ypoL4OKHiz1jUFFIAS9rHt8CAHf37+LAP0CcxYizGNH+Ho4/u4/8dN5G68bdZ4gaWC9IgwHdVGsUUVO93gXkOkeqUkglkaoUqUoROIGVAhZNThHAAR+ux2o9cAcQXOAkJMJiY81lYODp+se3LFnvjo+J4C1sPMX+IRgY1PgMOLSwvZ2e0r8HB1MCGsetm/EmlIro4gxRgwUi2sWa+zh6jMAJ2l0Ai8cDliuzVUS5gDMYgcVje2uukthL5GpEtLjRm7ReLnoQUS6gexDRJkWUMZovmj0L8wnffpvU89dfB+7f76iIZu2KKGiGJpKTqTV31opuiVkSJZUEzs/hNW3OF2CIqFFEN5mYCxSvPwigHo1R9c5rE3Pv3we++AL4nd+xJt1zYKycJXoRYUVERGMKHWu4lnkwANIUSis4bEtbK12Mz1lQRAFABi4GO0hEE0XOosZ7aRRZ74k444DrQo3jzW9wlUKudS/nyizMWpANfHhVa2tx31I+FZr6qq+Ci37qsSGiHTILyuLlIACPY2oN65md0AVpeA4nGPYqyHVWRD137vswRDROHmCg1FwAonnOK2vuFRFdQhZNKPWq65gECwgucC2YsYi+9E3g4UOkX/p6SU4ZGNzonZXsfNZoSM41gTzbwHF4jKfx05J0VimJjDEr8hGOn+AArlXIgS1G7ghnCVW4Wm1vjgM4DpxUrd2aWzm6xVi+Z7G/DwGG7PzU7onNDNGDgylRiyIa5dITjYooUAYYdAorCoLSlntnv+J9N8HYgReJ6MnJ8uiWmb9x5FOr71FrTQnYcbqiIkrnl4z7p+Zy4fRTRAWnolyNvdThDjKzAdpVRTTLgL/+a+CrX6Vr0YRvWWyCTI8os1BE+XAEnD6YG99S+bmlKfDf/zvw7W/T65nBoiLKxhM4ty1ToIu/Z4whVSm01oizGAf+epwgNhBFOrQKn1b+PsmSamL8wx/S2vL1r/c/eEFES0fFRVhzB3uN54wIhkDyGCpXvRWqlZEk5GApiGgZZAcg9RzgybJFcNtoHekD0Jpf4VKpAo0lceySTteNNIWGBvNW2z+W98E6O3Xxs8x3VzrXyJrbQxFN086KqHmdahjALXpcmxwG64IMx3B7Zr506hGNY2SeM/d9+I4/P0v0YLoem+e8suZeWXOXQETU38yN5M4d4OQEXqZx4B/ghdEL1CMRhpshojdvNvaIbsti9ODsAUIZwhc+bgxu4O7BXbx6/VW8cfQGvvbC1/CNL30Dggl8fPpx4/NIJSHjCYZwVyIDi9jzprbt1hsoQPbcVK7dmmsScz3h0Yb7yZPqm/XeHgVpVPQpVGKWiJrPbQXFyySBlorocLg8zqQIMLBWRIvgitOEyHUnWy5AG8ogqFZEr1+v3nAGAdxEWfWIylwCOl+LNRcAsqR/jygTAsjzbtezlGVYRp2y53AHWUFWd1YR/eUvaXP+ta/Rfw8GpBpZvF7rHlEU1tx4xppbp4j+/OfAf/pPwM9+tvwcsz2iMoYbxmCWibkAFedc7pYFPK31dhTRNF5KYweIcCypXp9/Ttbp7353flxSVxRE1KgR67bmsjgG32suxIlgcGGhdNYwlsfRiJRZ7kyT8P0am+eWYdLnG9FVEXVcu6TTdcMQtDUpoirwq9eq0pq7DiLaTxFV0GWh1AazKi+AjdlzZTSBO+jXajdVRO3GtywWBjjj8EcHUyI6A3N+diHzlxVXRHQBWRxCBIPN9NUY9epXv5r/+aaI6NERXRwLC91sZX7TkIpCfW7v3cbrN17HvcN7uL13GzcGN7Dv78N3fLjCxd2Duxin49IiW4VQhkCSYABnrUTUzBN1hWtnvwsCOHL9iqix3jHGiOBpvTS6BUCpiKrxcp9CJc7OiKR53lRJXoFozPXLLSbmGhTWXMYYGGPtc0SL1xXJCJzxbrbchWPOoWp0i0EQwE2klTVXKgnECSXtrhJWVMwxk8kKiqjjAirvZleUknqHgFrbl8MdZFpRUWFXFdG336bP/9VX6b+bxvYsgBRROyLKByMgSdoV0fv36d8f/pBU2RnMzppOz57A1fYzRA084UHmcuOJucC0R1QhX/p8szyrniH6wx/S+fPrv77awQsiCsyMiVgTsjyDG6Wt6g0pohczL9oaM0Q0y7NSJXe4A+k7UzfAjsCkPDcS0Tyn192hR7SrIqq1Xk/hvUfvZBVK9dCvUURnrLl9ZogalKFIXftpDeHuMr6FzZBrYGOBRTIar0REmetZj29R3nLKfLB3rZqIGmvuVY/oFRFdRBZPIPwN3bwrknPLHo9NKaLAkipqxsBsY4TLkt20BjeHNzHyRvj07NPaG78hosMLsOYCFrZcA6OIrrlSPje6pSYxFwAwGsFhohxN1AozugWYfm4rVNLnEkQXZ4gaGFKo9TTmvQ4zCYoyl3aqdBUWiajW9UQZIGtuYpd+LHMJJAmN31iDNTcriGifOaJMOECuKHzHFlJS7xDqk1/LFMQ1jfhZO9IUeO89suUahdt8F5ZElGfFedhizWXDIXiaQhVFikpFVCnggw/I9v34Mb22BZhzXz593GmGqIGZJWp6/LeiiEIvbTKTjF7P3Jr59CmN1fnWt1Zfnw0RtVk/DN59F3j0qPVhMpdw4sSCiA6AJN0ZRdQQUaAIIPQdWuN2qGjUONLHoGJcVxNKFStLrNPeP3j6Ad5/8r7VYxtRWlZXVESLNTcL3HpFlHNkDl9dERUr9Ih2DCsCADXYHBHVWiOLQ7grhI9yx0WeWSqirlj6PoL965VE1BRKeAdV+bJiZSLKGBOMsZ8yxv5oHS9o21BJTOmYm8DeHvXGzBJRKclmuSlFFFjqEy2tPFtIzo1kQUQtFK57h/eQ5Rk+O/+s+rmyCL7UNMdzjYqo4AKHwSH2fcueySCAk2RrVUSN/W4uMReoVkQ5hxiMullzDRFdgzXXbMwczSgIqU4RLfpGOOPt1tzidVn1F9VhkYiOx0RemhTRNINU7TclqSSQxKSIrmrNZQwyiahXsWePaC9F1LFQRPNsdxXRv/kbWk+NLRfoT0TbNpbDIdnfQ9psVCqiDx7Q5/RP/gkVY374w6WnMZ9pevaEzp0eimiqUkQygsOdjfYqlj2iyJc2mZWE48/+jP797ndXP/hwSPfNNLVTRPMc+P73gT/5k9anzvIMTmhBRAdDQKZQXfux14kFImo2/y53kZpgsR2y55rzojWoCLBXRFnR16e1ddp7JCOcJqerh1wZgraiylWStjpFtLgHZnq1fmTBBY1v6U1Eu41vAaZJv5sgoplMoNME7rB/voXwfGtFtI6I5tBIz+d751WagIOBrVi0uAxYhyL6vwJ4dw3PsxPI4hBOj5jn3rhzZ56ImotzE0TU9MLtmCLqCru+h6E7xK3RLTycPCwJ7CxCGWIoQb1HPTbwTfjKja/gxX3Lweu+D5FWhy71xWfnn4ExhhuDgtQdH1NhY7H3soAY7UGFlgFUVYroCkTUEHBxdk5ks4qImk1eGLZvJC+KiBoyX6eIBgEczaAtRvEYRdRZlYhyBxACWRqTRbRHHx0TAlCqe4+o19wjKphArnNoz9tNRfTtt6nQd+/e9Gfmu7DYBBERzekzb0t3HAzAwZAXoVKViuj9+9RP+/rrwN/7e8AnnwAfz/e5Cy5o1vT4jBTRg25hQ65wobXGOB23J3qvGXOK6MLmeWmGaBRRaNPXvtaZbFdiZpZoayELIDU2y4CPPmpVzTKZwEmlnTVXa+TbnCVqiOhwOKeIesKDdHeXiFopop16RB0qiFgSLJOJsXJIY2lZXe3aK22svkvn6eL7KFxzfdK5Z9F75mqPsKLpeyq+6w30iMpibIo76k9ESRG1+HySBMpdHk8VjA4BLhCPF4ioTOmevua96bOIlYgoY+wlAP8jgP9rPS9ny9AaWRLBGWyYiD56NF0INklEhSAyuqCImpvXthTRNlvuLF7cfxEOd5aCi1SukGQJBlJPE1K3hUIRzXVHVaoGkYxwEp7ghdEL0xv4yUm1GlrA2Tuws+YqNZ/uxjmpQeuw5j4telTrrLlAGVhk0yOqtYZUa7Dmmo1ow+gWAMBgQFbbJG0t0khFM0QZ2Go9olwAQiDPJBjQi4jyPtbcNIVyRONYgGmF2909RTSOKajorbfmSWTHHlGeZe1qKAAMBtSHXczQrFRE798H7t6l9eib36R/F1RRhztUVBuPqYrfcWSSuRY2PboFKPqpgkGtIjo3Q/QnPyH3wfe+t56DzxBRK2vuo0cIIZGF41Z7bjY5b50hCgC82DeomjmqG8FkAgwG0JzPpfe6woX0BK0BO0ZETchWLboqoryY/Qht1fuotUb24BPg88/LNPze6EHQqlCGbhnStljoC0PkgY9c5ytbc+G4yNPY2sYMALpIBzYZBjYo3xNHdVDgBUCODRHtnx4uvAAqS5s/H62RxxFyb9mFErgDYBAsEdFcpuTWW2Es3mXBqoro/wHgfwNQu2tkjP0vjLGfMMZ+8siiH2OrkNT/tTFrLkBEVGuaowZslogClcm5nHEILjauiGqtEWVRp+AZhzuVwUWhpM9xmOi19of2QhBAJNPesVXx6dmnEFzgzt7MyJKTk8Z4ezHahw7DdiJ8XqiWs0qMGXnRE2VY0Wlxk6+z5gLtioaJfR8M7KrpTRgOiXibzcrJCRG9OoUmCMgumSatRRqZS7hp8V2voIia6j6A3tVT1tuaKxqr7SUR9ZzdI6LvvUdKwltvzf/c96koZbEZ11qDZcpuozAYkDU3mpBKrPX8ZxdFZM19/XX6b88DfuM36HXOrL9GZcb5ObxD+9EtBrPXwqaJKED21Koe0TnnQhQRAf/KV4Dbt9dz4FkiamHNzR9+gfdwjI9xCnz4Ye3jtNZQ4cSOiA5HNK853jIRLRJzgek16nIX8ANkFUFS20SqUrjcbQ6HHBcqZWdFVFspfTKXwI9/DPzohzhPVhxvIyU0ALaGABrBBZQZA7P4nYUh1JCu75WsuWbUjdaVSdd1UCbFveP7LK/NqqDAC4BRRL0ViCh33XKUV/2BigwQbzk8yuEOnMEe4sn8+DwlEwiL0WDPA3oTUcbYPwPwUGv9F02P01r/n1rrb2utv33r1q2+h9sIdBRBIafh5JvCYmDRpono0REpQQvVHjPCZZNIVAKtdSdFFKgOLjKhR8M0X2t/aC8EAYTKAZWtHGRxnpzjLDnDnb07041uGNL/GhRRsXcARCFUm8VkdnTLzOtfiYgaRfTJU9qAV23oZq25TYqGlHTDXBcRLY4JoHl0C0DKNjj1grRcG1JJuGlGz1Vjl7aFKKzyrKc1lzsuKaJdrbmOaExkLImoXxOosU28/TYF/bz00vzPzdgeW0VU2iuiZM2NyvN9boP4wQe0xhoiCgDf+Q59nz/6Ufmj8m/GY7jPIhH1ArL6VYQVla/tBz+g8+Uf/+P1HbijInr+8BPkwyGe7jvIPrhf+7hyhqhN+nUQkCoebmYsRSUKImrWp1lFFL4PuWNE1Gp0y+kpFY8sbeqGiOa2RFRJIJxgdBohTCer7XvWpIgCRb+4X6wHi+trFJVjUFZJze1jYwZmgnY6vs8yV6CYG37RkIULzNlbQRF1i3aDJnU9SajI43mVhYFgeIA4nFfbc5PIfmXNXUkR/R8A/E+MsQ8B/N8AfpMx9ntreVVbgumhczZJRA8O6KLcFhG9eZMqPafz1RpXuBu35pZBRR9/BnxWHUBUh8XgolCGcIULN5Y7oYg64ECarkzuPz37FJ7waN6sgbFWNymi+weA1lBt9tw6IrqKNbfYFPInp0T0qqrfttbcGZvWhRDRpqHpXay5OVlzEQQr28JFkZTLGe/1XGaOaB9F1MqaaxTRLc0dXkIYkg32rbeqP6/BYP1EdDgsSUjZEz27Qbx/nwoSs8R4bw/4O3+HZosWqo/ggj7H8Rjute5E1IzrALZERJmgVMyFz7ecIXp6SurTN74xLcKuAx0V0dOHn4BduwZ9+w4ef/hu7bmb5RkQR1aKKBFRDhVvuUd0NJpPKkexRgY+UqidIqJWPf6np9Tr3aEIJ7xijJCFNTdTEpiEOJIOEEer2XMNEV2x+AgU11KVIlpMVsiKMSirW3PtSbtBLlNACGr76ICySFTMDb9oyPAcAhx8tEJqruu1fz5JQmTVrSGio2UiSorolTUXWIGIaq3/d631S1rrLwP4XQB/orX+n9f2yraAbBtElLH5wKIilntj5MlsvBcDi7i7cWtulEVgjCH4f/8Y+GeJPrsAACAASURBVC//pdPfzgYXhTJEKENSVjvMH7sw+D5ZMJLVAoseR48RyhAv7r84TxDMd9fUI7pPdtPs7GntYwBUE9FVrblFoAKrG90CUFXQ89o3kuaGHAQlETXhWp0xS0TbRrcUx3TAwVoKCqZ31Y3TtZx7ohiO3meGKABwQXNEO49vEdzemquUdULlhePddykVdTYtdxaDQYewIktrru9T/1Mczc/NBejcun8feO21ZbX9e9+jz+6//TcAxWeaJHCyHPxazbXSAk94YIzZj5daIwQXtEGe+XznZoialNp/9I/We2DHIaJfWPsBNNr7Tx9/jsObL2H48qs4iU5q+0TnFFErIrob1twlRZS7AOOQntgZIqq1thu/dXraOdDKijwUkONTQOc4RABxer6aPVdK5EzTmrsiyJpboYimKaAUVJE+u2pqbi8imsSA6zYWKuuOt1Frbni++ixv36KoUSqi1bPlg9E1yGg8l6itZHplzS1wNUd0BiURXWHmUC/cuQM8fEgbuTDcbLhO3QiXLSmivubg52OaN9kRd/fvlsFFcRZj6A7pprsriqjsr4hqrfHZ+WcYuAMcDRdUO9Pb2DBzUBREVJ23VHvPzogQzlZ0V7XmakWVvydPmoleUSVtVETN6ygUUYc7nW+Gc8cD6Jo7P6cbcZMiWpxHTpo1XhvmO3YTuRZnQ6mI9txwkCKqeiii3E4RdYvXtSt9ou+8Q99jXf/hcLh+RZQxiGCAPImW1Cg8fkwprbO2XIOjI+DNN4E//3MaPcIEMB5TYm7PNFlPeCUZ3TQEE5T0ObPJNDNEveMnwF/+JfB3/27n+ahWKGaJlumcNcWs6MlDpDLC4Zfu4ej1ryOERHT/rysfWxJR7rZb7IMAHKzsn9s48sJ2W0FEywDCYLXguXVC5hJa6/Z056dPO18LwvXse0SL4qwLjv0wW0kR1UkC7bjgKyTZGggmoMzaOvudFdeWGYOyamouXLfderoAJVPAcTrbgpesuRfsopHhGJ436NXSYmCriGbI6xXR/WtAliGOpkWOK2vuFGsholrrP9Va/7N1PNc2kRWVzI0qogARUaWoKlvEcm8MoxFtsBcUUYc7a0t5tUWURRiExcX+9GnnRUpwgZcOXsIknUBrjaEIaHO8bUW0sGytMuz8UfgISZbgpYOXln95fEwEr2HEhNgnhVOdn9Y+BsB0dMvsJtbSylgHlSuIKKZCS50iCpRV0nIsSNX3v2DN7W3LNccD6JprG90ClEE3rlSNbgHzOzeW61VEe95MueN2G9+S51RxF7xxo1GmIFZV7beF8Zj6MetsuUA3a66tIgoa35HH0dSaazaI94sexCoiCpAqGkXAT39Km5jzc7KA9yRrL+6/iHuH99ofeAEQXEAtKKLlrMg//QHda/7+37+YgxeFrHIGY81a+/TB+wCAw9uv4MbtV8H29nH8wTuVjyVrbgxntN9eHPZ9CMZJLdoGjLOjGN0CTAkoY4yKy4G7M0TUqrVCa7ondbwWuOdbp+bK86fkdAHDwVgiVWlZPOmKPO2nFFbB4Q4yM3Jndm0tvr9sDYpob2tumgBO9yKwwx3IXJJ9fzYo8IIgozHcYLX9vPAC5ND4/9l7syZJsvM68Fy/vkV4RO6VWVvW0gvQCxpNNAcgVgIkCHGgATWiUTKJHBuAkpkg6Wke5mV+wjzoQU+kSZqhUaRxTKJxg9lQlESCACnCGuCIDYDdXb0ACVTXXlm5xerrdZ+Hz6/H5uHhHuGRGdUVx6ysuyozIyIj3O+95zvnO180QREVUhFN2TPNGp17nOZR8m/C9yj/4SwnOiwIlopoH2TIAD8LRRSgvsjTJqKMUVV+WBGN49RPSxVNxq204wU3CHppeQWwWd1ETafPrxrG/VYLoIhyMMCbHHKTBhEK3G/dx4qxghUjpel+QmIuAKgrtJEH7RyK6HAohGkmdqBpICIB3oo/yyyiF1dJM611ZRJRwyDy3u32RrdkvY+MkbrtBZmfo7xnyrbmKlMSUcbpPghFzmsvPpAINduaCwwdlhZBEb1xg+75cbZcYD49oojHdzhOUohIDiR7e3TdjyvCXLkC7O4C3/42rRMzKqI1vZa+TpwCSBEdVN084QF37kD/8XvAT//0/NbjnIpoY/8WLOjQdi5C5RrWLj+Do9vvIgpH1xtSRGMiOgmMUW/iWfWIyvCXWBFljA3cv5qiwTPUx4uIttu07xRWRI3cATx+64QKP7qOlRM6f0yrika+PxVBSwNXOCmVhpGqiArTSIqBUz8Hm9Ka63tTEe6NygaiKMKhFu9Fc7bn+nYH2ozneZkMnFlgchwECMF0I3XP1OtrYGBwWnTOiKIIYeAVTh1+v2JJRPsQ2G2AsdNXRNfXaXO+f//0iSiQOsJF9t2dVp+oE9BNXmn13exT2HMB4NraNVxeuQzDjw8WZ62IGgYYGLgXTNUj+qD9AEEY4NLKpdEvhuHkkB3QxgzDyGfNTSOiwNREQ4QCvBFbUrIU0T5rLjCBiMY9ojMRUcZ6vSqHh2SRmZTMaJrQ3GxrbqKI2mUR0Tg1t2AwhITsV4oKEtGQZ4cVARlV+7PCG28A29v0Zxxkz3MK8ehHMkc0ryJasQDXTQ7YXOF0iP7xj8eroRKf/CRwfAz13R9SUJFqnP26NQW4whGaOiK7m7y/buCAf+evwdc2aGTNvCCJaHwQTFs/gjBA5+A+Vo2VxJq/+dSLCOwOGvd+lPr93HHBavkOs9ysnp01t4+Ips2x1bkO33jMFFEZoli0R7SAIhq0m9Q6c/kyjJMWdK5PTURDzwW0koioLKiYxuDaKq25KTMri2Km1NwpCHdVq6Km17DPupRZMEciGoQBIseGVpmNiPI4GTj0M84/sTV33OhHVqvBhAqnRTbwMCLXES+hl/j9gCUR7UPgdKmiMeWBb2owRv1MZ0VENzeJgPQt2qetiMpxK5VG38J0MiFYZwwM1cBObWegn/BMIXsLfVFYEfWEh/3OPjYqG9TzOoyTEzrsZgQVAbGNslrLTs0NQ6pAD5Mx+f5NeYARkQBvtkh9zDpQSGtulrXOcQBFgVB5LwBlFkgiKke3TLLJVCpQPT/bmit8IBQ0vqWMHlGNNsKiCYUSMuQonDS6R8L3ESFCqGZbc4EFUkTDEPjBD4Bbt7LVUKD3mUy4nsMohOLlV0S5WU2IaKJU3LlD6+okIvrBDwKbm9Bf/WvobRu11a3H0rKlKipgkJVNvr/em38L4/CExrXMsx8qJqIK6H1LWz8aTgM4OcHq1uXk/V155kPQwHH4w9dHvj8IA6i2OzmoKAY3FkcRHSYpGtfg64ujiLqBO7nHX54Biiqiupm/R7TdJLKyvQ0cHWFFr6PltYqNu4ohQ3zK6M9O9sHhFGppzTW0coiopuYm7RJkzU0P5pmEbWsbrq6gAXeuI1x84QO2Da2aw82QAcWg85vIUkTj1FxujHF7WBYR0Q5dzyKicD++VEQBLInoAAK7C9U4I9Jy4QLw8OHZKaLAgD33tBVR27ehMAVGo917PVMqor0H7alnZwpdJ9uWX3yO6P3WfUSI0tVQoKdkT1BEAYBbFkQ7g4i223SgH6eITql4JYro6mp2aEC1Cvg+9eUhQxGtVODF12VpRDSHvRlAoohGUTRW3fZDH6onaO5nGYpovFmxKUMpFLW4IhoiylXxVhUVgRp/z1koovv7wJ/+KfCv/zXwO79DhOHDH87+mRyFlSiKgCgEE/l7RMma68IX/qAtV1GAa9cm/LACfOITUO4/wEt3fdTXxwQtLTg444AZkwDbBnwf7qt/BX374uQCwaywLCCKwB06UKfdnw23Ae2kiepOr9eera9jo3YOjVvvjhReA+EXJKIVRJ57qtkKCSYRUUVDYKiIZC/pGSP36BaguCKqcIRcyU9Eaytkn/c81H0GEQp0/eJq3bRKYRrk5ycMfVQRZQxCLx4WNIyeIlrMmiuC6X/PNXMNurWKfXTmqoj6oQ84DrQ8tvoM9BTRCam5qgJ1XPBWtQoTKtxOg2y5UQgEwdKaG2MZ19SHwO2CnyURleMPzkIRBegwHverynl0p6mIVrQKKVM7O6SuzEpEF0URjXsL+YTewmHYvo2D7gF2ajvjN2xZPJigiAKAaq0guLc//hvSRrcAsxPRSIA3msDGxexvjK97btPzZBLRWWeI9j/n/j5V3p99dvL3mya0E7on/NBPrQj7wofmx4fgEq25klAWhbT0hnnHq/g+HUxUdTF7RNtt4PXXKYH1/n0icc88A/z8z5OyOEl1y0FEk4MCWH5FtFIFfA+ebyd9vdjbo9mheYphL79MY6s6nan7Q88aXJFENKRD5jvvwGufYPV//J/nr/DGZFGuH8NFvyiK0Dh5gA07HFwvGcPWtRfwcO9VHHUPsVPvFQECz4YWhPmJqFkF2vdJTS+BjBRCp0P3QqWCoBOMrI0ap+RfPwqge97kFOA5wxPe5Fm3jQbdOwWLyVzhEBqfqPKJUCDstqHVLiXnoJW2D5hAy2vB0ou1aYW+C9TKCSuSJDMwdeCoLy8jnqwQIIShzPYZMsYKjbqRIMJtTfV7MsZwbuMy7sKF3TrGvE5nvtMFgmBmIqroORVRXYU2br/UNJh6FZFtwxUuFcmESPb2Jx1LItoHcdaKqMRpE9GNDTokpCTnTjtupChs38aavkKE4Pnn6bA5pTW396ALoojGr0H1fNgFekTvtu6CKxznaxnqyMEBHaxzXDPcqkF09qgannYoHEdEZ7DmyvRb3mgBuxPmIsaHPcV2AW1M2Eg8jqdUInp4SO9JHkW0UoHq0oY97t7wQx+aVyIRja2506bmSmtuVMCaGyICtPQEwH6oigqhKogQgc2RiHrCw8ndPYhvfB0X3jsi5f7iReCLXySlLSdRAJCfiPp+MSIaD00P7A70lXhW6b17wOc+l+91aRrwsY8RGX1ciWisiAYIgcNDBH/5TYRXrkC//sz8n1wS0a4DGKPrR8trITw+xhpM4Ny5ga+ZT30A1ht/hcP7e4NEtNNGJc8M0RiKaQIeHTRntU0WhnRTMYYgDEZaOXROY7k8COi2vRBEdNWccJ1PMUMUIKUvVPlEchWEAdDpQruwmgTpqSdNVHYraLrN7L03BaHnAWpJRFRac4f7eiURDQNY2ux5JtMRUReKPt2cYwDYWruI+4qK/ZO7uDr1o2TD79B5RrNmC27jOqXli0k9opqKSsY9b1qrgG3DCRxaJ4Mg2dufdCyJaB8C14axckYHgM1NOoj45cweLARNo8U+JTn3NKy5vvARhAEqTkD9juvrNNfx5s3ZHnhRFFGAov3d/Km5Xb+LhtPApZVL2Qeaw8NcaigAcKsOPx5HkPqezEERFaEAXAfccbMTc4HkuldsB9DGKKKOA1hW0oenzdrsX632bGqTXh9AiqgTK6Jj3AK+8GF68edcwrUnldBpe0TBORSw/Km5nkeKVg7rFVc4wBQIXYNasjXXDVwcO8c4cU7QcdvAH38NOD5B5ad+DmuvfHKETOSG/EwybGEDimhua258KHRc8DVOIUVRNLk/tB8f/SjwzjuTrbwLCq5wCkVDBHzjG3C9LvBTn5u9YJQHMVlk3S4Uc3QWccNpQDk5QR3G6LVz7Ro2UcGt2z9C9/pHEhIXdFoUZFNEEfWmH9M1Ezqd5HWmEWFN0QDDhA9BxGYes1xzIgiDfD3+U8wQBeKCiKZBuA6ySml+4AJ2F2p9tdc6cnSElWeew35nv7CyTUqhOd+wItsGqlVqeSljXqmqQzAU6xH1/akdOgCgcg2b1U0ctPdxKcVGXgb8ThMcChRrxtRcJU4W9iYQUZ1n/h5ERO/BCRxyAgQBlOrSmgsse0QHELg21BlnDk0NRekNYD9tIgqMTc49DWtuElTUiqt+Gxu0STabU48MoQe2aWNZhIHBpgnVE7kPKB2P+n02KhPI0cFBPiUPgFpbIaWiNaZPtNmk92qYPM1CRCMBNFs0RzUrMRcYseamvld91lwZqDUT+u+1nD2iqiCSMq5I44c+NLc8m73sUWHTbvycg4EV6hEtYs0FKDijDGuu7du417qHG49u4I39N3C3eRcAcOlhFy8+jGB88jO498qz05NQIFdY0VSKaDXeO1yXDpF7e3TvXJxgSR9+bV/9Ko10eQzR6xENgWYT3ksvAusbMPgpVP4lWYxHQA2vHw23gXrTpb6sYXKzvo6N+g7Yvfs47FJBNoxChHanOBH1fYisfrJ5ISaicv53WlgRDAM+wjMPLMrtaJlBEYWqZiedgka3IIqgrazRGWx9HTg8xIqxgiiK0PaKjZCj1Nzy5ogCsSIaBD3FsttFWDFTP+NpoCgcoTZZPU4QRRAljB7ZtrYROTYedR7N9Djj4Hda0KDMvAfLETcig4hGto1wgoNIqdWhOz6cwKECfSB6LRxPOJZEVCKKYiJ6BiRQQtpzz4KIylmifSEGp6WI2n5MRJvx5ri+Tn+iqBdWMA2k8rcI6ZOmCe56vUb1CbADG1zh2Ru165KFOa8iWl8hgjFuPqsc3TL8fmkaEdQpDi8iFECzQfMRJymO0prbpeeZ1CNaisoi7zVNA+o5ekkqFTqYjpkJG4QUZKSVqIjOmpoLlca1F+kRLRJWBACBqc0cVnSneQc3Ht3A/dZ9qIqK3dVdvLTzEp5bfxbnv/V9mOcu4NJHPw/bt3FkH01+wBS03BZCPR4inrdHNK8imhBRB5wpRESfeooOuE8IeKweCK4AmgbvEx8DUIKFPg/kWh+PcOm35jqBAzdwsdpwaL0cXuMYA7/+FNbuH+Ooe4goinozRIsQ0fgaEM585yOmIiaicl0aJimqooKZfYpoHkQR8K1vzbYPpyAXEXVdWlOmUG6T63BCQcBvUvuPthIXSTc2gKMj1PQaGGPFxrhEEbU/lDS+RT5GYMTrj1xfu11K0sXoZzzt8+SxMSeI94dZbaWmtYoVF3jUfTRVQvEk+N0WzYed8TxNRQ0tUxENXBsw9OzPo1qFaRMRTfaXnEXO9zuenB1yAkLPRRQKCpw4K7zwAlXC8xyIy8bWFlkz+tQyjWvJwXqesAMbGtegnjRJwVxZ6alnswQWxf2ECwHTnNhb2A/bt1FRJ5AYaaXOqYhyqw6BEFFzzOaaNkNUwjTnr4gaBqAo4DYt+CNENAzpNZQxQ1RCblKyT3oSTBMMDKovUt0C8t801ycCUsJGI6um0/aIkiJaLDVXWnPz9IgCQKDPpohGUYSD7gFWzVW8fP5lfGDzA9i2tukzfu01uta/8AWsW5uoaBXca90rvC4d28d49/BdHNpHRFomKqLFwooUq0ZJyY5Da1mjUcyW+z4AZ5z6qZ66Dnz+83CrOrjCS7EQToQSqx+dDjjjA4powyEitXrYGV+4u3YNW10gOD7EiXMSE1GbiGjOwyyPC9miO7+xFGMRE1FJwNPuXa1Sg1eEiN6/T6nUv/VbpY7acANaK+YxQxTIRx4AIqIMDOpqvDdtbgJHR1DAUNNraLkZKfMjD9Yr4DHMXvxmjFFBRY+JqPzMul0EJpHAWVNz5WOIKYjozImv1Sq2XRW+8HHszBhMmQK/2y5HEU2KGuOvJeHagKZnr3OWBdMO4Ph23/iWZY8osCSiCYIuqURq5YysuQD1Bf3Tf3o2VtL+5NwYqqLSmIo597skpOv4mKqfitKrgs5CRMf1Qp4FTBM8JqLjxn70I0kRzoK0UudURNUVek/D1pjq9jyIqFRErfrkAz1jQLUK1u2CMTb6PsVEJzJN+KFfPhHNg7iwoY2ZCSsdBJrjl6bGa0YFHAqMSQmT41C0R3QaRdSYTRHt+B2IUGCzsjlYVXZd4JvfpLUxTjW+VL8EN3BxaB+mPlYagjDArcYtekjh5iOiBRVRVCqk/Lsu+K3b9G9PGBGV81PFL/xPwMc/Dk94p2PLlYhniQ4roifOCSpQoTc7423dV6+iDh3ag30c2od0fzs2NL2S+xqQhexTV0R9n+6VDEUUAHSrXsyaK88DR0c0HqmkQDJPeFCYkq0gzUBE89gpASBoNajQIIv/Gxv0XrZaqOt1dP1u/sBGz0tC3spKTOaMkzUXoPXV94EgQHCWimj8eyr6jPe1ZWHVjmCqJvY7GWn+U8K329AYLyenQdMzx7cErg3oE+a6WhbMSIFwunACBxBiOb4lxpKIxgg6VPk6UyJ6lkibJRr34M2zTzSKosHRLZIQ1Oukjs6SnLtIiqhhQPV8IAonbmye8CBCkU8RZWyy0hiDG3SgCtKIaBSRGj6OiE44uI+DVETV9ZxEz7KAbpc2x2FFVA7yNjVEUXQ2RDTe1DQ/TLWtJ4qo7ZVmsVc0HS9jB2vGlEFqskd0TuNbANAIlxkOqQ2nAcYYVoyh6+9b3yIl5gtfSEj9qrmKml7Dvda93PMabzdu0xghhdNnJOfHjkEUp0gWUUSh61AYvQ/85i0q7p1hIMxZoZ8EluZcyIs+RVReG0EYoON3sNaJiek4IrqxAVZfwebDJhpOg1pGbBtqgfEPPD4/hM4p92DKa3kCEdX0Cnw125Y+gIMDuu/+4T8EHjwA/uN/nC23IUau60Lu/dMqopo2uUe03SCyIq3XfQV5uRblVkULFPDyghTR+HO07eRzltbcMpwGClMQamr+sKISFVE4DrbNTXS8TpKLMQmylSsLIhQIbRuaUS2lNYJr+nhFNIoQeKSITiSiUAHbQdfvggf5Z1S/37EkojEUEWLD3IBhPZ6x+TOjXqeboi+wSCaSzrNP1BUuoihChZukfkpSJVXRWa25i6SIggZsT1KYk57ZPIro+npuBZ0r1C8hWinW3E6HDhh9RDSKol4RYkpFNAgDUkQ38qm2kiAMW+sAJIcnz6Dft5QDbr0OXL2ab4YokBQ2VC9It+YmiqhX3rUnrV4zWHOVomFFCgOYMvFApTAFjDEEujqTInrinKCm1wYPVq0W8OqrNJ7l0qWB779Yvwhf+LmCLk6cExzZR7hQu4CqVqX+tFyKaEEiyhi4SWNb+O27T5waKtF/77qBe7pENFZE+8OKmm4TURRhtRkftMc5SBij9Ny7x0AUkUpTkIiySgUM7PQVUWmbnUREFQ3+8DiQLBwe0j78wgvA3/t7wI9+BPzhHw5kSUwDT3gw1AmKWqNBa94UrUq5e0TbDWjVeo+syILk0RGqWhVc4fn7RGOlkGk6WEm5FKqi0toK0PoaE1HZN1qGIsoVDqEqhRRRgQi8DCIKYBMVcIXjYedh5rcHYYC9oz3ceHRj4rrvhz7gONAqsyXmSmQqor4PEYWAPmHcWUJEbdheBzyMlkQ0xpKIxjCvPo3r/8f/icqzz5/1SzkbMNYLLIpxGopoQrr8iBSVfmVqViK6YNZcFQrgehMV0SRFOI8imrM/FIjtStUqRDtlY00Z3XLQPcAb+2/Qodw0p1NEPZfGKWzkfJ0xEc1SRD2dFvtSDricA//kn+QflyGtud4Ya67wwRUOxXHLu/bkZjVjj2gha66Wv68vOSxNqYi6gQsncLA6rPh+4xvUF/z5z4/8TN2oY8VYwYP2g0yru7TkVrUqztfOQ+d6ASIaUAGgwGFBMU3g1i2qdj+pRDRWROWIjomEo0ykWHMbTgOqosI66RDhyHI/XLsGs+3AsgMaEWU74LUCRMg0wcEgTlsRzUtEuQZh6Ajz9rD2p7L/xE+QM+GNN4A/+ZOZyGguRbTRSA/Py4Feau4kItocnDO5ukqF3aMjMMZQ1+uFiWiZdkvOhnpE50BEFaYg5FP0iJZgzQVoXNtWdQsnzkkSYjWMltvCjUc30HAb0Lg2kbT6Iiai1XLyVkgRHXMtOQ5NI9AnK6IaOLjrAoGgIuciTHRYACyJ6BI9DI1wOQ1F1A5sMMZgytEt/TbT9fXprbl9wTYLgfiAIoedZ8H2beh8QuN7FBWaIQrEm1a1iiBNEU0hol2/izAKewf3aXpET46gRDkScyX6FI0RIho/v6fRsnWqSotEQkTpkD38WfqhTwWcMtV4uVlNu2nFqblRXkud70OoPHcQhqqoZB8LAvpTEA2XrOJrZp+NdX8f+O53aa7mGOv5pZVLCMIgs7/oduM2gjDAtbVrNHc2TgKPJhRWphnfAgDctADbpvfuMZ0FOiukIpp7REeZsCzAccBDaguIoggNt4FVcxV49IjWoayCTvyZbT0ioqY6bu7EXACJ8+UsFVERicSpMAyd64BhwLNzjCWRe0x/sfNTnwI++Ungr/8a+Mu/nOqlhnF7yrxGtwByjqgKEXiZhDnotKDV+oiobHWJC/Irxgo84SXhSpkoy7LaB1Ir4+vVcZI1S5hG0o8983MwjlDliApbc2ckorJ1pdulUS5RNKJ0RlGEu827ePfwXXDG8dzWc7i8chlu4CYBZKkvUSqi1VNQRF0XAhGYbkwMKwIA06UiJ4eyVERjLInoEj1sbhLxiw+TSmzNm7cianADynFMOPsJy/o6VQCnUVrkzyyKImoY4FDAvBzW3DxBRfv7VMHc3s79EhJrbiel5yWFiDpBTPyE17PmFqyCi5MjUoLzEtFqlQ7ySAkrkoporNadShLnMDinymc8J3RYFfWFTwWcbnfBFFGGMO997PsIVZ77kKMqKgItJslT3KsNpwFDNQaVsz/7M0pR/umfHvtzVa2K9co6HnYepqrT0pJ7vnY+uZ90rpPl3IxTfseQ8ySsSOGFeoy4Sc/DL+/S638CIdVIeXg/9bAiANyhlo+W14IIBantBweT589ubAD1OtbvHkIBg2p7xYiopoErKoR9ttbcccqMpmiAacDv5iCirRbtMcPFzi98AXj5ZXIs/Pf/Xvil5i5QnJxMTUQTRTTu9U5DEAaIuh2otaG+9HiEC0DOCwD5VFHPQwSAlTiSgzMOwaKeI6lPES1DDQVkP606MWE4QVlhRZKIdjrQuY41cw0H3YOkAO0EDt4+eBsP2g+wVd3C8+eepzXfXIfO9UxVNFFEC9jqNrPlhAAAIABJREFUs8A1Y7wi6roIEIIbE0SPahVgDKYbJ+YWdNu8n7Ekokv0sLVFROOoN6NPjnCZFxLSJS24/eEesyTnSrVjgRRRAOBekPl+RlEEJ3Am23L39ui/Tz2V+yUk1lzfHSUMzXh0Tt+hSxJRX/j0+qOoMNEQx0e04OYMVJKbk+J64625mnI2aqiEadJ4Foy6BfzQhxYxOvyUNQ9YKqEzEFEOBlGAiAq1oDU3VqmLXh9hFKLltQbV0Js3gXffBT796Ynv4cX6RYhQ4EH7wcC/i1DgVuMWKloFF2oXkn+X141vxtfPGFU0UUQnHS6GoMSpqfzpZwr93PsJZ66IAskIqCObLJYrqkX72iQiyhhw9Sr4e7exo65iLTKK3ceMgRsmjXM4TXQ6dKjVtGwiyjXAMOA7Oay5sTuqs1IZHJXEGPWLfuADwB//MXDjRqGXmmt0ixBEhKcM+2KMQVF1Cl0bo/T5HimMWn3oOeIRLogo0VXnOlpejsCixJpbXuFFVVSIUCAyjEEiqk8erZUXeW3MEpHnIUI0+wxMedaIf6ed2g6CMMCRfYSD7gHeevQWPOHh6Y2ncXXtalIYZYxh29pGy22h66cXfHzhQXFcSusvAYqerYgGCKEaE9YJRQEqFZhO0EtkX1pzAQDLd2GJHvpHuMRKm7SyzQOyar5ZiRf+lZXBCpEkLycnwPnzxR5c2kgXRRGVRDQQmdZcJ3AovGmSIrq3R4eqAhVjrnCwqkX9DO32oGLTbFIoRGznkj1eAHrWXKCw3Vk0TsB1M/9hLv4+7rhw9KE6mW0Dug4P4myJaKWSzIQddgv4wocWqMn3lYJZrbmcQwfH8YQEyQS+D6FNqYgWtG8nQTKyPzSKgP/6X+m6/qmfmvjzpmpis7qJ/c5+b+4ogNtNsuQ+s/HMgEVRft0zOCyArqnaqH0rjEIoQVi4Yi3nSPKnc4ZfvQ+RKKLCPX3nQtJ3ZgOmghPnBHW9Dn58Qu0aeVoZrl0D3ngDF48DAPViiigAxTDhu9MHd02FeIYoGJusiBoGfDvHuIzDQzgI8LZyiN3uI2xbfe4bzilJ97d+C/j936f9KKuX89lngQ9+EEBORbTVorVgSkUUiMlDhiLqN6nAra0MEdGNDXKFNZvA6irqRh0nzgmiKMoOIZqTNReglFxVWnNNE4JFpSmiMtgpLxGVRZaZZ2DK/TEmojW9hqpWxa3GLURRhLpRx/W160mLWD+2qlu417qH/c4+rq1dG/m673SghSitGMw1g5xsQowWhF0XIo8iCsSzRH1AiKU1tw9LRXSJHiQRHeoTnZc1VypuiSI6rJrJv7+PFFF1giKaK6jI94H33psqDIVbdaoSt4YqvEMzRF3RIy2JNRcoTDRE4xh8ZS1/4IQ8SDpueo+oacITXhKkdSboU0T7P0sRCoRRCM2L/60sImpZwPXrI8mxucE5NHBEIvvaSxBbc4v0iE6riDacBrjCUdNjMvjmm8C9e8DP/mzuTfpi/SIAJKpow2ngsHuI87XzqGqDB5GEiPaPREgBEdGgUH8oAKhXroLtXgG/eLnQz72fIEenuIF7urZcoKeIdmmdEqGg/lC5p01SRIFeb++bbw48Zl5wo3I2YUXx6wzCYCz55wqHYlbgCXdyOM3BAVpaBFQtHNspe7CmAb/yK8DuLvD228Bbb6X/+d73yGofwxNe0q89FjPMEJXgmgGBMIOIUjuQtjJ07hiaqb5irECEYqz6lqAsy2of5BosTL2niFarmcWGopCKqBA+FWsmQBLWom6R0ScmhTCxlQM4XyPB4dLKJXxg8wOpJBSg63iruoUj+yg9vb7TggalxBFqxviihlREzRzPJYlo0RnV73MsFdElejAMUsWGknObYc7UuIIYIF1HR6MjNEyTXtM0RHTRFNFYfeRekNkjavtxeJOascjfukUV26mIaI025/ZQj1CzCVy8mPxVFgkUpgwS0YLJuaJxAr51cfI3SiSKqJfaIxqaRr6gi3nCNKHG12S/WyAZ3eLFr7usa49z4CtfmenndXAgpOCpiQcYz4MwlULWXOg6bcYFCxUNt4EVY4WUhiAAvv51cj+89FLux9C5jnPVc3jUfYSt6hbea7w3YsmVkAqdp8cHrkwiWnzO27kPfwK1538CbFob9fsA8rqxAxuWdspzuft6RAFaS1aNVeDRW/T1PCnjm5ukkr/zzsBj5gU3TQhnhvnX06DTScaciFBk3uN6pQYfIV37Wdf34SE6a9TX1vba6Um3lQrwq7+a/dq+8Q0KNvJ9QNOSx8lUF0sgoooek4cx1tygFRPR1SEi2jfCBU89hbpO72vLa8HSM66FmIjyMomoVERNAzhsJkRUhAJcK9maK4nWhN720PcAxspRfuO54RLrlXWsmWu5xt9sW9vY7+xjv7OPSyuDRVqv00QVvDxFVI+LGp43Km7EYUWmkWO/tywYD1pQhCCivCSiAJaK6BLDSEnOlUpP2bB9GwpTYISMiNGwIioT7KZJzl00RZRzQNNyKaKmamYvxHt79HhXrxZ/GfUVsub2K6JRNKKISiJa02tEsPqtuXkRhhDNE/C1nP2hQK9H1HZSe0T9Cm1+Z23NZa5LSmDfZykrs5oTk9OyekRnhaLQpifCfO6GKcKKoOvpBY4MdP0ufOH3bLnf+hYVnb7whcJDyM/XzoOB4Z2DdwZSctOgKVpPEe2mqxxRFIH5UyiiipoEnDypkCqOL/zTv08Ng3qiY0XUVE0KwTo4oH7DPJ9nPE80UfcLK6JViDKsuUIA3/428ODB5O/tdIBqFVEUTVTLtEoNPsTkouLBAdqrlaRNJFUVzYOdHdpjHlEiaq7RLXLPn0kRjXtEMxRRBQzKytBzrKxQG0RckNe4hopWmRxY5PsIFQaFl6fvJIqonP0ah+CVqYhSwrCWaWPuR+g6lMRehuU+HtfWj8yzTxhSUaPbhaEaIwFHEn63XbIiStdraqBTPL4lryLKul08b13DNqxlj2iMJRFdYhDb25TIGls05GI3j8CikaCitGTV9fX3hyIKULS/52f2iNq+nS+o6MqVwodkAFBNC4Irg4TBtkmN6rfmBi4M1YCpmtNbc9ttiDAAX8uZmAsMEFEAgxuMbcOL56edtSIKxxmxrSeKaGzbXZhrjzHo3ABCMXZO2wB8H4Irua25MgQrWFsB/vN/Br7znVzpyjJ+fwUG8Ad/QMrJ889PpfRrXMO2tY0wCrFj7YxYcvuhcz0ZAZSpiE5BRJfAgJJ+qjNEASKRlpUQ0SQE69GjfLZcCWnPZazwYZZXqojclNaCIjg6An7jN+h++pM/yf7eKEqsudJtM5mIhtlE1PcRNI7grlrYqGygqlVx7MxARAHgIaWc5p4halkzKUaKNqFHtN2AxtTRQgNjA8m5AFDX62h77cHQpmF4HkJNLWWkioT8HIVpJONbwoqJMArLt+Zm2Jj7EfoeoJYUllStDlhzJ+LOHeDP/xx49VUAvYCjw27PxRdGIUKnC61URZTOP2khZJHjQGgcqppjr7BovJcZYNkj2oclEV1iELu7ZD+INw3ZxzGPPtGEdEmimZasKolo0eHZtk2q4SJVnEwzUxEVMVHIDCpqteizmeKwDgCcqxBVc1ARHTO6xeBGoogPDNXOCXFCnyuvF6hqc06E3SHCNEDabRueQZvfmRNR14UKZdCaKxaUiAJQuQYWW3MnIfI8REUVUa4i+Mr/CjzzDB2c/8N/GKs2SjTcBqyTDrT/6zeA118HfuZnKABlSlyoX8C1tWtJz+g46FyHp0SkupZszV0CAwfUM7lPLQuG7eF87TzOWeeoqHpwUGjmckJEK5XC6jw3K2TXE1MWb19/Hfg3/4YUueeeozyAPpfSCOQYonh0CzCBiFZzKKJHR+hEHrC6hppew3plHR2vk6+QNYyNDSroPHiAKIryE9EZ1FCAyENip0yB327QeI80BW6IiFq6hSiKknaiVMyBiMqiTiDnNLdaEJU4+LDs1NyciqjwYkW0jN8zRRHNhLwPvvc9IAxR02uwdGtglnQyuqVMRVQfr4gK1wa0CXPfJWTRQ1rPl/sLgCURXWIYu7v039u3ASBpFi87OdcXPoIwINIlF/w0RXRtjRbgApY/ALTJVir5Q3JOA7EiCiBVFZWbXJaagx/9iP47LRFlHKJaGXw/U4ioK9wkuh4AfE2h97KAIuo1qEqpF1FEAaBaTVdEHQeeQQess7bmAoDmh4PW3NCHwhQi0bEVe1HAVBVaqOS6j4XvUsW7SI8ogMDQgX/8j4EvfhH44Q+BX/91GsWSgkD46PzNq1j9vf+X7u9f/VXgs58tfOjvh8IUbFY3J/YX6VxHEAlEcjZfCpaK6PQYUERPO6wIoMNep4NLK5donWg06BoroojKPtGCtlwgTk4ORe4U0gSeB3zta5RCu7MD/It/AXzpS3RPvPba+J+TB3nLSvaVLJKiWysIESFImyctcXiINjyw9bVkdiMwpT2XMXJaPXyYrD+nQUSTHtGximgTmrWS+rVkhEvsDJN7cmZgke8jUnmu/sa8GAgrAgAhEMT/X3pqbl5rru8BqlYOEZU9onmFBplf0moBP/gBAOoVdQIncdh4wiMiytTSWrN6iujo+SdwuoCec66rXE+k9XyRhJIzxJKILjGIlRX6I4nonBTRgaCi42NaMNIUpP4RLkVQcMzIqcA0k7EfaYFFtp8jMXdvjxazouNsYqiKimCCIuoLsg8bqtFLGQ39xJKaF+5JTERXcwSE9MOywLv0XiRENAgA34enq9C4VupmXxjxdaUFYtCaK3wq3MR9PAtVBOEceojJikYUIRRBIevVgH2fMRq78s/+GfXr/ft/T5bb/jTGTgeN3/m/gVdfxeozLwL/8l9O1e88LZJruqKNrcYvFdHpsQiK6IDdL+5NLEREGQM++lFSJAtCMWn9FnYBy+GDB8C//bek9Hz2s1SYWVsjMvzBDwLf/z6pnmmQv2tuRZR6mP1uRnH34ABteKhuXaAcB9WApVs4so/G/0wWdnaAhw/h+rR/ZF4XUUT7/ZQzRCVIEc0IK+q0oNbGENGNDXq/473RVE1whWcT0TkqosLovV+iQsWdUq25mpb5XvVDWnNLU0TDMP+54uCgVySKizPr5jp0ruNhh1x8fhgropVaaXuwTELOUkQLEdGlIjqAJRFdYhCMkSp66xaA3mJXtiKakC6piKapocD0I1ykIrpIMIzEcppmz+36XXCFj40sRxSRIvrUU1MvsFzhiCoVhK2+4IVmk6ru8TxFObrFVM2kEJH0iRaw5nrNY4BzGMMDwyehTxFNCHv8vJ7Bz1YNBZLrSnUD6keJybIf+vR+2fbiBBVJcA4tZJMLSr5PdrYCBw2ukAowcE2fPw989avAyy8Df/EXwG/+Jm2+P/oR8Ou/jsZ770L79GdR/eUvn/p92iOi+lIRnQPk4fnUZ4hKSCIqVRZJRItYcwEihJ//fOGnl7NkhZ3DchhF1FP97/4dWWy//GWyqPc7A155hX4fmeI7jKJE1KwCCoffHa+IRgcH6Fo6rGqvXWbdXEfX78INio1oAkDrgW3Di4uTmUq5bZMyN7MiOr5HNIpIEdZqY55jaIQLQAXiiUS0LILWB65wCL33eUpFtKx7q6g1N/RKJqJAfnuunHH/Ez9BimirBcYYtq1ttNxWEoAHxyHbdUmQM0KFl6KIujaga/kKt0tFNBVLIrrEKHZ36dDYbIIxNpIOWgbswIbGYztD2gxRCVkVLUpEHWfxiGgOa26mLffhQ7LUTmnLBWK1wqpCOF1SGQEiorVacviRibkG7ymivoiTc4soos0jKFYd6jhiPQ5p1lxJRDXl7ImoVER9+gwluUsU0UUsgnAOPVImK6K+T5XxAtZcAOlrhK4Df//vA7/0S3Tt/tqvAb/924gMA81f/LtY/R8+fSaqsSz0eKY2noiKAIoIlxXrKSAPZGd2n1oWHajlofrggNa3U7oneUUS0QmKaBgCv/u71FP99NPkDLh+ffT7nn6a3Crj7LlFiSjXAcOAb49XRO1H9xCurvbm+4JGawCYLrQoDizyHt6NX8N8Z4gCNEc0Yukqlu/ZgOtCG5df0D/CJYalW7B9e2xgUei55RG0PqiKikDvvV9lW3OByTNX+yF8F9C0coiwJGZ5iGgY0jlwcxP4yEfo79/7HgBgq7oFhSnY7+zDD30wx4VaIhFVtFgRTbHbkzV3CkVUUaiFZ4klEV0iBSl9oqVbc2VQURhSdWicIqqqNB+tqDXXthfTmuv4QByxP4yJibl7e/TfGYioqqhApUpkQ/aJDo1ucQMXjLFk1pvGtZ4iWqRHtHUCY1zFOQvVKnjHBqKoR9jj510kIqp69BlKt8CAIrpoRFRVoYVE7LNSm+H7VBkveKDijI8vVr30EvDP/znNqf3Jn0T7V38FYmMdq+ZsB81pkSiihjqeiPoeDRxfKqKFwRgjO+dZ9IcCvcOeJGiPHhVXQ2dAQkSdCYfr994D3noL+NzngF/+5fEuCkWhg/feXo+k9aOPiEoHSRZJ0LgGmAa8cdbcKEL76AGwtjYwN1PnOizdmq5PNCGi96HxCf2FJRFRRfY+phHRBhFMbWWMW6depyJUnyJa1aoIozAp1A4j9Iigla6IskFFVNp0yySikxKG+xEG/tkoosfHZJfe2iIyeu0aFWeiCFzh2Kpu4cg+QtfvQnO8Ul1JXNrtU3pEhevkDyuKx0vJmbpLEJZEdIlRnD9PN0lfn2iZ1lyZPlfRKrTphOF4RRSYboTLoiqiYQQIMdIj6gYU95+ZmLu3R7aU+vSVPq6QIjowS7TZHNj0ZWKu7MPUFG0qa67bOoFe1JYLAJYFJQyBwB9QRAOECHX97ImoDCtyiXgFYZAQvIVWRENa7jNV0T5rbpFURlVRU/ueE2xsAF/5CvClL6ER2WCMYcUY0581ZyhMgaqo8I0MRdR3l0R0BtT02tnNU+0nolFEimiR/tAZwaukIk605u7tEcn8xCcmOwM+8hH673e/O/q1TofWZs5zzZdUmALVqMJ3xii23S7abgv6+ubIWju1PdcwgPV1ePv3T2WGKBAr86oKkUJEgyY9h7Yy5tyRMsJlUmAREdF5WXP7FFFDS4o9ZSEhonl6RD03mas5MyRZzDPCRRYFpG36lVfoXBgH4m1b24iiCC23RbO8SySiSY9omiLqOYCh59sv+8dBLYlogiURXWIUnAOXLs1NEXWFiyiKSP3LSsyVWFsrRkRl8/uiKaKGARUK4Lkj6tFAeFMafJ8q6DOooUC8OVeqRDbabTqoDSuicWKuhM51KkQUseZGEbxOE8a4jT4L1SrN2HKcASLqQQCmkfStnhmkNTcmor7we6NblL6wokUC59BDOuxOIqJhWdbcMWg4DdT1eukHtiLQuU6KqOf1LOp9iHwfDFgeFqbEs5vPYtvaPpsn7yei7TatWadJRCv0/KEzoWi3t0fuIyOHcry2RtkA3/3uYPAXkMwQBZCLiALUJ+qPsw4fHKADD9bW6Bgkac+dKrRoZwfewcN8ibmaNjORoN5HDWFKX58fE1F1nCIKjBBRgxtQmDKWiEZ+iUphHzjjEFpvLQ6MnAmtRZ5DN8gllVMRVcpaF4tYc+XoFulueOEF2mdjy7qhGjQ3OIpKJ6KcawDnoz2iUQThu+C6mT9AUf7Oy/7QBEsiukQ6dneB+/cB3y9dER0IKpIEM4uIrq8TWRqXGjgMN66ALhoZME0oYGCeP2KPlO9JPwEcwHvv0e//zDMzvQSpiApEpIi6Lh3GYyIaRREpon2D6HWuF7bmBq0GRBhAn5KIKmCAbQ+EFXkQwCIooqoKcJ4kIAdhkNwfWggiNgsZVkT/m3kvyx7RghazvETUDVw4gXNmtlwJnevw9PhwN6SKRlGEaGnNfXzRT0SnDSqaAcw0wcCyrbmdDu2vRQqLr7zSC/wafqyiRLRijVVEvUcP4EGgtn155Gs611HTa9P1iZ4/D69xmBTExkKObpmxf1yOJREpKpbfihXR1Yxzx+YmnU9i4s8YQ1WrouOnv2/SmstQbt+7qqjkYDJNwDAglPJmiEooagFrrudCUUtaFzWN/uQhooeHtK/Kc52qAh/+MHDjRvLzO7UdwHOhRazUPZgxBqZqo4qo5yGIBFSjwFlTrk/LImeCJRFdIh27u7QA370LVVER9ffrzQg7IGteoojKPtBxWF8n5S6tPyb1CeKD5aIporK3MAhTFVFDNcarUHt79D5duTLTS1AVmq0VsFgRHR7dEvqIomiAEGtcgwgFhKElY1QmIUlHLDq6BSBrLtigIuo48FkI6MbZE1HGgEoFzHHI4hn2KaJx3+jCFUE4hxZQyMa8rLl5iGjDpXt41ThbIqpxbSwRDaMQCAK6BpeHhccP/XY/qaKcoiIKVQVXNYgsRXSaedAf/CD9bsOhRUNENI+TQTMt+G764b+zfwfgHNbmhdSvr1fWYfv22F7JcfDPbSCMQujHzexvLGGGKNCXBptKRBtQFQ0si6zIES59546qVk0PLBICYRjMp0dU4XT2ikfc5S02FIHCVYRcmby3hyFEGIDrJfZ/V6v5rLkHB6MFpVdeoc/o9dcBUEvARb6GTVRKLwZzTR+1ebsuAoRLIjojlkR0iXT0BRbJhLuyVFHbt3s9iDIxN6v6WTQ5V6p2i0YGYiLKvWCkny5XUNHVqzMvXpxxgCkQ1SopokNEVB4uhq25AKinDsilirondADU16YgovEGwt0+5di24RkqmKJkJy6eFmJ1WFVUsuZKRdRdXCLKwrAXPDUOnocQEZhabFZr3mJVw2nAVM0Bxf0soHMdQleJdKcRUT9YKqKPKzSNPjepiBpGMprqtMB1M5uI7u3RGnEhneylQlVpHNLbbw8e3PuIqAhFLpKiV+vwfRdRii29fXAfysoaqkb6e7Zuxum5BUOLvC36OeNwQvBgSUSUM07zMdOsua0GjffIWuNSRriMDSyaMuQtDzjjCKMQkWkC1epciChXOITKJ/eIxr9naT2iAF27eRXRzaHzxM4OtZH9zd8k45ousBVY0EsnooqqjxY1XBcCEbheQPRYWnNHsCSiS6SjUqEq8u3bSU9eWX2iSVARQIpoVlAR0Pt63uTcBVdEuecPqEdhFMIV7vigomYT2N+fuT8U6CVaCquSqoj2j26RSFJGpYKUg4h6cSqhsTaFJS7eQBTHHewRNbSzV0MlYiKqcY2sucKnUUfxnNiFI6KVCtDtUr9v1n0cW3O5VowoyoNRlioqQoGW1zpzWy4QX9OGCR/hyCFoqYi+DyBnicqgolMeE8SNCg26T0MUERF96qnBeaF58Mor5FT6/vfp72F8/Ra25tYQgWZpDqNz9ADV9e2xhSiNa1PZc726BWga9EcZ/aVBQPvS2hQhd0PIUkSDTnPyeI+UES5jA4viAh7U+SiiACCe+wDw/PMQoSh9Pq/CFIQan6yIxr9nqUS0Wp1MRB2HrothIgrQPbG/D9y7R3+XjzUPRdQfUkQdhxRRc6mIzoIlEV1iPHZ3YyJKG1sZiqgbuHADlxb0KCKVM6s/FCDbLuf5FVFJRBeNDMShFKovBpQjJ3B64U1pmMbGlQGucARWpaeIMpYoBm7gQmGDquMIEc2RnOs2j8EVFbw+RTKqrpO9zXEHe0RNdXGIaKUC2HbSP+2HPh0A5XuzaD2im5tAowFd5AsrKnrQkIffrOTcltdCFEVnbssF4mvaNKnvOFUR9ZeK6OMMSUQfPTpdW24MbmQooo8e0do7zXp+7hzty/HYCtg05gqWhTAKEUZhPiIaJ/v6nUGbbBj46DYOUEsJKurHRmUDtm8n2QZ54IU+sLEBfT+DiJY0ugXo6xFNG9/SbkKbNFqsVqP7v08RNVUzPbBojoposrZ++lPAZz4zH2suUxCqOYjoPBTRPNZc+Rmk9Xp/6ENE6qRlfU5EVNHSFVEiolb6D6VhSURHsCSiS4zH7i4dtuOejjIU0Xute1CYgs3KJi0+njdZEVUU2piKWnMfE0V0ILwpDXt7tClul5NCqSoqRNXsKaK1WjJY2QmckcAkqYh7Wrxc5FFEm8cwrCkDJ+KI8wFF1HHg6XxxiGifNVcqoskMUWDxiiBxJVlrdXKEFYWFe4BkhX6cIhqEAY7tY3CFo6afrk0yDaSIGuOJaLAkoo81LIsOr+32qQYVSXCzOl4RnXUe9CuvkNJ7+/bADFF57+UiorEa6HcHFdHu/l1EUQjrXDYRXTNJsSyiinrCA988B77/KLFRjqBEIqowBdDG9Ih2WtDqE54jZYSLDCwaq4jOaY4o0BsTlrfYUPQ5RB4i6nkQZ6GIyl7vNEXUMIiMvv46nSfnpogaI8FXkePQfjmNIrq05iZYEtElxiPuE+V37oIxNrMiavs2juwjbFvbpLjlGd0isb6e35p79y4tTlaBKtVpQNMARSFFtE85sgN7/AB4aeN6+unS7GWccYhqhQ4xJyeZo1sA2nw1rsHX8ltzaYboDIeJISIadbsLSURlkJMr3N4MUWDxiGh8GNcbbQqeGtfLGVtzp1VE9zv7uHlyEz84/AHeevQW/vbh3+K1+6/h+w++jyP7CKvGaqHe03lBUzRAVeEp0TKs6P0Iy+qRmjNQRBXTROiOWSf39uh+nJZsvfgi7W+vvTZAROU9nSdkTLficLpue+Df2/t3AAC1nd3Mn9e4hrpRL9Qn6gkP+rnztH+MCx4smYgyVYMIBsmDcGyEvjtZEQWI+PQpogASIjoQWOR5iIC5zREFyG1S5DMuAoUpiFSOKGePaKGeyEmwrLFjtBIcHpIgMe6s+Mor9BhvvklEVFVLX7sVbTQ1VyZjq2YB0rtUREewJKJLjMfmJlWV4j7RvHMCx+Fe6x64wiliG+gpnJMUUfk9eRRRIYC33gKeey5R+RYGjAGmmYTwyI3M9m2Y6pg5VA8e0MJaki0XiK25VZNI7v37A6Nb3MDp1Fw0AAAgAElEQVRNDZLRFA2eHi8XOay5XrsBoz7F6BYJywK33WTj9e02YJiLQ0TjmapqfCBwA5dem23PZROcGfEGnrgbxhWVfB8hA3jBeH6d61AVFU23iZbbQhAG0LiGVWMVO9YOdld3cX39OnZXsw+4pwXGGDRVh2dqo+Nb4jEGS0X0MUZ/EfJMrLljekSDALh5c7b1XNdJAXrzzV4xt6AiqlZJEfWGrLmdR/dgQIV6bmfiY6yb63ACJ7c91xUu9O04nOnhw/RvOjmhfXJlipaOFCiajnCIXAVydEvWDFGJjQ16TX2j42RgkSv6LL991tyyC22SdIpQFPqMCz2HQsFOYYqNeQDSmlvmuiiVyyxV9OCA+obHnekuX6b7/LXX6HGq1dL7wrlujhY14nt8KkV00c4IZ4ilNrzEeDDW6xP91AdnsuZ2/S5OnBNcrF/sLaJHR/QceYIJ1tZogXHd7AHge3tUcX3xxalf61xhmlDjER8iElCZCjuwsWKM2Xiljeupp0p7Caqiwq7EFU3bTjZ9ubGmzTLVuQ6Hx5//BEXUDzyEndZ0M0QlqlUoB/H4liiC53QAY2NxiKhpAmGYjEQBYpWt2108NRSgTW91NR6dcBGe8NJn1vo+hMqhFwzDUJiCD+98eCHUzrzQeUxEx4UVKWrxMJklFgP99rcS1LWi4GaF0lqjaPBAfOsWkdFZC4s/+ZOUFPqd79DfLQtBSOt3HpLCqlVo4FTg60P78D5WK6u51rD1yjpuNW7h2Dke31bSB094qJ07T395+JDG0Qyj0ehlQpQArhkQYUChTvG97DeooK3mcexsbNDPNhpJMa8/sChZQ113btbc/v576aSaR48oVBXCcZH5zsuworLHtwCk7o8rQBweZlvsGSNV9L/8lx4RLRlKyhzRQCqiRoHnk69tac1NsNxll8jG7i5wcADNDWay5t5t0jzSbauvz/H4mBaePDdk3uTcN96gTbREBbFUGAa4S4uZrHD6wh8fVLS3B5w/X+r4AbLm9pGQjMRcCZ3rlDCq6xOJqNduAELAWMlhuR6HarUXVuR58KIAMPTFIqLomxsK9Ky5ixZUJLG1Bf2IrG9jA4t8H6HGpzpMPU4kFIivaWNUEZVhRWyphj6+kER0a+tMigncrCKKolF77t4ekaxr12Z7ggsXaF/Y30/mGhdSywwDGuPw7V5IjBu4CBpHsDbO53oJqqJixVjBkZ0RPhRDtgMY1RUidA8epH9jSaNbJBRNI4LY1/voN4mIaqs5CqUpI1xkYFHHi9+7MAS+8x2EugbUanOz5gZhkHzG80jNHZcw3I/I8xDNY3wLMF4RjSISLdL6Q/vx8st0bx0ezmUP5poBEQyegYVjA5oGtYiDSDoarl8v+RU+vlgS0SWyEfeJavsHUyuiba+NptvE+dr5wQX06ChffyjQI6JZ9lzfpxlrzz+/eLZciT5FNAiD7KAiz6MKesmkmiscwjTIggj0FNEgWxEVoYAwjYnW3N4M0dmIqOJ6CAOfEnMh6PCkLIidJVYM1H4iKsOKFlERBYDNTWiHJ0AUjb+XfR+CK6X3IC0idK7DM/j4HtEyD1tLnC76iegZgMc9Y6I7lAa6twdcuZLL8u0EDu4076DttUe/KBUgILEhFlLLGINmVAeIaNtrAycnqE0IKurHemUdbuCOhvcMQRa+dK7T7Mdx1tySiSjXTZoV3GfP9ZuxNXc1x/6UMsKFMYaKVun9zt/+NnDrFsKf+RwUo/y1X2EKGGPzteYynouIhvFM1lJ7RCdZcxsNOttNuperVWrJ6n/MEqHoBqLARxSGyb8FThfQ9OKFgX/wD4Bnny35FT6+WBLRJbJx8SKgKNDuP0QQBoMN+jlxt3kXGtdwzhrq1Tk+ztcfCuQjoj/4AW04H/pQ4dd4ajDNniIaCdhBTETTFNH33qPelJKJqKqoQLUCMUREnYBSYNMWVTnOxTPVyYroLDNEJSwLChhCu5sQUW5WS68ET41EEe31DiWK6KIS0a0tMM+D5vqZiqhQp1NEHzfoXEdo6AiGAltIEQ3KtZ8tcbqQRPQM+kMBgMdrQOj0Ha7bbVICJ6znHa+DvaM9vLn/Jh62H2K/s5/+jS+9RG6ivhmikrTkgW5a8Jzetd9pH4LbLsytC7l+HqD0XMYYHnUeZX7fCBE9OhoghwBI+Wo0SpkhKqFo+qgi2mqAqRrUSo4wQ8uiVqCUwCI7sEmR/vrXgeeeQ/j8c3NbNznjcw8rgqqljrrph/z63Ky5aZDv/SRFFBgszpQMmSQvvN75J3BtwNBLLww8aXj/nzaWmA2aBly4APUeWWmKBhY13SbaXhsXahcGF2nXpYUnryJqmrQhZFlz33iDNo5ZbU/zhGlCdWhTlIqoqqgDczsT/PCH9P5fuVLqS+CMAwqHkH2ifT2iqX2D6M0S9Q1tIhF1G0dQoUBZneFAUa2CQ0Hk2Ai7HfgQ0KsTBpCfJmIiyhwnIccL3SMK9Ea4NMePcAk9F9C0xSH8c4SmaIBhwhsaYbFURN8H2Nigvvq0PsRTgBKTnAFFdMI86IbTwLuH7+Ltg7fR8lq4UL+AulEfrzZWKsBnPgO88AIAFJ4vqVUsBE4v/bX98A4saGAFyLtstznoHqDpNsd+3wARPX+eSOf+EMFut6nwWqoialDBtY/0Bu0m1GotX5hNyggXgIioCDw4f/C7tBf8wi9Q7+S8iKjCE0WUMTY/a27gjR+tAyRhRqUS0UqF3udxiqgc3ZLH3fDUU+SIm0Nrlvyd++32wnVIEX0CHETzxJKILjEZV65Au78PhKJwn+jd5l3oXMdWdWgRKZKYC9BClZWc67qkiL7wwmIHjBgGuNPrEbUDO3t+6NWrpTe1J3Hw9bgiXCeC5wROamIu0COinqFOtOZ6rWMYTJutr7VapdRSx0Fod+FBQK+c/fzJBJJsOk5iF1YZX/geUYBGuIxTREPfA1T1idhYda4DpknvRZ9iIntEFWPB5hAvkR+aBnz5y0R6zgCJNdfuO1zv7dHa0PeaoijCkX2EG49u4IdHP4QbuLi8chkvbb+Ei/WLqOt1uIE7ftzSZz8LfO5zAKYhojXAdeGHlOJuHz2EBT2f8tSHi/WLMFUTN09uji1Ue8JLxoBhJ07kHbbnlji6RSJVEW03oNUKpPKmjHCxNAt47bvoPrgNfOlLgGUhjMK59cnLedVFP+O84EpszY3CgYTgYYSeCzAGRS2xRSaeGz6WiB4e5h/Hxxjwj/7RXApQXEtXRLluPHb5CIuGBT6xL7Ew2N2FJiLg8LBQn+iJc4Ku38XF+sXRG7XIDFGJLCL67ru02SyyLRcgRdQPgChMFNFUW26jQZXAOVT2khQ+q0KLu6pChAK+8McqopJsecZka67bPKY5dbMUBCwLHAyw7R4RXUBFVM4SVRUVLAhoE19URXRlBdC0TCIqfBdQy5+Ft4jQuQ4YBnyIgeJKGIVQgmA5umWJqcErMRGV1tyUedBBGODNR2/ix8c/BgBcW7uGD21/CDu1naRYKBNaZQtHFoIwKKSUaRULcFz4wifV9eQENWbkLw7HUJiC6+vXEYQBbjdup36PK9xe0NzaGhGL4cCiORBRrhnUI9pPRDtNaFYBIpoywsV8eAj23e+i+/wzpMCBigpzt+ZGYi5FwiQ1d4i0D4MKlRqUsh0z1ep4a+7BARVRz5jsKcaoIhp4NtQy+2WfULz/TxtLzI7dXWjgwIOHuRXRKIpwr3UPpmpio5JCNosqogBtYCcn6daRN96gg3bJNtbSYZpgYFD8AF2/izAK0xXRH9PhpMyxLRJyIws+8CwlzaE3uiUtMRdAUs32dZ4rNdeoz9jn06eI+t0WAoTJEPaFgGHQxmjbqGpV1PRaj8wsKhFljAKLjhsQoaDq9xCER0T0ibDmcg3MNCkIa4SIiuWctyWmBpfWXKmI7u+T9bSvsHi/dR+e8PD0xtN44dwL2KxujhRs5d6QZ1anCEUhtUyv1hNFlIKKGrDWd6YK+qtqVVyoXcCRfZSaousJr0dEGUsPLJJEtMweUd0gRVRac6MIfqcFLc/oFomNDTpzyLYg3wf7oz9CtbqK7mc+nnxbGIWnYs2dhyKaWHOHbMzDEJ4zH8fMJEW0oEo/D/QU0V4frfBc8KVzZmYsiegSk1GvU8Lcgwe5FdFj5xi2b6eroQApotVqT1nKg/V1qtYNV85sm/opX3zxzKtmExH/vtwXSRpiqiJ68ya9P9vbo1+bEYk19+WXgL/zdwBkJ+ZK6FyHp6tkgw5HSQxAB46o04Zen2GGKABUKrQ5Og6cThPgHHqRWV3zBmP0WToOLq9cxtMbTy8+EQWAzc14lmj6CBdpzX0SFFEA0Cu1ESIaRRGYv1REl5geI4ro0DxoN3DxqPsIm5VNrJnjiZfOKQhlUiotMIU1t1oHPBee76DttVFpdMDPTb/fnK+dh6VbuNW4NbK2eMIbLHJKItpfVD456WVBlAQeE9FIkivPQ+C70GoFiOjwCJevfx04OED157+ErtJTSedKRGNFdG7WXMaBlFE3wwh9by6zUmFZ6UTU86hAcUbp1/2QrRphHxENXBvqHJKSnzQ8GaeNJWYGu3IF/OE+/HFpm32QamhFq2C9MoaQFEnMlRiXnPv222SbWXRbLpAQUdXvRbGnKqI3b1J/6ByItaxm9vcdJTNEx/SIAmTP9bR4yRijinoBhVAZKzMSUUWhPivbgd1tALoBPeO1nQliIppAbqSLTES3tqA1WoAIUotK0pr7JPSIAoBm1YmI9h2CloroErOCcw3QdJozCFChdHs7CYa727oLBoaL9cmjUgZGhWSgKElRKxYYGHy7jY7bgtWwZ1KeGGO4vnYdURThvZP3kn+P4nFRAzOgz5+ngmZ/+GDJo1sAQNEleaB1OmgcI0IEtagiClDx/Mc/pnEtH/sYqs88DxGKpIh7GoqoCMVc3CqMMTBVHbExD2Nuhcpx1lzZwrUIiuhwam4YQvhuuaNsnlAsiegS+XDlCrSug6CRMT4lxqF9CDdwcal+afw3FZkhKiEtO8NE9M03iaRezD//7MwQV3t5PH/SUI3RRf3khP7MKf2XKxyMsYFgCSdwoHM9c4PRud4jomMCi9xuE/B96GuzbxxK1SJF1GkDpjF4kFkEmObg+yD/f1HDigBSRCMFaLbGKKL+E2PNBciemGrNXSqiS8wAxhiYYSB0bTrY982D7vpdHNvH2KntpKelD0GOCskanTbVfMlKBRoUNJuPIFoN1IQys/JkqAYur1xG020mY2cGEnMl0gKL5kBEJXkIY0XUj88vWpFCqXRu3bsHfO1rdG75uZ9L+ndlkWCeRFRVKEjID/25jQpJC3YaRujNKUOgWqU1eNhpJRNzF4CI9ooasSLqeQgQQjUXeL9/TLAkokvkQ9wn6t+9lfltYRTifus+LN3CqjlmUxGCNp2iiqgkov1V1E6HYvEfB1su0KeIxmrouPmhwFzH0Eirj0TW6BYJmruoUdV0nCJ6QhXMMogol0TUbgGGkQQmLQwqlcH34XGw5m5tUb/3yckoEY0iiOAJs+ZaK/ARIupXREUARYRLRXSJmcCNCvWIvvceEAQJEb3TvANVUbFj7eR6nKpWRRRFiWslDVPNl6xUoIGj2zmh/tApEnPTcM46h1VzFXebd+EETjoR3d6m/XrORFQZUrH8piSiBfpQ5QiXv/1beo2/+IuArqOiVsAYQ8cnJW/e1lyA1OV5uVUo2CmPNXcO+4NlkU17+FxRZIbonCF7QZMeUdddEtGS8GScNpaYHdvb0DQD/r07md/24PZb8P7qm7jkZZAaGThUVBHVNBo10q+IvvUWVdEeB1suMNAjCvRSEQdw8yaRmTn0h0pIq49E1ugWCZ3rgG6QgjSGiLqNQ2jgs80QjaFULcC24TptaKa1eBHpw9bcx4GIbm5CAYPabI8GjwUBFRmeIGuubliIuIKg207+LfQ9CspaKqJLzABumBCuTf2hnANXr6LpNtFyaUZoXteBLFZmJedOq4jq4IDjQm20YEIt7cB/dfUqFKbgx8c/ToLwBoiortP+L5NzXZfWzxKDigCAqzrAlETF8ptUxC6kiAK99+VTnwJ2dwGQ6l1RK6eiiPZfK3NTRGWw082bYwOLxDytucBon+jBARUnFqAoONwjKoPIlmFFs2Pqq4kxtssY+wZj7C3G2JuMsf+tzBe2xIJBUaBduAz/wd2x3+J89//Dg9/+NWy8/kPUf/P/Ab73vfSE22kScyXW1gaJ6BtvkJ1oJ191+cwhFVFvQn/otWtzVXg548nhJQgDiFBMVEQ1rgGGDh/hWGuu1zyGAZ70Qs30Gq06ET3XXaygIolha263SxtmyXNfS4VhAPU69GbKCBffp4PIk6SIch0wTHidZvJvoecuiegSM4MbFeoRjedBR6qKO807MFQD56rncj+OqZpQmJLZJzqLNReuC6vl0HqWZ1ZjDmhcw5XVK+j6Xdxr3QOA0daK/uTcOYxuAUBjRlSVet8BBO0GoOnQqgVnUj//PP2JZ7ZKWLqVfC4RIjDMZ8/uLwzOjYiurCJcWwX+238D/tW/Av7wD8lt1meXDX0PiqaXXxSWRHS4T/TwcCGCigAAmgYOpXctOfRal4ro7Jjlig4A/O9RFL3GGKsD+BvG2J9GUXSjpNe2xIJBu7SL8NtvIXRsKGYfgfI84D/9J7z3vT+Dcv4cLv/drwB//hfAH/0RbcJf+tJgEt40M0Ql1tep3wYAWi2yPX32s4+HLRfo9Yi6pEaNWHMbDSLaH//48E+WClVRE2tuElQ0ZnSLhJy7mKmINo9RYypQK7jRp0CxavQ8Kodemf3xSkeaNXeR+0MlNjehndwbDSvyfQhEUDRt8dTnOUHnOmCa8OwW5BE8UUQXoAq/xOMLbpoQd+4AfgS8/DKO7CPYvo3r69cL3V+MsYmBRdMTUQ64DmoyqKjE+369so5NdxOH3UMalTT82Ds7wI0bvWRUoPweUSVOg5WKaKsBxbKKF9peeIH+DKGqVfGo8whu4M69R1RiXv37vFKF+F9+BehWyIb85pvA979PReWXXgJefpnWRrXczwhArwDSr4hGNLtejpg7c3AOhSlJv7EMIlsS0dkxNRGNoug+gPvx/7cYY28BuARgSUTfp1AvX6E5XLdvwniWhjjj/n3g934PB0e30X7lJVz92V+EVtsGvnyVKmvf/CZw9y7wS78EXIrDi46P6ZA3DVlZXwdef536TG/coMXqxRdL+x3nDkUBdB3rQkNYOz9qh715k/579epcXwZXODyfFtQ8o1sASs3NsuZGUQS/3YBRXZlqFt0IqlUoUYTQ9xeTiJom9X4FAamgtr3YtlyJzU3ob76DzhhFVFGfHCWQVH4Dnt1nzV0qokuUAG5U4MZrbPjUddxr3UNVq6bP1Z6AilrBiXMy9uszWXNdF9ZxG3hqt/DrmoTdlV203FZ628f58/Tfhw/np4jG8zFlX5/fbkArcR61bK3p+B1EUfR4W3OZAh+Czh5XrwJf/CLwzjtERl99FfjWtxCiDUWbQyhkmjW33SbL9qIoooyBq3pPEbVJEeVLIjozSrmiGWPXAHwEwHdSvvZVAF8FgCtXrpTxdEucEbTLNE7Ev3UTxjPPAd/5DvCnfwq/YuDOL3wO9avPYKsW9zUqCimV168Dv//7+P/bu9sYybL7ruPfc5/qsXu6Z3qePLuzD/Z67V2WtaNNso4RJLZfeO0IGwXbBANRBIoigUgQCBneIF7wAgmFBxFFsrKGIEUJyLFghSIICZECirDixYjYOCaW2fWOd3dmeranH6q66t66dXhx7u2umemZ6a66detW399Hak1XTU/3me7bp+7//P/nf3j5ZfjYx+BDH3IZ0fX16VZf19Zc8Lm97cpyL16E88cvc6qEZpNmYrmyekRX4ddfd8HMnEuNJ0tzB6MBxpiHdqU1xhBGTWLPHlmae3iGaEH7fDodfDzGpO7w9arJz8Dd33d7l5clEN3YIBzEjPp7d67iJwkpY/ywPgFY4AV4zSbxzmFJmDKiUgSv0XKl7p0ON7se8W7M42uPT/W52mGbzf4mcRofOU/n1S0nypZ5HmvRKo/FbVZ247k0hPE9n/dtvO/ov5zsnLu97RYvV4qd533jSnPH2YJAsrdDePlSYZ8/b1iUnwk+72ZFMN9AdGwnutYGgVvkf/ZZVzL7jW8w/sPfw7s6h0Xyo0pzK9SoKOdF0cG1NMrOCA5axZSz19nMV7Qxpgv8BvDz1tqdu//eWvtF4IsAL7zwwv37j0vlhe0VWD9L8t0/hhu33WrZ00/zxp/5k4zNkKtnjlhouHoVfvZn4ZVX4Ld+y+05uHVr+kY8+b7S116DN96Aj3506v/Pwtzd5GbSHM8PnTRZmjtMhzT8xrHKxaKgQdIMjxx/nMaw16NxvqCV9XbbBQRQzYxoHnQOBoeB6DIsipw75zIh27dJ0uQwW5GV5tat+ULU7JLcePPgsU1id9UpIyoz8FttUsakTz7OW723WW2sstKYLtDKewn0k/6RgehJzxDNee0OG29nt21zyjzd94iaM2fca+Hbb7vM1+pq4a97nvEgzPaIWkvS26HVfbqwz583LJp7IDqxwDC3rrl3ddK/Q6cDP/zDpO85i3+/j5lFELhtS5MZ0fzolqpkROGOjGg6dIvxyojObqbfGmNMiAtCf9Va+5VihiRVFfohXLxI8v033AHdL73E9qdfYosBl7uX71/a2WrBZz8Ln/ykC7S2tqbbHwqHgejv/777c1m65U66XyC6ve2yxXM8tiXnez7WWsZ2fKyOubnIj4ij4MjxD9Mh9HpEZ6b82d5tMhAtsJyqMHlGNP9e9PtLkxGNjjrCJS/NrVFGFCBqd11pbtZYTRlRKYLfbJFiefvKGdJxyiOrj0z9ufIS0P3k6CZx0waitFpw86Z7v+zMkzGHDYvmcHQLHJbmjpMYBgNGaULQLfa1pB22D34u8wpEPeO5s2mNmdse0XsyokeY5z5Y2u07A9Fbt9wcXEDjw6J4YeTO2gZG2iNamKkzosalT14GvmWt/YXihiRVFXgB5umnSfoGPv5Zxpcu8r0b36QZNLnUfUi5izHwgz/oMqS//duuA900VlZcCc/mpttzOk3n3UVrNNz+h7uVcH5oLl9VHY1HDEdDVhvHm+xDL2Q78o8uze3vQjwsLhDtdPCXIRDd33dBzLI0K1pbc/t9t7fvPMIlK80Nw+MtSpwWUWuF7XECSYINQ2ySaI+ozMy/8ij2kStcv9jlXPvc0R3Sj8kzHs2ged+GRTMFotYenpVZtosXXXf9ZtNt4ymYMQYviEh7Q+zODiPGhEVtHclMHsE2z27jgRdgjzqFoCDHDUTndp53u31nae7mZuENtGblhxGDiYyoFzYwXj06zM/TLN/BDwN/GfiIMeZ/ZW+fKGhcUlHB5SuM/tyn4fJl3tx9kziNeWztseN3Abx4ET7/eReQTsPzDldOl6lJ0aT7ZUTz80NLOIomv2kZjAaM7fihHXNzkR8xbkQHZ2hNGu68Q4SPKWplO8uIehiCTgX3iE6W5saxa3O/DBlRzyM6e/7ejGgc1zYjmpBi+313IzYaKSMqM/PPbsAnPgnNJu9amb3By4M656bjdLpMWT5fLeqsxkuX3Ny5s1P4GaI5L4wYj2KSbdetP1wpNvM6GYjOs9u4b/y57Q+FO6uk7qf0jGiF9ocCeMHEHtHhPkFUr20s8zJL19z/DnM6NEkqK/RCknFCP+lzfe86G+0NulHJ+/fW110J6zIHosPhvc+XtD8UDvec9GK3Avmwjrk5d4RLRLy3x90hV7y9RYOguFKaMCQMGjRGFQ3wJktz8wxxFcd5BG/jPP71N+8pzU2x+FG9MqJh1ggr7m3jrXRgpIyozC6fYy90Ljy0EdxxtMM2W/tbRwado/FouoxrPl8tah/e5KLrHEpzwWWx0iQm2XFdh8PVYquoWqFrWDTPrrngrqd5nVMKh9ncBwWbqU3n93/sdODGDff+aOS2cD333Hy+1pT8qEHaUyBaNOWU5URCPyROY16//TqhH86072Vqzz3nztmc0wvX3OUZ0ckym50dF1zP+diWXF6a20tOFoiGfnaEy37vnr/LM6JF7um40rnMu1k/DPqqZLI0N1/JXZJAlI0Nou09kmRiQSQrzfXqVpqbBaLJ3o7LBqg0VwrQjVxJ7uXu5UI+X555OyorOlNpLiwu83ThwuHC67wC0ajBOIkZ7bpANFgtNvPqGe/gPPB5BqJXVq4c3Wm/IPk9wf0yomM7ZmzHc2uWdEdGdGvL3R9VLSMaRoxHbjtLOhzUbtF2XuaX55dTKfRCtgfuzK8n15+c28b5B/rAB8r/mkVqNl0ZZ5Ic3uyWuD8UDktze3EPz3j372x4F5cRbZAMe4d7i5g4Q5RiW/CHnRUYxK4ku2p83/38JjOiy7BHFFzn3LEhvr0JG0+557JmRXV7cY267gY47u/i56W5XlDNa06WRuRHUx/XcpQ82Nkf7d/RfTcPEGYKRBeVEQ1DF2xsbs4tEPWCiYxo1CCcQ3OZdtimn/TnGohO23H5uPKxp+MUJm7r0nHKjd4NbvRukI7TO0qRC9Vuu3uiOK5kx1xwixokCek4ZRQPaLUquGVoCSkQlRPJA5YzzTOst5awUVAVNLIb/cHgMBB97TUXoJawPxQOy8ZOWtIVeqErzbWpe8HI/i/50S1Re8W1Yi/K3ftGqibPbi9ZaS4bG4R49G/dhPe4p9J4cHBod50cBKK9HRp5RrRmwbhUX+iHhH54T0Y0HbvjNJYyIwruNW+OgagfRiQ2dXtEO+25NNvJg7O5ZQtLMFmaC+7e4PredW72b5KOU840z3C5e5lONKdzMzvZ5+33K3mGKLiMKKMRYztmFO8TrE15DKHcQYGonEg7bBP64dFnhsrxTO4tzMtY8/2hJWVhJl8wj1uWC64ZQ9jsEOykZfcAABDbSURBVJO64CsLRPOjWxorBS9OPPss3L5d7OcsUrPpvg/LFohmZ4kmt29hrcUYwziOIQjwFlHlsEBeu0OAR7y/h8W6jKgaFUkFtYJ7GxaNxiNgyiDoscfgqadcB/pFef559zoyp985L2owxpJs3SJor8ylodC59jl8zz/2MWhVlC9OD0YD3tl/h83+JmM7Zr21zuXu5Zm6Ph9LXk3U77uFiW73cNG+IvyoCaOEdDwijYfuscxMgaicyFpzjbXmfLrb1UYeiOYNi3Z33QrgCy+UNgRjzEG79pMEogBRy3UZnez8G6cx9PaIzhW8QPHBDxb7+YrWai1nRrTdJmx14fZtknFC5GcHdQfBYsrtFykICIMGcX832yM6UkZUKqkdtrneu36weASHgehUGdGzZ10X+0V673vd25z4YYMUS7K9RXDh8bl8Dc94nG0t4PibAuUZ0dduv4YxhrOts1zqXjrx/cHU8kC013P3QxUry4UsI2otSTzAJjFBY0le7ytOgahI2SYzouCyoVDa/tBc4AXEaXzso1tyUavL/l2B6HA0xPT6hE/UrFy72XSHsff7rszaX54gzh3hskmcxu5YniTLiM5xn1NVRc0O8f7ewfEtZl77oERm0A7bWGvZH+0flIPOFIjWQJ4RHY0Twu6SNjgsQcNv0ApbdKMul7qXCun0fCJ3l+ZOe9b8HPkNd+8W7+9CkuA3FYgWoX53HCKLdlQgWuL+0Fye+TpxRrS9cliamxkO9ogGSXFniC6LydLcZWlUlIk2LsL29sERLmmcZUSXeJ/TtKJW9zAQ1R5Rqai8PHI/OZx7FYg+mB81SBmTMFYg+gC+5/PM+We4euZq+UEoHL5+bm66YLSSGdGsJ0Z2FJAyosVQICpStslmReA65l69WnqXzjzgOOm+lrDVZYwlnTjCJd7ZKvzolqUwWZq7LGW5mXDjAvR7JPt7AFlGNKxfaS4uI5oO991N/UiBqFRTw2/gGe+OfaKpdc2K6vh7exxe6IKqmJRwRYFoZTUarqLojTfc44o1KoKJjOjOFgDBHDow15ECUZGyTe4R3d11K4All+WCu3EJvODEK+lRx7Usj/t7B88Nd95xR7fULRBtNt3PsddbukDU37iAj0e8eR3gYI9oLUtz2yswHDIYDbJmRfXqHCzLwRhDK7yzYdFoPMIzXi1/b48jbyhjsYQFnyEqBTLGZUWvXXOPK5kRzRY1sjNp/ZYC0SJo5hIpWxC4lb/BoPTzQydttDe41L104n8XtVbAGOL+DuDavY92d2gQ1C8QzYPPra2lC0TzI1ySWzcBSLM9onUtzWUwYDgaqjRXKq0dttkf3Vmaq7Lc+/Oiw0WlYEWBaKW12zAaufujter9rPysFDfe2waUES2KAlGRshlzeP7ka6+5kpRLJw8IZ7XWXONi9+T7UsMggigiyUpzXcfcnivNXanZAc95drvfX7o9oqyvE5mA+B0XiI5H9W1WFHZWYDBkkOy7jKgCUamodtgmHadu0QQFog/jT+zjU0a04vLX0LNnS9+qdBz560IeiPoKRAtRvZ+0SB00GoeBaInnhxYh9EKIGsQDF4gOR0Po7dFodl3n2DppTjR6WraMaBAQrq4fBKIHzYpquNcsaq+CHRMPe3jJqH7XsSyNVuDmmbw8Nx2ntfydPa6DMvtmkzBasjm6bvJAtIL7QwFMo4GHYdzfw8PgqWtuIZbn7lfkNGk23d7QBe0PnYUx5uC4C5jIiK7W7OgWuDP4XLZAFHeES3L7FtZaxkmMN6dD5avOtNuEuHJ5k46hpt8Hqb5W2MIYc1Ceq4zog+V7RGl3CH39XldafoRLBfeHAhCGeBjo9/HxDhtPykwUiIosQrMJb7/t3n/sscWOZQpho3WYEU2HeHs9wjM1DESXOSMKROcuwPY2SRqTjmL8oKaZwFbLlZbvuZVuZUSlqjzj0QyaBxlRBaIP5mWdTk2no+9T1VU8I0oUuQC03ydQIFoYBaIii5AHMI0GXL682LFMIWp2SIZuRT5OY6LeoH6NimDpA9Hw3AUYjUhu33KBaFjTF9a7A1FlRKXCWkFLgegx+UEInk/QqVn/gmWUB6JLkBENjKcFy4IoEBVZhDyAWcD5oUWIWt3DjOiwR7Qf1zMQnQw+l61ZERCdd02y4re/z9ja2pbm0m4T4ikjKkuhHbZJ0uSgYZEC0fvzjAfPvJ/wPe9d9FDkYZ58Et7//oU0bzyWMMTHQJq6km9jFj2iU0Gzl8gi5CUdS7Y/NBc2O4zjAaPxiOHOFp06Ht0Ch0fxpOlSZkQPAtG3rpEyVkZ0r6dAVCqvHbpFr52hO0KrjkcuHZdvfPiRDxM2zyx6KPIwGxvwuc8tehT3ZwxeEMIoJoiaD/94OZblS8WInAZ5RnRJA9Go1YU0ZTDYI93dcTfxdQxE86N4YCkDUX/1DF7YILn+FmPsYYfJulFpriyRVujmmt14F1BG9EGMMRhjXLd3kRnlfRQCdWAujGYvkUV497vh1q2l3B8KELXdfpu9nU3o9WjUNRAFF4D2eksZiGIM0do54htvkmJp1jUQ9X2isKXSXFkKgRcQ+RG7QwWix3GudY4zyohKAbyoAQPwG8qIFkWzl8giPPKIe1tSUbsLwN7eLXeGaF1Lc8FlRJvNpdzrCxCe3SD59h/VuzSXbHFlbxMPXxlRqbxW2GJ7sA0oEH2Yx9aWrzO9VNNBRrSxhAvPFbWcd04islBBq4vBsLf7jjtDNGrVt5V5s7mc2dBMtL5BTOpKc6Oa/gyBoNXBJIkyorIU8n2ioEBUpCxe9tqgjGhxNHuJyImZrMtoPNzH6/UJ6niGaO6552BnZ9GjmFq4cYGEMRaLX+NA1LTbrNKgTaiMqFTeZCDqe2pWJFKGvGooaC5fl/yqUiAqIifXbBLiEw9jGr0hrF5Z9IgW5/nnFz2CmUTnLmCxAHg1Ls2l1eI9nHXvKyMqFdcKXBWGsqEi5ckb+gUNBaJFUWmuiJxcs+m6jA6HRL1BffeHngLRxuGZbXXOiN5RXq2MqFRcI2jge74CUZEStaIOPh5Rq7PooZwaCkRF5OTyQHQwoNEfKhBdYmGzDV3XfKrOe0RpZyvcvu/eRCquE3aIfGXvRcqy0jrDB7iEr9LcwmgpTUROzveJwiZsbRFZT4HoEov8CM6cgb09ZURBZbmyNJ5Yf2LRQxCpl7xapq7NGedAGVERmUrYbMPWO/U+uuUUCLwAs+aaTflRjTsB5oGoynJlSQReoNJckTLlC5UKRAujGUxEprLSWmP95k26nFEguuSip59hOE4PGjHUkjKiIiLyIMqIFk6BqIhMJWh1eNJmx7YoEF1q0ZWrDDfW8eucXcn3iCojKiIiR8kXKps1rh4qmEpzRWQ6+UQchpqUl1zoueDLMzV+SVBGVEREHkQZ0cLV+K5DRGaS37ivroIxix2LzCTvvOl7Ne4Wqz2iIiLyIE88Ac89B+vrix7JqVHjOiwRmUmeBVVZ7tI71z6H7/nKiIIyoiIicrRz5+AnfmLRozhVanzXISIzUSB6ajSDJpe6lxY9jMXyPFdupUBURESkFMqIish0JktzRU6DF1+Ed71r0aMQERGpBQWiIjIdZUTltPmxH1v0CERERGpDpbkiMh0FoiIiIiIyJQWiIjKdRx+FZ5+Fq1cXPRIRERERWTIqzRWR6bTb8JnPLHoUIiIiIrKElBEVERERERGRUikQFRERERERkVIpEBUREREREZFSKRAVERERERGRUikQFRERERERkVIpEBUREREREZFSKRAVERERERGRUikQFRERERERkVIpEBUREREREZFSKRAVERERERGRUikQFRERERERkVIpEBUREREREZFSKRAVERERERGRUs0UiBpjPm6M+bYx5jvGmC8UNSgRERERERE5vaYORI0xPvCLwEvAM8BPGmOeKWpgIiIiIiIicjrNkhH9IeA71trvWmtj4NeBTxUzLBERERERETmtZglErwBvTDy+lj13B2PMzxhjvmaM+drNmzdn+HIiIiIiIiJyGswSiJojnrP3PGHtF621L1hrXzh//vwMX05EREREREROg2CGf3sNeHTi8SPAmw/6B6+++uqmMeb1Gb5mGTaAzUUPQgRdi1Ituh6lSnQ9SpXoepQqqcL1+NhxPshYe08S81iMMQHwf4GPAt8H/gD4i9bab071CSvCGPM1a+0Lix6HiK5FqRJdj1Iluh6lSnQ9SpUs0/U4dUbUWjsyxvwN4D8DPvClZQ9CRUREREREZP5mKc3FWvubwG8WNBYRERERERGpgVmaFZ1WX1z0AEQyuhalSnQ9SpXoepQq0fUoVbI01+PUe0RFREREREREpqGMqIiIiIiIiJRKgaiIiIiIiIiUSoFoxhjzcWPMt40x3zHGfGHR45F6McY8aoz5XWPMt4wx3zTG/Fz2/FljzH8xxvxx9uf6oscq9WGM8Y0xXzfG/Mfs8RPGmK9m1+O/NcZEix6j1IMxZs0Y82VjzB9l8+SHND/Kohhj/lb2Wv0NY8yvGWOamh+lLMaYLxljbhhjvjHx3JHzoXH+RRbf/G9jzA8sbuT3UiCKu9kCfhF4CXgG+EljzDOLHZXUzAj429ba9wMvAn89uwa/APyOtfYp4HeyxyJl+TngWxOP/zHwT7PrcQv4qwsZldTRPwf+k7X2fcDzuOtS86OUzhhzBfibwAvW2j+BO8LwL6D5Ucrzr4GP3/Xc/ebDl4CnsrefAX6ppDEeiwJR54eA71hrv2utjYFfBz614DFJjVhr37LW/s/s/V3cTdYV3HX4K9mH/Qrw6cWMUOrGGPMI8Engl7PHBvgI8OXsQ3Q9SimMMavAnwZeBrDWxtba22h+lMUJgJYxJgDawFtofpSSWGt/D3jnrqfvNx9+Cvg31vkfwJox5nI5I304BaLOFeCNicfXsudESmeMeRz4IPBV4KK19i1wwSpwYXEjk5r5Z8DfBcbZ43PAbWvtKHuseVLK8iRwE/hXWan4LxtjOmh+lAWw1n4f+CfA93AB6DbwKpofZbHuNx9WOsZRIOqYI57TuTZSOmNMF/gN4OettTuLHo/UkzHmx4Eb1tpXJ58+4kM1T0oZAuAHgF+y1n4Q6KEyXFmQbO/dp4AngHcBHVz54900P0oVVPq1W4Gocw14dOLxI8CbCxqL1JQxJsQFob9qrf1K9vT1vIQi+/PGosYntfJh4M8aY17DbVX4CC5DupaVooHmSSnPNeCatfar2eMv4wJTzY+yCB8D/p+19qa1NgG+AvwImh9lse43H1Y6xlEg6vwB8FTW8SzCbTp/ZcFjkhrJ9t+9DHzLWvsLE3/1CvBT2fs/BfyHsscm9WOt/XvW2kestY/j5sP/aq39PPC7wJ/PPkzXo5TCWvs28IYx5unsqY8C/wfNj7IY3wNeNMa0s9fu/HrU/CiLdL/58BXgr2Tdc18EtvMS3iow1lYmO7tQxphP4Fb8feBL1tp/tOAhSY0YY/4U8N+AP+RwT97fx+0T/XfAVdyL32estXdvUBeZG2PMjwJ/x1r748aYJ3EZ0rPA14G/ZK0dLnJ8Ug/GmA/gGmdFwHeBn8Ytpmt+lNIZY/4h8Dlcx/uvA38Nt+9O86PMnTHm14AfBTaA68A/AP49R8yH2WLJv8R12e0DP22t/doixn0UBaIiIiIiIiJSKpXmioiIiIiISKkUiIqIiIiIiEipFIiKiIiIiIhIqRSIioiIiIiISKkUiIqIiIiIiEipFIiKiIiIiIhIqRSIioiIiIiISKn+P4jrUvPHRGUbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(figsize=(16,8))\n",
    "plt.plot(testing[0:100].index,testing['actual'][0:100], color = 'r',alpha = 0.5)\n",
    "plt.plot(testing[0:100].index,testing['NN_predictions'][0:100], color = 'g',alpha = 0.2)\n",
    "#plt.scatter(testing[0:100].index,testing['LY_rebounding'][0:100],color = 'b',alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"labels ['rebound_prediction_x' 'rebound_prediction_y'] not contained in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-676-9f19245d9688>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mrebounds_2017\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'player'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rebound_prediction'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mdf_2017\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_2017\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrebounds_2017\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mleft_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'player'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'player'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mdf_2017\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rebound_prediction_x'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rebound_prediction_y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3692\u001b[0m                                            \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3693\u001b[0m                                            \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3694\u001b[0;31m                                            errors=errors)\n\u001b[0m\u001b[1;32m   3695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3696\u001b[0m     @rewrite_axis_style_signature('mapper', [('copy', True),\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3106\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3108\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3110\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3138\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3139\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3141\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   4385\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4386\u001b[0m                 raise KeyError(\n\u001b[0;32m-> 4387\u001b[0;31m                     'labels %s not contained in axis' % labels[mask])\n\u001b[0m\u001b[1;32m   4388\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4389\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"labels ['rebound_prediction_x' 'rebound_prediction_y'] not contained in axis\""
     ]
    }
   ],
   "source": [
    "pred_2017rebounds = rebounds[rebounds['season']==2017].drop(['team','player','rebounds','Games'],axis=1)\n",
    "rebounds_2017 = NN_model.predict(pred_2017rebounds)\n",
    "test_2 =pd.DataFrame(rebounds_2017)\n",
    "gbr_reb_2017 = pd.DataFrame(gbr.predict(pred_2017rebounds))\n",
    "LR_reb_2017 = pd.DataFrame(LR.predict(pred_2017rebounds))\n",
    "test_3 = pd.merge(rebounds,pred_2017rebounds,left_index=True,right_index=True).reset_index()\n",
    "test_3['predictions']=test_2[0]\n",
    "test_3['gbr_pred'] = gbr_reb_2017[0]\n",
    "test_3['LR_pred'] = LR_reb_2017[0]\n",
    "test_3['mean_pred'] = (test_3['predictions']+test_3['gbr_pred']+test_3['LR_pred'])/3\n",
    "test_3 = test_3[test_3['Games']>30]\n",
    "test_3[['player','rebounds','rebounds_ly_x','predictions','gbr_pred','LR_pred','mean_pred']].sort_values(by='rebounds_ly_x',ascending=False)[50:100]\n",
    "\n",
    "rebounds_2017 = test_3[['player','LR_pred']]\n",
    "rebounds_2017.columns = ['player','rebound_prediction']\n",
    "df_2017 = pd.merge(df_2017,rebounds_2017, how='left',left_on='player',right_on='player')\n",
    "df_2017.drop(['rebound_prediction_x','rebound_prediction_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MSE using NN:{}'.format(np.mean((test_3['rebounds']-test_3['predictions'])**2)))\n",
    "print('MSE using mean:{}'.format(np.mean((test_3['rebounds']-np.mean(test_3['rebounds']))**2)))\n",
    "print('MSE using last year stats:{}'.format(np.mean((test_3['rebounds']-test_3['rebounds_ly_x'])**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE using NN:1.5360105666030683\n",
      "MSE using mean:6.292553316074948\n",
      "MSE using last year stats:1.808012820512822\n",
      "MSE using gbr:1.3305627955364254\n",
      "MSE using LR:1.3304784320633838\n",
      "MSE using combo:1.3020509773938502\n"
     ]
    }
   ],
   "source": [
    "print('MSE using NN:{}'.format(np.mean((test_3['rebounds']-test_3['predictions'])**2)))\n",
    "print('MSE using mean:{}'.format(np.mean((test_3['rebounds']-np.mean(test_3['rebounds']))**2)))\n",
    "print('MSE using last year stats:{}'.format(np.mean((test_3['rebounds']-test_3['rebounds_ly_x'])**2)))\n",
    "print('MSE using gbr:{}'.format(np.mean((test_3['rebounds']-test_3['gbr_pred'])**2)))\n",
    "print('MSE using LR:{}'.format(np.mean((test_3['rebounds']-test_3['LR_pred'])**2)))\n",
    "print('MSE using combo:{}'.format(np.mean((test_3['rebounds']-test_3['mean_pred'])**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8111346 , 0.75668588, 0.78079755, 0.72744262, 0.75121757])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.5),X_train,y_train,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(LinearRegression(),X_train,y_train,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''next is assists'''\n",
    "\n",
    "\n",
    "query= '''\n",
    "        \n",
    "        DROP TABLE IF EXISTS assists_pred;\n",
    "        CREATE TABLE assists_pred(\n",
    "        season int, --these come from player_stats\n",
    "        player varchar(50),\n",
    "        Age int,\n",
    "        team varchar(50),\n",
    "        ast float, -- these come from player_stats\n",
    "        ast_ly float,\n",
    "        change_ast_ly float,\n",
    "        Games float,\n",
    "        C_PF int,\n",
    "        PG int,\n",
    "        SG_SF int,\n",
    "        starter_change int, \n",
    "        \n",
    "        -- these come from team_changes\n",
    "        high_usageplayer_added int,\n",
    "        usagemin_opened float,\n",
    "        maxusage_added float,\n",
    "        high_usageplayer_dropped int,\n",
    "        assists_opened float,\n",
    "        max_assistsdropped float,\n",
    "        max_assistsadded float,\n",
    "        points_opened float,\n",
    "        threes_opened float,\n",
    "        \n",
    "        -- from player_advstats\n",
    "        per_ly float,\n",
    "        change_per float,\n",
    "        usagerank float,\n",
    "        usagerank_ly float,\n",
    "        ast_perc_ly float,\n",
    "        change_assist_perc float,\n",
    "        offensive_winshares float,\n",
    "        offensive_boxplusminus float,\n",
    "        boxplusminus float,\n",
    "        value_overreplacement float,\n",
    "        \n",
    "        career_ast float,\n",
    "        yearspro int\n",
    "        );\n",
    "        \n",
    "        INSERT INTO assists_pred(season,player,age,team,ast,ast_ly,change_ast_ly,starter_change,Games,C_PF,PG,SG_SF)\n",
    "        SELECT season,player,age,startingteam,ast,ast_ly,change_ast_ly,starter-starter_ly,Games,\n",
    "        case when pos in ('C','PF') then 1 else 0 end,case when pos='PG' then 1 else 0 end,case when pos in('SG','SF') then 1 else 0 end from player_stats;\n",
    "        \n",
    "        update assists_pred ap\n",
    "        set high_usageplayer_added = tc.high_usageplayer_added,usagemin_opened=tc.usagemin_opened,\n",
    "        maxusage_added=tc.max_usageadded,high_usageplayer_dropped=tc.high_usageplayer_dropped,assists_opened=tc.ast_opened,\n",
    "        max_assistsdropped=tc.max_astdropped,max_assistsadded=tc.max_astadded,points_opened = tc.points_opened,threes_opened = tc.threes_opened\n",
    "        from team_changes tc\n",
    "        where tc.team = ap.team and ap.season=tc.season;\n",
    "        \n",
    "        update assists_pred ap\n",
    "        set per_ly=pa.per_ly,change_per=pa.change_per,usagerank=pa.usagerank,usagerank_ly=pa.usagerank_ly\n",
    "        ,ast_perc_ly = pa.ast_perc_ly,change_assist_perc = pa.change_assist_perc,offensive_winshares=pa.offensive_winshares,\n",
    "        offensive_boxplusminus=pa.offensive_boxplusminus,boxplusminus=pa.boxplusminus,value_overreplacement=pa.value_overreplacement\n",
    "        from player_advstats pa\n",
    "        where ap.player = pa.player and ap.season = pa.season and ap.team = pa.startingteam;\n",
    "        \n",
    "        update assists_pred ap\n",
    "        set career_ast = pc.career_ast, yearspro = pc.yearspro\n",
    "        from player_careerstats pc\n",
    "        where ap.player = pc.player and ap.season = pc.season;\n",
    "        \n",
    "        \n",
    "        select * from assists_pred where season>2009\n",
    "        '''\n",
    "\n",
    "\n",
    "cur.execute(query)\n",
    "data = cur.fetchall()\n",
    "assists_df = pd.DataFrame(np.array(data))\n",
    "assists_df.columns = ['season','player','age','team','assists','assists_ly','change_assists_ly','Games','C_PF','PG','SG_SF','starter_change','high_usageplayer_added','usagemin_opened','maxusage_added','high_usageplayer_dropped','assists_opened','max_assistsdropped',\n",
    "                    'max_assistsadded','points_opened','threes_opened','per_ly','change_per','usagerank','usagerank_ly','ast_perc_ly','change_ast_perc','offensive_winshares','offensive_boxplusminus','boxplusminus','value_overreplacement','career_assists','yearspro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "assists_df['age_squared']=assists_df['age']*assists_df['age']\n",
    "assists = assists_df[assists_df['assists_ly'].notna()]\n",
    "for i in assists.columns:\n",
    "    if i not in(['player','team']):\n",
    "        assists[i]=pd.to_numeric(assists[i])\n",
    "assists = assists.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = assists[(assists['season']!=2017) & (assists['Games']>30)].drop(['player','team','assists','Games'],axis=1)\n",
    "y = assists[(assists['season']!=2017) & (assists['Games']>30)]['assists']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1564/1564 [==============================] - 3s 2ms/step - loss: 1653.6629\n",
      "Epoch 2/1000\n",
      "1564/1564 [==============================] - 0s 79us/step - loss: 225.7326\n",
      "Epoch 3/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 73.6309\n",
      "Epoch 4/1000\n",
      "1564/1564 [==============================] - 0s 80us/step - loss: 41.1137\n",
      "Epoch 5/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 27.5922\n",
      "Epoch 6/1000\n",
      "1564/1564 [==============================] - 0s 79us/step - loss: 20.5626\n",
      "Epoch 7/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 16.4568\n",
      "Epoch 8/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 14.4388\n",
      "Epoch 9/1000\n",
      "1564/1564 [==============================] - 0s 77us/step - loss: 12.8704\n",
      "Epoch 10/1000\n",
      "1564/1564 [==============================] - 0s 84us/step - loss: 11.9371\n",
      "Epoch 11/1000\n",
      "1564/1564 [==============================] - 0s 79us/step - loss: 11.3382\n",
      "Epoch 12/1000\n",
      "1564/1564 [==============================] - 0s 77us/step - loss: 10.4479\n",
      "Epoch 13/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 10.1286\n",
      "Epoch 14/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 9.5093\n",
      "Epoch 15/1000\n",
      "1564/1564 [==============================] - 0s 76us/step - loss: 8.7585\n",
      "Epoch 16/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 8.5027\n",
      "Epoch 17/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 8.3016\n",
      "Epoch 18/1000\n",
      "1564/1564 [==============================] - 0s 79us/step - loss: 8.1256\n",
      "Epoch 19/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 7.9777\n",
      "Epoch 20/1000\n",
      "1564/1564 [==============================] - 0s 84us/step - loss: 7.8525\n",
      "Epoch 21/1000\n",
      "1564/1564 [==============================] - 0s 81us/step - loss: 7.7377\n",
      "Epoch 22/1000\n",
      "1564/1564 [==============================] - 0s 81us/step - loss: 7.6428\n",
      "Epoch 23/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 7.5460\n",
      "Epoch 24/1000\n",
      "1564/1564 [==============================] - 0s 79us/step - loss: 7.4783\n",
      "Epoch 25/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 7.3895\n",
      "Epoch 26/1000\n",
      "1564/1564 [==============================] - 0s 83us/step - loss: 7.3033\n",
      "Epoch 27/1000\n",
      "1564/1564 [==============================] - 0s 76us/step - loss: 7.2226\n",
      "Epoch 28/1000\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 7.1518\n",
      "Epoch 29/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 7.0844\n",
      "Epoch 30/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 7.0230\n",
      "Epoch 31/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 6.9515\n",
      "Epoch 32/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 6.8908\n",
      "Epoch 33/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 6.8273\n",
      "Epoch 34/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 6.7590\n",
      "Epoch 35/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 6.6974\n",
      "Epoch 36/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 6.6437\n",
      "Epoch 37/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 6.5957\n",
      "Epoch 38/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 6.5222\n",
      "Epoch 39/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 6.4635\n",
      "Epoch 40/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 6.4013\n",
      "Epoch 41/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 6.3435\n",
      "Epoch 42/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 6.3100\n",
      "Epoch 43/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 6.2450\n",
      "Epoch 44/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 6.1785\n",
      "Epoch 45/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 6.1282\n",
      "Epoch 46/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 6.0799\n",
      "Epoch 47/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 6.0317\n",
      "Epoch 48/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 5.9954\n",
      "Epoch 49/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 5.9251\n",
      "Epoch 50/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 5.8719\n",
      "Epoch 51/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 5.8218\n",
      "Epoch 52/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 5.7743\n",
      "Epoch 53/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 5.7274\n",
      "Epoch 54/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 5.6791\n",
      "Epoch 55/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 5.6333\n",
      "Epoch 56/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 5.5825\n",
      "Epoch 57/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 5.5467\n",
      "Epoch 58/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 5.5051\n",
      "Epoch 59/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 5.4690\n",
      "Epoch 60/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 5.4104\n",
      "Epoch 61/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 5.3675\n",
      "Epoch 62/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 5.3372\n",
      "Epoch 63/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 5.2941\n",
      "Epoch 64/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 5.2534\n",
      "Epoch 65/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 5.2135\n",
      "Epoch 66/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 5.1837\n",
      "Epoch 67/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 5.1330\n",
      "Epoch 68/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 5.1012\n",
      "Epoch 69/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 5.0792\n",
      "Epoch 70/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 5.0677\n",
      "Epoch 71/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 5.0115\n",
      "Epoch 72/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 4.9534\n",
      "Epoch 73/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 4.9125\n",
      "Epoch 74/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 4.8690\n",
      "Epoch 75/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 4.8857\n",
      "Epoch 76/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 4.8120\n",
      "Epoch 77/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 4.7760\n",
      "Epoch 78/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 4.7415\n",
      "Epoch 79/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 4.7084\n",
      "Epoch 80/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 4.6761\n",
      "Epoch 81/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 4.6506\n",
      "Epoch 82/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 4.6458\n",
      "Epoch 83/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 4.5919\n",
      "Epoch 84/1000\n",
      "1564/1564 [==============================] - 0s 76us/step - loss: 4.5871\n",
      "Epoch 85/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 4.5596\n",
      "Epoch 86/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 4.5048\n",
      "Epoch 87/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 4.4712\n",
      "Epoch 88/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 4.4570\n",
      "Epoch 89/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 4.4474\n",
      "Epoch 90/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 4.4132\n",
      "Epoch 91/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 4.3841\n",
      "Epoch 92/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 4.3474\n",
      "Epoch 93/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 4.3395\n",
      "Epoch 94/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 4.3231\n",
      "Epoch 95/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 4.2724\n",
      "Epoch 96/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 4.2939\n",
      "Epoch 97/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 4.2383\n",
      "Epoch 98/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 4.2327\n",
      "Epoch 99/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 4.2452\n",
      "Epoch 100/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 4.1728\n",
      "Epoch 101/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 4.1558\n",
      "Epoch 102/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 4.1604\n",
      "Epoch 103/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 4.1212\n",
      "Epoch 104/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 4.1130\n",
      "Epoch 105/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 4.0888\n",
      "Epoch 106/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 4.0673\n",
      "Epoch 107/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 4.0634\n",
      "Epoch 108/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 4.0528\n",
      "Epoch 109/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 4.0568\n",
      "Epoch 110/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 4.1723\n",
      "Epoch 111/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 4.0589\n",
      "Epoch 112/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.9862\n",
      "Epoch 113/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 3.9569\n",
      "Epoch 114/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 3.9838\n",
      "Epoch 115/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.9917\n",
      "Epoch 116/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.9142\n",
      "Epoch 117/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.9224\n",
      "Epoch 118/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.9114\n",
      "Epoch 119/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.9965\n",
      "Epoch 120/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 3.8838\n",
      "Epoch 121/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.8889\n",
      "Epoch 122/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 3.8595\n",
      "Epoch 123/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 3.8370\n",
      "Epoch 124/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.8570\n",
      "Epoch 125/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.8176\n",
      "Epoch 126/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.8175\n",
      "Epoch 127/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.8380\n",
      "Epoch 128/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.8233\n",
      "Epoch 129/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 3.8158\n",
      "Epoch 130/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 4.2442\n",
      "Epoch 131/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 5.1594\n",
      "Epoch 132/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 4.7924\n",
      "Epoch 133/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.7415\n",
      "Epoch 134/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.7345\n",
      "Epoch 135/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.7278\n",
      "Epoch 136/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.7210\n",
      "Epoch 137/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.7147\n",
      "Epoch 138/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.7089\n",
      "Epoch 139/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.7031\n",
      "Epoch 140/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.6975\n",
      "Epoch 141/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.6921\n",
      "Epoch 142/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.6871\n",
      "Epoch 143/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.6824\n",
      "Epoch 144/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.6779\n",
      "Epoch 145/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.6734\n",
      "Epoch 146/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.6692\n",
      "Epoch 147/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.6652\n",
      "Epoch 148/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.6610\n",
      "Epoch 149/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 3.6574\n",
      "Epoch 150/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.6538\n",
      "Epoch 151/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.6504\n",
      "Epoch 152/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.6471\n",
      "Epoch 153/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.6441\n",
      "Epoch 154/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.6412\n",
      "Epoch 155/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.6384\n",
      "Epoch 156/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.6357\n",
      "Epoch 157/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.6333\n",
      "Epoch 158/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.6307\n",
      "Epoch 159/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.6284\n",
      "Epoch 160/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.6264\n",
      "Epoch 161/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.6242\n",
      "Epoch 162/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.6223\n",
      "Epoch 163/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.6207\n",
      "Epoch 164/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 3.6189\n",
      "Epoch 165/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.6172\n",
      "Epoch 166/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.6157\n",
      "Epoch 167/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.6141\n",
      "Epoch 168/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.6128\n",
      "Epoch 169/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.6114\n",
      "Epoch 170/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.6103\n",
      "Epoch 171/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.6090\n",
      "Epoch 172/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.6081\n",
      "Epoch 173/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.6068\n",
      "Epoch 174/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.6059\n",
      "Epoch 175/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.6049\n",
      "Epoch 176/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.6041\n",
      "Epoch 177/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.6033\n",
      "Epoch 178/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.6027\n",
      "Epoch 179/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.6020\n",
      "Epoch 180/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.6014\n",
      "Epoch 181/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.6008\n",
      "Epoch 182/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.6004\n",
      "Epoch 183/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5997\n",
      "Epoch 184/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5993\n",
      "Epoch 185/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 3.5988\n",
      "Epoch 186/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5983\n",
      "Epoch 187/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5979\n",
      "Epoch 188/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5975\n",
      "Epoch 189/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5971\n",
      "Epoch 190/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5969\n",
      "Epoch 191/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5967\n",
      "Epoch 192/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5963\n",
      "Epoch 193/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5960\n",
      "Epoch 194/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5958\n",
      "Epoch 195/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5956\n",
      "Epoch 196/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5953\n",
      "Epoch 197/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5952\n",
      "Epoch 198/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 3.5951\n",
      "Epoch 199/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.5950\n",
      "Epoch 200/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5946\n",
      "Epoch 201/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.5945\n",
      "Epoch 202/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5944\n",
      "Epoch 203/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5943\n",
      "Epoch 204/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5942\n",
      "Epoch 205/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 3.5941\n",
      "Epoch 206/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5941\n",
      "Epoch 207/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5940\n",
      "Epoch 208/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5939\n",
      "Epoch 209/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5938\n",
      "Epoch 210/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.5939\n",
      "Epoch 211/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5937\n",
      "Epoch 212/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5937\n",
      "Epoch 213/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5936\n",
      "Epoch 214/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5936\n",
      "Epoch 215/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5935\n",
      "Epoch 216/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5936\n",
      "Epoch 217/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 3.5935\n",
      "Epoch 218/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 219/1000\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 3.5934\n",
      "Epoch 220/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 3.5934\n",
      "Epoch 221/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 3.5934\n",
      "Epoch 222/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5935\n",
      "Epoch 223/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.5934\n",
      "Epoch 224/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5934\n",
      "Epoch 225/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5933\n",
      "Epoch 226/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5933\n",
      "Epoch 227/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5934\n",
      "Epoch 228/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 229/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5933\n",
      "Epoch 230/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5933\n",
      "Epoch 231/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.5933\n",
      "Epoch 232/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 233/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5933\n",
      "Epoch 234/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5934\n",
      "Epoch 235/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5933\n",
      "Epoch 236/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5933\n",
      "Epoch 237/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5934\n",
      "Epoch 238/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5933\n",
      "Epoch 239/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5933\n",
      "Epoch 240/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5932\n",
      "Epoch 241/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5933\n",
      "Epoch 242/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.5932\n",
      "Epoch 243/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5932\n",
      "Epoch 244/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5932\n",
      "Epoch 245/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5933\n",
      "Epoch 246/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5933\n",
      "Epoch 247/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5932\n",
      "Epoch 248/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5933\n",
      "Epoch 249/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5933\n",
      "Epoch 250/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5933\n",
      "Epoch 251/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5932\n",
      "Epoch 252/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5933\n",
      "Epoch 253/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.5933\n",
      "Epoch 254/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5932\n",
      "Epoch 255/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5933\n",
      "Epoch 256/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5933\n",
      "Epoch 257/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5934\n",
      "Epoch 258/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5933\n",
      "Epoch 259/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5932\n",
      "Epoch 260/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5932\n",
      "Epoch 261/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5933\n",
      "Epoch 262/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5932\n",
      "Epoch 263/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5932\n",
      "Epoch 264/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.5932\n",
      "Epoch 265/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5932\n",
      "Epoch 266/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5933\n",
      "Epoch 267/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5932\n",
      "Epoch 268/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5933\n",
      "Epoch 269/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5933\n",
      "Epoch 270/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5933\n",
      "Epoch 271/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5932\n",
      "Epoch 272/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 273/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5931\n",
      "Epoch 274/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5932\n",
      "Epoch 275/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 3.5933\n",
      "Epoch 276/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5934\n",
      "Epoch 277/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5932\n",
      "Epoch 278/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5932\n",
      "Epoch 279/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5932\n",
      "Epoch 280/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5933\n",
      "Epoch 281/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5932\n",
      "Epoch 282/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5933\n",
      "Epoch 283/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5932\n",
      "Epoch 284/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 285/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 286/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.5932\n",
      "Epoch 287/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5936\n",
      "Epoch 288/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 3.5933\n",
      "Epoch 289/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5933\n",
      "Epoch 290/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5933\n",
      "Epoch 291/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5932\n",
      "Epoch 292/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 3.5932\n",
      "Epoch 293/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5932\n",
      "Epoch 294/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5932\n",
      "Epoch 295/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 3.5933\n",
      "Epoch 296/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5932\n",
      "Epoch 297/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5932\n",
      "Epoch 298/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5932\n",
      "Epoch 299/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5932\n",
      "Epoch 300/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5932\n",
      "Epoch 301/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5932\n",
      "Epoch 302/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5932\n",
      "Epoch 303/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 3.5932\n",
      "Epoch 304/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5933\n",
      "Epoch 305/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5933\n",
      "Epoch 306/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5932\n",
      "Epoch 307/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5932\n",
      "Epoch 308/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5933\n",
      "Epoch 309/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5932\n",
      "Epoch 310/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5932\n",
      "Epoch 311/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5932\n",
      "Epoch 312/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 313/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5932\n",
      "Epoch 314/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5933\n",
      "Epoch 315/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5932\n",
      "Epoch 316/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5933\n",
      "Epoch 317/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5933\n",
      "Epoch 318/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5932\n",
      "Epoch 319/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5932\n",
      "Epoch 320/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5932\n",
      "Epoch 321/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5933\n",
      "Epoch 322/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5935\n",
      "Epoch 323/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5933\n",
      "Epoch 324/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5933\n",
      "Epoch 325/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5932\n",
      "Epoch 326/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5933\n",
      "Epoch 327/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5933\n",
      "Epoch 328/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5933\n",
      "Epoch 329/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5933\n",
      "Epoch 330/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5932\n",
      "Epoch 331/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5933\n",
      "Epoch 332/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5932\n",
      "Epoch 333/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5932\n",
      "Epoch 334/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5933\n",
      "Epoch 335/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5932\n",
      "Epoch 336/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5933\n",
      "Epoch 337/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 3.5932\n",
      "Epoch 338/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5933\n",
      "Epoch 339/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5932\n",
      "Epoch 340/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.5932\n",
      "Epoch 341/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5932\n",
      "Epoch 342/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 3.5932\n",
      "Epoch 343/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5932\n",
      "Epoch 344/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5932\n",
      "Epoch 345/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5934\n",
      "Epoch 346/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5932\n",
      "Epoch 347/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 348/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 349/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.5932\n",
      "Epoch 350/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.5933\n",
      "Epoch 351/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 3.5932\n",
      "Epoch 352/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5933\n",
      "Epoch 353/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5932\n",
      "Epoch 354/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5932\n",
      "Epoch 355/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5932\n",
      "Epoch 356/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 3.5933\n",
      "Epoch 357/1000\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 3.5932\n",
      "Epoch 358/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.5933\n",
      "Epoch 359/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.5934\n",
      "Epoch 360/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.5932\n",
      "Epoch 361/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.5932\n",
      "Epoch 362/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5932\n",
      "Epoch 363/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.5932\n",
      "Epoch 364/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5934\n",
      "Epoch 365/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5934\n",
      "Epoch 366/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5933\n",
      "Epoch 367/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5932\n",
      "Epoch 368/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5933\n",
      "Epoch 369/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5932\n",
      "Epoch 370/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5932\n",
      "Epoch 371/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5933\n",
      "Epoch 372/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.5935\n",
      "Epoch 373/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5931\n",
      "Epoch 374/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.5932\n",
      "Epoch 375/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5932\n",
      "Epoch 376/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5933\n",
      "Epoch 377/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5932\n",
      "Epoch 378/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5932\n",
      "Epoch 379/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5932\n",
      "Epoch 380/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 381/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5932\n",
      "Epoch 382/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5932\n",
      "Epoch 383/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 3.5932\n",
      "Epoch 384/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5933\n",
      "Epoch 385/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5934\n",
      "Epoch 386/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5932\n",
      "Epoch 387/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5931\n",
      "Epoch 388/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5931\n",
      "Epoch 389/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5933\n",
      "Epoch 390/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.5933\n",
      "Epoch 391/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5932\n",
      "Epoch 392/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5933\n",
      "Epoch 393/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5931\n",
      "Epoch 394/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5931\n",
      "Epoch 395/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5932\n",
      "Epoch 396/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5933\n",
      "Epoch 397/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5933\n",
      "Epoch 398/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5932\n",
      "Epoch 399/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5934\n",
      "Epoch 400/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5935\n",
      "Epoch 401/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5933\n",
      "Epoch 402/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5932\n",
      "Epoch 403/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5933\n",
      "Epoch 404/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.5932\n",
      "Epoch 405/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5932\n",
      "Epoch 406/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5932\n",
      "Epoch 407/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.5932\n",
      "Epoch 408/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5932\n",
      "Epoch 409/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 3.5932\n",
      "Epoch 410/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5932\n",
      "Epoch 411/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5933\n",
      "Epoch 412/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5932\n",
      "Epoch 413/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5931\n",
      "Epoch 414/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5932\n",
      "Epoch 415/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.5932\n",
      "Epoch 416/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5934\n",
      "Epoch 417/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5932\n",
      "Epoch 418/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5932\n",
      "Epoch 419/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5932\n",
      "Epoch 420/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5933\n",
      "Epoch 421/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5932\n",
      "Epoch 422/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5935\n",
      "Epoch 423/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5932\n",
      "Epoch 424/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5934\n",
      "Epoch 425/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5933\n",
      "Epoch 426/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.5932\n",
      "Epoch 427/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5933\n",
      "Epoch 428/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.5933\n",
      "Epoch 429/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5932\n",
      "Epoch 430/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.5932\n",
      "Epoch 431/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.5931\n",
      "Epoch 432/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5932\n",
      "Epoch 433/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5931\n",
      "Epoch 434/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5933\n",
      "Epoch 435/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5933\n",
      "Epoch 436/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5932\n",
      "Epoch 437/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 3.5932\n",
      "Epoch 438/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.5931\n",
      "Epoch 439/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 3.5931\n",
      "Epoch 440/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5936\n",
      "Epoch 441/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5931\n",
      "Epoch 442/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5932\n",
      "Epoch 443/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5932\n",
      "Epoch 444/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5931\n",
      "Epoch 445/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5933\n",
      "Epoch 446/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5935\n",
      "Epoch 447/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.5932\n",
      "Epoch 448/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5933\n",
      "Epoch 449/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.5932\n",
      "Epoch 450/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.5931\n",
      "Epoch 451/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5931\n",
      "Epoch 452/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5932\n",
      "Epoch 453/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5932\n",
      "Epoch 454/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5935\n",
      "Epoch 455/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5933\n",
      "Epoch 456/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5931\n",
      "Epoch 457/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5931\n",
      "Epoch 458/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.5932\n",
      "Epoch 459/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5931\n",
      "Epoch 460/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5932\n",
      "Epoch 461/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5932\n",
      "Epoch 462/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5934\n",
      "Epoch 463/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5936\n",
      "Epoch 464/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5931\n",
      "Epoch 465/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5932\n",
      "Epoch 466/1000\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 3.5932\n",
      "Epoch 467/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 3.5932\n",
      "Epoch 468/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 3.5930\n",
      "Epoch 469/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.5931\n",
      "Epoch 470/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.5933\n",
      "Epoch 471/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5931\n",
      "Epoch 472/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.5935\n",
      "Epoch 473/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5933\n",
      "Epoch 474/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5932\n",
      "Epoch 475/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5932\n",
      "Epoch 476/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5932\n",
      "Epoch 477/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5933\n",
      "Epoch 478/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5939\n",
      "Epoch 479/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5932\n",
      "Epoch 480/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5934\n",
      "Epoch 481/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5934\n",
      "Epoch 482/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5932\n",
      "Epoch 483/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5932\n",
      "Epoch 484/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5931\n",
      "Epoch 485/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5932\n",
      "Epoch 486/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5933\n",
      "Epoch 487/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5931\n",
      "Epoch 488/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 489/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.5931\n",
      "Epoch 490/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 3.5932\n",
      "Epoch 491/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5932\n",
      "Epoch 492/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 3.5933\n",
      "Epoch 493/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5931\n",
      "Epoch 494/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5932\n",
      "Epoch 495/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5932\n",
      "Epoch 496/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5930\n",
      "Epoch 497/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 498/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5936\n",
      "Epoch 499/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5932\n",
      "Epoch 500/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.5932\n",
      "Epoch 501/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5932\n",
      "Epoch 502/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5932\n",
      "Epoch 503/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5930\n",
      "Epoch 504/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5932\n",
      "Epoch 505/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5936\n",
      "Epoch 506/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.5937\n",
      "Epoch 507/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5934\n",
      "Epoch 508/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 509/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5936\n",
      "Epoch 510/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5935\n",
      "Epoch 511/1000\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 3.5934\n",
      "Epoch 512/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5936\n",
      "Epoch 513/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 514/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 515/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5935\n",
      "Epoch 516/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5934\n",
      "Epoch 517/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5934\n",
      "Epoch 518/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 519/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5934\n",
      "Epoch 520/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5934\n",
      "Epoch 521/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.5936\n",
      "Epoch 522/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5934\n",
      "Epoch 523/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5934\n",
      "Epoch 524/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.5935\n",
      "Epoch 525/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5934\n",
      "Epoch 526/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 527/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 528/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5935\n",
      "Epoch 529/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 530/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 531/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5935\n",
      "Epoch 532/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.5934\n",
      "Epoch 533/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5935\n",
      "Epoch 534/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5934\n",
      "Epoch 535/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5934\n",
      "Epoch 536/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 537/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5936\n",
      "Epoch 538/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5936\n",
      "Epoch 539/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5935\n",
      "Epoch 540/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5936\n",
      "Epoch 541/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 542/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 543/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.5936\n",
      "Epoch 544/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5934\n",
      "Epoch 545/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.5934\n",
      "Epoch 546/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5935\n",
      "Epoch 547/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 548/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 549/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 550/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5934\n",
      "Epoch 551/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 552/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 553/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5936\n",
      "Epoch 554/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5935\n",
      "Epoch 555/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5936\n",
      "Epoch 556/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5936\n",
      "Epoch 557/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5935\n",
      "Epoch 558/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5936\n",
      "Epoch 559/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 560/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 561/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 562/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5936\n",
      "Epoch 563/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5936\n",
      "Epoch 564/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5935\n",
      "Epoch 565/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.5935\n",
      "Epoch 566/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5935\n",
      "Epoch 567/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5937\n",
      "Epoch 568/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 569/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5935\n",
      "Epoch 570/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 571/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5934\n",
      "Epoch 572/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5934\n",
      "Epoch 573/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5934\n",
      "Epoch 574/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5935\n",
      "Epoch 575/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5935\n",
      "Epoch 576/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.5936\n",
      "Epoch 577/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5935\n",
      "Epoch 578/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5935\n",
      "Epoch 579/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5935\n",
      "Epoch 580/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5935\n",
      "Epoch 581/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5937\n",
      "Epoch 582/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 583/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 584/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 3.5937\n",
      "Epoch 585/1000\n",
      "1564/1564 [==============================] - 0s 76us/step - loss: 3.5935\n",
      "Epoch 586/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 3.5935\n",
      "Epoch 587/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.5935\n",
      "Epoch 588/1000\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 3.5935\n",
      "Epoch 589/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5934\n",
      "Epoch 590/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5935\n",
      "Epoch 591/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.5935\n",
      "Epoch 592/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5937\n",
      "Epoch 593/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 594/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5936\n",
      "Epoch 595/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5935\n",
      "Epoch 596/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.5935\n",
      "Epoch 597/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5935\n",
      "Epoch 598/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.5935\n",
      "Epoch 599/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5934\n",
      "Epoch 600/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5934\n",
      "Epoch 601/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5934\n",
      "Epoch 602/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 603/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 604/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 605/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 606/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 607/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.5935\n",
      "Epoch 608/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5935\n",
      "Epoch 609/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5935\n",
      "Epoch 610/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5935\n",
      "Epoch 611/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5936\n",
      "Epoch 612/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5934\n",
      "Epoch 613/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5934\n",
      "Epoch 614/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5934\n",
      "Epoch 615/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5937\n",
      "Epoch 616/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 617/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5935\n",
      "Epoch 618/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.5935\n",
      "Epoch 619/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5934\n",
      "Epoch 620/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5934\n",
      "Epoch 621/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5934\n",
      "Epoch 622/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5936\n",
      "Epoch 623/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5934\n",
      "Epoch 624/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 625/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 626/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 627/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 628/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5934\n",
      "Epoch 629/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5935\n",
      "Epoch 630/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.5935\n",
      "Epoch 631/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5938\n",
      "Epoch 632/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5934\n",
      "Epoch 633/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5934\n",
      "Epoch 634/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5934\n",
      "Epoch 635/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5935\n",
      "Epoch 636/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5935\n",
      "Epoch 637/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5934\n",
      "Epoch 638/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5934\n",
      "Epoch 639/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.5935\n",
      "Epoch 640/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 3.5935\n",
      "Epoch 641/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.5936\n",
      "Epoch 642/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5935\n",
      "Epoch 643/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5935\n",
      "Epoch 644/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5934\n",
      "Epoch 645/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5934\n",
      "Epoch 646/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.5935\n",
      "Epoch 647/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5935\n",
      "Epoch 648/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5934\n",
      "Epoch 649/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 3.5936\n",
      "Epoch 650/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 3.5935\n",
      "Epoch 651/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.5935\n",
      "Epoch 652/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 3.5935\n",
      "Epoch 653/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5935\n",
      "Epoch 654/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.5935\n",
      "Epoch 655/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.5934\n",
      "Epoch 656/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5935\n",
      "Epoch 657/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.5936\n",
      "Epoch 658/1000\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 3.5935\n",
      "Epoch 659/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 3.5935\n",
      "Epoch 660/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5936\n",
      "Epoch 661/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.5934\n",
      "Epoch 662/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.5935\n",
      "Epoch 663/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5936\n",
      "Epoch 664/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5934\n",
      "Epoch 665/1000\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 3.5935\n",
      "Epoch 666/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 3.5935\n",
      "Epoch 667/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 3.5935\n",
      "Epoch 668/1000\n",
      "1564/1564 [==============================] - 0s 76us/step - loss: 3.5935\n",
      "Epoch 669/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 3.5934\n",
      "Epoch 670/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.5934\n",
      "Epoch 671/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5935\n",
      "Epoch 672/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 673/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 674/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 675/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5935\n",
      "Epoch 676/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 677/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5934\n",
      "Epoch 678/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5934\n",
      "Epoch 679/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 3.5934\n",
      "Epoch 680/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5936\n",
      "Epoch 681/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5940\n",
      "Epoch 682/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5934\n",
      "Epoch 683/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5934\n",
      "Epoch 684/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5935\n",
      "Epoch 685/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5935\n",
      "Epoch 686/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 687/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 688/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 689/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5936\n",
      "Epoch 690/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5938\n",
      "Epoch 691/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.5936\n",
      "Epoch 692/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.5937\n",
      "Epoch 693/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5934\n",
      "Epoch 694/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5934\n",
      "Epoch 695/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 696/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.5934\n",
      "Epoch 697/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5935\n",
      "Epoch 698/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5937\n",
      "Epoch 699/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5936\n",
      "Epoch 700/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.5935\n",
      "Epoch 701/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.5935\n",
      "Epoch 702/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.5934\n",
      "Epoch 703/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.5936\n",
      "Epoch 704/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.5938\n",
      "Epoch 705/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5935\n",
      "Epoch 706/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.5935\n",
      "Epoch 707/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 3.5937\n",
      "Epoch 708/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 3.5935\n",
      "Epoch 709/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.5935\n",
      "Epoch 710/1000\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 3.5935\n",
      "Epoch 711/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.5934\n",
      "Epoch 712/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 3.5935\n",
      "Epoch 713/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5934\n",
      "Epoch 714/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5935\n",
      "Epoch 715/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5936\n",
      "Epoch 716/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5934\n",
      "Epoch 717/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 718/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 719/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5935\n",
      "Epoch 720/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.5935\n",
      "Epoch 721/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.5935\n",
      "Epoch 722/1000\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 3.5937\n",
      "Epoch 723/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 3.5934\n",
      "Epoch 724/1000\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 3.5934\n",
      "Epoch 725/1000\n",
      "1564/1564 [==============================] - 0s 77us/step - loss: 3.5935\n",
      "Epoch 726/1000\n",
      "1564/1564 [==============================] - 0s 79us/step - loss: 3.5934\n",
      "Epoch 727/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 3.5935\n",
      "Epoch 728/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.5934\n",
      "Epoch 729/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 3.5936\n",
      "Epoch 730/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 3.5935\n",
      "Epoch 731/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 3.5934\n",
      "Epoch 732/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 3.5936\n",
      "Epoch 733/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 3.5934\n",
      "Epoch 734/1000\n",
      "1564/1564 [==============================] - 0s 89us/step - loss: 3.5935\n",
      "Epoch 735/1000\n",
      "1564/1564 [==============================] - 0s 81us/step - loss: 3.5935\n",
      "Epoch 736/1000\n",
      "1564/1564 [==============================] - 0s 82us/step - loss: 3.5934\n",
      "Epoch 737/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 3.5937\n",
      "Epoch 738/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5935\n",
      "Epoch 739/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.5935\n",
      "Epoch 740/1000\n",
      "1564/1564 [==============================] - 0s 85us/step - loss: 3.5934\n",
      "Epoch 741/1000\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 3.5936\n",
      "Epoch 742/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.5939\n",
      "Epoch 743/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 3.5935\n",
      "Epoch 744/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.5935\n",
      "Epoch 745/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5934\n",
      "Epoch 746/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.5935\n",
      "Epoch 747/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 3.5935\n",
      "Epoch 748/1000\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 3.5935\n",
      "Epoch 749/1000\n",
      "1564/1564 [==============================] - 0s 76us/step - loss: 3.5937\n",
      "Epoch 750/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 3.5935\n",
      "Epoch 751/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 3.5937\n",
      "Epoch 752/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5936\n",
      "Epoch 753/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 754/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5935\n",
      "Epoch 755/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 3.5936\n",
      "Epoch 756/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 3.5935\n",
      "Epoch 757/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 3.5934\n",
      "Epoch 758/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.5934\n",
      "Epoch 759/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5935\n",
      "Epoch 760/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5934\n",
      "Epoch 761/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5936\n",
      "Epoch 762/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 763/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5934\n",
      "Epoch 764/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5934\n",
      "Epoch 765/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5938\n",
      "Epoch 766/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5935\n",
      "Epoch 767/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.5934\n",
      "Epoch 768/1000\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 3.5934\n",
      "Epoch 769/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 3.5934\n",
      "Epoch 770/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5935\n",
      "Epoch 771/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 772/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 3.5935\n",
      "Epoch 773/1000\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 3.5935\n",
      "Epoch 774/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.5934\n",
      "Epoch 775/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.5935\n",
      "Epoch 776/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 3.5935\n",
      "Epoch 777/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 3.5935\n",
      "Epoch 778/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 3.5936\n",
      "Epoch 779/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 3.5935\n",
      "Epoch 780/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 3.5935\n",
      "Epoch 781/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 3.5939\n",
      "Epoch 782/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 3.5935\n",
      "Epoch 783/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 3.5935\n",
      "Epoch 784/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 3.5935\n",
      "Epoch 785/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.5935\n",
      "Epoch 786/1000\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 3.5935\n",
      "Epoch 787/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 3.5935\n",
      "Epoch 788/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 3.5935\n",
      "Epoch 789/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.5935\n",
      "Epoch 790/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5936\n",
      "Epoch 791/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5934\n",
      "Epoch 792/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 793/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5936\n",
      "Epoch 794/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5936\n",
      "Epoch 795/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 796/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.5935\n",
      "Epoch 797/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5935\n",
      "Epoch 798/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5935\n",
      "Epoch 799/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5935\n",
      "Epoch 800/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 801/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5934\n",
      "Epoch 802/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5935\n",
      "Epoch 803/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5934\n",
      "Epoch 804/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5934\n",
      "Epoch 805/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5934\n",
      "Epoch 806/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5934\n",
      "Epoch 807/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.5934\n",
      "Epoch 808/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5935\n",
      "Epoch 809/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.5935\n",
      "Epoch 810/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5937\n",
      "Epoch 811/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 812/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5935\n",
      "Epoch 813/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 814/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 815/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 816/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5935\n",
      "Epoch 817/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5935\n",
      "Epoch 818/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5934\n",
      "Epoch 819/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5935\n",
      "Epoch 820/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5936\n",
      "Epoch 821/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 822/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5937\n",
      "Epoch 823/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 824/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 825/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5935\n",
      "Epoch 826/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 827/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5935\n",
      "Epoch 828/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5934\n",
      "Epoch 829/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.5934\n",
      "Epoch 830/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.5934\n",
      "Epoch 831/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5935\n",
      "Epoch 832/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5935\n",
      "Epoch 833/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5934\n",
      "Epoch 834/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5936\n",
      "Epoch 835/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 836/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5935\n",
      "Epoch 837/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5936\n",
      "Epoch 838/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5936\n",
      "Epoch 839/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.5935\n",
      "Epoch 840/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 3.5936\n",
      "Epoch 841/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 3.5935\n",
      "Epoch 842/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5934\n",
      "Epoch 843/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 844/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5937\n",
      "Epoch 845/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 846/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5935\n",
      "Epoch 847/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5935\n",
      "Epoch 848/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 849/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5935\n",
      "Epoch 850/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.5934\n",
      "Epoch 851/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5935\n",
      "Epoch 852/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5934\n",
      "Epoch 853/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5934\n",
      "Epoch 854/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5937\n",
      "Epoch 855/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5938\n",
      "Epoch 856/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 857/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5935\n",
      "Epoch 858/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5934\n",
      "Epoch 859/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 860/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5935\n",
      "Epoch 861/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5938\n",
      "Epoch 862/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5934\n",
      "Epoch 863/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.5935\n",
      "Epoch 864/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5935\n",
      "Epoch 865/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5935\n",
      "Epoch 866/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5934\n",
      "Epoch 867/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5935\n",
      "Epoch 868/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5934\n",
      "Epoch 869/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5934\n",
      "Epoch 870/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 871/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.5934\n",
      "Epoch 872/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5936\n",
      "Epoch 873/1000\n",
      "1564/1564 [==============================] - 0s 76us/step - loss: 3.5933\n",
      "Epoch 874/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 3.5935\n",
      "Epoch 875/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 3.5934\n",
      "Epoch 876/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5935\n",
      "Epoch 877/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5935\n",
      "Epoch 878/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.5935\n",
      "Epoch 879/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5934\n",
      "Epoch 880/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5935\n",
      "Epoch 881/1000\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 3.5935\n",
      "Epoch 882/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.5934\n",
      "Epoch 883/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5936\n",
      "Epoch 884/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5936\n",
      "Epoch 885/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 886/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5935\n",
      "Epoch 887/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 888/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 889/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 890/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5935\n",
      "Epoch 891/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5938\n",
      "Epoch 892/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.5935\n",
      "Epoch 893/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5934\n",
      "Epoch 894/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5935\n",
      "Epoch 895/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5934\n",
      "Epoch 896/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5935\n",
      "Epoch 897/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5935\n",
      "Epoch 898/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 899/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5934\n",
      "Epoch 900/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 901/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5934\n",
      "Epoch 902/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.5934\n",
      "Epoch 903/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5934\n",
      "Epoch 904/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5935\n",
      "Epoch 905/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5934\n",
      "Epoch 906/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5934\n",
      "Epoch 907/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 908/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 909/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 910/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5934\n",
      "Epoch 911/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 912/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 913/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.5937\n",
      "Epoch 914/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5935\n",
      "Epoch 915/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.5934\n",
      "Epoch 916/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5935\n",
      "Epoch 917/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5937\n",
      "Epoch 918/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5940\n",
      "Epoch 919/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 920/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5934\n",
      "Epoch 921/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5935\n",
      "Epoch 922/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5934\n",
      "Epoch 923/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.5935\n",
      "Epoch 924/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.5937\n",
      "Epoch 925/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5933\n",
      "Epoch 926/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5934\n",
      "Epoch 927/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5934\n",
      "Epoch 928/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5934\n",
      "Epoch 929/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5936\n",
      "Epoch 930/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 931/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5937\n",
      "Epoch 932/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5934\n",
      "Epoch 933/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5935\n",
      "Epoch 934/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5941\n",
      "Epoch 935/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5937\n",
      "Epoch 936/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5935\n",
      "Epoch 937/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5935\n",
      "Epoch 938/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5934\n",
      "Epoch 939/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5935\n",
      "Epoch 940/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5935\n",
      "Epoch 941/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5936\n",
      "Epoch 942/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 943/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 944/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 945/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 3.5934\n",
      "Epoch 946/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5935\n",
      "Epoch 947/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.5935\n",
      "Epoch 948/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5936\n",
      "Epoch 949/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5934\n",
      "Epoch 950/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5935\n",
      "Epoch 951/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 952/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5934\n",
      "Epoch 953/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5936\n",
      "Epoch 954/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 955/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5936\n",
      "Epoch 956/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.5935\n",
      "Epoch 957/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5936\n",
      "Epoch 958/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.5936\n",
      "Epoch 959/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5935\n",
      "Epoch 960/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5934\n",
      "Epoch 961/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5936\n",
      "Epoch 962/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5937\n",
      "Epoch 963/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5937\n",
      "Epoch 964/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5936\n",
      "Epoch 965/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 966/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 3.5934\n",
      "Epoch 967/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.5936\n",
      "Epoch 968/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.5934\n",
      "Epoch 969/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5933\n",
      "Epoch 970/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5935\n",
      "Epoch 971/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 3.5935\n",
      "Epoch 972/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 973/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 974/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5936\n",
      "Epoch 975/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5935\n",
      "Epoch 976/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 977/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5935\n",
      "Epoch 978/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5934\n",
      "Epoch 979/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5934\n",
      "Epoch 980/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.5935\n",
      "Epoch 981/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5934\n",
      "Epoch 982/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 983/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5936\n",
      "Epoch 984/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5934\n",
      "Epoch 985/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 986/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5934\n",
      "Epoch 987/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 3.5934\n",
      "Epoch 988/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.5935\n",
      "Epoch 989/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.5934\n",
      "Epoch 990/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.5934\n",
      "Epoch 991/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.5934\n",
      "Epoch 992/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5934\n",
      "Epoch 993/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 3.5934\n",
      "Epoch 994/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 995/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 3.5938\n",
      "Epoch 996/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5935\n",
      "Epoch 997/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5938\n",
      "Epoch 998/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.5934\n",
      "Epoch 999/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.5934\n",
      "Epoch 1000/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 3.5935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a4c6549b0>"
      ]
     },
     "execution_count": 683,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_ast = Sequential()\n",
    "NN_ast.add(Dense(units=16,input_dim=30,activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_ast.add(Dense(units=8, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_ast.add(Dense(units=4, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_ast.add(Dense(units=1,activation='linear'))\n",
    "NN_ast.compile(loss='mse', optimizer='adam')\n",
    "NN_ast.fit(np.array(X_train), np.array(y_train), epochs=1000,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = NN_ast.predict(X_test)\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.5)\n",
    "gbr.fit(X_train,y_train)\n",
    "gbr_predictions = gbr.predict(X_test)\n",
    "LR = LinearRegression(fit_intercept=True).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN_predictions</th>\n",
       "      <th>actual</th>\n",
       "      <th>GBR_predictions</th>\n",
       "      <th>LY_assists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>10.7</td>\n",
       "      <td>10.179965</td>\n",
       "      <td>11.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>11.7</td>\n",
       "      <td>9.588353</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>10.2</td>\n",
       "      <td>9.872247</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>6.7</td>\n",
       "      <td>8.634457</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>9.8</td>\n",
       "      <td>8.940234</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>10.4</td>\n",
       "      <td>10.715098</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>10.7</td>\n",
       "      <td>9.554498</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>9.2</td>\n",
       "      <td>10.761729</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6.311065</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.168340</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.065906</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>9.1</td>\n",
       "      <td>7.524985</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>5.5</td>\n",
       "      <td>7.667351</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>7.9</td>\n",
       "      <td>7.376697</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.101129</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.479363</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.443585</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>6.7</td>\n",
       "      <td>4.645301</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>6.2</td>\n",
       "      <td>7.046483</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.784702</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.801691</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>8.5</td>\n",
       "      <td>6.968482</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.272251</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7.024964</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5.358710</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.181683</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>7.7</td>\n",
       "      <td>6.383354</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>7.6</td>\n",
       "      <td>6.447132</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.189159</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>4.6</td>\n",
       "      <td>6.735906</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.859272</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.610365</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.727826</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.384005</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.501913</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.620086</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.424583</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.570157</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.414244</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.619042</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.567250</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.524629</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.835699</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.454250</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.452319</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.656955</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.530618</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.406583</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.477059</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.330344</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.477784</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.675086</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.572720</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.331908</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.545299</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.489366</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.404374</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.022384</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.654020</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>2.185104</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.157930</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>671 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     NN_predictions  actual  GBR_predictions  LY_assists\n",
       "371        2.185104    10.7        10.179965        11.4\n",
       "184        2.185104    11.7         9.588353        11.2\n",
       "498        2.185104    10.2         9.872247        10.7\n",
       "604        2.185104     6.7         8.634457        10.7\n",
       "573        2.185104     9.8         8.940234        10.7\n",
       "518        2.185104    10.4        10.715098        10.4\n",
       "20         2.185104    10.7         9.554498        10.2\n",
       "286        2.185104     9.2        10.761729        10.0\n",
       "259        2.185104     8.8         6.311065         8.9\n",
       "359        2.185104     7.4         7.168340         8.8\n",
       "549        2.185104    10.0         8.065906         8.8\n",
       "147        2.185104     9.1         7.524985         8.7\n",
       "272        2.185104     5.5         7.667351         8.2\n",
       "541        2.185104     7.9         7.376697         8.0\n",
       "480        2.185104     7.6         7.101129         7.7\n",
       "70         2.185104     5.0         5.479363         7.6\n",
       "263        2.185104     5.2         5.443585         7.4\n",
       "285        2.185104     6.7         4.645301         7.0\n",
       "441        2.185104     6.2         7.046483         7.0\n",
       "621        2.185104     7.5         6.784702         7.0\n",
       "593        2.185104     6.0         4.801691         6.9\n",
       "500        2.185104     8.5         6.968482         6.9\n",
       "487        2.185104     6.4         6.272251         6.8\n",
       "102        2.185104     6.6         7.024964         6.7\n",
       "553        2.185104     5.9         5.358710         6.7\n",
       "516        2.185104     3.5         4.181683         6.6\n",
       "166        2.185104     7.7         6.383354         6.6\n",
       "160        2.185104     7.6         6.447132         6.6\n",
       "296        2.185104     5.5         5.189159         6.5\n",
       "133        2.185104     4.6         6.735906         6.5\n",
       "..              ...     ...              ...         ...\n",
       "46         2.185104     1.4         0.859272         0.3\n",
       "601        2.185104     0.4         0.610365         0.3\n",
       "513        2.185104     0.5         0.727826         0.3\n",
       "321        2.185104     0.7         0.384005         0.3\n",
       "394        2.185104     0.6         0.501913         0.2\n",
       "396        2.185104     0.2         0.620086         0.2\n",
       "323        2.185104     0.3         0.424583         0.2\n",
       "399        2.185104     0.5         0.570157         0.2\n",
       "388        2.185104     0.4         0.414244         0.2\n",
       "572        2.185104     0.8         0.619042         0.2\n",
       "357        2.185104     0.6         0.567250         0.2\n",
       "568        2.185104     0.3         0.524629         0.2\n",
       "135        2.185104     1.0         0.835699         0.2\n",
       "521        2.185104     0.1         0.454250         0.2\n",
       "476        2.185104     0.9         0.452319         0.2\n",
       "247        2.185104     0.4         0.656955         0.2\n",
       "470        2.185104     0.9         0.530618         0.2\n",
       "328        2.185104     0.4         0.406583         0.2\n",
       "156        2.185104     0.7         0.477059         0.2\n",
       "472        2.185104     0.2         0.330344         0.1\n",
       "95         2.185104     0.2         0.477784         0.1\n",
       "418        2.185104     0.1         0.675086         0.1\n",
       "52         2.185104     0.3         0.572720         0.1\n",
       "51         2.185104     0.2         0.331908         0.1\n",
       "314        2.185104     0.2         0.545299         0.1\n",
       "76         2.185104     0.3         0.489366         0.1\n",
       "409        2.185104     0.4         0.404374         0.1\n",
       "16         2.185104     1.5         1.022384         0.0\n",
       "600        2.185104     0.9         0.654020         0.0\n",
       "540        2.185104     1.8         0.157930         0.0\n",
       "\n",
       "[671 rows x 4 columns]"
      ]
     },
     "execution_count": 695,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing = pd.DataFrame(predictions)\n",
    "testing.columns=['NN_predictions']\n",
    "testing['actual'] = y_test.reset_index()['assists']\n",
    "testing['GBR_predictions']=gbr_predictions\n",
    "testing['LY_assists']=X_test['assists_ly'].reset_index()['assists_ly']\n",
    "testing.sort_values(by='LY_assists',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2017assists = assists[assists['season']==2017].drop(['team','player','assists','Games'],axis=1)\n",
    "assists_2017 = NN_ast.predict(pred_2017assists)\n",
    "gbr_ast_2017 = pd.DataFrame(gbr.predict(pred_2017assists))\n",
    "LR_ast_2017 = pd.DataFrame(LR.predict(pred_2017assists))\n",
    "test_2 =pd.DataFrame(assists_2017)\n",
    "test_3 = pd.merge(assists,pred_2017assists,left_index=True,right_index=True).reset_index()\n",
    "test_3['predictions']=test_2[0]\n",
    "test_3['gbr_pred'] = gbr_ast_2017[0]\n",
    "test_3['LR_pred'] = LR_ast_2017[0]\n",
    "test_3['mean_pred'] = (test_3['predictions']+test_3['gbr_pred']+test_3['LR_pred'])/3\n",
    "test_3 = test_3[test_3['Games']>30]\n",
    "test_3[['player','assists','predictions','assists_ly_x','gbr_pred','LR_pred','mean_pred']].sort_values(by='assists_ly_x',ascending=False)[0:50]\n",
    "\n",
    "assists_2017 = test_3[['player','LR_pred']]\n",
    "assists_2017.columns = ['player','assist_prediction']\n",
    "df_2017 = pd.merge(df_2017,assists_2017,how='left',left_on='player',right_on='player')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE using NN:0.7428029483598435\n",
      "MSE using mean:3.3617587113740988\n",
      "MSE using last year stats:0.850384615384615\n",
      "MSE using LR:0.5360204938681716\n",
      "MSE using GB:0.5081943911208421\n",
      "MSE using combo:0.5386291140274688\n"
     ]
    }
   ],
   "source": [
    "print('MSE using NN:{}'.format(np.mean((test_3['assists']-test_3['predictions'])**2)))\n",
    "print('MSE using mean:{}'.format(np.mean((test_3['assists']-np.mean(test_3['assists']))**2)))\n",
    "print('MSE using last year stats:{}'.format(np.mean((test_3['assists']-test_3['assists_ly_x'])**2)))\n",
    "print('MSE using LR:{}'.format(np.mean((test_3['assists']-test_3['LR_pred'])**2)))\n",
    "print('MSE using GB:{}'.format(np.mean((test_3['assists']-test_3['gbr_pred'])**2)))\n",
    "print('MSE using combo:{}'.format(np.mean((test_3['assists']-test_3['mean_pred'])**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''next is steals.  In the future, may want to add minutes from last season?'''\n",
    "\n",
    "\n",
    "query= '''\n",
    "        \n",
    "        DROP TABLE IF EXISTS steals_pred;\n",
    "        CREATE TABLE steals_pred(\n",
    "        season int, --these come from player_stats\n",
    "        player varchar(50),\n",
    "        Age int,\n",
    "        team varchar(50),\n",
    "        stl float, -- these come from player_stats\n",
    "        stl_ly float,\n",
    "        change_stl_ly float,\n",
    "        Games float,\n",
    "        C_PF int,\n",
    "        PG int,\n",
    "        SG_SF int,\n",
    "        starter_change int, \n",
    "        \n",
    "\n",
    "        -- from player_advstats\n",
    "        per_ly float,\n",
    "        change_per float,\n",
    "        stl_perc_ly float,\n",
    "        change_stl_perc_ly float,\n",
    "        defensive_winshares float,\n",
    "        defensive_boxplusminus float,\n",
    "        boxplusminus float,\n",
    "        value_overreplacement float,\n",
    "        \n",
    "        career_stl float,\n",
    "        yearspro int\n",
    "        );\n",
    "        \n",
    "        INSERT INTO steals_pred(season,player,age,team,stl,stl_ly,change_stl_ly,starter_change,Games,C_PF,PG,SG_SF)\n",
    "        SELECT season,player,age,startingteam,stl,stl_ly,change_stl_ly,starter-starter_ly,Games,\n",
    "        case when pos in ('C','PF') then 1 else 0 end,case when pos='PG' then 1 else 0 end,case when pos in('SG','SF') then 1 else 0 end from player_stats;\n",
    "        \n",
    "        \n",
    "        update steals_pred sp\n",
    "        set per_ly=pa.per_ly,change_per=pa.change_per,stl_perc_ly = pa.stl_perc_ly,change_stl_perc_ly = pa.change_stl_perc_ly\n",
    "        ,defensive_winshares=pa.defensive_winshares,defensive_boxplusminus=pa.defensive_boxplusminus\n",
    "        ,boxplusminus=pa.boxplusminus,value_overreplacement=pa.value_overreplacement\n",
    "        from player_advstats pa\n",
    "        where sp.player = pa.player and sp.season = pa.season and sp.team = pa.startingteam;\n",
    "        \n",
    "        update steals_pred sp\n",
    "        set career_stl = pc.career_stl, yearspro = pc.yearspro\n",
    "        from player_careerstats pc\n",
    "        where sp.player = pc.player and sp.season = pc.season;\n",
    "        \n",
    "        \n",
    "        select * from steals_pred where season>2009\n",
    "        '''\n",
    "\n",
    "\n",
    "cur.execute(query)\n",
    "data = cur.fetchall()\n",
    "steals_df = pd.DataFrame(np.array(data))\n",
    "steals_df.columns = ['season','player','age','team','steals','steals_ly','change_steals_ly','Games','C_PF','PG','SG_SF','starter_change'\n",
    "                    ,'per_ly','change_per','stl_perc_ly','change_stl_perc','defensive_winshares','defensive_boxplusminus','boxplusminus','value_overreplacement','career_steals','yearspro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "steals_df['age_squared']=steals_df['age']*steals_df['age']\n",
    "steals = steals_df[steals_df['steals_ly'].notna()]\n",
    "for i in steals.columns:\n",
    "    if i not in(['player','team']):\n",
    "        steals[i]=pd.to_numeric(steals[i])\n",
    "steals = steals.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = steals[(steals['season']!=2017) & (steals['Games']>30)].drop(['player','team','steals','Games'],axis=1)\n",
    "y = steals[(steals['season']!=2017) & (steals['Games']>30)]['steals']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1564/1564 [==============================] - 3s 2ms/step - loss: 10895.7234\n",
      "Epoch 2/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1496.2554\n",
      "Epoch 3/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 56.6961\n",
      "Epoch 4/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 17.7054\n",
      "Epoch 5/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 4.9112\n",
      "Epoch 6/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.3506\n",
      "Epoch 7/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.9323\n",
      "Epoch 8/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.8289\n",
      "Epoch 9/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.8137\n",
      "Epoch 10/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.8065\n",
      "Epoch 11/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.8040\n",
      "Epoch 12/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.8015\n",
      "Epoch 13/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.7993\n",
      "Epoch 14/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.7974\n",
      "Epoch 15/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.7958\n",
      "Epoch 16/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.7946\n",
      "Epoch 17/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.7932\n",
      "Epoch 18/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.7920\n",
      "Epoch 19/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.7910\n",
      "Epoch 20/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.7900\n",
      "Epoch 21/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.7892\n",
      "Epoch 22/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.7885\n",
      "Epoch 23/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.7873\n",
      "Epoch 24/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.7865\n",
      "Epoch 25/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.7858\n",
      "Epoch 26/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.7849\n",
      "Epoch 27/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7841\n",
      "Epoch 28/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.7833\n",
      "Epoch 29/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7824\n",
      "Epoch 30/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.7815\n",
      "Epoch 31/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.7807\n",
      "Epoch 32/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7798\n",
      "Epoch 33/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7789\n",
      "Epoch 34/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.7779\n",
      "Epoch 35/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.7770\n",
      "Epoch 36/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7760\n",
      "Epoch 37/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7752\n",
      "Epoch 38/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.7741\n",
      "Epoch 39/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.7731\n",
      "Epoch 40/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.7721\n",
      "Epoch 41/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7711\n",
      "Epoch 42/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.7700\n",
      "Epoch 43/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7690\n",
      "Epoch 44/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.7679\n",
      "Epoch 45/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7669\n",
      "Epoch 46/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.7657\n",
      "Epoch 47/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7646\n",
      "Epoch 48/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.7635\n",
      "Epoch 49/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.7624\n",
      "Epoch 50/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.7613\n",
      "Epoch 51/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.7601\n",
      "Epoch 52/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.7589\n",
      "Epoch 53/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7577\n",
      "Epoch 54/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.7565\n",
      "Epoch 55/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.7552\n",
      "Epoch 56/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.7540\n",
      "Epoch 57/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7528\n",
      "Epoch 58/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7515\n",
      "Epoch 59/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7503\n",
      "Epoch 60/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.7490\n",
      "Epoch 61/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7477\n",
      "Epoch 62/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.7464\n",
      "Epoch 63/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.7451\n",
      "Epoch 64/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.7437\n",
      "Epoch 65/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.7424\n",
      "Epoch 66/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7410\n",
      "Epoch 67/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.7397\n",
      "Epoch 68/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.7383\n",
      "Epoch 69/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.7370\n",
      "Epoch 70/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.7356\n",
      "Epoch 71/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.7341\n",
      "Epoch 72/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.7327\n",
      "Epoch 73/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.7313\n",
      "Epoch 74/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.7298\n",
      "Epoch 75/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.7284\n",
      "Epoch 76/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.7269\n",
      "Epoch 77/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.7254\n",
      "Epoch 78/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7239\n",
      "Epoch 79/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.7224\n",
      "Epoch 80/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.7208\n",
      "Epoch 81/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.7193\n",
      "Epoch 82/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.7177\n",
      "Epoch 83/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.7162\n",
      "Epoch 84/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.7146\n",
      "Epoch 85/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.7131\n",
      "Epoch 86/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7116\n",
      "Epoch 87/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7099\n",
      "Epoch 88/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7083\n",
      "Epoch 89/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.7066\n",
      "Epoch 90/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.7050\n",
      "Epoch 91/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.7034\n",
      "Epoch 92/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.7018\n",
      "Epoch 93/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.7001\n",
      "Epoch 94/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.6984\n",
      "Epoch 95/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.6967\n",
      "Epoch 96/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.6950\n",
      "Epoch 97/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.6933\n",
      "Epoch 98/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.6916\n",
      "Epoch 99/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.6900\n",
      "Epoch 100/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.6881\n",
      "Epoch 101/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.6864\n",
      "Epoch 102/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.6847\n",
      "Epoch 103/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6830\n",
      "Epoch 104/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6812\n",
      "Epoch 105/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6795\n",
      "Epoch 106/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6777\n",
      "Epoch 107/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.6760\n",
      "Epoch 108/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6742\n",
      "Epoch 109/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.6723\n",
      "Epoch 110/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.6704\n",
      "Epoch 111/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.6685\n",
      "Epoch 112/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.6666\n",
      "Epoch 113/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.6647\n",
      "Epoch 114/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.6629\n",
      "Epoch 115/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.6610\n",
      "Epoch 116/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.6591\n",
      "Epoch 117/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.6572\n",
      "Epoch 118/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.6553\n",
      "Epoch 119/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.6534\n",
      "Epoch 120/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.6515\n",
      "Epoch 121/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.6496\n",
      "Epoch 122/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6477\n",
      "Epoch 123/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.6457\n",
      "Epoch 124/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6438\n",
      "Epoch 125/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.6419\n",
      "Epoch 126/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6399\n",
      "Epoch 127/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.6380\n",
      "Epoch 128/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.6360\n",
      "Epoch 129/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.6341\n",
      "Epoch 130/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.6321\n",
      "Epoch 131/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.6301\n",
      "Epoch 132/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.6281\n",
      "Epoch 133/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.6261\n",
      "Epoch 134/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.6241\n",
      "Epoch 135/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6221\n",
      "Epoch 136/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6200\n",
      "Epoch 137/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6180\n",
      "Epoch 138/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6160\n",
      "Epoch 139/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6139\n",
      "Epoch 140/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.6119\n",
      "Epoch 141/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.6099\n",
      "Epoch 142/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.6078\n",
      "Epoch 143/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.6057\n",
      "Epoch 144/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6037\n",
      "Epoch 145/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6016\n",
      "Epoch 146/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5995\n",
      "Epoch 147/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5974\n",
      "Epoch 148/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.5953\n",
      "Epoch 149/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5932\n",
      "Epoch 150/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.5911\n",
      "Epoch 151/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5890\n",
      "Epoch 152/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5869\n",
      "Epoch 153/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5848\n",
      "Epoch 154/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.5826\n",
      "Epoch 155/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.5805\n",
      "Epoch 156/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5784\n",
      "Epoch 157/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.5763\n",
      "Epoch 158/1000\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 0.5741\n",
      "Epoch 159/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5720\n",
      "Epoch 160/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5698\n",
      "Epoch 161/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5677\n",
      "Epoch 162/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5655\n",
      "Epoch 163/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.5634\n",
      "Epoch 164/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5612\n",
      "Epoch 165/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5590\n",
      "Epoch 166/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.5569\n",
      "Epoch 167/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.5547\n",
      "Epoch 168/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5526\n",
      "Epoch 169/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5504\n",
      "Epoch 170/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5482\n",
      "Epoch 171/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5460\n",
      "Epoch 172/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5438\n",
      "Epoch 173/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.5416\n",
      "Epoch 174/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5394\n",
      "Epoch 175/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5372\n",
      "Epoch 176/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5350\n",
      "Epoch 177/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5328\n",
      "Epoch 178/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5306\n",
      "Epoch 179/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5284\n",
      "Epoch 180/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.5262\n",
      "Epoch 181/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5240\n",
      "Epoch 182/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5218\n",
      "Epoch 183/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5196\n",
      "Epoch 184/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.5174\n",
      "Epoch 185/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.5151\n",
      "Epoch 186/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.5129\n",
      "Epoch 187/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.5107\n",
      "Epoch 188/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.5085\n",
      "Epoch 189/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.5063\n",
      "Epoch 190/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.5041\n",
      "Epoch 191/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.5019\n",
      "Epoch 192/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.4996\n",
      "Epoch 193/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4974\n",
      "Epoch 194/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4952\n",
      "Epoch 195/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4930\n",
      "Epoch 196/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4908\n",
      "Epoch 197/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4885\n",
      "Epoch 198/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4863\n",
      "Epoch 199/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4841\n",
      "Epoch 200/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4819\n",
      "Epoch 201/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4796\n",
      "Epoch 202/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4774\n",
      "Epoch 203/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4751\n",
      "Epoch 204/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4730\n",
      "Epoch 205/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4708\n",
      "Epoch 206/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4685\n",
      "Epoch 207/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4664\n",
      "Epoch 208/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4641\n",
      "Epoch 209/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.4620\n",
      "Epoch 210/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4598\n",
      "Epoch 211/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4576\n",
      "Epoch 212/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4554\n",
      "Epoch 213/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.4532\n",
      "Epoch 214/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.4510\n",
      "Epoch 215/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4488\n",
      "Epoch 216/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4466\n",
      "Epoch 217/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.4444\n",
      "Epoch 218/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4422\n",
      "Epoch 219/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4401\n",
      "Epoch 220/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4379\n",
      "Epoch 221/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4357\n",
      "Epoch 222/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4336\n",
      "Epoch 223/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4314\n",
      "Epoch 224/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.4292\n",
      "Epoch 225/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4271\n",
      "Epoch 226/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.4249\n",
      "Epoch 227/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4228\n",
      "Epoch 228/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4206\n",
      "Epoch 229/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4184\n",
      "Epoch 230/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4163\n",
      "Epoch 231/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4142\n",
      "Epoch 232/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4120\n",
      "Epoch 233/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4099\n",
      "Epoch 234/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4078\n",
      "Epoch 235/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4057\n",
      "Epoch 236/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4036\n",
      "Epoch 237/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4015\n",
      "Epoch 238/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.3994\n",
      "Epoch 239/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.3973\n",
      "Epoch 240/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3952\n",
      "Epoch 241/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3931\n",
      "Epoch 242/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3910\n",
      "Epoch 243/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3890\n",
      "Epoch 244/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.3869\n",
      "Epoch 245/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.3849\n",
      "Epoch 246/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3829\n",
      "Epoch 247/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.3808\n",
      "Epoch 248/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3788\n",
      "Epoch 249/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.3768\n",
      "Epoch 250/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3747\n",
      "Epoch 251/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.3727\n",
      "Epoch 252/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3707\n",
      "Epoch 253/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.3687\n",
      "Epoch 254/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3667\n",
      "Epoch 255/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.3647\n",
      "Epoch 256/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.3628\n",
      "Epoch 257/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.3608\n",
      "Epoch 258/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.3589\n",
      "Epoch 259/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.3569\n",
      "Epoch 260/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3550\n",
      "Epoch 261/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3530\n",
      "Epoch 262/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3511\n",
      "Epoch 263/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3491\n",
      "Epoch 264/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.3472\n",
      "Epoch 265/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3453\n",
      "Epoch 266/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3435\n",
      "Epoch 267/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3416\n",
      "Epoch 268/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3398\n",
      "Epoch 269/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.3379\n",
      "Epoch 270/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3360\n",
      "Epoch 271/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3342\n",
      "Epoch 272/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.3324\n",
      "Epoch 273/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.3306\n",
      "Epoch 274/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3288\n",
      "Epoch 275/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.3270\n",
      "Epoch 276/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.3251\n",
      "Epoch 277/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3233\n",
      "Epoch 278/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3215\n",
      "Epoch 279/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3198\n",
      "Epoch 280/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.3180\n",
      "Epoch 281/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.3163\n",
      "Epoch 282/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.3146\n",
      "Epoch 283/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3128\n",
      "Epoch 284/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.3112\n",
      "Epoch 285/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.3095\n",
      "Epoch 286/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3078\n",
      "Epoch 287/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3061\n",
      "Epoch 288/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3044\n",
      "Epoch 289/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3027\n",
      "Epoch 290/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3011\n",
      "Epoch 291/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2995\n",
      "Epoch 292/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2978\n",
      "Epoch 293/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2962\n",
      "Epoch 294/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2946\n",
      "Epoch 295/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2930\n",
      "Epoch 296/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2915\n",
      "Epoch 297/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2899\n",
      "Epoch 298/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2883\n",
      "Epoch 299/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2868\n",
      "Epoch 300/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2853\n",
      "Epoch 301/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2838\n",
      "Epoch 302/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.2823\n",
      "Epoch 303/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2808\n",
      "Epoch 304/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2793\n",
      "Epoch 305/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2778\n",
      "Epoch 306/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.2763\n",
      "Epoch 307/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2749\n",
      "Epoch 308/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.2734\n",
      "Epoch 309/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2720\n",
      "Epoch 310/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2706\n",
      "Epoch 311/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2692\n",
      "Epoch 312/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2678\n",
      "Epoch 313/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2664\n",
      "Epoch 314/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2650\n",
      "Epoch 315/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2637\n",
      "Epoch 316/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2623\n",
      "Epoch 317/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2610\n",
      "Epoch 318/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2597\n",
      "Epoch 319/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2583\n",
      "Epoch 320/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2571\n",
      "Epoch 321/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2558\n",
      "Epoch 322/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2545\n",
      "Epoch 323/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2533\n",
      "Epoch 324/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2520\n",
      "Epoch 325/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2508\n",
      "Epoch 326/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2496\n",
      "Epoch 327/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2483\n",
      "Epoch 328/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2471\n",
      "Epoch 329/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2460\n",
      "Epoch 330/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2448\n",
      "Epoch 331/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2437\n",
      "Epoch 332/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2425\n",
      "Epoch 333/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2414\n",
      "Epoch 334/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.2403\n",
      "Epoch 335/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2392\n",
      "Epoch 336/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2381\n",
      "Epoch 337/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2370\n",
      "Epoch 338/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2359\n",
      "Epoch 339/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2348\n",
      "Epoch 340/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2338\n",
      "Epoch 341/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2328\n",
      "Epoch 342/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2318\n",
      "Epoch 343/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2308\n",
      "Epoch 344/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2298\n",
      "Epoch 345/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2288\n",
      "Epoch 346/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2278\n",
      "Epoch 347/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2268\n",
      "Epoch 348/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2259\n",
      "Epoch 349/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2249\n",
      "Epoch 350/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2240\n",
      "Epoch 351/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2231\n",
      "Epoch 352/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2222\n",
      "Epoch 353/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2213\n",
      "Epoch 354/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2205\n",
      "Epoch 355/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2196\n",
      "Epoch 356/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2187\n",
      "Epoch 357/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2179\n",
      "Epoch 358/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2170\n",
      "Epoch 359/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2162\n",
      "Epoch 360/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2154\n",
      "Epoch 361/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2146\n",
      "Epoch 362/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2138\n",
      "Epoch 363/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2131\n",
      "Epoch 364/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2123\n",
      "Epoch 365/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2116\n",
      "Epoch 366/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2108\n",
      "Epoch 367/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2101\n",
      "Epoch 368/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2094\n",
      "Epoch 369/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2087\n",
      "Epoch 370/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2080\n",
      "Epoch 371/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2073\n",
      "Epoch 372/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2066\n",
      "Epoch 373/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2059\n",
      "Epoch 374/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2053\n",
      "Epoch 375/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2047\n",
      "Epoch 376/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2040\n",
      "Epoch 377/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2034\n",
      "Epoch 378/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2028\n",
      "Epoch 379/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2022\n",
      "Epoch 380/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2016\n",
      "Epoch 381/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2011\n",
      "Epoch 382/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2005\n",
      "Epoch 383/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1999\n",
      "Epoch 384/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1994\n",
      "Epoch 385/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1988\n",
      "Epoch 386/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1983\n",
      "Epoch 387/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1978\n",
      "Epoch 388/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1972\n",
      "Epoch 389/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1967\n",
      "Epoch 390/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1962\n",
      "Epoch 391/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1958\n",
      "Epoch 392/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1953\n",
      "Epoch 393/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1948\n",
      "Epoch 394/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1944\n",
      "Epoch 395/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1939\n",
      "Epoch 396/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1935\n",
      "Epoch 397/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1930\n",
      "Epoch 398/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1926\n",
      "Epoch 399/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1921\n",
      "Epoch 400/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1917\n",
      "Epoch 401/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1913\n",
      "Epoch 402/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1909\n",
      "Epoch 403/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1906\n",
      "Epoch 404/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1902\n",
      "Epoch 405/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1898\n",
      "Epoch 406/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1895\n",
      "Epoch 407/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1891\n",
      "Epoch 408/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1888\n",
      "Epoch 409/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1884\n",
      "Epoch 410/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1881\n",
      "Epoch 411/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1878\n",
      "Epoch 412/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1875\n",
      "Epoch 413/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.1871\n",
      "Epoch 414/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1868\n",
      "Epoch 415/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1866\n",
      "Epoch 416/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1863\n",
      "Epoch 417/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1860\n",
      "Epoch 418/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1857\n",
      "Epoch 419/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1854\n",
      "Epoch 420/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1852\n",
      "Epoch 421/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1849\n",
      "Epoch 422/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1847\n",
      "Epoch 423/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1844\n",
      "Epoch 424/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1842\n",
      "Epoch 425/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1839\n",
      "Epoch 426/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1837\n",
      "Epoch 427/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1835\n",
      "Epoch 428/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1833\n",
      "Epoch 429/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1830\n",
      "Epoch 430/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1828\n",
      "Epoch 431/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1826\n",
      "Epoch 432/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1824\n",
      "Epoch 433/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1822\n",
      "Epoch 434/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1821\n",
      "Epoch 435/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1819\n",
      "Epoch 436/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1817\n",
      "Epoch 437/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1815\n",
      "Epoch 438/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1814\n",
      "Epoch 439/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1812\n",
      "Epoch 440/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1810\n",
      "Epoch 441/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1809\n",
      "Epoch 442/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1807\n",
      "Epoch 443/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1806\n",
      "Epoch 444/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1805\n",
      "Epoch 445/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1803\n",
      "Epoch 446/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1802\n",
      "Epoch 447/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1800\n",
      "Epoch 448/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1799\n",
      "Epoch 449/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1798\n",
      "Epoch 450/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1797\n",
      "Epoch 451/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1796\n",
      "Epoch 452/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1795\n",
      "Epoch 453/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1794\n",
      "Epoch 454/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1793\n",
      "Epoch 455/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1792\n",
      "Epoch 456/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1791\n",
      "Epoch 457/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1790\n",
      "Epoch 458/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1789\n",
      "Epoch 459/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1788\n",
      "Epoch 460/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1787\n",
      "Epoch 461/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1787\n",
      "Epoch 462/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1786\n",
      "Epoch 463/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1785\n",
      "Epoch 464/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1784\n",
      "Epoch 465/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1784\n",
      "Epoch 466/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1783\n",
      "Epoch 467/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1782\n",
      "Epoch 468/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1782\n",
      "Epoch 469/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1781\n",
      "Epoch 470/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1780\n",
      "Epoch 471/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1780\n",
      "Epoch 472/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1779\n",
      "Epoch 473/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1779\n",
      "Epoch 474/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1778\n",
      "Epoch 475/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1778\n",
      "Epoch 476/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1777\n",
      "Epoch 477/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1777\n",
      "Epoch 478/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1776\n",
      "Epoch 479/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1776\n",
      "Epoch 480/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1775\n",
      "Epoch 481/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1775\n",
      "Epoch 482/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1775\n",
      "Epoch 483/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1774\n",
      "Epoch 484/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1774\n",
      "Epoch 485/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1774\n",
      "Epoch 486/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1773\n",
      "Epoch 487/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1773\n",
      "Epoch 488/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1773\n",
      "Epoch 489/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1772\n",
      "Epoch 490/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1772\n",
      "Epoch 491/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1772\n",
      "Epoch 492/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1772\n",
      "Epoch 493/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1771\n",
      "Epoch 494/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1771\n",
      "Epoch 495/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1771\n",
      "Epoch 496/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1771\n",
      "Epoch 497/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1771\n",
      "Epoch 498/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1770\n",
      "Epoch 499/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1770\n",
      "Epoch 500/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1770\n",
      "Epoch 501/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1770\n",
      "Epoch 502/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1770\n",
      "Epoch 503/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1770\n",
      "Epoch 504/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1769\n",
      "Epoch 505/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1769\n",
      "Epoch 506/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1769\n",
      "Epoch 507/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1769\n",
      "Epoch 508/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1769\n",
      "Epoch 509/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1769\n",
      "Epoch 510/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1768\n",
      "Epoch 511/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1768\n",
      "Epoch 512/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1768\n",
      "Epoch 513/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1768\n",
      "Epoch 514/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1768\n",
      "Epoch 515/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1768\n",
      "Epoch 516/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1768\n",
      "Epoch 517/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1768\n",
      "Epoch 518/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1768\n",
      "Epoch 519/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1767\n",
      "Epoch 520/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1767\n",
      "Epoch 521/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1767\n",
      "Epoch 522/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1767\n",
      "Epoch 523/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1767\n",
      "Epoch 524/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1767\n",
      "Epoch 525/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1767\n",
      "Epoch 526/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1767\n",
      "Epoch 527/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1767\n",
      "Epoch 528/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1767\n",
      "Epoch 529/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1767\n",
      "Epoch 530/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1767\n",
      "Epoch 531/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1767\n",
      "Epoch 532/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.1767\n",
      "Epoch 533/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1767\n",
      "Epoch 534/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1767\n",
      "Epoch 535/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1767\n",
      "Epoch 536/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1767\n",
      "Epoch 537/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1767\n",
      "Epoch 538/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1767\n",
      "Epoch 539/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1767\n",
      "Epoch 540/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1767\n",
      "Epoch 541/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1767\n",
      "Epoch 542/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1767\n",
      "Epoch 543/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1767\n",
      "Epoch 544/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1767\n",
      "Epoch 545/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1767\n",
      "Epoch 546/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1767\n",
      "Epoch 547/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1767\n",
      "Epoch 548/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1767\n",
      "Epoch 549/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1767\n",
      "Epoch 550/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1767\n",
      "Epoch 551/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1766\n",
      "Epoch 552/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1766\n",
      "Epoch 553/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1766\n",
      "Epoch 554/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1766\n",
      "Epoch 555/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1766\n",
      "Epoch 556/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1766\n",
      "Epoch 557/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1766\n",
      "Epoch 558/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1766\n",
      "Epoch 559/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1766\n",
      "Epoch 560/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1766\n",
      "Epoch 561/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1766\n",
      "Epoch 562/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1766\n",
      "Epoch 563/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1766\n",
      "Epoch 564/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1766\n",
      "Epoch 565/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1766\n",
      "Epoch 566/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1766\n",
      "Epoch 567/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1766\n",
      "Epoch 568/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1766\n",
      "Epoch 569/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 570/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1766\n",
      "Epoch 571/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1766\n",
      "Epoch 572/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1766\n",
      "Epoch 573/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1766\n",
      "Epoch 574/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1766\n",
      "Epoch 575/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1766\n",
      "Epoch 576/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1766\n",
      "Epoch 577/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1766\n",
      "Epoch 578/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1766\n",
      "Epoch 579/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1766\n",
      "Epoch 580/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1766\n",
      "Epoch 581/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1766\n",
      "Epoch 582/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1766\n",
      "Epoch 583/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1766\n",
      "Epoch 584/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1766\n",
      "Epoch 585/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1766\n",
      "Epoch 586/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1766\n",
      "Epoch 587/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1766\n",
      "Epoch 588/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1766\n",
      "Epoch 589/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1766\n",
      "Epoch 590/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1766\n",
      "Epoch 591/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.1766\n",
      "Epoch 592/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1766\n",
      "Epoch 593/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 594/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1766\n",
      "Epoch 595/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1766\n",
      "Epoch 596/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1766\n",
      "Epoch 597/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1766\n",
      "Epoch 598/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1766\n",
      "Epoch 599/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.1766\n",
      "Epoch 600/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.1766\n",
      "Epoch 601/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.1766\n",
      "Epoch 602/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.1766\n",
      "Epoch 603/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.1766\n",
      "Epoch 604/1000\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 0.1766\n",
      "Epoch 605/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1766\n",
      "Epoch 606/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1766\n",
      "Epoch 607/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1766\n",
      "Epoch 608/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 609/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1766\n",
      "Epoch 610/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1766\n",
      "Epoch 611/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.1766\n",
      "Epoch 612/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 0.1766\n",
      "Epoch 613/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.1766\n",
      "Epoch 614/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1766\n",
      "Epoch 615/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.1766\n",
      "Epoch 616/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.1766\n",
      "Epoch 617/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1766\n",
      "Epoch 618/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.1766\n",
      "Epoch 619/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 0.1766\n",
      "Epoch 620/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1766\n",
      "Epoch 621/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1766\n",
      "Epoch 622/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.1766\n",
      "Epoch 623/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.1766\n",
      "Epoch 624/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1766\n",
      "Epoch 625/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1766\n",
      "Epoch 626/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1766\n",
      "Epoch 627/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1766\n",
      "Epoch 628/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1766\n",
      "Epoch 629/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1766\n",
      "Epoch 630/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1766\n",
      "Epoch 631/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1766\n",
      "Epoch 632/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1766\n",
      "Epoch 633/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1766\n",
      "Epoch 634/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1766\n",
      "Epoch 635/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1766\n",
      "Epoch 636/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1766\n",
      "Epoch 637/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1766\n",
      "Epoch 638/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1766\n",
      "Epoch 639/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1766\n",
      "Epoch 640/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1766\n",
      "Epoch 641/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1766\n",
      "Epoch 642/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1766\n",
      "Epoch 643/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1766\n",
      "Epoch 644/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1766\n",
      "Epoch 645/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1766\n",
      "Epoch 646/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1766\n",
      "Epoch 647/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 648/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1766\n",
      "Epoch 649/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1766\n",
      "Epoch 650/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1766\n",
      "Epoch 651/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1766\n",
      "Epoch 652/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1766\n",
      "Epoch 653/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1766\n",
      "Epoch 654/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1766\n",
      "Epoch 655/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1766\n",
      "Epoch 656/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1766\n",
      "Epoch 657/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1766\n",
      "Epoch 658/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1766\n",
      "Epoch 659/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1766\n",
      "Epoch 660/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1766\n",
      "Epoch 661/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1766\n",
      "Epoch 662/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1766\n",
      "Epoch 663/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1766\n",
      "Epoch 664/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 665/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1766\n",
      "Epoch 666/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1766\n",
      "Epoch 667/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1766\n",
      "Epoch 668/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1766\n",
      "Epoch 669/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1766\n",
      "Epoch 670/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1766\n",
      "Epoch 671/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1766\n",
      "Epoch 672/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1767\n",
      "Epoch 673/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1766\n",
      "Epoch 674/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1766\n",
      "Epoch 675/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1766\n",
      "Epoch 676/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1766\n",
      "Epoch 677/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1766\n",
      "Epoch 678/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1766\n",
      "Epoch 679/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1766\n",
      "Epoch 680/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1766\n",
      "Epoch 681/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1766\n",
      "Epoch 682/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1766\n",
      "Epoch 683/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1766\n",
      "Epoch 684/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1766\n",
      "Epoch 685/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 686/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 687/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 688/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1766\n",
      "Epoch 689/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 690/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 691/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1767\n",
      "Epoch 692/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1766\n",
      "Epoch 693/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1766\n",
      "Epoch 694/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1766\n",
      "Epoch 695/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.1766\n",
      "Epoch 696/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1766\n",
      "Epoch 697/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1766\n",
      "Epoch 698/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1766\n",
      "Epoch 699/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1766\n",
      "Epoch 700/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1766\n",
      "Epoch 701/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1766\n",
      "Epoch 702/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1766\n",
      "Epoch 703/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1766\n",
      "Epoch 704/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1766\n",
      "Epoch 705/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 706/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1766\n",
      "Epoch 707/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1766\n",
      "Epoch 708/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 709/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 710/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1766\n",
      "Epoch 711/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1766\n",
      "Epoch 712/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 713/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1766\n",
      "Epoch 714/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1766\n",
      "Epoch 715/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1767\n",
      "Epoch 716/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1766\n",
      "Epoch 717/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 718/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1766\n",
      "Epoch 719/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 720/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1766\n",
      "Epoch 721/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 722/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 723/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1766\n",
      "Epoch 724/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1766\n",
      "Epoch 725/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 726/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1766\n",
      "Epoch 727/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1766\n",
      "Epoch 728/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1766\n",
      "Epoch 729/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1766\n",
      "Epoch 730/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1766\n",
      "Epoch 731/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 732/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1766\n",
      "Epoch 733/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 734/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1766\n",
      "Epoch 735/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1766\n",
      "Epoch 736/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1766\n",
      "Epoch 737/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1766\n",
      "Epoch 738/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 739/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1766\n",
      "Epoch 740/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1766\n",
      "Epoch 741/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1766\n",
      "Epoch 742/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 743/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1766\n",
      "Epoch 744/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1766\n",
      "Epoch 745/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1766\n",
      "Epoch 746/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 747/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1766\n",
      "Epoch 748/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 749/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 750/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1766\n",
      "Epoch 751/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 752/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.1766\n",
      "Epoch 753/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1766\n",
      "Epoch 754/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 755/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1766\n",
      "Epoch 756/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1766\n",
      "Epoch 757/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1766\n",
      "Epoch 758/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1767\n",
      "Epoch 759/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1766\n",
      "Epoch 760/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1766\n",
      "Epoch 761/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1766\n",
      "Epoch 762/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1766\n",
      "Epoch 763/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1766\n",
      "Epoch 764/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1766\n",
      "Epoch 765/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1766\n",
      "Epoch 766/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1766\n",
      "Epoch 767/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1766\n",
      "Epoch 768/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1767\n",
      "Epoch 769/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1766\n",
      "Epoch 770/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1767\n",
      "Epoch 771/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1767\n",
      "Epoch 772/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1766\n",
      "Epoch 773/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1767\n",
      "Epoch 774/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1767\n",
      "Epoch 775/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1766\n",
      "Epoch 776/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1766\n",
      "Epoch 777/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1766\n",
      "Epoch 778/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1766\n",
      "Epoch 779/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.1766\n",
      "Epoch 780/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1766\n",
      "Epoch 781/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1766\n",
      "Epoch 782/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1766\n",
      "Epoch 783/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1766\n",
      "Epoch 784/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 785/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1766\n",
      "Epoch 786/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1766\n",
      "Epoch 787/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1766\n",
      "Epoch 788/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1766\n",
      "Epoch 789/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1766\n",
      "Epoch 790/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1766\n",
      "Epoch 791/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1767\n",
      "Epoch 792/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1767\n",
      "Epoch 793/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1766\n",
      "Epoch 794/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 795/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 796/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1767\n",
      "Epoch 797/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1766\n",
      "Epoch 798/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1766\n",
      "Epoch 799/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1766\n",
      "Epoch 800/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 801/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1766\n",
      "Epoch 802/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1767\n",
      "Epoch 803/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1766\n",
      "Epoch 804/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 805/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1766\n",
      "Epoch 806/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1766\n",
      "Epoch 807/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 808/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1767\n",
      "Epoch 809/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1767\n",
      "Epoch 810/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1767\n",
      "Epoch 811/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1767\n",
      "Epoch 812/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1767\n",
      "Epoch 813/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1766\n",
      "Epoch 814/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1766\n",
      "Epoch 815/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1766\n",
      "Epoch 816/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1766\n",
      "Epoch 817/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1766\n",
      "Epoch 818/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1767\n",
      "Epoch 819/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1766\n",
      "Epoch 820/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1766\n",
      "Epoch 821/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1766\n",
      "Epoch 822/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1766\n",
      "Epoch 823/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.1766\n",
      "Epoch 824/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.1766\n",
      "Epoch 825/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1766\n",
      "Epoch 826/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1766\n",
      "Epoch 827/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1766\n",
      "Epoch 828/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1766\n",
      "Epoch 829/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1767\n",
      "Epoch 830/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1766\n",
      "Epoch 831/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1766\n",
      "Epoch 832/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1767\n",
      "Epoch 833/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1766\n",
      "Epoch 834/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1767\n",
      "Epoch 835/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1766\n",
      "Epoch 836/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1767\n",
      "Epoch 837/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1766\n",
      "Epoch 838/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1766\n",
      "Epoch 839/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1767\n",
      "Epoch 840/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1766\n",
      "Epoch 841/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 842/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 843/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 844/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1766\n",
      "Epoch 845/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1767\n",
      "Epoch 846/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1766\n",
      "Epoch 847/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1767\n",
      "Epoch 848/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1766\n",
      "Epoch 849/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1766\n",
      "Epoch 850/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1767\n",
      "Epoch 851/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1766\n",
      "Epoch 852/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 853/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1766\n",
      "Epoch 854/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1766\n",
      "Epoch 855/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1767\n",
      "Epoch 856/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1767\n",
      "Epoch 857/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1766\n",
      "Epoch 858/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1766\n",
      "Epoch 859/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1766\n",
      "Epoch 860/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1766\n",
      "Epoch 861/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1767\n",
      "Epoch 862/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1766\n",
      "Epoch 863/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1766\n",
      "Epoch 864/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1766\n",
      "Epoch 865/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1766\n",
      "Epoch 866/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1766\n",
      "Epoch 867/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1766\n",
      "Epoch 868/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 869/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1767\n",
      "Epoch 870/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1766\n",
      "Epoch 871/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1766\n",
      "Epoch 872/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1767\n",
      "Epoch 873/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1767\n",
      "Epoch 874/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1766\n",
      "Epoch 875/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1767\n",
      "Epoch 876/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1766\n",
      "Epoch 877/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1766\n",
      "Epoch 878/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1766\n",
      "Epoch 879/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1766\n",
      "Epoch 880/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 881/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1767\n",
      "Epoch 882/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1766\n",
      "Epoch 883/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1766\n",
      "Epoch 884/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1766\n",
      "Epoch 885/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1767\n",
      "Epoch 886/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1767\n",
      "Epoch 887/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 888/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1766\n",
      "Epoch 889/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1766\n",
      "Epoch 890/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.1767\n",
      "Epoch 891/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.1766\n",
      "Epoch 892/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1767\n",
      "Epoch 893/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1766\n",
      "Epoch 894/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1767\n",
      "Epoch 895/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1766\n",
      "Epoch 896/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1766\n",
      "Epoch 897/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1766\n",
      "Epoch 898/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1766\n",
      "Epoch 899/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1766\n",
      "Epoch 900/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1766\n",
      "Epoch 901/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1766\n",
      "Epoch 902/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 903/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1767\n",
      "Epoch 904/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1766\n",
      "Epoch 905/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1766\n",
      "Epoch 906/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1766\n",
      "Epoch 907/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1766\n",
      "Epoch 908/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1766\n",
      "Epoch 909/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1767\n",
      "Epoch 910/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1767\n",
      "Epoch 911/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1767\n",
      "Epoch 912/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1766\n",
      "Epoch 913/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1767\n",
      "Epoch 914/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1766\n",
      "Epoch 915/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1767\n",
      "Epoch 916/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1766\n",
      "Epoch 917/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1767\n",
      "Epoch 918/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1766\n",
      "Epoch 919/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1766\n",
      "Epoch 920/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1766\n",
      "Epoch 921/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1766\n",
      "Epoch 922/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1766\n",
      "Epoch 923/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1767\n",
      "Epoch 924/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1766\n",
      "Epoch 925/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1766\n",
      "Epoch 926/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1766\n",
      "Epoch 927/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1766\n",
      "Epoch 928/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1767\n",
      "Epoch 929/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1766\n",
      "Epoch 930/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1766\n",
      "Epoch 931/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1767\n",
      "Epoch 932/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1766\n",
      "Epoch 933/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1767\n",
      "Epoch 934/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1766\n",
      "Epoch 935/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1767\n",
      "Epoch 936/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1766\n",
      "Epoch 937/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1766\n",
      "Epoch 938/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1767\n",
      "Epoch 939/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1766\n",
      "Epoch 940/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1766\n",
      "Epoch 941/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1766\n",
      "Epoch 942/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1766\n",
      "Epoch 943/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1766\n",
      "Epoch 944/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1767\n",
      "Epoch 945/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1766\n",
      "Epoch 946/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1766\n",
      "Epoch 947/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1766\n",
      "Epoch 948/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1766\n",
      "Epoch 949/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1767\n",
      "Epoch 950/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1767\n",
      "Epoch 951/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1766\n",
      "Epoch 952/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1766\n",
      "Epoch 953/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1767\n",
      "Epoch 954/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1766\n",
      "Epoch 955/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1767\n",
      "Epoch 956/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1767\n",
      "Epoch 957/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1766\n",
      "Epoch 958/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1766\n",
      "Epoch 959/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1766\n",
      "Epoch 960/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1766\n",
      "Epoch 961/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1766\n",
      "Epoch 962/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1767\n",
      "Epoch 963/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1767\n",
      "Epoch 964/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1766\n",
      "Epoch 965/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1766\n",
      "Epoch 966/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1766\n",
      "Epoch 967/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1766\n",
      "Epoch 968/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1767\n",
      "Epoch 969/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1766\n",
      "Epoch 970/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1766\n",
      "Epoch 971/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1767\n",
      "Epoch 972/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1767\n",
      "Epoch 973/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1766\n",
      "Epoch 974/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1766\n",
      "Epoch 975/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1766\n",
      "Epoch 976/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1766\n",
      "Epoch 977/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n",
      "Epoch 978/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1766\n",
      "Epoch 979/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1766\n",
      "Epoch 980/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1767\n",
      "Epoch 981/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1767\n",
      "Epoch 982/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1767\n",
      "Epoch 983/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1767\n",
      "Epoch 984/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1767\n",
      "Epoch 985/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1767\n",
      "Epoch 986/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1767\n",
      "Epoch 987/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1766\n",
      "Epoch 988/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1766\n",
      "Epoch 989/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1766\n",
      "Epoch 990/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1766\n",
      "Epoch 991/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1766\n",
      "Epoch 992/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1766\n",
      "Epoch 993/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1766\n",
      "Epoch 994/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1766\n",
      "Epoch 995/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1767\n",
      "Epoch 996/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1766\n",
      "Epoch 997/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1766\n",
      "Epoch 998/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1767\n",
      "Epoch 999/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1767\n",
      "Epoch 1000/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3a91fb70>"
      ]
     },
     "execution_count": 702,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_stl = Sequential()\n",
    "NN_stl.add(Dense(units=16,input_dim=19,activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_stl.add(Dense(units=8, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_stl.add(Dense(units=4, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_stl.add(Dense(units=1,activation='linear'))\n",
    "NN_stl.compile(loss='mse', optimizer='adam')\n",
    "NN_stl.fit(np.array(X_train), np.array(y_train), epochs=1000,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN_predictions</th>\n",
       "      <th>actual</th>\n",
       "      <th>GBR_predictions</th>\n",
       "      <th>LY_steals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.454891</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.134646</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.189457</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.280472</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.233885</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.499002</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.466510</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.371099</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.964955</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.849743</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.369724</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.155034</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.027242</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.418851</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.049432</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.141173</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.443533</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.163192</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.529337</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.340270</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.309157</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.290180</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.171268</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.954877</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.501210</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.914118</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.204268</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.132592</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.376970</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.287150</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.203707</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.024356</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.345627</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.990541</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.106258</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.160362</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.352056</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.237837</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.027250</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993929</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.103449</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.955497</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.224454</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.444496</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.984404</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.290636</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.914767</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966912</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.113880</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.76273</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.128003</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     NN_predictions  actual  GBR_predictions  LY_steals\n",
       "258         0.76273     1.5         1.454891        1.5\n",
       "290         0.76273     1.0         1.134646        1.5\n",
       "146         0.76273     1.6         1.189457        1.5\n",
       "606         0.76273     1.1         1.280472        1.5\n",
       "430         0.76273     1.7         1.233885        1.5\n",
       "135         0.76273     1.6         1.499002        1.5\n",
       "316         0.76273     1.6         1.466510        1.5\n",
       "30          0.76273     1.4         1.371099        1.5\n",
       "421         0.76273     1.0         0.964955        1.5\n",
       "588         0.76273     1.1         0.849743        1.5\n",
       "17          0.76273     1.1         1.369724        1.4\n",
       "190         0.76273     1.8         1.155034        1.4\n",
       "394         0.76273     0.8         1.027242        1.4\n",
       "282         0.76273     1.3         1.418851        1.4\n",
       "9           0.76273     1.0         1.049432        1.4\n",
       "254         0.76273     1.5         1.141173        1.4\n",
       "388         0.76273     1.3         1.443533        1.4\n",
       "326         0.76273     1.4         1.163192        1.4\n",
       "49          0.76273     1.3         1.529337        1.4\n",
       "328         0.76273     1.2         1.340270        1.4\n",
       "622         0.76273     1.1         1.309157        1.4\n",
       "11          0.76273     1.2         1.290180        1.3\n",
       "538         0.76273     1.0         1.171268        1.3\n",
       "417         0.76273     0.9         0.954877        1.3\n",
       "446         0.76273     1.1         1.501210        1.3\n",
       "154         0.76273     1.5         0.914118        1.3\n",
       "108         0.76273     0.6         1.204268        1.3\n",
       "350         0.76273     1.0         1.132592        1.3\n",
       "144         0.76273     1.5         1.376970        1.3\n",
       "72          0.76273     1.4         1.287150        1.3\n",
       "555         0.76273     1.2         1.203707        1.3\n",
       "136         0.76273     1.0         1.024356        1.3\n",
       "159         0.76273     1.3         1.345627        1.2\n",
       "182         0.76273     1.3         0.990541        1.2\n",
       "536         0.76273     1.2         1.106258        1.2\n",
       "522         0.76273     0.7         1.160362        1.2\n",
       "222         0.76273     1.7         1.352056        1.2\n",
       "527         0.76273     1.5         1.237837        1.2\n",
       "573         0.76273     1.0         1.027250        1.2\n",
       "481         0.76273     1.0         0.993929        1.2\n",
       "494         0.76273     0.9         1.103449        1.2\n",
       "532         0.76273     1.0         0.955497        1.2\n",
       "380         0.76273     1.2         1.224454        1.2\n",
       "652         0.76273     1.3         1.444496        1.2\n",
       "448         0.76273     1.2         0.984404        1.2\n",
       "89          0.76273     1.1         1.290636        1.2\n",
       "381         0.76273     0.9         0.914767        1.2\n",
       "83          0.76273     1.0         0.966912        1.2\n",
       "461         0.76273     1.5         1.113880        1.2\n",
       "398         0.76273     0.9         1.128003        1.2"
      ]
     },
     "execution_count": 703,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = NN_stl.predict(X_test)\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.5)\n",
    "gbr.fit(X_train,y_train)\n",
    "gbr_predictions = gbr.predict(X_test)\n",
    "LR = LinearRegression(fit_intercept=True).fit(X_train,y_train)\n",
    "\n",
    "testing = pd.DataFrame(predictions)\n",
    "testing.columns=['NN_predictions']\n",
    "testing['actual'] = y_test.reset_index()['steals']\n",
    "testing['GBR_predictions']=gbr_predictions\n",
    "testing['LY_steals']=X_test['steals_ly'].reset_index()['steals_ly']\n",
    "testing.sort_values(by='LY_steals',ascending=False)[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2017steals = steals[steals['season']==2017].drop(['team','player','steals','Games'],axis=1)\n",
    "steals_2017 = NN_stl.predict(pred_2017steals)\n",
    "gbr_stl_2017 = pd.DataFrame(gbr.predict(pred_2017steals))\n",
    "LR_stl_2017 = pd.DataFrame(LR.predict(pred_2017steals))\n",
    "test_2 =pd.DataFrame(steals_2017)\n",
    "test_3 = pd.merge(steals,pred_2017steals,left_index=True,right_index=True).reset_index()\n",
    "test_3['predictions']=test_2[0]\n",
    "test_3['gbr_pred'] = gbr_stl_2017[0]\n",
    "test_3['LR_pred'] = LR_stl_2017[0]\n",
    "test_3['mean_pred'] = (test_3['predictions']+test_3['gbr_pred']+test_3['LR_pred'])/3\n",
    "test_3 = test_3[test_3['Games']>30]\n",
    "test_3[['player','steals','predictions','LR_pred','gbr_pred','mean_pred','steals_ly_x']].sort_values(by='steals_ly_x',ascending=False)[0:50]\n",
    "\n",
    "steals_2017 = test_3[['player','LR_pred']]\n",
    "steals_2017.columns = ['player','steal_prediction']\n",
    "df_2017 = pd.merge(df_2017,steals_2017, how = 'left',left_on='player',right_on='player')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE using LR:0.05558796722155904\n",
      "MSE using GB:0.05758201819927772\n",
      "MSE using NN:0.06117266689151495\n",
      "MSE using combo:0.05569501924904028\n",
      "MSE using mean:0.17097129766600938\n",
      "MSE using last year stats:0.08067307692307688\n"
     ]
    }
   ],
   "source": [
    "print('MSE using LR:{}'.format(np.mean((test_3['steals']-test_3['LR_pred'])**2)))\n",
    "print('MSE using GB:{}'.format(np.mean((test_3['steals']-test_3['gbr_pred'])**2)))\n",
    "print('MSE using NN:{}'.format(np.mean((test_3['steals']-test_3['predictions'])**2)))\n",
    "print('MSE using combo:{}'.format(np.mean((test_3['steals']-test_3['mean_pred'])**2)))\n",
    "print('MSE using mean:{}'.format(np.mean((test_3['steals']-np.mean(test_3['steals']))**2)))\n",
    "print('MSE using last year stats:{}'.format(np.mean((test_3['steals']-test_3['steals_ly_x'])**2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01125328 0.04008531 0.10639288 0.04426043 0.02392808 0.00408012\n",
      " 0.0016119  0.0723225  0.04320477 0.05824298 0.0763244  0.08581513\n",
      " 0.04672878 0.07181035 0.06675481 0.04345141 0.15460267 0.01074619\n",
      " 0.03838401]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['season', 'age', 'steals_ly', 'change_steals_ly', 'C_PF', 'PG', 'SG_SF',\n",
       "       'starter_change', 'per_ly', 'change_per', 'stl_perc_ly',\n",
       "       'change_stl_perc', 'defensive_winshares', 'defensive_boxplusminus',\n",
       "       'boxplusminus', 'value_overreplacement', 'career_steals', 'yearspro',\n",
       "       'age_squared'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gbr.feature_importances_)\n",
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''next is blocks.  In the future, may want to add minutes from last season?'''\n",
    "\n",
    "\n",
    "query= '''\n",
    "        \n",
    "        DROP TABLE IF EXISTS blocks_pred;\n",
    "        CREATE TABLE blocks_pred(\n",
    "        season int, --these come from player_stats\n",
    "        player varchar(50),\n",
    "        Age int,\n",
    "        team varchar(50),\n",
    "        blk float, -- these come from player_stats\n",
    "        blk_ly float,\n",
    "        change_blk_ly float,\n",
    "        Games float,\n",
    "        C_PF int,\n",
    "        PG int,\n",
    "        SG_SF int,\n",
    "        starter_change int, \n",
    "        \n",
    "\n",
    "        -- from player_advstats\n",
    "        per_ly float,\n",
    "        change_per float,\n",
    "        blk_perc_ly float,\n",
    "        change_blk_perc_ly float,\n",
    "        defensive_winshares float,\n",
    "        defensive_boxplusminus float,\n",
    "        boxplusminus float,\n",
    "        value_overreplacement float,\n",
    "        \n",
    "        career_blk float,\n",
    "        yearspro int\n",
    "        );\n",
    "        \n",
    "        INSERT INTO blocks_pred(season,player,age,team,blk,blk_ly,change_blk_ly,starter_change,Games,C_PF,PG,SG_SF)\n",
    "        SELECT season,player,age,startingteam,blk,blk_ly,change_blk_ly,starter-starter_ly,Games,\n",
    "        case when pos in ('C','PF') then 1 else 0 end,case when pos='PG' then 1 else 0 end,case when pos in('SG','SF') then 1 else 0 end from player_stats;\n",
    "        \n",
    "        \n",
    "        update blocks_pred bp\n",
    "        set per_ly=pa.per_ly,change_per=pa.change_per,blk_perc_ly = pa.blk_perc_ly,change_blk_perc_ly = pa.change_blk_perc_ly\n",
    "        ,defensive_winshares=pa.defensive_winshares,defensive_boxplusminus=pa.defensive_boxplusminus\n",
    "        ,boxplusminus=pa.boxplusminus,value_overreplacement=pa.value_overreplacement\n",
    "        from player_advstats pa\n",
    "        where bp.player = pa.player and bp.season = pa.season and bp.team = pa.startingteam;\n",
    "        \n",
    "        update blocks_pred bp\n",
    "        set career_blk = pc.career_blk, yearspro = pc.yearspro\n",
    "        from player_careerstats pc\n",
    "        where bp.player = pc.player and bp.season = pc.season;\n",
    "        \n",
    "        \n",
    "        select * from blocks_pred where season>2009\n",
    "        '''\n",
    "\n",
    "\n",
    "cur.execute(query)\n",
    "data = cur.fetchall()\n",
    "blocks_df = pd.DataFrame(np.array(data))\n",
    "blocks_df.columns = ['season','player','age','team','blocks','blocks_ly','change_blocks_ly','Games','C_PF','PG','SG_SF','starter_change'\n",
    "                    ,'per_ly','change_per','blk_perc_ly','change_blk_perc','defensive_winshares','defensive_boxplusminus','boxplusminus','value_overreplacement','career_blocks','yearspro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "blocks_df['age_squared']=blocks_df['age']*blocks_df['age']\n",
    "blocks = blocks_df[blocks_df['blocks_ly'].notna()]\n",
    "for i in blocks.columns:\n",
    "    if i not in(['player','team']):\n",
    "        blocks[i]=pd.to_numeric(blocks[i])\n",
    "blocks = blocks.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = blocks[(blocks['season']!=2017) & (blocks['Games']>30)].drop(['player','team','blocks','Games'],axis=1)\n",
    "#X = blocks[(blocks['season']!=2017) & (blocks['Games']>30)][['blocks_ly','career_blocks','starter_change']]\n",
    "y = blocks[(blocks['season']!=2017) & (blocks['Games']>30)]['blocks']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1564/1564 [==============================] - 3s 2ms/step - loss: 23781.4684\n",
      "Epoch 2/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6679.2557\n",
      "Epoch 3/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1589.2965\n",
      "Epoch 4/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 632.9107\n",
      "Epoch 5/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 353.8284\n",
      "Epoch 6/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 223.7671\n",
      "Epoch 7/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 146.5323\n",
      "Epoch 8/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 96.6282\n",
      "Epoch 9/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 63.3425\n",
      "Epoch 10/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 40.9493\n",
      "Epoch 11/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 26.1784\n",
      "Epoch 12/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 16.4330\n",
      "Epoch 13/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 10.2363\n",
      "Epoch 14/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.3436\n",
      "Epoch 15/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 3.9315\n",
      "Epoch 16/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 2.5168\n",
      "Epoch 17/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.7102\n",
      "Epoch 18/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.2280\n",
      "Epoch 19/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.9602\n",
      "Epoch 20/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.8170\n",
      "Epoch 21/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.7337\n",
      "Epoch 22/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.6920\n",
      "Epoch 23/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.6608\n",
      "Epoch 24/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.6428\n",
      "Epoch 25/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.6248\n",
      "Epoch 26/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.6102\n",
      "Epoch 27/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5953\n",
      "Epoch 28/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5813\n",
      "Epoch 29/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5694\n",
      "Epoch 30/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.5574\n",
      "Epoch 31/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.5453\n",
      "Epoch 32/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5333\n",
      "Epoch 33/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5235\n",
      "Epoch 34/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5134\n",
      "Epoch 35/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5023\n",
      "Epoch 36/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.4932\n",
      "Epoch 37/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.4829\n",
      "Epoch 38/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.4732\n",
      "Epoch 39/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.4645\n",
      "Epoch 40/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.4559\n",
      "Epoch 41/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.4465\n",
      "Epoch 42/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4376\n",
      "Epoch 43/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4293\n",
      "Epoch 44/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4240\n",
      "Epoch 45/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4145\n",
      "Epoch 46/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4080\n",
      "Epoch 47/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.4019\n",
      "Epoch 48/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.3966\n",
      "Epoch 49/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.3915\n",
      "Epoch 50/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.3858\n",
      "Epoch 51/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.3798\n",
      "Epoch 52/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.3754\n",
      "Epoch 53/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.3714\n",
      "Epoch 54/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.3677\n",
      "Epoch 55/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.3632\n",
      "Epoch 56/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.3600\n",
      "Epoch 57/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.3562\n",
      "Epoch 58/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.3529\n",
      "Epoch 59/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.3495\n",
      "Epoch 60/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.3454\n",
      "Epoch 61/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.3410\n",
      "Epoch 62/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3377\n",
      "Epoch 63/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.3349\n",
      "Epoch 64/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.3318\n",
      "Epoch 65/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.3288\n",
      "Epoch 66/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.3269\n",
      "Epoch 67/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.3234\n",
      "Epoch 68/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.3204\n",
      "Epoch 69/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.3176\n",
      "Epoch 70/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.3149\n",
      "Epoch 71/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.3123\n",
      "Epoch 72/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.3099\n",
      "Epoch 73/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.3080\n",
      "Epoch 74/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.3059\n",
      "Epoch 75/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.3036\n",
      "Epoch 76/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.3019\n",
      "Epoch 77/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2998\n",
      "Epoch 78/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2975\n",
      "Epoch 79/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2957\n",
      "Epoch 80/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2941\n",
      "Epoch 81/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2922\n",
      "Epoch 82/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2907\n",
      "Epoch 83/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2886\n",
      "Epoch 84/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2871\n",
      "Epoch 85/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2854\n",
      "Epoch 86/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2839\n",
      "Epoch 87/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2820\n",
      "Epoch 88/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.2811\n",
      "Epoch 89/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2795\n",
      "Epoch 90/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2784\n",
      "Epoch 91/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2771\n",
      "Epoch 92/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2758\n",
      "Epoch 93/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2741\n",
      "Epoch 94/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2728\n",
      "Epoch 95/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2719\n",
      "Epoch 96/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2710\n",
      "Epoch 97/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2701\n",
      "Epoch 98/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2693\n",
      "Epoch 99/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2687\n",
      "Epoch 100/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2678\n",
      "Epoch 101/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2673\n",
      "Epoch 102/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2658\n",
      "Epoch 103/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2653\n",
      "Epoch 104/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2647\n",
      "Epoch 105/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2641\n",
      "Epoch 106/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2637\n",
      "Epoch 107/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2631\n",
      "Epoch 108/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2626\n",
      "Epoch 109/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2621\n",
      "Epoch 110/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2617\n",
      "Epoch 111/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2614\n",
      "Epoch 112/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2611\n",
      "Epoch 113/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2607\n",
      "Epoch 114/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2605\n",
      "Epoch 115/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2602\n",
      "Epoch 116/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2601\n",
      "Epoch 117/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2598\n",
      "Epoch 118/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2595\n",
      "Epoch 119/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2592\n",
      "Epoch 120/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2591\n",
      "Epoch 121/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2588\n",
      "Epoch 122/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2586\n",
      "Epoch 123/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2586\n",
      "Epoch 124/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2586\n",
      "Epoch 125/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2582\n",
      "Epoch 126/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2583\n",
      "Epoch 127/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2583\n",
      "Epoch 128/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2582\n",
      "Epoch 129/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2580\n",
      "Epoch 130/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2579\n",
      "Epoch 131/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2578\n",
      "Epoch 132/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2578\n",
      "Epoch 133/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2576\n",
      "Epoch 134/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2576\n",
      "Epoch 135/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2576\n",
      "Epoch 136/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2574\n",
      "Epoch 137/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2574\n",
      "Epoch 138/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2574\n",
      "Epoch 139/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2572\n",
      "Epoch 140/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2572\n",
      "Epoch 141/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2571\n",
      "Epoch 142/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2570\n",
      "Epoch 143/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2569\n",
      "Epoch 144/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2570\n",
      "Epoch 145/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2568\n",
      "Epoch 146/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2566\n",
      "Epoch 147/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2568\n",
      "Epoch 148/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2565\n",
      "Epoch 149/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2564\n",
      "Epoch 150/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2564\n",
      "Epoch 151/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2563\n",
      "Epoch 152/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2562\n",
      "Epoch 153/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2561\n",
      "Epoch 154/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2561\n",
      "Epoch 155/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2560\n",
      "Epoch 156/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2559\n",
      "Epoch 157/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2559\n",
      "Epoch 158/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2558\n",
      "Epoch 159/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2557\n",
      "Epoch 160/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2556\n",
      "Epoch 161/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2556\n",
      "Epoch 162/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2554\n",
      "Epoch 163/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2553\n",
      "Epoch 164/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2551\n",
      "Epoch 165/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.2550\n",
      "Epoch 166/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.2549\n",
      "Epoch 167/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.2549\n",
      "Epoch 168/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.2548\n",
      "Epoch 169/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2548\n",
      "Epoch 170/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2546\n",
      "Epoch 171/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2545\n",
      "Epoch 172/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2546\n",
      "Epoch 173/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2545\n",
      "Epoch 174/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2544\n",
      "Epoch 175/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2543\n",
      "Epoch 176/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2543\n",
      "Epoch 177/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2542\n",
      "Epoch 178/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2543\n",
      "Epoch 179/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2541\n",
      "Epoch 180/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2541\n",
      "Epoch 181/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2539\n",
      "Epoch 182/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2538\n",
      "Epoch 183/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2538\n",
      "Epoch 184/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2537\n",
      "Epoch 185/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2536\n",
      "Epoch 186/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2536\n",
      "Epoch 187/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2535\n",
      "Epoch 188/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2534\n",
      "Epoch 189/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2536\n",
      "Epoch 190/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2534\n",
      "Epoch 191/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2534\n",
      "Epoch 192/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2532\n",
      "Epoch 193/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2532\n",
      "Epoch 194/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2531\n",
      "Epoch 195/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2532\n",
      "Epoch 196/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2528\n",
      "Epoch 197/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2528\n",
      "Epoch 198/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2529\n",
      "Epoch 199/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2528\n",
      "Epoch 200/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2527\n",
      "Epoch 201/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2526\n",
      "Epoch 202/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2525\n",
      "Epoch 203/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2524\n",
      "Epoch 204/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2524\n",
      "Epoch 205/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2523\n",
      "Epoch 206/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2523\n",
      "Epoch 207/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2523\n",
      "Epoch 208/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2521\n",
      "Epoch 209/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2521\n",
      "Epoch 210/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2521\n",
      "Epoch 211/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2521\n",
      "Epoch 212/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2521\n",
      "Epoch 213/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2520\n",
      "Epoch 214/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2518\n",
      "Epoch 215/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2517\n",
      "Epoch 216/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2521\n",
      "Epoch 217/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2517\n",
      "Epoch 218/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2517\n",
      "Epoch 219/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2516\n",
      "Epoch 220/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2515\n",
      "Epoch 221/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2514\n",
      "Epoch 222/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2514\n",
      "Epoch 223/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2515\n",
      "Epoch 224/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2512\n",
      "Epoch 225/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2512\n",
      "Epoch 226/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2514\n",
      "Epoch 227/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2513\n",
      "Epoch 228/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2511\n",
      "Epoch 229/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2511\n",
      "Epoch 230/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2511\n",
      "Epoch 231/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2509\n",
      "Epoch 232/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2510\n",
      "Epoch 233/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2509\n",
      "Epoch 234/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2508\n",
      "Epoch 235/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2507\n",
      "Epoch 236/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2508\n",
      "Epoch 237/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2506\n",
      "Epoch 238/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2507\n",
      "Epoch 239/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2506\n",
      "Epoch 240/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2505\n",
      "Epoch 241/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2504\n",
      "Epoch 242/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2504\n",
      "Epoch 243/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2503\n",
      "Epoch 244/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2505\n",
      "Epoch 245/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2503\n",
      "Epoch 246/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2503\n",
      "Epoch 247/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2502\n",
      "Epoch 248/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2502\n",
      "Epoch 249/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2502\n",
      "Epoch 250/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2501\n",
      "Epoch 251/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2501\n",
      "Epoch 252/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2502\n",
      "Epoch 253/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2502\n",
      "Epoch 254/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2500\n",
      "Epoch 255/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.2498\n",
      "Epoch 256/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2503\n",
      "Epoch 257/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.2498\n",
      "Epoch 258/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2498\n",
      "Epoch 259/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2497\n",
      "Epoch 260/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2498\n",
      "Epoch 261/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2498\n",
      "Epoch 262/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2497\n",
      "Epoch 263/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2497\n",
      "Epoch 264/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2497\n",
      "Epoch 265/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2495\n",
      "Epoch 266/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2496\n",
      "Epoch 267/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2495\n",
      "Epoch 268/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2494\n",
      "Epoch 269/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2494\n",
      "Epoch 270/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2494\n",
      "Epoch 271/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2493\n",
      "Epoch 272/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2492\n",
      "Epoch 273/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2493\n",
      "Epoch 274/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2492\n",
      "Epoch 275/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2491\n",
      "Epoch 276/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2491\n",
      "Epoch 277/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2491\n",
      "Epoch 278/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2492\n",
      "Epoch 279/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2491\n",
      "Epoch 280/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2493\n",
      "Epoch 281/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2490\n",
      "Epoch 282/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2489\n",
      "Epoch 283/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2491\n",
      "Epoch 284/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2488\n",
      "Epoch 285/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2490\n",
      "Epoch 286/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2490\n",
      "Epoch 287/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2489\n",
      "Epoch 288/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2493\n",
      "Epoch 289/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2486\n",
      "Epoch 290/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2488\n",
      "Epoch 291/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2488\n",
      "Epoch 292/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2488\n",
      "Epoch 293/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.2486\n",
      "Epoch 294/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2488\n",
      "Epoch 295/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2488\n",
      "Epoch 296/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2487\n",
      "Epoch 297/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2486\n",
      "Epoch 298/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2485\n",
      "Epoch 299/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2486\n",
      "Epoch 300/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2485\n",
      "Epoch 301/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2487\n",
      "Epoch 302/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2486\n",
      "Epoch 303/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2484\n",
      "Epoch 304/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2485\n",
      "Epoch 305/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2484\n",
      "Epoch 306/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2486\n",
      "Epoch 307/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2494\n",
      "Epoch 308/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2484\n",
      "Epoch 309/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2486\n",
      "Epoch 310/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2484\n",
      "Epoch 311/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2485\n",
      "Epoch 312/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2483\n",
      "Epoch 313/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2486\n",
      "Epoch 314/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2489\n",
      "Epoch 315/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2487\n",
      "Epoch 316/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2488\n",
      "Epoch 317/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2487\n",
      "Epoch 318/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2490\n",
      "Epoch 319/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2482\n",
      "Epoch 320/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2484\n",
      "Epoch 321/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2481\n",
      "Epoch 322/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2480\n",
      "Epoch 323/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2486\n",
      "Epoch 324/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2479\n",
      "Epoch 325/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2480\n",
      "Epoch 326/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2483\n",
      "Epoch 327/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2480\n",
      "Epoch 328/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2480\n",
      "Epoch 329/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2483\n",
      "Epoch 330/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2482\n",
      "Epoch 331/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2481\n",
      "Epoch 332/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2480\n",
      "Epoch 333/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2481\n",
      "Epoch 334/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2481\n",
      "Epoch 335/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2479\n",
      "Epoch 336/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2483\n",
      "Epoch 337/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2492\n",
      "Epoch 338/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2488\n",
      "Epoch 339/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2478\n",
      "Epoch 340/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2480\n",
      "Epoch 341/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2477\n",
      "Epoch 342/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2481\n",
      "Epoch 343/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2479\n",
      "Epoch 344/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2480\n",
      "Epoch 345/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2484\n",
      "Epoch 346/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2481\n",
      "Epoch 347/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2478\n",
      "Epoch 348/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2478\n",
      "Epoch 349/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2482\n",
      "Epoch 350/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2477\n",
      "Epoch 351/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2478\n",
      "Epoch 352/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2481\n",
      "Epoch 353/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2480\n",
      "Epoch 354/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2474\n",
      "Epoch 355/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2478\n",
      "Epoch 356/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2477\n",
      "Epoch 357/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2480\n",
      "Epoch 358/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2478\n",
      "Epoch 359/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2481\n",
      "Epoch 360/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2488\n",
      "Epoch 361/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2480\n",
      "Epoch 362/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2480\n",
      "Epoch 363/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2477\n",
      "Epoch 364/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2486\n",
      "Epoch 365/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2473\n",
      "Epoch 366/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2479\n",
      "Epoch 367/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2482\n",
      "Epoch 368/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2475\n",
      "Epoch 369/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2475\n",
      "Epoch 370/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2478\n",
      "Epoch 371/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2474\n",
      "Epoch 372/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2475\n",
      "Epoch 373/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2475\n",
      "Epoch 374/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2476\n",
      "Epoch 375/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2481\n",
      "Epoch 376/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2480\n",
      "Epoch 377/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2480\n",
      "Epoch 378/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2477\n",
      "Epoch 379/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2481\n",
      "Epoch 380/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2475\n",
      "Epoch 381/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2475\n",
      "Epoch 382/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2474\n",
      "Epoch 383/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2479\n",
      "Epoch 384/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.2483\n",
      "Epoch 385/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2484\n",
      "Epoch 386/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2477\n",
      "Epoch 387/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.2470\n",
      "Epoch 388/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2482\n",
      "Epoch 389/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2480\n",
      "Epoch 390/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2480\n",
      "Epoch 391/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2483\n",
      "Epoch 392/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2474\n",
      "Epoch 393/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2474\n",
      "Epoch 394/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2485\n",
      "Epoch 395/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2471\n",
      "Epoch 396/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2476\n",
      "Epoch 397/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2474\n",
      "Epoch 398/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2482\n",
      "Epoch 399/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2475\n",
      "Epoch 400/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2475\n",
      "Epoch 401/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2475\n",
      "Epoch 402/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2478\n",
      "Epoch 403/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2485\n",
      "Epoch 404/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2475\n",
      "Epoch 405/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2473\n",
      "Epoch 406/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2473\n",
      "Epoch 407/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2493\n",
      "Epoch 408/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2512\n",
      "Epoch 409/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2471\n",
      "Epoch 410/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2475\n",
      "Epoch 411/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2476\n",
      "Epoch 412/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2479\n",
      "Epoch 413/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2473\n",
      "Epoch 414/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2476\n",
      "Epoch 415/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2474\n",
      "Epoch 416/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2472\n",
      "Epoch 417/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2474\n",
      "Epoch 418/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2479\n",
      "Epoch 419/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2475\n",
      "Epoch 420/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2473\n",
      "Epoch 421/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2468\n",
      "Epoch 422/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2478\n",
      "Epoch 423/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2478\n",
      "Epoch 424/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2471\n",
      "Epoch 425/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2475\n",
      "Epoch 426/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2472\n",
      "Epoch 427/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2475\n",
      "Epoch 428/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2471\n",
      "Epoch 429/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2471\n",
      "Epoch 430/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2473\n",
      "Epoch 431/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2478\n",
      "Epoch 432/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2470\n",
      "Epoch 433/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2471\n",
      "Epoch 434/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2470\n",
      "Epoch 435/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2470\n",
      "Epoch 436/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2469\n",
      "Epoch 437/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2472\n",
      "Epoch 438/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2472\n",
      "Epoch 439/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2474\n",
      "Epoch 440/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2467\n",
      "Epoch 441/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2468\n",
      "Epoch 442/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2469\n",
      "Epoch 443/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2467\n",
      "Epoch 444/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2468\n",
      "Epoch 445/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2467\n",
      "Epoch 446/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2469\n",
      "Epoch 447/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2476\n",
      "Epoch 448/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2476\n",
      "Epoch 449/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2484\n",
      "Epoch 450/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2472\n",
      "Epoch 451/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2466\n",
      "Epoch 452/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2469\n",
      "Epoch 453/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2470\n",
      "Epoch 454/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2484\n",
      "Epoch 455/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2496\n",
      "Epoch 456/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2478\n",
      "Epoch 457/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2490\n",
      "Epoch 458/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2480\n",
      "Epoch 459/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2468\n",
      "Epoch 460/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2470\n",
      "Epoch 461/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2466\n",
      "Epoch 462/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2481\n",
      "Epoch 463/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2473\n",
      "Epoch 464/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2467\n",
      "Epoch 465/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2469\n",
      "Epoch 466/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2471\n",
      "Epoch 467/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2468\n",
      "Epoch 468/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2463\n",
      "Epoch 469/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2464\n",
      "Epoch 470/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2463\n",
      "Epoch 471/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2470\n",
      "Epoch 472/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2465\n",
      "Epoch 473/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2467\n",
      "Epoch 474/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2464\n",
      "Epoch 475/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2472\n",
      "Epoch 476/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2475\n",
      "Epoch 477/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2464\n",
      "Epoch 478/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2463\n",
      "Epoch 479/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2464\n",
      "Epoch 480/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2467\n",
      "Epoch 481/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2466\n",
      "Epoch 482/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2481\n",
      "Epoch 483/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2468\n",
      "Epoch 484/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2469\n",
      "Epoch 485/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2468\n",
      "Epoch 486/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2486\n",
      "Epoch 487/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2471\n",
      "Epoch 488/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2468\n",
      "Epoch 489/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2468\n",
      "Epoch 490/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2461\n",
      "Epoch 491/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2478\n",
      "Epoch 492/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2466\n",
      "Epoch 493/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2466\n",
      "Epoch 494/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2472\n",
      "Epoch 495/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2465\n",
      "Epoch 496/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2460\n",
      "Epoch 497/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2459\n",
      "Epoch 498/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2467\n",
      "Epoch 499/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2477\n",
      "Epoch 500/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2466\n",
      "Epoch 501/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2476\n",
      "Epoch 502/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2463\n",
      "Epoch 503/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2479\n",
      "Epoch 504/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2480\n",
      "Epoch 505/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2465\n",
      "Epoch 506/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2475\n",
      "Epoch 507/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2463\n",
      "Epoch 508/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2478\n",
      "Epoch 509/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2468\n",
      "Epoch 510/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2473\n",
      "Epoch 511/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2496\n",
      "Epoch 512/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2459\n",
      "Epoch 513/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2464\n",
      "Epoch 514/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2459\n",
      "Epoch 515/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2458\n",
      "Epoch 516/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2467\n",
      "Epoch 517/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2466\n",
      "Epoch 518/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2461\n",
      "Epoch 519/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2459\n",
      "Epoch 520/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2471\n",
      "Epoch 521/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2472\n",
      "Epoch 522/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2459\n",
      "Epoch 523/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2457\n",
      "Epoch 524/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2456\n",
      "Epoch 525/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2462\n",
      "Epoch 526/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2459\n",
      "Epoch 527/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2478\n",
      "Epoch 528/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2460\n",
      "Epoch 529/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2462\n",
      "Epoch 530/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2458\n",
      "Epoch 531/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2468\n",
      "Epoch 532/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2474\n",
      "Epoch 533/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2459\n",
      "Epoch 534/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2469\n",
      "Epoch 535/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2459\n",
      "Epoch 536/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2457\n",
      "Epoch 537/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2459\n",
      "Epoch 538/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2454\n",
      "Epoch 539/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2456\n",
      "Epoch 540/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2460\n",
      "Epoch 541/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2465\n",
      "Epoch 542/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.2487\n",
      "Epoch 543/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2455\n",
      "Epoch 544/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2459\n",
      "Epoch 545/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2470\n",
      "Epoch 546/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2451\n",
      "Epoch 547/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2461\n",
      "Epoch 548/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2460\n",
      "Epoch 549/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2512\n",
      "Epoch 550/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2459\n",
      "Epoch 551/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2449\n",
      "Epoch 552/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2452\n",
      "Epoch 553/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2513\n",
      "Epoch 554/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2473\n",
      "Epoch 555/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2449\n",
      "Epoch 556/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2458\n",
      "Epoch 557/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2457\n",
      "Epoch 558/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2449\n",
      "Epoch 559/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2457\n",
      "Epoch 560/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2464\n",
      "Epoch 561/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2467\n",
      "Epoch 562/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2447\n",
      "Epoch 563/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2452\n",
      "Epoch 564/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2449\n",
      "Epoch 565/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2458\n",
      "Epoch 566/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2463\n",
      "Epoch 567/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2446\n",
      "Epoch 568/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2448\n",
      "Epoch 569/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2449\n",
      "Epoch 570/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2450\n",
      "Epoch 571/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2451\n",
      "Epoch 572/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2455\n",
      "Epoch 573/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2447\n",
      "Epoch 574/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2447\n",
      "Epoch 575/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2447\n",
      "Epoch 576/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2456\n",
      "Epoch 577/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2477\n",
      "Epoch 578/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2500\n",
      "Epoch 579/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2485\n",
      "Epoch 580/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2518\n",
      "Epoch 581/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2459\n",
      "Epoch 582/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2471\n",
      "Epoch 583/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2457\n",
      "Epoch 584/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2443\n",
      "Epoch 585/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2453\n",
      "Epoch 586/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2451\n",
      "Epoch 587/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2454\n",
      "Epoch 588/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2457\n",
      "Epoch 589/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2473\n",
      "Epoch 590/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2463\n",
      "Epoch 591/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2448\n",
      "Epoch 592/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2465\n",
      "Epoch 593/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2490\n",
      "Epoch 594/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2448\n",
      "Epoch 595/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2444\n",
      "Epoch 596/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2446\n",
      "Epoch 597/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2461\n",
      "Epoch 598/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2466\n",
      "Epoch 599/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2449\n",
      "Epoch 600/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2444\n",
      "Epoch 601/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2444\n",
      "Epoch 602/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2453\n",
      "Epoch 603/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2443\n",
      "Epoch 604/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2452\n",
      "Epoch 605/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2451\n",
      "Epoch 606/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2456\n",
      "Epoch 607/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2484\n",
      "Epoch 608/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2438\n",
      "Epoch 609/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2447\n",
      "Epoch 610/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2455\n",
      "Epoch 611/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2449\n",
      "Epoch 612/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2437\n",
      "Epoch 613/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.2483\n",
      "Epoch 614/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2468\n",
      "Epoch 615/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2465\n",
      "Epoch 616/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2464\n",
      "Epoch 617/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2474\n",
      "Epoch 618/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2449\n",
      "Epoch 619/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2449\n",
      "Epoch 620/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2439\n",
      "Epoch 621/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2469\n",
      "Epoch 622/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2438\n",
      "Epoch 623/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2451\n",
      "Epoch 624/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2455\n",
      "Epoch 625/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2444\n",
      "Epoch 626/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2445\n",
      "Epoch 627/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2437\n",
      "Epoch 628/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2442\n",
      "Epoch 629/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2451\n",
      "Epoch 630/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2471\n",
      "Epoch 631/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2540\n",
      "Epoch 632/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.2478\n",
      "Epoch 633/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2463\n",
      "Epoch 634/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2453\n",
      "Epoch 635/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2461\n",
      "Epoch 636/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2443\n",
      "Epoch 637/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2461\n",
      "Epoch 638/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2449\n",
      "Epoch 639/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2437\n",
      "Epoch 640/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2436\n",
      "Epoch 641/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2464\n",
      "Epoch 642/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2439\n",
      "Epoch 643/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2469\n",
      "Epoch 644/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2588\n",
      "Epoch 645/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2536\n",
      "Epoch 646/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2474\n",
      "Epoch 647/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2458\n",
      "Epoch 648/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2470\n",
      "Epoch 649/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2427\n",
      "Epoch 650/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2432\n",
      "Epoch 651/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2451\n",
      "Epoch 652/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.2447\n",
      "Epoch 653/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2473\n",
      "Epoch 654/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2503\n",
      "Epoch 655/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2474\n",
      "Epoch 656/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2463\n",
      "Epoch 657/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2525\n",
      "Epoch 658/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2456\n",
      "Epoch 659/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2451\n",
      "Epoch 660/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2435\n",
      "Epoch 661/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2491\n",
      "Epoch 662/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2440\n",
      "Epoch 663/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2428\n",
      "Epoch 664/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2422\n",
      "Epoch 665/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2433\n",
      "Epoch 666/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2441\n",
      "Epoch 667/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2470\n",
      "Epoch 668/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2436\n",
      "Epoch 669/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2434\n",
      "Epoch 670/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2422\n",
      "Epoch 671/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2432\n",
      "Epoch 672/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2421\n",
      "Epoch 673/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2418\n",
      "Epoch 674/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2463\n",
      "Epoch 675/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2450\n",
      "Epoch 676/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2447\n",
      "Epoch 677/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2446\n",
      "Epoch 678/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2510\n",
      "Epoch 679/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2497\n",
      "Epoch 680/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2465\n",
      "Epoch 681/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2570\n",
      "Epoch 682/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2423\n",
      "Epoch 683/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2439\n",
      "Epoch 684/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2424\n",
      "Epoch 685/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2426\n",
      "Epoch 686/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2437\n",
      "Epoch 687/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2464\n",
      "Epoch 688/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2448\n",
      "Epoch 689/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2496\n",
      "Epoch 690/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2460\n",
      "Epoch 691/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2427\n",
      "Epoch 692/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2415\n",
      "Epoch 693/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2491\n",
      "Epoch 694/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2452\n",
      "Epoch 695/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2464\n",
      "Epoch 696/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2411\n",
      "Epoch 697/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2453\n",
      "Epoch 698/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2454\n",
      "Epoch 699/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2416\n",
      "Epoch 700/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2419\n",
      "Epoch 701/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2418\n",
      "Epoch 702/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2414\n",
      "Epoch 703/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2430\n",
      "Epoch 704/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2434\n",
      "Epoch 705/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2518\n",
      "Epoch 706/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2452\n",
      "Epoch 707/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2438\n",
      "Epoch 708/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2428\n",
      "Epoch 709/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2412\n",
      "Epoch 710/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2417\n",
      "Epoch 711/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.2432\n",
      "Epoch 712/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2405\n",
      "Epoch 713/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2414\n",
      "Epoch 714/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2426\n",
      "Epoch 715/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2424\n",
      "Epoch 716/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2416\n",
      "Epoch 717/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2421\n",
      "Epoch 718/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2404\n",
      "Epoch 719/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2419\n",
      "Epoch 720/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2409\n",
      "Epoch 721/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2457\n",
      "Epoch 722/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2464\n",
      "Epoch 723/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2484\n",
      "Epoch 724/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2497\n",
      "Epoch 725/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2452\n",
      "Epoch 726/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2481\n",
      "Epoch 727/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2479\n",
      "Epoch 728/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2570\n",
      "Epoch 729/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2498\n",
      "Epoch 730/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2421\n",
      "Epoch 731/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2431\n",
      "Epoch 732/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2447\n",
      "Epoch 733/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2427\n",
      "Epoch 734/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2440\n",
      "Epoch 735/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2409\n",
      "Epoch 736/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.2402\n",
      "Epoch 737/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2406\n",
      "Epoch 738/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2399\n",
      "Epoch 739/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.2409\n",
      "Epoch 740/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.2436\n",
      "Epoch 741/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2461\n",
      "Epoch 742/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2537\n",
      "Epoch 743/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2617\n",
      "Epoch 744/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2438\n",
      "Epoch 745/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2410\n",
      "Epoch 746/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2401\n",
      "Epoch 747/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2473\n",
      "Epoch 748/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2439\n",
      "Epoch 749/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2399\n",
      "Epoch 750/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2499\n",
      "Epoch 751/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2480\n",
      "Epoch 752/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2405\n",
      "Epoch 753/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2434\n",
      "Epoch 754/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2396\n",
      "Epoch 755/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2435\n",
      "Epoch 756/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2468\n",
      "Epoch 757/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2409\n",
      "Epoch 758/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2400\n",
      "Epoch 759/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2393\n",
      "Epoch 760/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2431\n",
      "Epoch 761/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2575\n",
      "Epoch 762/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2625\n",
      "Epoch 763/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2415\n",
      "Epoch 764/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2396\n",
      "Epoch 765/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2402\n",
      "Epoch 766/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2462\n",
      "Epoch 767/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2438\n",
      "Epoch 768/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2458\n",
      "Epoch 769/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2391\n",
      "Epoch 770/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2406\n",
      "Epoch 771/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2411\n",
      "Epoch 772/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2404\n",
      "Epoch 773/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2450\n",
      "Epoch 774/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2510\n",
      "Epoch 775/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2505\n",
      "Epoch 776/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2409\n",
      "Epoch 777/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2459\n",
      "Epoch 778/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2393\n",
      "Epoch 779/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2412\n",
      "Epoch 780/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.2420\n",
      "Epoch 781/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2390\n",
      "Epoch 782/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2416\n",
      "Epoch 783/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2427\n",
      "Epoch 784/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2464\n",
      "Epoch 785/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2398\n",
      "Epoch 786/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2502\n",
      "Epoch 787/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2628\n",
      "Epoch 788/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2473\n",
      "Epoch 789/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2390\n",
      "Epoch 790/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2455\n",
      "Epoch 791/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.2396\n",
      "Epoch 792/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2459\n",
      "Epoch 793/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2489\n",
      "Epoch 794/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2620\n",
      "Epoch 795/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2471\n",
      "Epoch 796/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2572\n",
      "Epoch 797/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2497\n",
      "Epoch 798/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2435\n",
      "Epoch 799/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2430\n",
      "Epoch 800/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.2387\n",
      "Epoch 801/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2482\n",
      "Epoch 802/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2675\n",
      "Epoch 803/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2464\n",
      "Epoch 804/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2398\n",
      "Epoch 805/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2426\n",
      "Epoch 806/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2519\n",
      "Epoch 807/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2394\n",
      "Epoch 808/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2433\n",
      "Epoch 809/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2458\n",
      "Epoch 810/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2446\n",
      "Epoch 811/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2490\n",
      "Epoch 812/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2370\n",
      "Epoch 813/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2438\n",
      "Epoch 814/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2403\n",
      "Epoch 815/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2390\n",
      "Epoch 816/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2432\n",
      "Epoch 817/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2400\n",
      "Epoch 818/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2444\n",
      "Epoch 819/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2508\n",
      "Epoch 820/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2432\n",
      "Epoch 821/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2390\n",
      "Epoch 822/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2385\n",
      "Epoch 823/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2397\n",
      "Epoch 824/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2463\n",
      "Epoch 825/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2528\n",
      "Epoch 826/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2457\n",
      "Epoch 827/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2380\n",
      "Epoch 828/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2385\n",
      "Epoch 829/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2375\n",
      "Epoch 830/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2383\n",
      "Epoch 831/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2525\n",
      "Epoch 832/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2539\n",
      "Epoch 833/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2406\n",
      "Epoch 834/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2414\n",
      "Epoch 835/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2378\n",
      "Epoch 836/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2398\n",
      "Epoch 837/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2431\n",
      "Epoch 838/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2399\n",
      "Epoch 839/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2454\n",
      "Epoch 840/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2379\n",
      "Epoch 841/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2412\n",
      "Epoch 842/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2370\n",
      "Epoch 843/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2445\n",
      "Epoch 844/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2478\n",
      "Epoch 845/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2372\n",
      "Epoch 846/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2450\n",
      "Epoch 847/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2428\n",
      "Epoch 848/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2424\n",
      "Epoch 849/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2502\n",
      "Epoch 850/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2393\n",
      "Epoch 851/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2450\n",
      "Epoch 852/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2483\n",
      "Epoch 853/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2422\n",
      "Epoch 854/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2544\n",
      "Epoch 855/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2667\n",
      "Epoch 856/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2467\n",
      "Epoch 857/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2399\n",
      "Epoch 858/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2481\n",
      "Epoch 859/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.2500\n",
      "Epoch 860/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.2389\n",
      "Epoch 861/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2389\n",
      "Epoch 862/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2370\n",
      "Epoch 863/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2496\n",
      "Epoch 864/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2573\n",
      "Epoch 865/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2542\n",
      "Epoch 866/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2704\n",
      "Epoch 867/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2988\n",
      "Epoch 868/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2577\n",
      "Epoch 869/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2444\n",
      "Epoch 870/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2400\n",
      "Epoch 871/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2406\n",
      "Epoch 872/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2601\n",
      "Epoch 873/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.2478\n",
      "Epoch 874/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.2409\n",
      "Epoch 875/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2380\n",
      "Epoch 876/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2507\n",
      "Epoch 877/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2552\n",
      "Epoch 878/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.2392\n",
      "Epoch 879/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2443\n",
      "Epoch 880/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2495\n",
      "Epoch 881/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2470\n",
      "Epoch 882/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2375\n",
      "Epoch 883/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2368\n",
      "Epoch 884/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2534\n",
      "Epoch 885/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2367\n",
      "Epoch 886/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2472\n",
      "Epoch 887/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2459\n",
      "Epoch 888/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2403\n",
      "Epoch 889/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2388\n",
      "Epoch 890/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2450\n",
      "Epoch 891/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.2534\n",
      "Epoch 892/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2377\n",
      "Epoch 893/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2399\n",
      "Epoch 894/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2425\n",
      "Epoch 895/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2623\n",
      "Epoch 896/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2449\n",
      "Epoch 897/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2361\n",
      "Epoch 898/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2363\n",
      "Epoch 899/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2405\n",
      "Epoch 900/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2511\n",
      "Epoch 901/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2387\n",
      "Epoch 902/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2381\n",
      "Epoch 903/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2475\n",
      "Epoch 904/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2454\n",
      "Epoch 905/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2795\n",
      "Epoch 906/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2420\n",
      "Epoch 907/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2361\n",
      "Epoch 908/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2421\n",
      "Epoch 909/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2408\n",
      "Epoch 910/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2386\n",
      "Epoch 911/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2579\n",
      "Epoch 912/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2542\n",
      "Epoch 913/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2434\n",
      "Epoch 914/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2366\n",
      "Epoch 915/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2434\n",
      "Epoch 916/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2403\n",
      "Epoch 917/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2384\n",
      "Epoch 918/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2515\n",
      "Epoch 919/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2722\n",
      "Epoch 920/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2573\n",
      "Epoch 921/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2378\n",
      "Epoch 922/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2562\n",
      "Epoch 923/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2422\n",
      "Epoch 924/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2376\n",
      "Epoch 925/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2405\n",
      "Epoch 926/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2922\n",
      "Epoch 927/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2563\n",
      "Epoch 928/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2448\n",
      "Epoch 929/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2364\n",
      "Epoch 930/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2361\n",
      "Epoch 931/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2355\n",
      "Epoch 932/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2389\n",
      "Epoch 933/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2376\n",
      "Epoch 934/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2401\n",
      "Epoch 935/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2373\n",
      "Epoch 936/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2490\n",
      "Epoch 937/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2586\n",
      "Epoch 938/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2543\n",
      "Epoch 939/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2516\n",
      "Epoch 940/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2628\n",
      "Epoch 941/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2367\n",
      "Epoch 942/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2481\n",
      "Epoch 943/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2419\n",
      "Epoch 944/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2364\n",
      "Epoch 945/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2361\n",
      "Epoch 946/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2391\n",
      "Epoch 947/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.2346\n",
      "Epoch 948/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2384\n",
      "Epoch 949/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2363\n",
      "Epoch 950/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2409\n",
      "Epoch 951/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2382\n",
      "Epoch 952/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2369\n",
      "Epoch 953/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2341\n",
      "Epoch 954/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2442\n",
      "Epoch 955/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2750\n",
      "Epoch 956/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2484\n",
      "Epoch 957/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2422\n",
      "Epoch 958/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2518\n",
      "Epoch 959/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2629\n",
      "Epoch 960/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2422\n",
      "Epoch 961/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2367\n",
      "Epoch 962/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2367\n",
      "Epoch 963/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2353\n",
      "Epoch 964/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2451\n",
      "Epoch 965/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2380\n",
      "Epoch 966/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.2421\n",
      "Epoch 967/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2418\n",
      "Epoch 968/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2451\n",
      "Epoch 969/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2375\n",
      "Epoch 970/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2473\n",
      "Epoch 971/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2374\n",
      "Epoch 972/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2354\n",
      "Epoch 973/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2445\n",
      "Epoch 974/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2431\n",
      "Epoch 975/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2401\n",
      "Epoch 976/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2450\n",
      "Epoch 977/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2360\n",
      "Epoch 978/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2393\n",
      "Epoch 979/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2394\n",
      "Epoch 980/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2413\n",
      "Epoch 981/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2415\n",
      "Epoch 982/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2369\n",
      "Epoch 983/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2361\n",
      "Epoch 984/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2409\n",
      "Epoch 985/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2448\n",
      "Epoch 986/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2431\n",
      "Epoch 987/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2375\n",
      "Epoch 988/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2373\n",
      "Epoch 989/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2389\n",
      "Epoch 990/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2491\n",
      "Epoch 991/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2486\n",
      "Epoch 992/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2456\n",
      "Epoch 993/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2428\n",
      "Epoch 994/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2370\n",
      "Epoch 995/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2387\n",
      "Epoch 996/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2406\n",
      "Epoch 997/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2423\n",
      "Epoch 998/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2435\n",
      "Epoch 999/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2436\n",
      "Epoch 1000/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2f893b00>"
      ]
     },
     "execution_count": 710,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_blk = Sequential()\n",
    "NN_blk.add(Dense(units=16,input_dim=X_train.shape[1],activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_blk.add(Dense(units=8, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_blk.add(Dense(units=8, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_blk.add(Dense(units=1,activation='linear'))\n",
    "NN_blk.compile(loss='mse', optimizer='adam')\n",
    "NN_blk.fit(np.array(X_train), np.array(y_train), epochs=1000,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN_predictions</th>\n",
       "      <th>actual</th>\n",
       "      <th>GBR_predictions</th>\n",
       "      <th>LY_blocks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.498077</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.080924</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>0.488021</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.379919</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>0.487632</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.243117</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.482654</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.015516</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.482013</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.115108</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>0.415103</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.930058</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.492431</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.045229</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.470005</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.215837</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0.470863</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.951137</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0.511547</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.246497</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.507053</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.034210</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>0.452652</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.899481</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>0.481323</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.960183</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>0.514072</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.158763</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.493026</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.955698</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>0.472213</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.957459</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>0.476745</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.094676</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>0.476760</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.963206</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>0.506725</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.055830</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.458225</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.759816</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>0.482288</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.839468</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>0.471485</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.124230</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>0.477424</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.647918</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.488319</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.904392</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>0.512027</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.941941</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>0.438354</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.063659</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>0.507179</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.006739</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>0.459251</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.283389</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.507556</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.728435</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.511768</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.154819</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.492561</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.836537</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>0.497249</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.656171</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>0.477558</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.836462</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.482708</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.048137</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>0.483390</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.674752</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>0.488273</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.808230</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.493404</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.928504</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>0.497898</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.911661</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0.502204</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.999186</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.516742</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.909985</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.487186</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.976580</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.504905</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.356281</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>0.477493</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.796490</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>0.511768</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.922040</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>0.502311</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.050214</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>0.498977</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.855962</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>0.492935</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.682650</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>0.503059</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.828942</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>0.404983</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.598218</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0.496547</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.498542</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     NN_predictions  actual  GBR_predictions  LY_blocks\n",
       "150        0.498077     0.7         1.080924        1.3\n",
       "516        0.488021     1.5         1.379919        1.3\n",
       "168        0.487632     1.2         1.243117        1.2\n",
       "165        0.482654     1.6         1.015516        1.2\n",
       "32         0.482013     1.2         1.115108        1.2\n",
       "404        0.415103     1.1         0.930058        1.2\n",
       "185        0.492431     0.9         1.045229        1.2\n",
       "79         0.470005     1.1         1.215837        1.2\n",
       "286        0.470863     1.1         0.951137        1.2\n",
       "202        0.511547     1.2         1.246497        1.2\n",
       "24         0.507053     1.5         1.034210        1.2\n",
       "547        0.452652     0.7         0.899481        1.1\n",
       "427        0.481323     1.1         0.960183        1.1\n",
       "342        0.514072     1.4         1.158763        1.1\n",
       "42         0.493026     1.2         0.955698        1.1\n",
       "273        0.472213     1.3         0.957459        1.1\n",
       "440        0.476745     1.4         1.094676        1.1\n",
       "665        0.476760     0.9         0.963206        1.1\n",
       "520        0.506725     1.0         1.055830        1.1\n",
       "68         0.458225     1.2         0.759816        1.1\n",
       "628        0.482288     1.0         0.839468        1.1\n",
       "320        0.471485     1.3         1.124230        1.1\n",
       "452        0.477424     0.5         0.647918        1.1\n",
       "138        0.488319     0.8         0.904392        1.1\n",
       "456        0.512027     1.0         0.941941        1.0\n",
       "301        0.438354     1.3         1.063659        1.0\n",
       "586        0.507179     0.6         1.006739        1.0\n",
       "358        0.459251     1.0         1.283389        1.0\n",
       "26         0.507556     0.5         0.728435        1.0\n",
       "184        0.511768     1.3         1.154819        1.0\n",
       "143        0.492561     0.4         0.836537        1.0\n",
       "167        0.497249     0.7         0.656171        1.0\n",
       "180        0.477558     1.0         0.836462        1.0\n",
       "65         0.482708     1.0         1.048137        1.0\n",
       "598        0.483390     0.5         0.674752        0.9\n",
       "649        0.488273     0.7         0.808230        0.9\n",
       "250        0.493404     1.1         0.928504        0.9\n",
       "542        0.497898     1.0         0.911661        0.9\n",
       "492        0.502204     1.6         0.999186        0.9\n",
       "503        0.516742     0.6         0.909985        0.9\n",
       "505        0.487186     0.7         0.976580        0.9\n",
       "198        0.504905     0.1         1.356281        0.9\n",
       "377        0.477493     0.3         0.796490        0.9\n",
       "368        0.511768     0.4         0.922040        0.9\n",
       "590        0.502311     0.7         1.050214        0.8\n",
       "266        0.498977     1.0         0.855962        0.8\n",
       "585        0.492935     0.8         0.682650        0.8\n",
       "618        0.503059     0.7         0.828942        0.8\n",
       "230        0.404983     0.6         0.598218        0.8\n",
       "235        0.496547     0.4         1.498542        0.8"
      ]
     },
     "execution_count": 711,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = NN_blk.predict(X_test)\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.3)\n",
    "gbr.fit(X_train,y_train)\n",
    "gbr_predictions = gbr.predict(X_test)\n",
    "LR = LinearRegression(fit_intercept=True).fit(X_train,y_train)\n",
    "\n",
    "testing = pd.DataFrame(predictions)\n",
    "testing.columns=['NN_predictions']\n",
    "testing['actual'] = y_test.reset_index()['blocks']\n",
    "testing['GBR_predictions']=gbr_predictions\n",
    "testing['LY_blocks']=X_test['blocks_ly'].reset_index()['blocks_ly']\n",
    "testing.sort_values(by='LY_blocks',ascending=False)[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2017blocks = blocks[blocks['season']==2017].drop(['team','player','blocks','Games'],axis=1)\n",
    "#pred_2017blocks = blocks[blocks['season']==2017][['blocks_ly','career_blocks','starter_change']]\n",
    "blocks_2017 = NN_blk.predict(pred_2017blocks)\n",
    "gbr_blk_2017 = pd.DataFrame(gbr.predict(pred_2017blocks))\n",
    "LR_blk_2017 = pd.DataFrame(LR.predict(pred_2017blocks))\n",
    "test_2 =pd.DataFrame(blocks_2017)\n",
    "test_3 = pd.merge(blocks,pred_2017blocks,left_index=True,right_index=True).reset_index()\n",
    "test_3['predictions']=test_2[0]\n",
    "test_3['gbr_pred'] = gbr_blk_2017[0]\n",
    "test_3['LR_pred'] = LR_blk_2017[0]\n",
    "test_3['mean_pred'] = (test_3['predictions']+test_3['gbr_pred']+test_3['LR_pred'])/3\n",
    "test_3 = test_3[test_3['Games']>30]\n",
    "test_3[['player','blocks','predictions','LR_pred','gbr_pred','mean_pred','blocks_ly_x']].sort_values(by='blocks_ly_x',ascending=False)[0:50]\n",
    "\n",
    "blocks_2017 = test_3[['player','LR_pred']]\n",
    "blocks_2017.columns=['player','block_predictions']\n",
    "df_2017=pd.merge(df_2017,blocks_2017,how='left',left_on='player',right_on='player')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE using LR:0.03683843835441125\n",
      "MSE using GB:0.04026709446110031\n",
      "MSE using NN:0.17920300539160033\n",
      "MSE using combo:0.04871856537916165\n",
      "MSE using mean:0.18036817882971723\n",
      "MSE using last year stats:0.047980769230769105\n"
     ]
    }
   ],
   "source": [
    "print('MSE using LR:{}'.format(np.mean((test_3['blocks']-test_3['LR_pred'])**2)))\n",
    "print('MSE using GB:{}'.format(np.mean((test_3['blocks']-test_3['gbr_pred'])**2)))\n",
    "print('MSE using NN:{}'.format(np.mean((test_3['blocks']-test_3['predictions'])**2)))\n",
    "print('MSE using combo:{}'.format(np.mean((test_3['blocks']-test_3['mean_pred'])**2)))\n",
    "print('MSE using mean:{}'.format(np.mean((test_3['blocks']-np.mean(test_3['blocks']))**2)))\n",
    "print('MSE using last year stats:{}'.format(np.mean((test_3['blocks']-test_3['blocks_ly_x'])**2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    " query= '''\n",
    "        \n",
    "        DROP TABLE IF EXISTS threes_pred;\n",
    "        CREATE TABLE threes_pred(\n",
    "        season int, --these come from player_stats\n",
    "        player varchar(50),\n",
    "        Age int,\n",
    "        team varchar(50),\n",
    "        threes_made float, -- these come from player_stats\n",
    "        threes_ly float,\n",
    "        change_threes float,\n",
    "        points_ly float,\n",
    "        change_points_ly float,\n",
    "        starter_change int,\n",
    "        C_PF int,\n",
    "        PG int,\n",
    "        SG_SF int,\n",
    "        Games int,\n",
    "        \n",
    "         -- these come from team_changes\n",
    "        high_usageplayer_added int,\n",
    "        usagemin_opened float,\n",
    "        maxusage_added float,\n",
    "        high_usageplayer_dropped int,\n",
    "        points_opened float,\n",
    "        max_pointsdropped float,\n",
    "        max_pointsadded float,\n",
    "        \n",
    "        three_ar_ly float, -- from player_advstats\n",
    "        change_3ar float,\n",
    "        per_ly float,\n",
    "        change_per float,\n",
    "        usagerank float,\n",
    "        usagerank_ly float,\n",
    "        offensive_winshares float,\n",
    "        offensive_boxplusminus float,\n",
    "        boxplusminus float,\n",
    "        value_overreplacement float,\n",
    "        \n",
    "        career_threes float,\n",
    "        yearspro int\n",
    "        );\n",
    "        \n",
    "        INSERT INTO threes_pred(season,player,age,team,threes_made,threes_ly,change_threes,points_ly,change_points_ly,starter_change,C_PF,PG,SG_SF,Games)\n",
    "        SELECT season,player,age,startingteam,threes_made,threes_ly,change_threes,points_ly,change_points_ly,starter-starter_ly,\n",
    "        case when pos in ('C','PF') then 1 else 0 end,case when pos='PG' then 1 else 0 end,case when pos in('SG','SF') then 1 else 0 end,Games\n",
    "        from player_stats;\n",
    "        \n",
    "        update threes_pred tp\n",
    "        set high_usageplayer_added = tc.high_usageplayer_added,usagemin_opened=tc.usagemin_opened,\n",
    "        maxusage_added=tc.max_usageadded,high_usageplayer_dropped=tc.high_usageplayer_dropped,points_opened=tc.points_opened,\n",
    "        max_pointsdropped=tc.max_pointsdropped,max_pointsadded=tc.max_pointsadded\n",
    "        from team_changes tc\n",
    "        where tc.team = tp.team and tp.season=tc.season;\n",
    "        \n",
    "        update threes_pred tp\n",
    "        set three_ar_ly = pa.threear_ly,change_3ar=pa.change_3ar,per_ly=pa.per_ly,change_per=pa.change_per,\n",
    "        usagerank=pa.usagerank,usagerank_ly=pa.usagerank_ly,offensive_winshares=pa.offensive_winshares,\n",
    "        offensive_boxplusminus=pa.offensive_boxplusminus,boxplusminus=pa.boxplusminus,value_overreplacement=pa.value_overreplacement\n",
    "        from player_advstats pa\n",
    "        where tp.player = pa.player and tp.season = pa.season and tp.team = pa.startingteam;\n",
    "        \n",
    "        update threes_pred tp\n",
    "        set career_threes = pc.career_threesmade, yearspro = pc.yearspro\n",
    "        from player_careerstats pc\n",
    "        where tp.player = pc.player and tp.season = pc.season;\n",
    "        \n",
    "        \n",
    "        select * from threes_pred where season>2009\n",
    "        '''\n",
    "\n",
    "\n",
    "cur.execute(query)\n",
    "data = cur.fetchall()\n",
    "threes_df = pd.DataFrame(np.array(data))\n",
    "threes_df.columns = ['season','player','age','team','3PM','3PM_ly','3PM_change','points_ly','change_points_ly','starter_change','C_PF','PG','SG_SF','Games','high_usageplayer_added','usagemin_opened','maxusage_added','high_usageplayer_dropped','points_opened','max_pointsdropped',\n",
    "                    'max_pointsadded','three_ar_ly','change_3ar','per_ly','change_per','usagerank','usagerank_ly','offensive_winshares','offensive_boxplusminus','boxplusminus','value_overreplacement','career_3PM','yearspro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "threes_df['age_squared']=threes_df['age']*threes_df['age']\n",
    "threes = threes_df[threes_df['3PM_ly'].notna()]\n",
    "for i in threes.columns:\n",
    "    if i not in(['player','team']):\n",
    "        threes[i]=pd.to_numeric(threes[i])\n",
    "threes = threes.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = threes[(threes['season']!=2017) & (threes['Games']>30)].drop(['player','team','3PM','Games'],axis=1)\n",
    "y = threes[(threes['season']!=2017) & (threes['Games']>30)]['3PM']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1564/1564 [==============================] - 3s 2ms/step - loss: 16.5297\n",
      "Epoch 2/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.1638\n",
      "Epoch 3/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.1287\n",
      "Epoch 4/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.1005\n",
      "Epoch 5/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.0758\n",
      "Epoch 6/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.0527\n",
      "Epoch 7/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 1.0315\n",
      "Epoch 8/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.0124\n",
      "Epoch 9/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.9947\n",
      "Epoch 10/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.9770\n",
      "Epoch 11/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.9608\n",
      "Epoch 12/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.9446\n",
      "Epoch 13/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.9292\n",
      "Epoch 14/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.9142\n",
      "Epoch 15/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.8999\n",
      "Epoch 16/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.8861\n",
      "Epoch 17/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.8721\n",
      "Epoch 18/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.8596\n",
      "Epoch 19/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.8470\n",
      "Epoch 20/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.8348\n",
      "Epoch 21/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.8231\n",
      "Epoch 22/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.8116\n",
      "Epoch 23/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.8003\n",
      "Epoch 24/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.7896\n",
      "Epoch 25/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.7790\n",
      "Epoch 26/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.7692\n",
      "Epoch 27/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.7594\n",
      "Epoch 28/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.7499\n",
      "Epoch 29/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.7409\n",
      "Epoch 30/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.7321\n",
      "Epoch 31/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.7238\n",
      "Epoch 32/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.7155\n",
      "Epoch 33/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.7079\n",
      "Epoch 34/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.7001\n",
      "Epoch 35/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.6927\n",
      "Epoch 36/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.6856\n",
      "Epoch 37/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.6790\n",
      "Epoch 38/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.6726\n",
      "Epoch 39/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.6661\n",
      "Epoch 40/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.6602\n",
      "Epoch 41/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.6543\n",
      "Epoch 42/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.6488\n",
      "Epoch 43/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6436\n",
      "Epoch 44/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.6388\n",
      "Epoch 45/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.6334\n",
      "Epoch 46/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.6287\n",
      "Epoch 47/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.6241\n",
      "Epoch 48/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.6199\n",
      "Epoch 49/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.6157\n",
      "Epoch 50/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.6122\n",
      "Epoch 51/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.6079\n",
      "Epoch 52/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.6043\n",
      "Epoch 53/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.6009\n",
      "Epoch 54/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.5974\n",
      "Epoch 55/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5943\n",
      "Epoch 56/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5913\n",
      "Epoch 57/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5884\n",
      "Epoch 58/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5858\n",
      "Epoch 59/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5829\n",
      "Epoch 60/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.5804\n",
      "Epoch 61/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5784\n",
      "Epoch 62/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.5758\n",
      "Epoch 63/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5735\n",
      "Epoch 64/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.5714\n",
      "Epoch 65/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.5696\n",
      "Epoch 66/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.5678\n",
      "Epoch 67/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5659\n",
      "Epoch 68/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5645\n",
      "Epoch 69/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5629\n",
      "Epoch 70/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.5613\n",
      "Epoch 71/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5599\n",
      "Epoch 72/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5585\n",
      "Epoch 73/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5572\n",
      "Epoch 74/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.5562\n",
      "Epoch 75/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5550\n",
      "Epoch 76/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5540\n",
      "Epoch 77/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5533\n",
      "Epoch 78/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5520\n",
      "Epoch 79/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5512\n",
      "Epoch 80/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5505\n",
      "Epoch 81/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.5495\n",
      "Epoch 82/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.5489\n",
      "Epoch 83/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.5481\n",
      "Epoch 84/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5474\n",
      "Epoch 85/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5469\n",
      "Epoch 86/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5462\n",
      "Epoch 87/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5456\n",
      "Epoch 88/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5451\n",
      "Epoch 89/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5446\n",
      "Epoch 90/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.5441\n",
      "Epoch 91/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5436\n",
      "Epoch 92/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5433\n",
      "Epoch 93/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5429\n",
      "Epoch 94/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.5425\n",
      "Epoch 95/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5422\n",
      "Epoch 96/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.5418\n",
      "Epoch 97/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5421\n",
      "Epoch 98/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5416\n",
      "Epoch 99/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5411\n",
      "Epoch 100/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5411\n",
      "Epoch 101/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5408\n",
      "Epoch 102/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.5407\n",
      "Epoch 103/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.5406\n",
      "Epoch 104/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5404\n",
      "Epoch 105/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5402\n",
      "Epoch 106/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5401\n",
      "Epoch 107/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5399\n",
      "Epoch 108/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5398\n",
      "Epoch 109/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5399\n",
      "Epoch 110/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5397\n",
      "Epoch 111/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 112/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5395\n",
      "Epoch 113/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.5394\n",
      "Epoch 114/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5393\n",
      "Epoch 115/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 116/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 117/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5394\n",
      "Epoch 118/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5391\n",
      "Epoch 119/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5393\n",
      "Epoch 120/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5391\n",
      "Epoch 121/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5391\n",
      "Epoch 122/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5389\n",
      "Epoch 123/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5391\n",
      "Epoch 124/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5389\n",
      "Epoch 125/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5392\n",
      "Epoch 126/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5389\n",
      "Epoch 127/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5393\n",
      "Epoch 128/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5393\n",
      "Epoch 129/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5391\n",
      "Epoch 130/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.5390\n",
      "Epoch 131/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5389\n",
      "Epoch 132/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5387\n",
      "Epoch 133/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5388\n",
      "Epoch 134/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5387\n",
      "Epoch 135/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5387\n",
      "Epoch 136/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5389\n",
      "Epoch 137/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5386\n",
      "Epoch 138/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5387\n",
      "Epoch 139/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5386\n",
      "Epoch 140/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5387\n",
      "Epoch 141/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5390\n",
      "Epoch 142/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5390\n",
      "Epoch 143/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5386\n",
      "Epoch 144/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5388\n",
      "Epoch 145/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5387\n",
      "Epoch 146/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5391\n",
      "Epoch 147/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5388\n",
      "Epoch 148/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5386\n",
      "Epoch 149/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5387\n",
      "Epoch 150/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5386\n",
      "Epoch 151/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5386\n",
      "Epoch 152/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5386\n",
      "Epoch 153/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5387\n",
      "Epoch 154/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5389\n",
      "Epoch 155/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5385\n",
      "Epoch 156/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5391\n",
      "Epoch 157/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5384\n",
      "Epoch 158/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5395\n",
      "Epoch 159/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 160/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 161/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 162/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5395\n",
      "Epoch 163/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 164/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5395\n",
      "Epoch 165/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 166/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 167/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 168/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 169/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 170/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 171/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 172/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 173/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 174/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 175/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 176/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 177/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 178/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 179/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 180/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 181/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 182/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5395\n",
      "Epoch 183/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.5395\n",
      "Epoch 184/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 185/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 186/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 187/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 188/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 189/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 190/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 191/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 192/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 193/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 194/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 195/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 196/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 197/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 198/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 199/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 200/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 201/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.5395\n",
      "Epoch 202/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 203/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 204/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 205/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 206/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 207/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 208/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 209/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 210/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 211/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 212/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5395\n",
      "Epoch 213/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 214/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 215/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 216/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 217/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 218/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 219/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 220/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 221/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5395\n",
      "Epoch 222/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.5395\n",
      "Epoch 223/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 224/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 225/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 226/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 227/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 228/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 229/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 230/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 231/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 232/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 233/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 234/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 235/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 236/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 237/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 238/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 239/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 240/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 241/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 242/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.5395\n",
      "Epoch 243/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.5395\n",
      "Epoch 244/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 245/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5395\n",
      "Epoch 246/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 247/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 248/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 249/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 250/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 251/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5395\n",
      "Epoch 252/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 253/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 254/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 255/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 256/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 257/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5395\n",
      "Epoch 258/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 259/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 260/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.5395\n",
      "Epoch 261/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5395\n",
      "Epoch 262/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 263/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 264/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 265/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 266/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 267/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 268/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 269/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.5395\n",
      "Epoch 270/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 271/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 272/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 273/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 274/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 275/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5395\n",
      "Epoch 276/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.5395\n",
      "Epoch 277/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5395\n",
      "Epoch 278/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 279/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 280/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 281/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 282/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.5395\n",
      "Epoch 283/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 284/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 285/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 286/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 287/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 288/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 289/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 290/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5395\n",
      "Epoch 291/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 292/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 293/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 294/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 295/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 296/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 297/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5395\n",
      "Epoch 298/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 299/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 300/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 301/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 302/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 303/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 304/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 305/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 306/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 307/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 308/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 309/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 310/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 311/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 312/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 313/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5395\n",
      "Epoch 314/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 315/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 316/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 317/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5395\n",
      "Epoch 318/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 319/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 320/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 321/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 322/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 323/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 324/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 325/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5396\n",
      "Epoch 326/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 327/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5395\n",
      "Epoch 328/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 329/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 330/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 331/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 332/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 333/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 334/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 335/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 336/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 337/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 338/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 339/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 340/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 341/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 342/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 343/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 344/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 345/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 346/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5395\n",
      "Epoch 347/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 348/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 349/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 350/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 351/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 352/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 353/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 354/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 355/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 356/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 357/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 358/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 359/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 360/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 361/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 362/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 363/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 364/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 365/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 366/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.5395\n",
      "Epoch 367/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 368/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 369/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 370/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 371/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 372/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 373/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 374/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 375/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 376/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 377/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 378/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 379/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 380/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 381/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 382/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 383/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.5395\n",
      "Epoch 384/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 385/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5395\n",
      "Epoch 386/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 387/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 388/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.5395\n",
      "Epoch 389/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.5395\n",
      "Epoch 390/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5396\n",
      "Epoch 391/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5395\n",
      "Epoch 392/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 393/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 394/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 395/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5395\n",
      "Epoch 396/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 397/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 398/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 399/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 400/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 401/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 402/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 403/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 404/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5395\n",
      "Epoch 405/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.5395\n",
      "Epoch 406/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 407/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 408/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 409/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 410/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 411/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 412/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 413/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 414/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.5395\n",
      "Epoch 415/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 416/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 417/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 418/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 419/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 420/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5396\n",
      "Epoch 421/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 422/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 423/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5395\n",
      "Epoch 424/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5395\n",
      "Epoch 425/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 426/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 427/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5396\n",
      "Epoch 428/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 429/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 430/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 431/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 432/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 433/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 434/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5396\n",
      "Epoch 435/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 436/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 437/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5395\n",
      "Epoch 438/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 439/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 440/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 441/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 442/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 443/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5396\n",
      "Epoch 444/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 445/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 446/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 447/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 448/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 449/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 450/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 451/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 452/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 453/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 454/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 455/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 456/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 457/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 458/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 459/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 460/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 461/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 462/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 463/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 464/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 465/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 466/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 467/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 468/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 469/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 470/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 471/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 472/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 473/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5395\n",
      "Epoch 474/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 475/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 476/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 477/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5395\n",
      "Epoch 478/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.5395\n",
      "Epoch 479/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.5395\n",
      "Epoch 480/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5395\n",
      "Epoch 481/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.5395\n",
      "Epoch 482/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 483/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 484/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 485/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 486/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 487/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 488/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 489/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 490/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 491/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.5395\n",
      "Epoch 492/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 493/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5395\n",
      "Epoch 494/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.5395\n",
      "Epoch 495/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5395\n",
      "Epoch 496/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 497/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 498/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 499/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 500/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5395\n",
      "Epoch 501/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 502/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5395\n",
      "Epoch 503/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 504/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5395\n",
      "Epoch 505/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5395\n",
      "Epoch 506/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 507/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 508/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5395\n",
      "Epoch 509/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 0.5395\n",
      "Epoch 510/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.5395\n",
      "Epoch 511/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.5395\n",
      "Epoch 512/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.5395\n",
      "Epoch 513/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 514/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 515/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 516/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5395\n",
      "Epoch 517/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5395\n",
      "Epoch 518/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 519/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 520/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5395\n",
      "Epoch 521/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 522/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 523/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5395\n",
      "Epoch 524/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 525/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.5395\n",
      "Epoch 526/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.5395\n",
      "Epoch 527/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 528/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5395\n",
      "Epoch 529/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 530/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 531/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 532/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 533/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5395\n",
      "Epoch 534/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.5395\n",
      "Epoch 535/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 536/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 537/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 538/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 539/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 540/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 541/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 542/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5395\n",
      "Epoch 543/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5395\n",
      "Epoch 544/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5395\n",
      "Epoch 545/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5395\n",
      "Epoch 546/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 547/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 548/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5396\n",
      "Epoch 549/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5394\n",
      "Epoch 550/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.5395\n",
      "Epoch 551/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.5395\n",
      "Epoch 552/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.5395\n",
      "Epoch 553/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.5395\n",
      "Epoch 554/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5395\n",
      "Epoch 555/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 556/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5395\n",
      "Epoch 557/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 558/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5395\n",
      "Epoch 559/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5395\n",
      "Epoch 560/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.5395\n",
      "Epoch 561/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5395\n",
      "Epoch 562/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5395\n",
      "Epoch 563/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 564/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5395\n",
      "Epoch 565/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 566/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 567/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5395\n",
      "Epoch 568/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.5395\n",
      "Epoch 569/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5395\n",
      "Epoch 570/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 571/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.5395\n",
      "Epoch 572/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 573/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 574/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 575/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 576/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 577/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 578/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 579/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 580/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 581/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 582/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 583/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 584/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 585/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 586/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 587/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 588/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 589/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 590/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5395\n",
      "Epoch 591/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 592/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 593/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 594/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 595/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 596/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 597/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 598/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 599/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 600/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 601/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 602/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 603/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 604/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 605/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 606/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 607/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 608/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 609/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 610/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 611/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 612/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 613/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 614/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 615/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 616/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 617/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 618/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 619/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 620/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 621/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 622/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 623/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 624/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 625/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 626/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 627/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5395\n",
      "Epoch 628/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 629/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 630/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 631/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 632/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 633/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 634/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 635/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 636/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 637/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 638/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 639/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 640/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 641/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 642/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 643/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 644/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 645/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.5395\n",
      "Epoch 646/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 647/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 648/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 649/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 650/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 651/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 652/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 653/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 654/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 655/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 656/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 657/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 658/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 659/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 660/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 661/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 662/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 663/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 664/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 665/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.5395\n",
      "Epoch 666/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 667/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 668/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 669/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 670/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 671/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 672/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 673/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 674/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 675/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 676/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 677/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 678/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 679/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 680/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 681/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 682/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 683/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 684/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 685/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5395\n",
      "Epoch 686/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 687/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 688/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 689/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 690/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 691/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 692/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 693/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 694/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 695/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 696/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 697/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 698/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 699/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 700/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 701/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5395\n",
      "Epoch 702/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 703/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 704/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 705/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 706/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 707/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 708/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 709/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 710/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 711/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 712/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 713/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 714/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 715/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 716/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 717/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 718/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 719/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 720/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 721/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 722/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 723/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 724/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.5395\n",
      "Epoch 725/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 726/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 727/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 728/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 729/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 730/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5396\n",
      "Epoch 731/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 732/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 733/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 734/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 735/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5395\n",
      "Epoch 736/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 737/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 738/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 739/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 740/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 741/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 742/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 743/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 744/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5395\n",
      "Epoch 745/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 746/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 747/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 748/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 749/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 750/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 751/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 752/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 753/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 754/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 755/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 756/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 757/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 758/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 759/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 760/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 761/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 762/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 763/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 764/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 765/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 766/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 767/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 768/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 769/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 770/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 771/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 772/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 773/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 774/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 775/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5395\n",
      "Epoch 776/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.5395\n",
      "Epoch 777/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.5395\n",
      "Epoch 778/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5396\n",
      "Epoch 779/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 780/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 781/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 782/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5395\n",
      "Epoch 783/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 784/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 785/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 786/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 787/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 788/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 789/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5396\n",
      "Epoch 790/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 791/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 792/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5396\n",
      "Epoch 793/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.5395\n",
      "Epoch 794/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 795/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 796/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 797/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 798/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 799/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 800/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5394\n",
      "Epoch 801/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 802/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5396\n",
      "Epoch 803/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 804/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 805/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 806/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 807/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5396\n",
      "Epoch 808/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5396\n",
      "Epoch 809/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 810/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 811/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 812/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5395\n",
      "Epoch 813/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 814/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 815/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 816/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 817/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 818/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 819/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 820/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5395\n",
      "Epoch 821/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5395\n",
      "Epoch 822/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 823/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 824/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 825/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 826/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 827/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 828/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 829/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 830/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 831/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5395\n",
      "Epoch 832/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 833/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 834/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5395\n",
      "Epoch 835/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 836/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 837/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 838/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 839/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 840/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 841/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 842/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 843/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 844/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 845/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 846/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 847/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 848/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 849/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5395\n",
      "Epoch 850/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 851/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 852/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 853/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 854/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 855/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 856/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 857/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 858/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 859/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 860/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5395\n",
      "Epoch 861/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 862/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 863/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 864/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 865/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 866/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 867/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 868/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 869/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 870/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 871/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 872/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 873/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 874/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 875/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 876/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 877/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 878/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 879/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 880/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 881/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 882/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 883/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 884/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 885/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 886/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 887/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 888/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 889/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 890/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5395\n",
      "Epoch 891/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 892/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 893/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 894/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 895/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 896/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 897/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 898/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 899/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5395\n",
      "Epoch 900/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 901/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 902/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 903/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 904/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 905/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 906/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 907/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 908/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 909/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5395\n",
      "Epoch 910/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5395\n",
      "Epoch 911/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 912/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 913/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 914/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 915/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 916/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 917/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 918/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 919/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5395\n",
      "Epoch 920/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 921/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 922/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 923/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 924/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 925/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 926/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 927/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 928/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 929/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 930/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 931/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 932/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 933/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 934/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 935/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 936/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 937/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 938/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 939/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5395\n",
      "Epoch 940/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 941/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 942/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 943/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 944/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 945/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 946/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 947/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5396\n",
      "Epoch 948/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 949/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5395\n",
      "Epoch 950/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 951/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 952/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 953/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 954/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 955/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 956/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 957/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 958/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 959/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 960/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 961/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 962/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 963/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 964/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 965/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 966/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 967/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 968/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 969/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5395\n",
      "Epoch 970/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 971/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 972/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 973/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 974/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5395\n",
      "Epoch 975/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5395\n",
      "Epoch 976/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 977/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5395\n",
      "Epoch 978/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5395\n",
      "Epoch 979/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.5395\n",
      "Epoch 980/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 981/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 982/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 983/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 984/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 985/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 986/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5395\n",
      "Epoch 987/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 988/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5395\n",
      "Epoch 989/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 990/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 991/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 992/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5395\n",
      "Epoch 993/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 994/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5395\n",
      "Epoch 995/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n",
      "Epoch 996/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5395\n",
      "Epoch 997/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5395\n",
      "Epoch 998/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5395\n",
      "Epoch 999/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5395\n",
      "Epoch 1000/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5395\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a4defd0f0>"
      ]
     },
     "execution_count": 722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_3s = Sequential()\n",
    "NN_3s.add(Dense(units=16,input_dim=X_train.shape[1],activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_3s.add(Dense(units=8, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_3s.add(Dense(units=4, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_3s.add(Dense(units=1,activation='linear'))\n",
    "NN_3s.compile(loss='mse', optimizer='adam')\n",
    "NN_3s.fit(np.array(X_train), np.array(y_train), epochs=1000,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN_predictions</th>\n",
       "      <th>actual</th>\n",
       "      <th>GBR_predictions</th>\n",
       "      <th>LY_3PM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.624457</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.682590</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.688230</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.648296</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.250570</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.560267</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.277598</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.566865</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.623985</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.704295</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.754473</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.563310</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.671537</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.931924</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.662534</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.642532</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.674533</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.912572</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.436628</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.224985</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.432895</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.524372</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.719411</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.341240</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.458456</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.367441</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.367921</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.766551</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.501663</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.632175</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.596181</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.749920</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.579282</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.251404</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.452147</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.377112</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.145353</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.395469</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.216515</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.503005</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.315665</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.794909</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.493872</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.651315</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.334853</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.514904</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.397960</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.796161</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.597180</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.784509</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.405756</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     NN_predictions  actual  GBR_predictions  LY_3PM\n",
       "324        0.784509     0.6         1.624457     1.7\n",
       "425        0.784509     2.1         1.682590     1.7\n",
       "31         0.784509     1.5         1.688230     1.7\n",
       "540        0.784509     2.2         1.648296     1.7\n",
       "288        0.784509     1.5         1.250570     1.7\n",
       "245        0.784509     1.0         1.560267     1.7\n",
       "24         0.784509     1.9         1.277598     1.7\n",
       "602        0.784509     0.9         1.566865     1.7\n",
       "268        0.784509     1.2         1.623985     1.7\n",
       "609        0.784509     1.5         1.704295     1.7\n",
       "611        0.784509     1.2         1.754473     1.7\n",
       "449        0.784509     1.7         1.563310     1.7\n",
       "373        0.784509     1.6         1.671537     1.7\n",
       "78         0.784509     2.1         1.931924     1.7\n",
       "295        0.784509     1.3         1.662534     1.7\n",
       "320        0.784509     1.6         1.642532     1.7\n",
       "48         0.784509     1.3         1.674533     1.7\n",
       "224        0.784509     0.7         1.912572     1.7\n",
       "111        0.784509     1.6         1.436628     1.6\n",
       "234        0.784509     1.1         1.224985     1.6\n",
       "535        0.784509     1.2         1.432895     1.6\n",
       "179        0.784509     1.4         1.524372     1.6\n",
       "42         0.784509     1.7         1.719411     1.6\n",
       "589        0.784509     1.6         1.341240     1.6\n",
       "13         0.784509     1.0         1.458456     1.6\n",
       "124        0.784509     1.8         1.367441     1.6\n",
       "620        0.784509     1.3         1.367921     1.6\n",
       "137        0.784509     1.8         1.766551     1.6\n",
       "92         0.784509     0.8         1.501663     1.6\n",
       "194        0.784509     1.4         1.632175     1.6\n",
       "260        0.784509     1.7         1.596181     1.6\n",
       "470        0.784509     0.8         1.749920     1.6\n",
       "329        0.784509     1.9         1.579282     1.6\n",
       "299        0.784509     1.8         1.251404     1.6\n",
       "188        0.784509     1.5         1.452147     1.6\n",
       "593        0.784509     2.2         1.377112     1.6\n",
       "147        0.784509     1.6         1.145353     1.6\n",
       "631        0.784509     1.5         1.395469     1.5\n",
       "362        0.784509     1.0         1.216515     1.5\n",
       "107        0.784509     1.5         1.503005     1.5\n",
       "123        0.784509     1.6         1.315665     1.5\n",
       "198        0.784509     0.8         0.794909     1.5\n",
       "304        0.784509     1.3         1.493872     1.5\n",
       "81         0.784509     2.0         1.651315     1.5\n",
       "515        0.784509     1.4         1.334853     1.5\n",
       "251        0.784509     0.7         1.514904     1.5\n",
       "69         0.784509     1.3         1.397960     1.5\n",
       "71         0.784509     2.0         1.796161     1.5\n",
       "349        0.784509     2.2         1.597180     1.5\n",
       "53         0.784509     1.8         1.405756     1.5"
      ]
     },
     "execution_count": 723,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = NN_3s.predict(X_test)\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.5)\n",
    "gbr.fit(X_train,y_train)\n",
    "gbr_predictions = gbr.predict(X_test)\n",
    "LR = LinearRegression(fit_intercept=True).fit(X_train,y_train)\n",
    "\n",
    "testing = pd.DataFrame(predictions)\n",
    "testing.columns=['NN_predictions']\n",
    "testing['actual'] = y_test.reset_index()['3PM']\n",
    "testing['GBR_predictions']=gbr_predictions\n",
    "testing['LY_3PM']=X_test['3PM_ly'].reset_index()['3PM_ly']\n",
    "testing.sort_values(by='LY_3PM',ascending=False)[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2017threes = threes[threes['season']==2017].drop(['team','player','3PM','Games'],axis=1)\n",
    "#pred_2017blocks = blocks[blocks['season']==2017][['blocks_ly','career_blocks','starter_change']]\n",
    "threes_2017 = NN_3s.predict(pred_2017threes)\n",
    "gbr_3PM_2017 = pd.DataFrame(gbr.predict(pred_2017threes))\n",
    "LR_3PM_2017 = pd.DataFrame(LR.predict(pred_2017threes))\n",
    "test_2 =pd.DataFrame(threes_2017)\n",
    "test_3 = pd.merge(threes,pred_2017threes,left_index=True,right_index=True).reset_index()\n",
    "test_3['predictions']=test_2[0]\n",
    "test_3['gbr_pred'] = gbr_3PM_2017[0]\n",
    "test_3['LR_pred'] = LR_3PM_2017[0]\n",
    "test_3['mean_pred'] = (test_3['predictions']+test_3['gbr_pred']+test_3['LR_pred'])/3\n",
    "test_3 = test_3[test_3['Games']>30]\n",
    "test_3[['player','3PM','predictions','LR_pred','gbr_pred','mean_pred','3PM_ly_x']].sort_values(by='3PM_ly_x',ascending=False)[0:50]\n",
    "\n",
    "threes_2017 = test_3[['player','LR_pred']]\n",
    "threes_2017.columns = ['player','three_prediction']\n",
    "df_2017 = pd.merge(df_2017,threes_2017,how='left',left_on='player',right_on='player')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE using LR:0.1628483859385458\n",
      "MSE using GB:0.17385807774763995\n",
      "MSE using NN:0.40353144379540246\n",
      "MSE using combo:0.19758697006733536\n",
      "MSE using mean:0.7179477933925056\n",
      "MSE using last year stats:0.2091987179487179\n"
     ]
    }
   ],
   "source": [
    "print('MSE using LR:{}'.format(np.mean((test_3['3PM']-test_3['LR_pred'])**2)))\n",
    "print('MSE using GB:{}'.format(np.mean((test_3['3PM']-test_3['gbr_pred'])**2)))\n",
    "print('MSE using NN:{}'.format(np.mean((test_3['3PM']-test_3['predictions'])**2)))\n",
    "print('MSE using combo:{}'.format(np.mean((test_3['3PM']-test_3['mean_pred'])**2)))\n",
    "print('MSE using mean:{}'.format(np.mean((test_3['3PM']-np.mean(test_3['3PM']))**2)))\n",
    "print('MSE using last year stats:{}'.format(np.mean((test_3['3PM']-test_3['3PM_ly_x'])**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [],
   "source": [
    "query= '''\n",
    "        \n",
    "        DROP TABLE IF EXISTS turnovers_pred;\n",
    "        CREATE TABLE turnovers_pred(\n",
    "        season int, -- these come from player_stats\n",
    "        player varchar(50),\n",
    "        Age int,\n",
    "        team varchar(50),\n",
    "        turnovers float, \n",
    "        turnovers_ly float,\n",
    "        change_tov_ly float,\n",
    "        starter_change int,\n",
    "        Games int,\n",
    "        C_PF int,\n",
    "        PG int,\n",
    "        SG_SF int,\n",
    "        \n",
    "         -- these come from team_changes\n",
    "        high_usageplayer_added int,\n",
    "        usagemin_opened float,\n",
    "        maxusage_added float,\n",
    "        high_usageplayer_dropped int,\n",
    "        \n",
    "        per_ly float,\n",
    "        change_per float,\n",
    "        usagerank float,\n",
    "        usagerank_ly float,\n",
    "        offensive_winshares float,\n",
    "        offensive_boxplusminus float,\n",
    "        \n",
    "        career_to float,\n",
    "        yearspro int\n",
    "        );\n",
    "        \n",
    "        INSERT INTO turnovers_pred(season,player,age,team,turnovers,turnovers_ly,change_tov_ly,starter_change,Games,C_PF,PG,SG_SF)\n",
    "        SELECT season,player,age,startingteam,tov,tov_ly,change_tov_ly,starter-starter_ly,Games,\n",
    "        case when pos in ('C','PF') then 1 else 0 end,case when pos='PG' then 1 else 0 end,case when pos in('SG','SF') then 1 else 0 end from player_stats;\n",
    "        \n",
    "        update turnovers_pred pp\n",
    "        set high_usageplayer_added = tc.high_usageplayer_added,usagemin_opened=tc.usagemin_opened,\n",
    "        maxusage_added=tc.max_usageadded,high_usageplayer_dropped=tc.high_usageplayer_dropped\n",
    "        from team_changes tc\n",
    "        where tc.team = pp.team and pp.season=tc.season;\n",
    "        \n",
    "        update turnovers_pred pp\n",
    "        set per_ly=pa.per_ly,change_per=pa.change_per,\n",
    "        usagerank=pa.usagerank,usagerank_ly=pa.usagerank_ly,offensive_winshares=pa.offensive_winshares,\n",
    "        offensive_boxplusminus=pa.offensive_boxplusminus\n",
    "        from player_advstats pa\n",
    "        where pp.player = pa.player and pp.season = pa.season and pp.team = pa.startingteam;\n",
    "        \n",
    "        update turnovers_pred pp\n",
    "        set career_to = pc.career_to, yearspro = pc.yearspro\n",
    "        from player_careerstats pc\n",
    "        where pp.player = pc.player and pp.season = pc.season;\n",
    "        \n",
    "        \n",
    "        select * from turnovers_pred where season>2009\n",
    "        '''\n",
    "\n",
    "\n",
    "cur.execute(query)\n",
    "data = cur.fetchall()\n",
    "to_df = pd.DataFrame(np.array(data))\n",
    "to_df.columns = ['season','player','age','team','turnovers','turnovers_ly','change_turnovers_ly','starter_change','Games','C_PF','PG','SG_SF','high_usageplayer_added','usagemin_opened','maxusage_added','high_usageplayer_dropped'\n",
    "                    ,'per_ly','change_per','usagerank','usagerank_ly','offensive_winshares','offensive_boxplusminus','career_turnovers','yearspro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "to_df['age_squared']=to_df['age']*to_df['age']\n",
    "tos = to_df[to_df['turnovers_ly'].notna()]\n",
    "for i in tos.columns:\n",
    "    if i not in(['player','team']):\n",
    "        tos[i]=pd.to_numeric(tos[i])\n",
    "tos = tos.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tos[(tos['season']!=2017) & (tos['Games']>30)].drop(['player','team','turnovers','Games'],axis=1)\n",
    "y = tos[(tos['season']!=2017) & (tos['Games']>30)]['turnovers']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1564/1564 [==============================] - 3s 2ms/step - loss: 1420993.9265\n",
      "Epoch 2/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1007348.9871\n",
      "Epoch 3/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 719244.4421\n",
      "Epoch 4/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 519045.8765\n",
      "Epoch 5/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 378106.6855\n",
      "Epoch 6/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 278492.6445\n",
      "Epoch 7/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 207253.9885\n",
      "Epoch 8/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 156603.6555\n",
      "Epoch 9/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 119886.5229\n",
      "Epoch 10/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 91289.0534\n",
      "Epoch 11/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 68771.5967\n",
      "Epoch 12/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 50513.9898\n",
      "Epoch 13/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 34846.2337\n",
      "Epoch 14/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 22785.1961\n",
      "Epoch 15/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 14696.8442\n",
      "Epoch 16/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 9324.5607\n",
      "Epoch 17/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 5872.9361\n",
      "Epoch 18/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 3700.4646\n",
      "Epoch 19/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 2436.3327\n",
      "Epoch 20/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1729.1333\n",
      "Epoch 21/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1339.8919\n",
      "Epoch 22/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1132.6949\n",
      "Epoch 23/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1017.5721\n",
      "Epoch 24/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 944.6453\n",
      "Epoch 25/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 897.0643\n",
      "Epoch 26/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 857.0711\n",
      "Epoch 27/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 822.9996\n",
      "Epoch 28/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 793.8610\n",
      "Epoch 29/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 767.8714\n",
      "Epoch 30/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 747.1546\n",
      "Epoch 31/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 727.0342\n",
      "Epoch 32/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 710.4382\n",
      "Epoch 33/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 692.2763\n",
      "Epoch 34/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 676.6287\n",
      "Epoch 35/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 662.5002\n",
      "Epoch 36/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 647.8633\n",
      "Epoch 37/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 634.9197\n",
      "Epoch 38/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 621.6489\n",
      "Epoch 39/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 608.9399\n",
      "Epoch 40/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 597.6931\n",
      "Epoch 41/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 587.1972\n",
      "Epoch 42/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 577.1143\n",
      "Epoch 43/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 567.5319\n",
      "Epoch 44/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 557.9554\n",
      "Epoch 45/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 549.6218\n",
      "Epoch 46/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 540.7722\n",
      "Epoch 47/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 532.8481\n",
      "Epoch 48/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 525.8938\n",
      "Epoch 49/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 519.0910\n",
      "Epoch 50/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 511.6977\n",
      "Epoch 51/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 504.8604\n",
      "Epoch 52/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 498.8801\n",
      "Epoch 53/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 492.3698\n",
      "Epoch 54/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 486.1402\n",
      "Epoch 55/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 480.2327\n",
      "Epoch 56/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 474.4990\n",
      "Epoch 57/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 468.6960\n",
      "Epoch 58/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 463.2012\n",
      "Epoch 59/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 457.8219\n",
      "Epoch 60/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 453.2758\n",
      "Epoch 61/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 448.3050\n",
      "Epoch 62/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 443.9207\n",
      "Epoch 63/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 440.0490\n",
      "Epoch 64/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 435.9080\n",
      "Epoch 65/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 432.2100\n",
      "Epoch 66/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 428.4673\n",
      "Epoch 67/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 425.1570\n",
      "Epoch 68/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 421.6735\n",
      "Epoch 69/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 418.3570\n",
      "Epoch 70/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 414.9101\n",
      "Epoch 71/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 411.3209\n",
      "Epoch 72/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 408.0763\n",
      "Epoch 73/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 404.8911\n",
      "Epoch 74/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 401.5610\n",
      "Epoch 75/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 398.2445\n",
      "Epoch 76/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 395.0364\n",
      "Epoch 77/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 391.6821\n",
      "Epoch 78/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 388.4763\n",
      "Epoch 79/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 385.0849\n",
      "Epoch 80/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 381.8615\n",
      "Epoch 81/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 378.7018\n",
      "Epoch 82/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 375.5812\n",
      "Epoch 83/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 372.4770\n",
      "Epoch 84/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 369.2483\n",
      "Epoch 85/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 365.9993\n",
      "Epoch 86/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 362.5393\n",
      "Epoch 87/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 359.3514\n",
      "Epoch 88/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 355.9568\n",
      "Epoch 89/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 352.8735\n",
      "Epoch 90/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 349.6031\n",
      "Epoch 91/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 346.2086\n",
      "Epoch 92/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 342.9129\n",
      "Epoch 93/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 339.8030\n",
      "Epoch 94/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 336.6460\n",
      "Epoch 95/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 333.2995\n",
      "Epoch 96/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 330.4216\n",
      "Epoch 97/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 326.9654\n",
      "Epoch 98/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 324.3616\n",
      "Epoch 99/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 320.8050\n",
      "Epoch 100/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 317.9591\n",
      "Epoch 101/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 314.4954\n",
      "Epoch 102/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 311.5008\n",
      "Epoch 103/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 308.2605\n",
      "Epoch 104/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 304.8313\n",
      "Epoch 105/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 301.7657\n",
      "Epoch 106/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 298.5331\n",
      "Epoch 107/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 295.4708\n",
      "Epoch 108/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 292.0607\n",
      "Epoch 109/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 288.9262\n",
      "Epoch 110/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 285.7680\n",
      "Epoch 111/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 282.5624\n",
      "Epoch 112/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 279.2983\n",
      "Epoch 113/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 276.0144\n",
      "Epoch 114/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 272.8354\n",
      "Epoch 115/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 269.8347\n",
      "Epoch 116/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 266.2847\n",
      "Epoch 117/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 263.0644\n",
      "Epoch 118/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 259.8836\n",
      "Epoch 119/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 256.3791\n",
      "Epoch 120/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 253.0792\n",
      "Epoch 121/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 249.4884\n",
      "Epoch 122/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 246.4648\n",
      "Epoch 123/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 242.5941\n",
      "Epoch 124/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 239.3458\n",
      "Epoch 125/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 236.2292\n",
      "Epoch 126/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 232.7503\n",
      "Epoch 127/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 229.4156\n",
      "Epoch 128/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 226.2750\n",
      "Epoch 129/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 223.1104\n",
      "Epoch 130/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 220.2342\n",
      "Epoch 131/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 216.6189\n",
      "Epoch 132/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 213.5745\n",
      "Epoch 133/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 210.3738\n",
      "Epoch 134/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 207.2544\n",
      "Epoch 135/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 204.1313\n",
      "Epoch 136/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 200.8991\n",
      "Epoch 137/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 197.7342\n",
      "Epoch 138/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 194.7099\n",
      "Epoch 139/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 191.5014\n",
      "Epoch 140/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 188.3862\n",
      "Epoch 141/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 185.2169\n",
      "Epoch 142/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 182.2243\n",
      "Epoch 143/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 179.3282\n",
      "Epoch 144/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 176.3781\n",
      "Epoch 145/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 173.4217\n",
      "Epoch 146/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 170.6170\n",
      "Epoch 147/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 167.9062\n",
      "Epoch 148/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 165.5059\n",
      "Epoch 149/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 162.5620\n",
      "Epoch 150/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 159.6229\n",
      "Epoch 151/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 156.8582\n",
      "Epoch 152/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 154.1321\n",
      "Epoch 153/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 151.4919\n",
      "Epoch 154/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 148.9308\n",
      "Epoch 155/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 146.3083\n",
      "Epoch 156/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 143.8111\n",
      "Epoch 157/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 141.1303\n",
      "Epoch 158/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 138.6681\n",
      "Epoch 159/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 136.1721\n",
      "Epoch 160/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 133.7318\n",
      "Epoch 161/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 131.1620\n",
      "Epoch 162/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 128.8221\n",
      "Epoch 163/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 126.5392\n",
      "Epoch 164/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 124.0996\n",
      "Epoch 165/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 121.5927\n",
      "Epoch 166/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 119.2682\n",
      "Epoch 167/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 117.0307\n",
      "Epoch 168/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 114.3394\n",
      "Epoch 169/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 111.9995\n",
      "Epoch 170/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 109.9646\n",
      "Epoch 171/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 107.7455\n",
      "Epoch 172/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 105.3996\n",
      "Epoch 173/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 103.1127\n",
      "Epoch 174/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 101.3158\n",
      "Epoch 175/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 99.0715\n",
      "Epoch 176/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 97.0803\n",
      "Epoch 177/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 95.1922\n",
      "Epoch 178/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 93.4470\n",
      "Epoch 179/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 91.6721\n",
      "Epoch 180/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 89.9985\n",
      "Epoch 181/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 88.3046\n",
      "Epoch 182/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 86.7587\n",
      "Epoch 183/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 85.2468\n",
      "Epoch 184/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 83.7835\n",
      "Epoch 185/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 82.4729\n",
      "Epoch 186/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 80.8618\n",
      "Epoch 187/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 79.5653\n",
      "Epoch 188/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 78.2484\n",
      "Epoch 189/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 76.9026\n",
      "Epoch 190/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 75.6104\n",
      "Epoch 191/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 74.4351\n",
      "Epoch 192/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 73.2149\n",
      "Epoch 193/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 72.1054\n",
      "Epoch 194/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 71.0113\n",
      "Epoch 195/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 69.8982\n",
      "Epoch 196/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 68.8194\n",
      "Epoch 197/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 67.7995\n",
      "Epoch 198/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 66.7474\n",
      "Epoch 199/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 65.7032\n",
      "Epoch 200/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 64.6972\n",
      "Epoch 201/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 63.7406\n",
      "Epoch 202/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 62.9586\n",
      "Epoch 203/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 61.8541\n",
      "Epoch 204/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 60.9572\n",
      "Epoch 205/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 60.0154\n",
      "Epoch 206/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 59.3025\n",
      "Epoch 207/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 58.2538\n",
      "Epoch 208/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 57.4046\n",
      "Epoch 209/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 56.5466\n",
      "Epoch 210/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 55.6958\n",
      "Epoch 211/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 54.9044\n",
      "Epoch 212/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 54.0973\n",
      "Epoch 213/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 53.3232\n",
      "Epoch 214/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 52.5118\n",
      "Epoch 215/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 51.6946\n",
      "Epoch 216/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 50.9684\n",
      "Epoch 217/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 50.1830\n",
      "Epoch 218/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 49.4858\n",
      "Epoch 219/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 48.7383\n",
      "Epoch 220/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 48.0915\n",
      "Epoch 221/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 47.3893\n",
      "Epoch 222/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 46.6250\n",
      "Epoch 223/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 46.0289\n",
      "Epoch 224/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 45.2617\n",
      "Epoch 225/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 44.6065\n",
      "Epoch 226/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 43.9062\n",
      "Epoch 227/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 43.2745\n",
      "Epoch 228/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 42.6581\n",
      "Epoch 229/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 42.0378\n",
      "Epoch 230/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 41.3519\n",
      "Epoch 231/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 40.7220\n",
      "Epoch 232/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 40.1534\n",
      "Epoch 233/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 39.5978\n",
      "Epoch 234/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 38.9694\n",
      "Epoch 235/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 38.3439\n",
      "Epoch 236/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 37.8196\n",
      "Epoch 237/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 37.2274\n",
      "Epoch 238/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 36.6731\n",
      "Epoch 239/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 36.0909\n",
      "Epoch 240/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 35.5732\n",
      "Epoch 241/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 35.0683\n",
      "Epoch 242/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 34.4577\n",
      "Epoch 243/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 33.9721\n",
      "Epoch 244/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 33.4673\n",
      "Epoch 245/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 32.9634\n",
      "Epoch 246/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 32.4491\n",
      "Epoch 247/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 31.9995\n",
      "Epoch 248/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 31.5036\n",
      "Epoch 249/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 31.0315\n",
      "Epoch 250/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 30.6460\n",
      "Epoch 251/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 30.1542\n",
      "Epoch 252/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 29.6944\n",
      "Epoch 253/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 29.2919\n",
      "Epoch 254/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 28.8347\n",
      "Epoch 255/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 28.2957\n",
      "Epoch 256/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 27.9144\n",
      "Epoch 257/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 27.4932\n",
      "Epoch 258/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 27.0408\n",
      "Epoch 259/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 26.6728\n",
      "Epoch 260/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 26.2612\n",
      "Epoch 261/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 25.8422\n",
      "Epoch 262/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 25.4721\n",
      "Epoch 263/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 25.0446\n",
      "Epoch 264/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 24.6924\n",
      "Epoch 265/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 24.3716\n",
      "Epoch 266/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 24.0078\n",
      "Epoch 267/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 23.5877\n",
      "Epoch 268/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 23.3068\n",
      "Epoch 269/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 22.9150\n",
      "Epoch 270/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 22.5595\n",
      "Epoch 271/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 22.2602\n",
      "Epoch 272/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 21.9038\n",
      "Epoch 273/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 21.6065\n",
      "Epoch 274/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 21.2933\n",
      "Epoch 275/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 20.9781\n",
      "Epoch 276/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 20.6809\n",
      "Epoch 277/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 20.3677\n",
      "Epoch 278/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 20.0735\n",
      "Epoch 279/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 19.8026\n",
      "Epoch 280/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 19.5128\n",
      "Epoch 281/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 19.2781\n",
      "Epoch 282/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 18.9320\n",
      "Epoch 283/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 18.7019\n",
      "Epoch 284/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 18.4330\n",
      "Epoch 285/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 18.1695\n",
      "Epoch 286/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 17.9340\n",
      "Epoch 287/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 17.6692\n",
      "Epoch 288/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 17.3967\n",
      "Epoch 289/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 17.1887\n",
      "Epoch 290/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 17.0137\n",
      "Epoch 291/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 16.6512\n",
      "Epoch 292/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 16.4409\n",
      "Epoch 293/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 16.1939\n",
      "Epoch 294/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 15.9633\n",
      "Epoch 295/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 15.7354\n",
      "Epoch 296/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 15.5593\n",
      "Epoch 297/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 15.3183\n",
      "Epoch 298/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 15.0726\n",
      "Epoch 299/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 14.8539\n",
      "Epoch 300/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 14.6625\n",
      "Epoch 301/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 14.4748\n",
      "Epoch 302/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 14.2635\n",
      "Epoch 303/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 14.0722\n",
      "Epoch 304/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 13.8933\n",
      "Epoch 305/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 13.6834\n",
      "Epoch 306/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 13.5145\n",
      "Epoch 307/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 13.3380\n",
      "Epoch 308/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 13.1527\n",
      "Epoch 309/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 12.9849\n",
      "Epoch 310/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 12.8168\n",
      "Epoch 311/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 12.6473\n",
      "Epoch 312/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 12.4856\n",
      "Epoch 313/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 12.3357\n",
      "Epoch 314/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 12.1976\n",
      "Epoch 315/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 12.0390\n",
      "Epoch 316/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 11.8963\n",
      "Epoch 317/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 11.7463\n",
      "Epoch 318/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 11.6131\n",
      "Epoch 319/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 11.4763\n",
      "Epoch 320/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 11.3576\n",
      "Epoch 321/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 11.2490\n",
      "Epoch 322/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 11.0868\n",
      "Epoch 323/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 11.0122\n",
      "Epoch 324/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 10.8327\n",
      "Epoch 325/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 10.7018\n",
      "Epoch 326/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 10.5894\n",
      "Epoch 327/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 10.4624\n",
      "Epoch 328/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 10.3644\n",
      "Epoch 329/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 10.2503\n",
      "Epoch 330/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 10.1452\n",
      "Epoch 331/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 10.0652\n",
      "Epoch 332/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 9.9582\n",
      "Epoch 333/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 9.8381\n",
      "Epoch 334/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 9.7272\n",
      "Epoch 335/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 9.6153\n",
      "Epoch 336/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 9.4877\n",
      "Epoch 337/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 9.4058\n",
      "Epoch 338/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 9.2864\n",
      "Epoch 339/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 9.1796\n",
      "Epoch 340/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 9.0826\n",
      "Epoch 341/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 8.9902\n",
      "Epoch 342/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 8.8874\n",
      "Epoch 343/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 8.7814\n",
      "Epoch 344/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 8.6917\n",
      "Epoch 345/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.6074\n",
      "Epoch 346/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 8.5064\n",
      "Epoch 347/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.4161\n",
      "Epoch 348/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 8.3438\n",
      "Epoch 349/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 8.2522\n",
      "Epoch 350/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 8.1628\n",
      "Epoch 351/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.0855\n",
      "Epoch 352/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 8.0190\n",
      "Epoch 353/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.9511\n",
      "Epoch 354/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.8634\n",
      "Epoch 355/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 7.7680\n",
      "Epoch 356/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.7136\n",
      "Epoch 357/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.6428\n",
      "Epoch 358/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.5827\n",
      "Epoch 359/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.4860\n",
      "Epoch 360/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.4347\n",
      "Epoch 361/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.3747\n",
      "Epoch 362/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.2951\n",
      "Epoch 363/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.2129\n",
      "Epoch 364/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.1319\n",
      "Epoch 365/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.0751\n",
      "Epoch 366/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.0050\n",
      "Epoch 367/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.9641\n",
      "Epoch 368/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.8988\n",
      "Epoch 369/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.8604\n",
      "Epoch 370/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.7719\n",
      "Epoch 371/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.7074\n",
      "Epoch 372/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.6875\n",
      "Epoch 373/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.6480\n",
      "Epoch 374/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.5484\n",
      "Epoch 375/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.4725\n",
      "Epoch 376/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 6.4468\n",
      "Epoch 377/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.3960\n",
      "Epoch 378/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.3297\n",
      "Epoch 379/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.2828\n",
      "Epoch 380/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.2203\n",
      "Epoch 381/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.1717\n",
      "Epoch 382/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.1354\n",
      "Epoch 383/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.0824\n",
      "Epoch 384/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.0462\n",
      "Epoch 385/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 5.9878\n",
      "Epoch 386/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 5.9650\n",
      "Epoch 387/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.9134\n",
      "Epoch 388/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 5.8726\n",
      "Epoch 389/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 5.8278\n",
      "Epoch 390/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 5.7787\n",
      "Epoch 391/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 5.7658\n",
      "Epoch 392/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 5.7305\n",
      "Epoch 393/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 5.6721\n",
      "Epoch 394/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 5.6198\n",
      "Epoch 395/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 5.6010\n",
      "Epoch 396/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.5555\n",
      "Epoch 397/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 5.5159\n",
      "Epoch 398/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 5.4776\n",
      "Epoch 399/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 5.4489\n",
      "Epoch 400/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 5.4740\n",
      "Epoch 401/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.4118\n",
      "Epoch 402/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 5.3458\n",
      "Epoch 403/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 5.2914\n",
      "Epoch 404/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.2715\n",
      "Epoch 405/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 5.2583\n",
      "Epoch 406/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 5.2037\n",
      "Epoch 407/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 5.1538\n",
      "Epoch 408/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 5.1279\n",
      "Epoch 409/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 5.0951\n",
      "Epoch 410/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 5.0633\n",
      "Epoch 411/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 5.0330\n",
      "Epoch 412/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 5.0023\n",
      "Epoch 413/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 4.9512\n",
      "Epoch 414/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 4.9293\n",
      "Epoch 415/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 4.8826\n",
      "Epoch 416/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 4.8490\n",
      "Epoch 417/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 4.8194\n",
      "Epoch 418/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 4.7837\n",
      "Epoch 419/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 4.7600\n",
      "Epoch 420/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 4.7207\n",
      "Epoch 421/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 4.6889\n",
      "Epoch 422/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 4.6624\n",
      "Epoch 423/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 4.6301\n",
      "Epoch 424/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 4.5892\n",
      "Epoch 425/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 4.6046\n",
      "Epoch 426/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 4.5420\n",
      "Epoch 427/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 4.5347\n",
      "Epoch 428/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 4.4705\n",
      "Epoch 429/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 4.4479\n",
      "Epoch 430/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 4.4150\n",
      "Epoch 431/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 4.3791\n",
      "Epoch 432/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 4.3565\n",
      "Epoch 433/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 4.3610\n",
      "Epoch 434/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 4.3015\n",
      "Epoch 435/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 4.2630\n",
      "Epoch 436/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 4.2284\n",
      "Epoch 437/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 4.2213\n",
      "Epoch 438/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 4.1922\n",
      "Epoch 439/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 4.1845\n",
      "Epoch 440/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 4.1130\n",
      "Epoch 441/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 4.0858\n",
      "Epoch 442/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 4.0619\n",
      "Epoch 443/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 4.0306\n",
      "Epoch 444/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 4.0119\n",
      "Epoch 445/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.9672\n",
      "Epoch 446/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 3.9480\n",
      "Epoch 447/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 3.9174\n",
      "Epoch 448/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.9072\n",
      "Epoch 449/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 3.8955\n",
      "Epoch 450/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 3.8536\n",
      "Epoch 451/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 3.8058\n",
      "Epoch 452/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.7939\n",
      "Epoch 453/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.7608\n",
      "Epoch 454/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.7328\n",
      "Epoch 455/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 3.7024\n",
      "Epoch 456/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 3.6833\n",
      "Epoch 457/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 3.6684\n",
      "Epoch 458/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 3.6290\n",
      "Epoch 459/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.6145\n",
      "Epoch 460/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.5767\n",
      "Epoch 461/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 3.5479\n",
      "Epoch 462/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 3.5207\n",
      "Epoch 463/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 3.4967\n",
      "Epoch 464/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.4698\n",
      "Epoch 465/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 3.4544\n",
      "Epoch 466/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.4342\n",
      "Epoch 467/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 3.4185\n",
      "Epoch 468/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 3.3776\n",
      "Epoch 469/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 3.3640\n",
      "Epoch 470/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 3.3265\n",
      "Epoch 471/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 3.3135\n",
      "Epoch 472/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 3.2712\n",
      "Epoch 473/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 3.2728\n",
      "Epoch 474/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.2386\n",
      "Epoch 475/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 3.2213\n",
      "Epoch 476/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 3.1833\n",
      "Epoch 477/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 3.1656\n",
      "Epoch 478/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 3.1459\n",
      "Epoch 479/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 3.1191\n",
      "Epoch 480/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 3.0955\n",
      "Epoch 481/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 3.0732\n",
      "Epoch 482/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.0499\n",
      "Epoch 483/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.0283\n",
      "Epoch 484/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 3.0081\n",
      "Epoch 485/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 2.9851\n",
      "Epoch 486/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.9754\n",
      "Epoch 487/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 2.9463\n",
      "Epoch 488/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 2.9392\n",
      "Epoch 489/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.8969\n",
      "Epoch 490/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.8769\n",
      "Epoch 491/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 2.8604\n",
      "Epoch 492/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 2.8532\n",
      "Epoch 493/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.8494\n",
      "Epoch 494/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 2.8146\n",
      "Epoch 495/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.7791\n",
      "Epoch 496/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.7688\n",
      "Epoch 497/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.7450\n",
      "Epoch 498/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 2.7148\n",
      "Epoch 499/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 2.7245\n",
      "Epoch 500/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.6747\n",
      "Epoch 501/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.6559\n",
      "Epoch 502/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 2.6374\n",
      "Epoch 503/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.6170\n",
      "Epoch 504/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.5983\n",
      "Epoch 505/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.5880\n",
      "Epoch 506/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 2.5697\n",
      "Epoch 507/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 2.5454\n",
      "Epoch 508/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.5555\n",
      "Epoch 509/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 2.5083\n",
      "Epoch 510/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 2.5035\n",
      "Epoch 511/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 2.4747\n",
      "Epoch 512/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 2.4528\n",
      "Epoch 513/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 2.4497\n",
      "Epoch 514/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 2.4192\n",
      "Epoch 515/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.4096\n",
      "Epoch 516/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.3909\n",
      "Epoch 517/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 2.3675\n",
      "Epoch 518/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 2.3523\n",
      "Epoch 519/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.3324\n",
      "Epoch 520/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 2.3131\n",
      "Epoch 521/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 2.2975\n",
      "Epoch 522/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 2.3005\n",
      "Epoch 523/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.2660\n",
      "Epoch 524/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 2.2404\n",
      "Epoch 525/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 2.2483\n",
      "Epoch 526/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 2.2535\n",
      "Epoch 527/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.1912\n",
      "Epoch 528/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.1825\n",
      "Epoch 529/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 2.1847\n",
      "Epoch 530/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.1683\n",
      "Epoch 531/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.1472\n",
      "Epoch 532/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 2.1365\n",
      "Epoch 533/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 2.1059\n",
      "Epoch 534/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 2.0811\n",
      "Epoch 535/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 2.0611\n",
      "Epoch 536/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.0568\n",
      "Epoch 537/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 2.0423\n",
      "Epoch 538/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 2.0258\n",
      "Epoch 539/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.0242\n",
      "Epoch 540/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.9851\n",
      "Epoch 541/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.9940\n",
      "Epoch 542/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.9611\n",
      "Epoch 543/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.9468\n",
      "Epoch 544/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.9510\n",
      "Epoch 545/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.9320\n",
      "Epoch 546/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.9018\n",
      "Epoch 547/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.8910\n",
      "Epoch 548/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.8990\n",
      "Epoch 549/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.8657\n",
      "Epoch 550/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.8643\n",
      "Epoch 551/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 1.8432\n",
      "Epoch 552/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.8207\n",
      "Epoch 553/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.8078\n",
      "Epoch 554/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.7874\n",
      "Epoch 555/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 1.7791\n",
      "Epoch 556/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.7719\n",
      "Epoch 557/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.7384\n",
      "Epoch 558/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.7355\n",
      "Epoch 559/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 1.7297\n",
      "Epoch 560/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.7048\n",
      "Epoch 561/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.7071\n",
      "Epoch 562/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 1.6846\n",
      "Epoch 563/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.6755\n",
      "Epoch 564/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.6546\n",
      "Epoch 565/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.6395\n",
      "Epoch 566/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.6244\n",
      "Epoch 567/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.6126\n",
      "Epoch 568/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.6073\n",
      "Epoch 569/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.5978\n",
      "Epoch 570/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.5860\n",
      "Epoch 571/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.5636\n",
      "Epoch 572/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.5547\n",
      "Epoch 573/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.5450\n",
      "Epoch 574/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.5397\n",
      "Epoch 575/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.5444\n",
      "Epoch 576/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.5305\n",
      "Epoch 577/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.5031\n",
      "Epoch 578/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.4871\n",
      "Epoch 579/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.4643\n",
      "Epoch 580/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.4594\n",
      "Epoch 581/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.4401\n",
      "Epoch 582/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.4310\n",
      "Epoch 583/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.4190\n",
      "Epoch 584/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.4025\n",
      "Epoch 585/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.4341\n",
      "Epoch 586/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.3798\n",
      "Epoch 587/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.3759\n",
      "Epoch 588/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.3709\n",
      "Epoch 589/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.3666\n",
      "Epoch 590/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.3433\n",
      "Epoch 591/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.3238\n",
      "Epoch 592/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.3031\n",
      "Epoch 593/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.2876\n",
      "Epoch 594/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 1.2960\n",
      "Epoch 595/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.2821\n",
      "Epoch 596/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.2607\n",
      "Epoch 597/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.2424\n",
      "Epoch 598/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.2513\n",
      "Epoch 599/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.2386\n",
      "Epoch 600/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2228\n",
      "Epoch 601/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.1910\n",
      "Epoch 602/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.1792\n",
      "Epoch 603/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.1802\n",
      "Epoch 604/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.1654\n",
      "Epoch 605/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.1519\n",
      "Epoch 606/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.1418\n",
      "Epoch 607/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.1404\n",
      "Epoch 608/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.1183\n",
      "Epoch 609/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.1107\n",
      "Epoch 610/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.0997\n",
      "Epoch 611/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.0891\n",
      "Epoch 612/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.0731\n",
      "Epoch 613/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.0786\n",
      "Epoch 614/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.0624\n",
      "Epoch 615/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.0481\n",
      "Epoch 616/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.0358\n",
      "Epoch 617/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.0369\n",
      "Epoch 618/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.0197\n",
      "Epoch 619/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.0077\n",
      "Epoch 620/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.0059\n",
      "Epoch 621/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.9980\n",
      "Epoch 622/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.0039\n",
      "Epoch 623/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.9831\n",
      "Epoch 624/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.9637\n",
      "Epoch 625/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.9549\n",
      "Epoch 626/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.9469\n",
      "Epoch 627/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.9515\n",
      "Epoch 628/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.9441\n",
      "Epoch 629/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.9371\n",
      "Epoch 630/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.9656\n",
      "Epoch 631/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.9019\n",
      "Epoch 632/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.8878\n",
      "Epoch 633/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.8823\n",
      "Epoch 634/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.8807\n",
      "Epoch 635/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.8844\n",
      "Epoch 636/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.8688\n",
      "Epoch 637/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.8610\n",
      "Epoch 638/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.8524\n",
      "Epoch 639/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.8558\n",
      "Epoch 640/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.8401\n",
      "Epoch 641/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.8219\n",
      "Epoch 642/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.8160\n",
      "Epoch 643/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.8077\n",
      "Epoch 644/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.7944\n",
      "Epoch 645/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7975\n",
      "Epoch 646/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.7899\n",
      "Epoch 647/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.7864\n",
      "Epoch 648/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.7977\n",
      "Epoch 649/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7966\n",
      "Epoch 650/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7551\n",
      "Epoch 651/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.7554\n",
      "Epoch 652/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7702\n",
      "Epoch 653/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.7536\n",
      "Epoch 654/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7522\n",
      "Epoch 655/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.7292\n",
      "Epoch 656/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.7327\n",
      "Epoch 657/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.7164\n",
      "Epoch 658/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.7154\n",
      "Epoch 659/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.6971\n",
      "Epoch 660/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.6940\n",
      "Epoch 661/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.6974\n",
      "Epoch 662/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6902\n",
      "Epoch 663/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6761\n",
      "Epoch 664/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.6758\n",
      "Epoch 665/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.6690\n",
      "Epoch 666/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.6692\n",
      "Epoch 667/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6609\n",
      "Epoch 668/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.6568\n",
      "Epoch 669/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.6501\n",
      "Epoch 670/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.6479\n",
      "Epoch 671/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.6323\n",
      "Epoch 672/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.6318\n",
      "Epoch 673/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.6241\n",
      "Epoch 674/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6190\n",
      "Epoch 675/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.6234\n",
      "Epoch 676/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.6145\n",
      "Epoch 677/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.6213\n",
      "Epoch 678/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.6132\n",
      "Epoch 679/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.6000\n",
      "Epoch 680/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6027\n",
      "Epoch 681/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5990\n",
      "Epoch 682/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5890\n",
      "Epoch 683/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5824\n",
      "Epoch 684/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5832\n",
      "Epoch 685/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5835\n",
      "Epoch 686/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5789\n",
      "Epoch 687/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5708\n",
      "Epoch 688/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5684\n",
      "Epoch 689/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.5651\n",
      "Epoch 690/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5558\n",
      "Epoch 691/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5525\n",
      "Epoch 692/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.5566\n",
      "Epoch 693/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5515\n",
      "Epoch 694/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5495\n",
      "Epoch 695/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5467\n",
      "Epoch 696/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5452\n",
      "Epoch 697/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5370\n",
      "Epoch 698/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5350\n",
      "Epoch 699/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5417\n",
      "Epoch 700/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5227\n",
      "Epoch 701/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5196\n",
      "Epoch 702/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5162\n",
      "Epoch 703/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5137\n",
      "Epoch 704/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5179\n",
      "Epoch 705/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5243\n",
      "Epoch 706/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5192\n",
      "Epoch 707/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5113\n",
      "Epoch 708/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5027\n",
      "Epoch 709/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5115\n",
      "Epoch 710/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5046\n",
      "Epoch 711/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.4998\n",
      "Epoch 712/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4958\n",
      "Epoch 713/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5166\n",
      "Epoch 714/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5017\n",
      "Epoch 715/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4885\n",
      "Epoch 716/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4798\n",
      "Epoch 717/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4759\n",
      "Epoch 718/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4829\n",
      "Epoch 719/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4797\n",
      "Epoch 720/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4710\n",
      "Epoch 721/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4670\n",
      "Epoch 722/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.4662\n",
      "Epoch 723/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4784\n",
      "Epoch 724/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4747\n",
      "Epoch 725/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4678\n",
      "Epoch 726/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4568\n",
      "Epoch 727/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4588\n",
      "Epoch 728/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4721\n",
      "Epoch 729/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.4622\n",
      "Epoch 730/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.4638\n",
      "Epoch 731/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4512\n",
      "Epoch 732/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4446\n",
      "Epoch 733/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4473\n",
      "Epoch 734/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4497\n",
      "Epoch 735/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.4486\n",
      "Epoch 736/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.4405\n",
      "Epoch 737/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4331\n",
      "Epoch 738/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4468\n",
      "Epoch 739/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4627\n",
      "Epoch 740/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.4500\n",
      "Epoch 741/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4321\n",
      "Epoch 742/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.4342\n",
      "Epoch 743/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.4232\n",
      "Epoch 744/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4201\n",
      "Epoch 745/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4271\n",
      "Epoch 746/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4197\n",
      "Epoch 747/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.4354\n",
      "Epoch 748/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.4429\n",
      "Epoch 749/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4172\n",
      "Epoch 750/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4229\n",
      "Epoch 751/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.4096\n",
      "Epoch 752/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.4313\n",
      "Epoch 753/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4163\n",
      "Epoch 754/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4144\n",
      "Epoch 755/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.4189\n",
      "Epoch 756/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.4066\n",
      "Epoch 757/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4073\n",
      "Epoch 758/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4114\n",
      "Epoch 759/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4026\n",
      "Epoch 760/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4050\n",
      "Epoch 761/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.4036\n",
      "Epoch 762/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4081\n",
      "Epoch 763/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.4058\n",
      "Epoch 764/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.3929\n",
      "Epoch 765/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.3925\n",
      "Epoch 766/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.3897\n",
      "Epoch 767/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.3953\n",
      "Epoch 768/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.3912\n",
      "Epoch 769/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.3968\n",
      "Epoch 770/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.3921\n",
      "Epoch 771/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.3859\n",
      "Epoch 772/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4004\n",
      "Epoch 773/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.3845\n",
      "Epoch 774/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.3801\n",
      "Epoch 775/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.3856\n",
      "Epoch 776/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.3788\n",
      "Epoch 777/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.3824\n",
      "Epoch 778/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.3781\n",
      "Epoch 779/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.3812\n",
      "Epoch 780/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.3736\n",
      "Epoch 781/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.3760\n",
      "Epoch 782/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.3711\n",
      "Epoch 783/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.3725\n",
      "Epoch 784/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.3964\n",
      "Epoch 785/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.3685\n",
      "Epoch 786/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.3695\n",
      "Epoch 787/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.3749\n",
      "Epoch 788/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.3705\n",
      "Epoch 789/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.3672\n",
      "Epoch 790/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.3853\n",
      "Epoch 791/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.3665\n",
      "Epoch 792/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.3633\n",
      "Epoch 793/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.3707\n",
      "Epoch 794/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.3627\n",
      "Epoch 795/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.3696\n",
      "Epoch 796/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.3658\n",
      "Epoch 797/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.3616\n",
      "Epoch 798/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.3705\n",
      "Epoch 799/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.3632\n",
      "Epoch 800/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.3573\n",
      "Epoch 801/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.3599\n",
      "Epoch 802/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.3596\n",
      "Epoch 803/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.3535\n",
      "Epoch 804/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.3547\n",
      "Epoch 805/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.3518\n",
      "Epoch 806/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3505\n",
      "Epoch 807/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.3504\n",
      "Epoch 808/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.3568\n",
      "Epoch 809/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.3576\n",
      "Epoch 810/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.3471\n",
      "Epoch 811/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.3425\n",
      "Epoch 812/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3500\n",
      "Epoch 813/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3522\n",
      "Epoch 814/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.3436\n",
      "Epoch 815/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.3582\n",
      "Epoch 816/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.3981\n",
      "Epoch 817/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3681\n",
      "Epoch 818/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.3464\n",
      "Epoch 819/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3605\n",
      "Epoch 820/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.3491\n",
      "Epoch 821/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.3726\n",
      "Epoch 822/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.3588\n",
      "Epoch 823/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.3561\n",
      "Epoch 824/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.3538\n",
      "Epoch 825/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.3677\n",
      "Epoch 826/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.3364\n",
      "Epoch 827/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.3304\n",
      "Epoch 828/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.3262\n",
      "Epoch 829/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.3331\n",
      "Epoch 830/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.3281\n",
      "Epoch 831/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.3325\n",
      "Epoch 832/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.3610\n",
      "Epoch 833/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3412\n",
      "Epoch 834/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.3281\n",
      "Epoch 835/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.3279\n",
      "Epoch 836/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.3318\n",
      "Epoch 837/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.3267\n",
      "Epoch 838/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.3224\n",
      "Epoch 839/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.3321\n",
      "Epoch 840/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.3181\n",
      "Epoch 841/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.3428\n",
      "Epoch 842/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.3269\n",
      "Epoch 843/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.3315\n",
      "Epoch 844/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.3221\n",
      "Epoch 845/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.3212\n",
      "Epoch 846/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.3181\n",
      "Epoch 847/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3238\n",
      "Epoch 848/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.3161\n",
      "Epoch 849/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.3197\n",
      "Epoch 850/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.3153\n",
      "Epoch 851/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.3126\n",
      "Epoch 852/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3203\n",
      "Epoch 853/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.3110\n",
      "Epoch 854/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3104\n",
      "Epoch 855/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.3155\n",
      "Epoch 856/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.3304\n",
      "Epoch 857/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.3315\n",
      "Epoch 858/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.3120\n",
      "Epoch 859/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.3093\n",
      "Epoch 860/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.3216\n",
      "Epoch 861/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.3148\n",
      "Epoch 862/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.3112\n",
      "Epoch 863/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.3109\n",
      "Epoch 864/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.3116\n",
      "Epoch 865/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.3301\n",
      "Epoch 866/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.3289\n",
      "Epoch 867/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.3199\n",
      "Epoch 868/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3278\n",
      "Epoch 869/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.3256\n",
      "Epoch 870/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.3249\n",
      "Epoch 871/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3042\n",
      "Epoch 872/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.3005\n",
      "Epoch 873/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.3064\n",
      "Epoch 874/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.3051\n",
      "Epoch 875/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.3021\n",
      "Epoch 876/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.2965\n",
      "Epoch 877/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.3074\n",
      "Epoch 878/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.3040\n",
      "Epoch 879/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.2915\n",
      "Epoch 880/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.3145\n",
      "Epoch 881/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3094\n",
      "Epoch 882/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.3036\n",
      "Epoch 883/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3186\n",
      "Epoch 884/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.3134\n",
      "Epoch 885/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.3013\n",
      "Epoch 886/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2978\n",
      "Epoch 887/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.3051\n",
      "Epoch 888/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2940\n",
      "Epoch 889/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.3007\n",
      "Epoch 890/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.3361\n",
      "Epoch 891/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.3167\n",
      "Epoch 892/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.3082\n",
      "Epoch 893/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2949\n",
      "Epoch 894/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2956\n",
      "Epoch 895/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.3042\n",
      "Epoch 896/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.3621\n",
      "Epoch 897/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.3339\n",
      "Epoch 898/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.3181\n",
      "Epoch 899/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2924\n",
      "Epoch 900/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2917\n",
      "Epoch 901/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2912\n",
      "Epoch 902/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2854\n",
      "Epoch 903/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2880\n",
      "Epoch 904/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2848\n",
      "Epoch 905/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2884\n",
      "Epoch 906/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2861\n",
      "Epoch 907/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2797\n",
      "Epoch 908/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.3241\n",
      "Epoch 909/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.3308\n",
      "Epoch 910/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.4067\n",
      "Epoch 911/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4297\n",
      "Epoch 912/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2978\n",
      "Epoch 913/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2885\n",
      "Epoch 914/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.2867\n",
      "Epoch 915/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2905\n",
      "Epoch 916/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.3015\n",
      "Epoch 917/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2913\n",
      "Epoch 918/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.3216\n",
      "Epoch 919/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.2838\n",
      "Epoch 920/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.2943\n",
      "Epoch 921/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2789\n",
      "Epoch 922/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2794\n",
      "Epoch 923/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.3044\n",
      "Epoch 924/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2966\n",
      "Epoch 925/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.2882\n",
      "Epoch 926/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2758\n",
      "Epoch 927/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2707\n",
      "Epoch 928/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2705\n",
      "Epoch 929/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2707\n",
      "Epoch 930/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2797\n",
      "Epoch 931/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2953\n",
      "Epoch 932/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.3417\n",
      "Epoch 933/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2905\n",
      "Epoch 934/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2888\n",
      "Epoch 935/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.3315\n",
      "Epoch 936/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.3289\n",
      "Epoch 937/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.3228\n",
      "Epoch 938/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2965\n",
      "Epoch 939/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3453\n",
      "Epoch 940/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.3758\n",
      "Epoch 941/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2751\n",
      "Epoch 942/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.2652\n",
      "Epoch 943/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.2671\n",
      "Epoch 944/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2729\n",
      "Epoch 945/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2774\n",
      "Epoch 946/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2716\n",
      "Epoch 947/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.3069\n",
      "Epoch 948/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2718\n",
      "Epoch 949/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2932\n",
      "Epoch 950/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.3024\n",
      "Epoch 951/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2614\n",
      "Epoch 952/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2835\n",
      "Epoch 953/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2715\n",
      "Epoch 954/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2926\n",
      "Epoch 955/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2581\n",
      "Epoch 956/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.2622\n",
      "Epoch 957/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2556\n",
      "Epoch 958/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2677\n",
      "Epoch 959/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2735\n",
      "Epoch 960/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2598\n",
      "Epoch 961/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2560\n",
      "Epoch 962/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2629\n",
      "Epoch 963/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2579\n",
      "Epoch 964/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2884\n",
      "Epoch 965/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2858\n",
      "Epoch 966/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2675\n",
      "Epoch 967/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.2708\n",
      "Epoch 968/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.2819\n",
      "Epoch 969/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2619\n",
      "Epoch 970/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2666\n",
      "Epoch 971/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2980\n",
      "Epoch 972/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2675\n",
      "Epoch 973/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.3000\n",
      "Epoch 974/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.3180\n",
      "Epoch 975/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.3364\n",
      "Epoch 976/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.3063\n",
      "Epoch 977/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.2764\n",
      "Epoch 978/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.2803\n",
      "Epoch 979/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.2620\n",
      "Epoch 980/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2836\n",
      "Epoch 981/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.3429\n",
      "Epoch 982/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.3841\n",
      "Epoch 983/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2910\n",
      "Epoch 984/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3252\n",
      "Epoch 985/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.3166\n",
      "Epoch 986/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.3243\n",
      "Epoch 987/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.3120\n",
      "Epoch 988/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2501\n",
      "Epoch 989/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2517\n",
      "Epoch 990/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2727\n",
      "Epoch 991/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.3606\n",
      "Epoch 992/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2609\n",
      "Epoch 993/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2640\n",
      "Epoch 994/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2611\n",
      "Epoch 995/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2644\n",
      "Epoch 996/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2655\n",
      "Epoch 997/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3032\n",
      "Epoch 998/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.2734\n",
      "Epoch 999/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2502\n",
      "Epoch 1000/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a49b07908>"
      ]
     },
     "execution_count": 570,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_tos = Sequential()\n",
    "NN_tos.add(Dense(units=8,input_dim=X_train.shape[1],activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_tos.add(Dense(units=4, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "#NN_tos.add(Dense(units=4, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_tos.add(Dense(units=1,activation='linear'))\n",
    "NN_tos.compile(loss='mse', optimizer='adam')\n",
    "NN_tos.fit(np.array(X_train), np.array(y_train), epochs=1000,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN_predictions</th>\n",
       "      <th>actual</th>\n",
       "      <th>GBR_predictions</th>\n",
       "      <th>LY_turnovers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>1.809606</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.812886</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>1.878378</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.876003</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1.179983</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.521914</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>2.128195</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.702078</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>2.142111</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.722741</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>1.941534</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.456472</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>1.229788</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.540747</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.056097</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.422336</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>1.685934</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.296503</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>0.957449</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.482042</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>0.910330</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.515332</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>2.118444</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.545929</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>1.777441</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.448162</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>1.908743</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.456774</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>1.823766</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.224496</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>1.491903</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.260688</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.448492</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.713037</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0.985693</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.231155</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.368978</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.039413</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.380102</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.084515</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>1.635320</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.202821</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>1.846670</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.415629</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>1.048269</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.245606</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.939443</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.466786</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.575994</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.177393</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0.811346</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.318890</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>0.888098</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.382355</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>1.236685</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.625206</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>1.605871</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.467542</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>1.750509</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.446071</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>1.821798</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.384647</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>1.808355</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.243258</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>1.858175</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.486396</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>1.882726</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.265405</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>2.283941</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.298583</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.499822</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.030092</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1.580114</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.029851</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>1.324011</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.345322</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1.213979</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.005219</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>0.754614</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.346752</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>1.722524</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.330680</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>2.398519</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.233860</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>1.685491</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.060324</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>1.098394</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.850451</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>1.356588</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.075659</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>1.300161</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.086355</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>1.301656</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.895360</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>1.707464</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.481501</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.958654</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.663204</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>1.211218</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.819402</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     NN_predictions  actual  GBR_predictions  LY_turnovers\n",
       "612        1.809606     2.0         2.812886           2.7\n",
       "167        1.878378     3.0         2.876003           2.7\n",
       "145        1.179983     2.3         2.521914           2.7\n",
       "538        2.128195     2.8         2.702078           2.7\n",
       "421        2.142111     2.3         2.722741           2.7\n",
       "494        1.941534     2.6         2.456472           2.7\n",
       "338        1.229788     2.1         1.540747           2.7\n",
       "32         1.056097     2.4         2.422336           2.7\n",
       "397        1.685934     2.4         2.296503           2.6\n",
       "390        0.957449     2.4         1.482042           2.6\n",
       "443        0.910330     3.2         2.515332           2.6\n",
       "227        2.118444     2.2         2.545929           2.6\n",
       "630        1.777441     2.7         2.448162           2.6\n",
       "593        1.908743     2.7         2.456774           2.5\n",
       "606        1.823766     2.9         2.224496           2.5\n",
       "381        1.491903     2.2         2.260688           2.5\n",
       "19         2.448492     2.3         2.713037           2.5\n",
       "283        0.985693     2.5         2.231155           2.5\n",
       "40         1.368978     2.3         2.039413           2.5\n",
       "95         1.380102     1.9         2.084515           2.5\n",
       "375        1.635320     1.9         2.202821           2.5\n",
       "419        1.846670     2.6         2.415629           2.5\n",
       "480        1.048269     2.1         2.245606           2.4\n",
       "152        0.939443     2.3         2.466786           2.4\n",
       "21         1.575994     2.9         2.177393           2.4\n",
       "224        0.811346     2.2         2.318890           2.4\n",
       "610        0.888098     2.1         1.382355           2.4\n",
       "217        1.236685     1.0         1.625206           2.4\n",
       "504        1.605871     2.6         2.467542           2.4\n",
       "284        1.750509     2.8         2.446071           2.4\n",
       "317        1.821798     2.1         2.384647           2.4\n",
       "655        1.808355     2.5         2.243258           2.4\n",
       "487        1.858175     2.5         2.486396           2.4\n",
       "184        1.882726     2.3         2.265405           2.4\n",
       "644        2.283941     2.3         2.298583           2.3\n",
       "31         1.499822     2.6         2.030092           2.3\n",
       "414        1.580114     2.6         2.029851           2.3\n",
       "320        1.324011     2.5         2.345322           2.3\n",
       "107        1.213979     2.0         2.005219           2.3\n",
       "345        0.754614     1.1         1.346752           2.3\n",
       "402        1.722524     1.6         2.330680           2.3\n",
       "357        2.398519     2.6         2.233860           2.3\n",
       "537        1.685491     2.1         2.060324           2.3\n",
       "329        1.098394     2.2         1.850451           2.3\n",
       "150        1.356588     1.2         2.075659           2.3\n",
       "576        1.300161     2.2         2.086355           2.3\n",
       "364        1.301656     2.2         1.895360           2.3\n",
       "253        1.707464     2.5         2.481501           2.2\n",
       "146        0.958654     2.2         1.663204           2.2\n",
       "642        1.211218     1.3         1.819402           2.2"
      ]
     },
     "execution_count": 731,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = NN_tos.predict(X_test)\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.5)\n",
    "gbr.fit(X_train,y_train)\n",
    "gbr_predictions = gbr.predict(X_test)\n",
    "LR = LinearRegression(fit_intercept=True).fit(X_train,y_train)\n",
    "\n",
    "testing = pd.DataFrame(predictions)\n",
    "testing.columns=['NN_predictions']\n",
    "testing['actual'] = y_test.reset_index()['turnovers']\n",
    "testing['GBR_predictions']=gbr_predictions\n",
    "testing['LY_turnovers']=X_test['turnovers_ly'].reset_index()['turnovers_ly']\n",
    "testing.sort_values(by='LY_turnovers',ascending=False)[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2017tos = tos[tos['season']==2017].drop(['team','player','turnovers','Games'],axis=1)\n",
    "#pred_2017blocks = blocks[blocks['season']==2017][['blocks_ly','career_blocks','starter_change']]\n",
    "tos_2017 = NN_tos.predict(pred_2017tos)\n",
    "gbr_tos_2017 = pd.DataFrame(gbr.predict(pred_2017tos))\n",
    "LR_tos_2017 = pd.DataFrame(LR.predict(pred_2017tos))\n",
    "test_2 =pd.DataFrame(tos_2017)\n",
    "test_3 = pd.merge(tos,pred_2017tos,left_index=True,right_index=True).reset_index()\n",
    "test_3['predictions']=test_2[0]\n",
    "test_3['gbr_pred'] = gbr_tos_2017[0]\n",
    "test_3['LR_pred'] = LR_tos_2017[0]\n",
    "test_3['mean_pred'] = (test_3['predictions']+test_3['gbr_pred']+test_3['LR_pred'])/3\n",
    "test_3 = test_3[test_3['Games']>30]\n",
    "test_3[['player','turnovers','predictions','LR_pred','gbr_pred','mean_pred','turnovers_ly_x']].sort_values(by='turnovers_ly_x',ascending=False)[0:50]\n",
    "\n",
    "to_2017 = test_3[['player','LR_pred']]\n",
    "to_2017.columns = ['player','turnover_prediction']\n",
    "df_2017 = pd.merge(df_2017,to_2017,how='left',left_on='player',right_on='player')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE using LR:0.16176478072561423\n",
      "MSE using GB:0.15615624546701495\n",
      "MSE using NN:0.9436539449348589\n",
      "MSE using combo:0.26753266621472155\n",
      "MSE using mean:0.6552399737015094\n",
      "MSE using last year stats:0.210833333333333\n"
     ]
    }
   ],
   "source": [
    "print('MSE using LR:{}'.format(np.mean((test_3['turnovers']-test_3['LR_pred'])**2)))\n",
    "print('MSE using GB:{}'.format(np.mean((test_3['turnovers']-test_3['gbr_pred'])**2)))\n",
    "print('MSE using NN:{}'.format(np.mean((test_3['turnovers']-test_3['predictions'])**2)))\n",
    "print('MSE using combo:{}'.format(np.mean((test_3['turnovers']-test_3['mean_pred'])**2)))\n",
    "print('MSE using mean:{}'.format(np.mean((test_3['turnovers']-np.mean(test_3['turnovers']))**2)))\n",
    "print('MSE using last year stats:{}'.format(np.mean((test_3['turnovers']-test_3['turnovers_ly_x'])**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [],
   "source": [
    " query= '''\n",
    "        \n",
    "        DROP TABLE IF EXISTS percentages;\n",
    "        CREATE TABLE percentages(\n",
    "        season int, --these come from player_stats\n",
    "        player varchar(50),\n",
    "        Age int,\n",
    "        team varchar(50),\n",
    "        FGM float, -- these come from player_stats\n",
    "        FGA float,\n",
    "        FG_percent float,\n",
    "        FG_percent_ly float,\n",
    "        FGM_ly float,\n",
    "        FGA_ly float,\n",
    "        FTM float,\n",
    "        FTA float,\n",
    "        FT_percent float,\n",
    "        FT_percent_ly float,\n",
    "        FTM_ly float,\n",
    "        FTA_ly float,\n",
    "        threes_ly float,\n",
    "        change_threes float,\n",
    "        points_ly float,\n",
    "        change_points_ly float,\n",
    "        starter_change int,\n",
    "        C_PF int,\n",
    "        PG int,\n",
    "        SG_SF int,\n",
    "        Games int,\n",
    "        \n",
    "         -- these come from team_changes\n",
    "        high_usageplayer_added int,\n",
    "        usagemin_opened float,\n",
    "        maxusage_added float,\n",
    "        high_usageplayer_dropped int,\n",
    "        points_opened float,\n",
    "        max_pointsdropped float,\n",
    "        max_pointsadded float,\n",
    "        \n",
    "        three_ar_ly float, -- from player_advstats\n",
    "        change_3ar float,\n",
    "        per_ly float,\n",
    "        change_per float,\n",
    "        usagerank float,\n",
    "        usagerank_ly float,\n",
    "        offensive_winshares float,\n",
    "        offensive_boxplusminus float,\n",
    "        boxplusminus float,\n",
    "        value_overreplacement float,\n",
    "        \n",
    "        career_FGM float,\n",
    "        career_FGA float,\n",
    "        career_FGPercent float,\n",
    "        career_FTM float,\n",
    "        career_FTA float,\n",
    "        career_FTPercent float,\n",
    "        yearspro int\n",
    "        );\n",
    "        \n",
    "        INSERT INTO percentages(season,player,age,team,FGM,FGA,FG_percent,FG_percent_ly,FGM_ly,FGA_ly,FTM,FTA,FT_percent\n",
    "        ,FT_percent_ly,FTM_ly,FTA_ly,threes_ly,change_threes,points_ly,change_points_ly,starter_change,C_PF,PG,SG_SF,Games)\n",
    "        SELECT season,player,age,startingteam,FG,FGA,case when FGA>0 then FG/FGA else 0 end as FG_percent,\n",
    "        case when fga_ly>0 then fg_ly/fga_ly else 0 end as FG_percent_ly,FG_ly,fga_ly,FTM,FTA,\n",
    "        case when FTA>0 then FTM/FTA else 0 end, case when fta_ly>0 then FTM_ly/FTA_ly else 0 end, FTM_ly,FTA_ly,\n",
    "        threes_ly,change_threes,points_ly,change_points_ly,starter-starter_ly,case when pos in ('C','PF') then 1 else 0 end,\n",
    "        case when pos='PG' then 1 else 0 end,case when pos in('SG','SF') then 1 else 0 end,Games\n",
    "        from player_stats;\n",
    "        \n",
    "        update percentages tp\n",
    "        set high_usageplayer_added = tc.high_usageplayer_added,usagemin_opened=tc.usagemin_opened,\n",
    "        maxusage_added=tc.max_usageadded,high_usageplayer_dropped=tc.high_usageplayer_dropped,points_opened=tc.points_opened,\n",
    "        max_pointsdropped=tc.max_pointsdropped,max_pointsadded=tc.max_pointsadded\n",
    "        from team_changes tc\n",
    "        where tc.team = tp.team and tp.season=tc.season;\n",
    "        \n",
    "        update percentages tp\n",
    "        set three_ar_ly = pa.threear_ly,change_3ar=pa.change_3ar,per_ly=pa.per_ly,change_per=pa.change_per,\n",
    "        usagerank=pa.usagerank,usagerank_ly=pa.usagerank_ly,offensive_winshares=pa.offensive_winshares,\n",
    "        offensive_boxplusminus=pa.offensive_boxplusminus,boxplusminus=pa.boxplusminus,value_overreplacement=pa.value_overreplacement\n",
    "        from player_advstats pa\n",
    "        where tp.player = pa.player and tp.season = pa.season and tp.team = pa.startingteam;\n",
    "        \n",
    "        update percentages tp\n",
    "        set career_fgm = pc.career_fgm,career_fga = pc.career_fga,career_FGpercent = case when pc.career_FGA>0 then pc.career_FGM/pc.career_FGA else 0 end,\n",
    "        career_FTM = pc.career_FTM,career_FTA = pc.career_FTA,career_FTPercent = case when pc.career_FTA>0 then pc.career_FTM/pc.career_FTA else 0 end,yearspro = pc.yearspro\n",
    "        from player_careerstats pc\n",
    "        where tp.player = pc.player and tp.season = pc.season;\n",
    "        \n",
    "        \n",
    "        select * from percentages where season>2009\n",
    "        '''\n",
    "\n",
    "cur.execute(query)\n",
    "data = cur.fetchall()\n",
    "percentages_df = pd.DataFrame(np.array(data))\n",
    "percentages_df.columns = ['season','player','age','team','FGM','FGA','FG_percent','FG_percent_ly','FGM_ly','FGA_ly','FTM','FTA',\n",
    "                     'FT_percent','FT_percent_ly','FTM_ly','FTA_ly','3PM_ly','3PM_change','points_ly','change_points_ly','starter_change'\n",
    "                     ,'C_PF','PG','SG_SF','Games','high_usageplayer_added','usagemin_opened','maxusage_added','high_usageplayer_dropped'\n",
    "                     ,'points_opened','max_pointsdropped','max_pointsadded','three_ar_ly','change_3ar','per_ly','change_per','usagerank','usagerank_ly'\n",
    "                     ,'offensive_winshares','offensive_boxplusminus','boxplusminus','value_overreplacement','career_FGM'\n",
    "                     ,'career_FGA','career_FGpercent','career_FTM','career_FTA','career_FTPercent','yearspro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "percentages_df['age_squared']=percentages_df['age']*percentages_df['age']\n",
    "percentages = percentages_df[percentages_df['FGM_ly'].notna()]\n",
    "for i in percentages.columns:\n",
    "    if i not in(['player','team']):\n",
    "        percentages[i]=pd.to_numeric(percentages[i])\n",
    "percentages = percentages.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = percentages[(percentages['season']!=2017) & (percentages['Games']>30)].drop(['player','team','FGM','FGA','FG_percent','FTM','FTA','Games'],axis=1)\n",
    "y = percentages[(percentages['season']!=2017) & (percentages['Games']>30)]['FGM']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1564/1564 [==============================] - 3s 2ms/step - loss: 2246.9775\n",
      "Epoch 2/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 283.7896\n",
      "Epoch 3/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 138.4396\n",
      "Epoch 4/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 77.1032\n",
      "Epoch 5/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 48.4732\n",
      "Epoch 6/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 39.6165\n",
      "Epoch 7/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 32.8565\n",
      "Epoch 8/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 30.9233\n",
      "Epoch 9/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 29.4573\n",
      "Epoch 10/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 28.0008\n",
      "Epoch 11/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 27.0016\n",
      "Epoch 12/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 25.9337\n",
      "Epoch 13/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 24.9353\n",
      "Epoch 14/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 24.4035\n",
      "Epoch 15/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 23.6662\n",
      "Epoch 16/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 22.2610\n",
      "Epoch 17/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 21.5473\n",
      "Epoch 18/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 20.8294\n",
      "Epoch 19/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 20.4632\n",
      "Epoch 20/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 19.9646\n",
      "Epoch 21/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 19.2912\n",
      "Epoch 22/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 18.8704\n",
      "Epoch 23/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 18.4459\n",
      "Epoch 24/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 18.5695\n",
      "Epoch 25/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 17.7035\n",
      "Epoch 26/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 17.2617\n",
      "Epoch 27/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 17.5757\n",
      "Epoch 28/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 16.4007\n",
      "Epoch 29/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 15.9687\n",
      "Epoch 30/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 15.6217\n",
      "Epoch 31/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 15.4822\n",
      "Epoch 32/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 14.9867\n",
      "Epoch 33/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 14.5631\n",
      "Epoch 34/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 14.2725\n",
      "Epoch 35/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 14.1510\n",
      "Epoch 36/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 13.7830\n",
      "Epoch 37/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 13.3641\n",
      "Epoch 38/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 13.2045\n",
      "Epoch 39/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 12.8183\n",
      "Epoch 40/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 12.6393\n",
      "Epoch 41/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 12.4012\n",
      "Epoch 42/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 12.2463\n",
      "Epoch 43/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 12.6979\n",
      "Epoch 44/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 12.0375\n",
      "Epoch 45/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 12.1168\n",
      "Epoch 46/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 11.9002\n",
      "Epoch 47/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 12.1057\n",
      "Epoch 48/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 11.2717\n",
      "Epoch 49/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 10.9584\n",
      "Epoch 50/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 10.8479\n",
      "Epoch 51/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 10.8141\n",
      "Epoch 52/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 10.6149\n",
      "Epoch 53/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 10.2004\n",
      "Epoch 54/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 10.0069\n",
      "Epoch 55/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 10.1522\n",
      "Epoch 56/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 10.1615\n",
      "Epoch 57/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 9.6849\n",
      "Epoch 58/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 9.3640\n",
      "Epoch 59/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 9.1837\n",
      "Epoch 60/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 9.0685\n",
      "Epoch 61/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 9.0056\n",
      "Epoch 62/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 8.9009\n",
      "Epoch 63/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 8.9303\n",
      "Epoch 64/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 8.7331\n",
      "Epoch 65/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 8.4537\n",
      "Epoch 66/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 8.3838\n",
      "Epoch 67/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.3354\n",
      "Epoch 68/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 8.2863\n",
      "Epoch 69/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 8.4427\n",
      "Epoch 70/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 8.1725\n",
      "Epoch 71/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 8.1391\n",
      "Epoch 72/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 8.0423\n",
      "Epoch 73/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.7176\n",
      "Epoch 74/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 7.7150\n",
      "Epoch 75/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.5960\n",
      "Epoch 76/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.4437\n",
      "Epoch 77/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.5595\n",
      "Epoch 78/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.2612\n",
      "Epoch 79/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.2013\n",
      "Epoch 80/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 7.1075\n",
      "Epoch 81/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.2389\n",
      "Epoch 82/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.3277\n",
      "Epoch 83/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.7847\n",
      "Epoch 84/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.7683\n",
      "Epoch 85/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.6202\n",
      "Epoch 86/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.6147\n",
      "Epoch 87/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.5467\n",
      "Epoch 88/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.4361\n",
      "Epoch 89/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.3621\n",
      "Epoch 90/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.3028\n",
      "Epoch 91/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.1807\n",
      "Epoch 92/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.0986\n",
      "Epoch 93/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.0438\n",
      "Epoch 94/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 5.9729\n",
      "Epoch 95/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 5.9211\n",
      "Epoch 96/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.8577\n",
      "Epoch 97/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 5.8731\n",
      "Epoch 98/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.1026\n",
      "Epoch 99/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 5.6601\n",
      "Epoch 100/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 5.4359\n",
      "Epoch 101/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 5.4932\n",
      "Epoch 102/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 5.4488\n",
      "Epoch 103/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 5.3967\n",
      "Epoch 104/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 5.2843\n",
      "Epoch 105/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 5.2696\n",
      "Epoch 106/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 5.1431\n",
      "Epoch 107/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 5.1574\n",
      "Epoch 108/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 5.1078\n",
      "Epoch 109/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 5.0309\n",
      "Epoch 110/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 4.8025\n",
      "Epoch 111/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 4.7391\n",
      "Epoch 112/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 4.6811\n",
      "Epoch 113/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 4.6291\n",
      "Epoch 114/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 4.5071\n",
      "Epoch 115/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 4.3993\n",
      "Epoch 116/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 4.3950\n",
      "Epoch 117/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 4.3878\n",
      "Epoch 118/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 4.3336\n",
      "Epoch 119/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 4.2601\n",
      "Epoch 120/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 4.2868\n",
      "Epoch 121/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 4.1969\n",
      "Epoch 122/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 4.1423\n",
      "Epoch 123/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 4.1530\n",
      "Epoch 124/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 4.0855\n",
      "Epoch 125/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.9792\n",
      "Epoch 126/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 3.8975\n",
      "Epoch 127/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.8738\n",
      "Epoch 128/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 3.9891\n",
      "Epoch 129/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 3.9666\n",
      "Epoch 130/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 4.0515\n",
      "Epoch 131/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 3.9543\n",
      "Epoch 132/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 3.8391\n",
      "Epoch 133/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 3.8845\n",
      "Epoch 134/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 3.6920\n",
      "Epoch 135/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 3.9860\n",
      "Epoch 136/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 3.7006\n",
      "Epoch 137/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.6098\n",
      "Epoch 138/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 3.6680\n",
      "Epoch 139/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.7066\n",
      "Epoch 140/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 3.5984\n",
      "Epoch 141/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 3.5875\n",
      "Epoch 142/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 3.5140\n",
      "Epoch 143/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.5532\n",
      "Epoch 144/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.4993\n",
      "Epoch 145/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 3.5370\n",
      "Epoch 146/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 3.3650\n",
      "Epoch 147/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.3668\n",
      "Epoch 148/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 3.4141\n",
      "Epoch 149/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 3.3880\n",
      "Epoch 150/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 3.4219\n",
      "Epoch 151/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 3.2872\n",
      "Epoch 152/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 3.2625\n",
      "Epoch 153/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 3.1993\n",
      "Epoch 154/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 3.1964\n",
      "Epoch 155/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 3.2202\n",
      "Epoch 156/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 3.2265\n",
      "Epoch 157/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 3.1639\n",
      "Epoch 158/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 3.1430\n",
      "Epoch 159/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 3.0896\n",
      "Epoch 160/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 3.1483\n",
      "Epoch 161/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 3.2292\n",
      "Epoch 162/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 3.3142\n",
      "Epoch 163/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 3.1349\n",
      "Epoch 164/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 3.0674\n",
      "Epoch 165/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 3.1744\n",
      "Epoch 166/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 3.0146\n",
      "Epoch 167/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 3.0173\n",
      "Epoch 168/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 3.0321\n",
      "Epoch 169/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 3.0880\n",
      "Epoch 170/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 2.9001\n",
      "Epoch 171/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 2.9224\n",
      "Epoch 172/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 2.9723\n",
      "Epoch 173/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 3.0701\n",
      "Epoch 174/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.9001\n",
      "Epoch 175/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.8783\n",
      "Epoch 176/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.8578\n",
      "Epoch 177/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.8555\n",
      "Epoch 178/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 2.7799\n",
      "Epoch 179/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.7181\n",
      "Epoch 180/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 2.7423\n",
      "Epoch 181/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 2.7623\n",
      "Epoch 182/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 2.7411\n",
      "Epoch 183/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 2.7580\n",
      "Epoch 184/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 2.7594\n",
      "Epoch 185/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 2.7358\n",
      "Epoch 186/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.7544\n",
      "Epoch 187/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 2.8385\n",
      "Epoch 188/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.7330\n",
      "Epoch 189/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 2.8103\n",
      "Epoch 190/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 2.6341\n",
      "Epoch 191/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 2.6355\n",
      "Epoch 192/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 2.6630\n",
      "Epoch 193/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 2.6906\n",
      "Epoch 194/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 2.6875\n",
      "Epoch 195/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 2.5411\n",
      "Epoch 196/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.6173\n",
      "Epoch 197/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 2.5726\n",
      "Epoch 198/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 2.6773\n",
      "Epoch 199/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.5190\n",
      "Epoch 200/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 2.4948\n",
      "Epoch 201/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 2.7266\n",
      "Epoch 202/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 3.0743\n",
      "Epoch 203/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.5625\n",
      "Epoch 204/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 2.3989\n",
      "Epoch 205/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.4099\n",
      "Epoch 206/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.5766\n",
      "Epoch 207/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 2.5628\n",
      "Epoch 208/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 2.7568\n",
      "Epoch 209/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.4358\n",
      "Epoch 210/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.4610\n",
      "Epoch 211/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.3687\n",
      "Epoch 212/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.4881\n",
      "Epoch 213/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 2.3826\n",
      "Epoch 214/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 2.4478\n",
      "Epoch 215/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.3172\n",
      "Epoch 216/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 2.4358\n",
      "Epoch 217/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 2.2431\n",
      "Epoch 218/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.4150\n",
      "Epoch 219/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 2.3109\n",
      "Epoch 220/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 2.2384\n",
      "Epoch 221/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 2.3220\n",
      "Epoch 222/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 2.4263\n",
      "Epoch 223/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 2.4614\n",
      "Epoch 224/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 2.4256\n",
      "Epoch 225/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.3966\n",
      "Epoch 226/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.2627\n",
      "Epoch 227/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.2505\n",
      "Epoch 228/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.1663\n",
      "Epoch 229/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.1570\n",
      "Epoch 230/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 2.4620\n",
      "Epoch 231/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 2.1882\n",
      "Epoch 232/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.1498\n",
      "Epoch 233/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 2.1331\n",
      "Epoch 234/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 2.1436\n",
      "Epoch 235/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 2.1581\n",
      "Epoch 236/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.1492\n",
      "Epoch 237/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 2.1925\n",
      "Epoch 238/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 2.2617\n",
      "Epoch 239/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 2.0885\n",
      "Epoch 240/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.1357\n",
      "Epoch 241/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 2.1744\n",
      "Epoch 242/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 2.4295\n",
      "Epoch 243/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 2.3119\n",
      "Epoch 244/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 2.2693\n",
      "Epoch 245/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 2.2543\n",
      "Epoch 246/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 2.1223\n",
      "Epoch 247/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 2.0718\n",
      "Epoch 248/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 2.0696\n",
      "Epoch 249/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 2.1631\n",
      "Epoch 250/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.0488\n",
      "Epoch 251/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 2.0182\n",
      "Epoch 252/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 2.0660\n",
      "Epoch 253/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.9728\n",
      "Epoch 254/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.0688\n",
      "Epoch 255/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.1876\n",
      "Epoch 256/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.2169\n",
      "Epoch 257/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.1284\n",
      "Epoch 258/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.2232\n",
      "Epoch 259/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.2130\n",
      "Epoch 260/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.0098\n",
      "Epoch 261/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 2.0479\n",
      "Epoch 262/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.9909\n",
      "Epoch 263/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.9782\n",
      "Epoch 264/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.1146\n",
      "Epoch 265/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.0696\n",
      "Epoch 266/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 2.0324\n",
      "Epoch 267/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 2.2494\n",
      "Epoch 268/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.3973\n",
      "Epoch 269/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.1603\n",
      "Epoch 270/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.1197\n",
      "Epoch 271/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.9316\n",
      "Epoch 272/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.8445\n",
      "Epoch 273/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.8299\n",
      "Epoch 274/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.9335\n",
      "Epoch 275/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.9380\n",
      "Epoch 276/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.9409\n",
      "Epoch 277/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 2.1164\n",
      "Epoch 278/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.9647\n",
      "Epoch 279/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.7541\n",
      "Epoch 280/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.8682\n",
      "Epoch 281/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.0421\n",
      "Epoch 282/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.8811\n",
      "Epoch 283/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.0606\n",
      "Epoch 284/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.9457\n",
      "Epoch 285/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.9223\n",
      "Epoch 286/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.9116\n",
      "Epoch 287/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.7542\n",
      "Epoch 288/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.7863\n",
      "Epoch 289/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.8357\n",
      "Epoch 290/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.8823\n",
      "Epoch 291/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.8364\n",
      "Epoch 292/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.7367\n",
      "Epoch 293/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.7355\n",
      "Epoch 294/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.6852\n",
      "Epoch 295/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.7791\n",
      "Epoch 296/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.8553\n",
      "Epoch 297/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.6880\n",
      "Epoch 298/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 1.6553\n",
      "Epoch 299/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.6803\n",
      "Epoch 300/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.8635\n",
      "Epoch 301/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.1394\n",
      "Epoch 302/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.9088\n",
      "Epoch 303/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.7695\n",
      "Epoch 304/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.7033\n",
      "Epoch 305/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.7652\n",
      "Epoch 306/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.6320\n",
      "Epoch 307/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.6318\n",
      "Epoch 308/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.6160\n",
      "Epoch 309/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.7799\n",
      "Epoch 310/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.8450\n",
      "Epoch 311/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.7549\n",
      "Epoch 312/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.8116\n",
      "Epoch 313/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.6973\n",
      "Epoch 314/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.6537\n",
      "Epoch 315/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.6285\n",
      "Epoch 316/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.6758\n",
      "Epoch 317/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.5609\n",
      "Epoch 318/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.6794\n",
      "Epoch 319/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.6021\n",
      "Epoch 320/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.6860\n",
      "Epoch 321/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.7031\n",
      "Epoch 322/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.6482\n",
      "Epoch 323/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.6698\n",
      "Epoch 324/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.7917\n",
      "Epoch 325/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.5119\n",
      "Epoch 326/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.6813\n",
      "Epoch 327/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.5576\n",
      "Epoch 328/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.6722\n",
      "Epoch 329/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.6992\n",
      "Epoch 330/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.5487\n",
      "Epoch 331/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.6331\n",
      "Epoch 332/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.4882\n",
      "Epoch 333/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.5578\n",
      "Epoch 334/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.7802\n",
      "Epoch 335/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 1.6554\n",
      "Epoch 336/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.6190\n",
      "Epoch 337/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.6916\n",
      "Epoch 338/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.5657\n",
      "Epoch 339/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.8475\n",
      "Epoch 340/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.7528\n",
      "Epoch 341/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.6807\n",
      "Epoch 342/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.6505\n",
      "Epoch 343/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.5397\n",
      "Epoch 344/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.5074\n",
      "Epoch 345/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.6173\n",
      "Epoch 346/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.6057\n",
      "Epoch 347/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.8000\n",
      "Epoch 348/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.6764\n",
      "Epoch 349/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.5395\n",
      "Epoch 350/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.5612\n",
      "Epoch 351/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.5218\n",
      "Epoch 352/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.7341\n",
      "Epoch 353/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.6972\n",
      "Epoch 354/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.6199\n",
      "Epoch 355/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.4512\n",
      "Epoch 356/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.5198\n",
      "Epoch 357/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.5550\n",
      "Epoch 358/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.5422\n",
      "Epoch 359/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.4294\n",
      "Epoch 360/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.5875\n",
      "Epoch 361/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.6631\n",
      "Epoch 362/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.7992\n",
      "Epoch 363/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 2.0166\n",
      "Epoch 364/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.6958\n",
      "Epoch 365/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.5610\n",
      "Epoch 366/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.5812\n",
      "Epoch 367/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.6978\n",
      "Epoch 368/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 2.0917\n",
      "Epoch 369/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.3823\n",
      "Epoch 370/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 2.3167\n",
      "Epoch 371/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.2628\n",
      "Epoch 372/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.8006\n",
      "Epoch 373/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.7243\n",
      "Epoch 374/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.5949\n",
      "Epoch 375/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.3568\n",
      "Epoch 376/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.4429\n",
      "Epoch 377/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.4963\n",
      "Epoch 378/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.4262\n",
      "Epoch 379/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.4271\n",
      "Epoch 380/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.3711\n",
      "Epoch 381/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.4021\n",
      "Epoch 382/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 2.0434\n",
      "Epoch 383/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.9887\n",
      "Epoch 384/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.8472\n",
      "Epoch 385/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.7715\n",
      "Epoch 386/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.7991\n",
      "Epoch 387/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.4574\n",
      "Epoch 388/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.5436\n",
      "Epoch 389/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.5650\n",
      "Epoch 390/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.4414\n",
      "Epoch 391/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.8502\n",
      "Epoch 392/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.5946\n",
      "Epoch 393/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.5207\n",
      "Epoch 394/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.5625\n",
      "Epoch 395/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.9433\n",
      "Epoch 396/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 2.3686\n",
      "Epoch 397/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 2.3834\n",
      "Epoch 398/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.7793\n",
      "Epoch 399/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.3792\n",
      "Epoch 400/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.4714\n",
      "Epoch 401/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.3749\n",
      "Epoch 402/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.4829\n",
      "Epoch 403/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.3387\n",
      "Epoch 404/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.5123\n",
      "Epoch 405/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 2.1498\n",
      "Epoch 406/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.7920\n",
      "Epoch 407/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.3172\n",
      "Epoch 408/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.3925\n",
      "Epoch 409/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.6382\n",
      "Epoch 410/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.9925\n",
      "Epoch 411/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.3589\n",
      "Epoch 412/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.4402\n",
      "Epoch 413/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.5754\n",
      "Epoch 414/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.5824\n",
      "Epoch 415/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.5515\n",
      "Epoch 416/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.6559\n",
      "Epoch 417/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.5451\n",
      "Epoch 418/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.4867\n",
      "Epoch 419/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.3827\n",
      "Epoch 420/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.6988\n",
      "Epoch 421/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.3199\n",
      "Epoch 422/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2651\n",
      "Epoch 423/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.5737\n",
      "Epoch 424/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.2272\n",
      "Epoch 425/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.6734\n",
      "Epoch 426/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.7524\n",
      "Epoch 427/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.4685\n",
      "Epoch 428/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.5797\n",
      "Epoch 429/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.5496\n",
      "Epoch 430/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.7382\n",
      "Epoch 431/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.7134\n",
      "Epoch 432/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.3715\n",
      "Epoch 433/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.5864\n",
      "Epoch 434/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.5548\n",
      "Epoch 435/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 1.3275\n",
      "Epoch 436/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.3049\n",
      "Epoch 437/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.4233\n",
      "Epoch 438/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.3152\n",
      "Epoch 439/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.5189\n",
      "Epoch 440/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.4472\n",
      "Epoch 441/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2669\n",
      "Epoch 442/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.2752\n",
      "Epoch 443/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.2235\n",
      "Epoch 444/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.3222\n",
      "Epoch 445/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.4667\n",
      "Epoch 446/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.8045\n",
      "Epoch 447/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2481\n",
      "Epoch 448/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.7682\n",
      "Epoch 449/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.9073\n",
      "Epoch 450/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.6018\n",
      "Epoch 451/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.4495\n",
      "Epoch 452/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.6750\n",
      "Epoch 453/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.5983\n",
      "Epoch 454/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.7733\n",
      "Epoch 455/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.5829\n",
      "Epoch 456/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.2759\n",
      "Epoch 457/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.3090\n",
      "Epoch 458/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.2631\n",
      "Epoch 459/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.8828\n",
      "Epoch 460/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.3435\n",
      "Epoch 461/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.2377\n",
      "Epoch 462/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.3003\n",
      "Epoch 463/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.6818\n",
      "Epoch 464/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.8368\n",
      "Epoch 465/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.3080\n",
      "Epoch 466/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.2280\n",
      "Epoch 467/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.2435\n",
      "Epoch 468/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.3630\n",
      "Epoch 469/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.5546\n",
      "Epoch 470/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.3014\n",
      "Epoch 471/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.2607\n",
      "Epoch 472/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.2085\n",
      "Epoch 473/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2010\n",
      "Epoch 474/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.1999\n",
      "Epoch 475/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.1550\n",
      "Epoch 476/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.1505\n",
      "Epoch 477/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.1652\n",
      "Epoch 478/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 1.2052\n",
      "Epoch 479/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.1964\n",
      "Epoch 480/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.1625\n",
      "Epoch 481/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.2698\n",
      "Epoch 482/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 1.4225\n",
      "Epoch 483/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.7373\n",
      "Epoch 484/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.3256\n",
      "Epoch 485/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.7222\n",
      "Epoch 486/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.5713\n",
      "Epoch 487/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.7595\n",
      "Epoch 488/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.4704\n",
      "Epoch 489/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.6689\n",
      "Epoch 490/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.6288\n",
      "Epoch 491/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.6094\n",
      "Epoch 492/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.3730\n",
      "Epoch 493/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.3919\n",
      "Epoch 494/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.5525\n",
      "Epoch 495/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.4269\n",
      "Epoch 496/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2301\n",
      "Epoch 497/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.2464\n",
      "Epoch 498/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.4838\n",
      "Epoch 499/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.2528\n",
      "Epoch 500/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.1496\n",
      "Epoch 501/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.7751\n",
      "Epoch 502/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.3799\n",
      "Epoch 503/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.2360\n",
      "Epoch 504/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.7289\n",
      "Epoch 505/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 1.7975\n",
      "Epoch 506/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.6114\n",
      "Epoch 507/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.2056\n",
      "Epoch 508/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.2443\n",
      "Epoch 509/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.8101\n",
      "Epoch 510/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.4796\n",
      "Epoch 511/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.5521\n",
      "Epoch 512/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.3838\n",
      "Epoch 513/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.2982\n",
      "Epoch 514/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.3777\n",
      "Epoch 515/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2556\n",
      "Epoch 516/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.3407\n",
      "Epoch 517/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.4740\n",
      "Epoch 518/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.5825\n",
      "Epoch 519/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.6930\n",
      "Epoch 520/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.3966\n",
      "Epoch 521/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.3223\n",
      "Epoch 522/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.4953\n",
      "Epoch 523/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.1390\n",
      "Epoch 524/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.1586\n",
      "Epoch 525/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.1452\n",
      "Epoch 526/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 1.2464\n",
      "Epoch 527/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.2674\n",
      "Epoch 528/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 1.0929\n",
      "Epoch 529/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.1297\n",
      "Epoch 530/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.3433\n",
      "Epoch 531/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.4344\n",
      "Epoch 532/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 1.3376\n",
      "Epoch 533/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2424\n",
      "Epoch 534/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.6656\n",
      "Epoch 535/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.8415\n",
      "Epoch 536/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.2264\n",
      "Epoch 537/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.3607\n",
      "Epoch 538/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2071\n",
      "Epoch 539/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.2585\n",
      "Epoch 540/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.2726\n",
      "Epoch 541/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.2236\n",
      "Epoch 542/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2515\n",
      "Epoch 543/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.3251\n",
      "Epoch 544/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.3156\n",
      "Epoch 545/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.3663\n",
      "Epoch 546/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.3864\n",
      "Epoch 547/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.4540\n",
      "Epoch 548/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2746\n",
      "Epoch 549/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2464\n",
      "Epoch 550/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2312\n",
      "Epoch 551/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.3097\n",
      "Epoch 552/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.5501\n",
      "Epoch 553/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2659\n",
      "Epoch 554/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.4438\n",
      "Epoch 555/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.2389\n",
      "Epoch 556/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.0988\n",
      "Epoch 557/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.1293\n",
      "Epoch 558/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.2053\n",
      "Epoch 559/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.0928\n",
      "Epoch 560/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.0802\n",
      "Epoch 561/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 1.2297\n",
      "Epoch 562/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.1538\n",
      "Epoch 563/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.4697\n",
      "Epoch 564/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.4158\n",
      "Epoch 565/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.3842\n",
      "Epoch 566/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.3604\n",
      "Epoch 567/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.3267\n",
      "Epoch 568/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.6164\n",
      "Epoch 569/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.7981\n",
      "Epoch 570/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.5602\n",
      "Epoch 571/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.4720\n",
      "Epoch 572/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.7592\n",
      "Epoch 573/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.8414\n",
      "Epoch 574/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.2558\n",
      "Epoch 575/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.1571\n",
      "Epoch 576/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.0559\n",
      "Epoch 577/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.1045\n",
      "Epoch 578/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.2112\n",
      "Epoch 579/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.1782\n",
      "Epoch 580/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.1694\n",
      "Epoch 581/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.1112\n",
      "Epoch 582/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.9098\n",
      "Epoch 583/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.5416\n",
      "Epoch 584/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.4867\n",
      "Epoch 585/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.3039\n",
      "Epoch 586/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.4406\n",
      "Epoch 587/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 1.2863\n",
      "Epoch 588/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.2414\n",
      "Epoch 589/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.0932\n",
      "Epoch 590/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.0869\n",
      "Epoch 591/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.0910\n",
      "Epoch 592/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2083\n",
      "Epoch 593/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.4181\n",
      "Epoch 594/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.5475\n",
      "Epoch 595/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.3607\n",
      "Epoch 596/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.1601\n",
      "Epoch 597/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.2314\n",
      "Epoch 598/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.2506\n",
      "Epoch 599/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 1.2351\n",
      "Epoch 600/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.3123\n",
      "Epoch 601/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.1639\n",
      "Epoch 602/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 1.2182\n",
      "Epoch 603/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 1.5218\n",
      "Epoch 604/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.6682\n",
      "Epoch 605/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.2260\n",
      "Epoch 606/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 1.0834\n",
      "Epoch 607/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.1857\n",
      "Epoch 608/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.5325\n",
      "Epoch 609/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2729\n",
      "Epoch 610/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.5074\n",
      "Epoch 611/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2451\n",
      "Epoch 612/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.0568\n",
      "Epoch 613/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.0429\n",
      "Epoch 614/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.0344\n",
      "Epoch 615/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.1091\n",
      "Epoch 616/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.0593\n",
      "Epoch 617/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.0752\n",
      "Epoch 618/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.2501\n",
      "Epoch 619/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.1482\n",
      "Epoch 620/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2927\n",
      "Epoch 621/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.1493\n",
      "Epoch 622/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.1110\n",
      "Epoch 623/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.1329\n",
      "Epoch 624/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.1294\n",
      "Epoch 625/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.0398\n",
      "Epoch 626/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.0768\n",
      "Epoch 627/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 1.1763\n",
      "Epoch 628/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.2523\n",
      "Epoch 629/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.3025\n",
      "Epoch 630/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.1674\n",
      "Epoch 631/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.9252\n",
      "Epoch 632/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.7303\n",
      "Epoch 633/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.6168\n",
      "Epoch 634/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.2298\n",
      "Epoch 635/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.4759\n",
      "Epoch 636/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.5407\n",
      "Epoch 637/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.3363\n",
      "Epoch 638/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2825\n",
      "Epoch 639/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.3104\n",
      "Epoch 640/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 1.1984\n",
      "Epoch 641/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.3482\n",
      "Epoch 642/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.0301\n",
      "Epoch 643/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.0506\n",
      "Epoch 644/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.0712\n",
      "Epoch 645/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 1.0106\n",
      "Epoch 646/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.2114\n",
      "Epoch 647/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.0620\n",
      "Epoch 648/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 1.2131\n",
      "Epoch 649/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.2678\n",
      "Epoch 650/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.6596\n",
      "Epoch 651/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 1.1311\n",
      "Epoch 652/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.3155\n",
      "Epoch 653/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2324\n",
      "Epoch 654/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.1077\n",
      "Epoch 655/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.2219\n",
      "Epoch 656/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.0530\n",
      "Epoch 657/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.0411\n",
      "Epoch 658/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.0721\n",
      "Epoch 659/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.9718\n",
      "Epoch 660/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.0466\n",
      "Epoch 661/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.0455\n",
      "Epoch 662/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.9796\n",
      "Epoch 663/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.0854\n",
      "Epoch 664/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.9858\n",
      "Epoch 665/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.9855\n",
      "Epoch 666/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 1.0695\n",
      "Epoch 667/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.0616\n",
      "Epoch 668/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.1421\n",
      "Epoch 669/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.0359\n",
      "Epoch 670/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.1454\n",
      "Epoch 671/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.3072\n",
      "Epoch 672/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2200\n",
      "Epoch 673/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 1.0908\n",
      "Epoch 674/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.0839\n",
      "Epoch 675/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.0058\n",
      "Epoch 676/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.9589\n",
      "Epoch 677/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.0552\n",
      "Epoch 678/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.3261\n",
      "Epoch 679/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.3273\n",
      "Epoch 680/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.0787\n",
      "Epoch 681/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 1.1928\n",
      "Epoch 682/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.6082\n",
      "Epoch 683/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.2547\n",
      "Epoch 684/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.0479\n",
      "Epoch 685/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.9982\n",
      "Epoch 686/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.0929\n",
      "Epoch 687/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.1208\n",
      "Epoch 688/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.1488\n",
      "Epoch 689/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.1663\n",
      "Epoch 690/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.0993\n",
      "Epoch 691/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.0215\n",
      "Epoch 692/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.0228\n",
      "Epoch 693/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.9558\n",
      "Epoch 694/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.1001\n",
      "Epoch 695/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.2989\n",
      "Epoch 696/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.1571\n",
      "Epoch 697/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.1262\n",
      "Epoch 698/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.2094\n",
      "Epoch 699/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.3887\n",
      "Epoch 700/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.0444\n",
      "Epoch 701/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.1578\n",
      "Epoch 702/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.0797\n",
      "Epoch 703/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 1.0556\n",
      "Epoch 704/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.1547\n",
      "Epoch 705/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.1545\n",
      "Epoch 706/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.3290\n",
      "Epoch 707/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.9993\n",
      "Epoch 708/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.0080\n",
      "Epoch 709/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.9754\n",
      "Epoch 710/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 1.2933\n",
      "Epoch 711/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 1.2673\n",
      "Epoch 712/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.1621\n",
      "Epoch 713/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.1382\n",
      "Epoch 714/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.4195\n",
      "Epoch 715/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 2.5398\n",
      "Epoch 716/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.9448\n",
      "Epoch 717/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.1283\n",
      "Epoch 718/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.2451\n",
      "Epoch 719/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.0245\n",
      "Epoch 720/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.1321\n",
      "Epoch 721/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.0178\n",
      "Epoch 722/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.9958\n",
      "Epoch 723/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.9818\n",
      "Epoch 724/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.0304\n",
      "Epoch 725/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.0434\n",
      "Epoch 726/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.1476\n",
      "Epoch 727/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.0579\n",
      "Epoch 728/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2704\n",
      "Epoch 729/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.4476\n",
      "Epoch 730/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.0587\n",
      "Epoch 731/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.9737\n",
      "Epoch 732/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.9549\n",
      "Epoch 733/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.1180\n",
      "Epoch 734/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 1.0249\n",
      "Epoch 735/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.0561\n",
      "Epoch 736/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.0638\n",
      "Epoch 737/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.9753\n",
      "Epoch 738/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.9745\n",
      "Epoch 739/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.9969\n",
      "Epoch 740/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.9899\n",
      "Epoch 741/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.0066\n",
      "Epoch 742/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.1099\n",
      "Epoch 743/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.0419\n",
      "Epoch 744/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.0148\n",
      "Epoch 745/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.0547\n",
      "Epoch 746/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.9364\n",
      "Epoch 747/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.9655\n",
      "Epoch 748/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 1.0551\n",
      "Epoch 749/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.0319\n",
      "Epoch 750/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.0092\n",
      "Epoch 751/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.1029\n",
      "Epoch 752/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.0357\n",
      "Epoch 753/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2245\n",
      "Epoch 754/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.4000\n",
      "Epoch 755/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.4714\n",
      "Epoch 756/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.3636\n",
      "Epoch 757/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.3809\n",
      "Epoch 758/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.0348\n",
      "Epoch 759/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.3244\n",
      "Epoch 760/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 1.5064\n",
      "Epoch 761/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.0362\n",
      "Epoch 762/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.9782\n",
      "Epoch 763/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.9871\n",
      "Epoch 764/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.1244\n",
      "Epoch 765/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.1197\n",
      "Epoch 766/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.5086\n",
      "Epoch 767/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2812\n",
      "Epoch 768/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.1066\n",
      "Epoch 769/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.1279\n",
      "Epoch 770/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.4171\n",
      "Epoch 771/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.0404\n",
      "Epoch 772/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.1048\n",
      "Epoch 773/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.2472\n",
      "Epoch 774/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.2743\n",
      "Epoch 775/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.1775\n",
      "Epoch 776/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.0434\n",
      "Epoch 777/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.1971\n",
      "Epoch 778/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.2574\n",
      "Epoch 779/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 1.2155\n",
      "Epoch 780/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 1.2901\n",
      "Epoch 781/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.2360\n",
      "Epoch 782/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.3162\n",
      "Epoch 783/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.2402\n",
      "Epoch 784/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 1.1300\n",
      "Epoch 785/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 1.1110\n",
      "Epoch 786/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.9200\n",
      "Epoch 787/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.9412\n",
      "Epoch 788/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 1.1387\n",
      "Epoch 789/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.9070\n",
      "Epoch 790/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.0159\n",
      "Epoch 791/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.0199\n",
      "Epoch 792/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.0352\n",
      "Epoch 793/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.9505\n",
      "Epoch 794/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.9738\n",
      "Epoch 795/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.0731\n",
      "Epoch 796/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.9896\n",
      "Epoch 797/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 1.0643\n",
      "Epoch 798/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.9749\n",
      "Epoch 799/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.9462\n",
      "Epoch 800/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.9184\n",
      "Epoch 801/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.0070\n",
      "Epoch 802/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.0468\n",
      "Epoch 803/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.1295\n",
      "Epoch 804/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.2037\n",
      "Epoch 805/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.0207\n",
      "Epoch 806/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.9557\n",
      "Epoch 807/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.9579\n",
      "Epoch 808/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.9647\n",
      "Epoch 809/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.9978\n",
      "Epoch 810/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.0319\n",
      "Epoch 811/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.1812\n",
      "Epoch 812/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.0840\n",
      "Epoch 813/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.9487\n",
      "Epoch 814/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.1109\n",
      "Epoch 815/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.0273\n",
      "Epoch 816/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.9671\n",
      "Epoch 817/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.9732\n",
      "Epoch 818/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.9413\n",
      "Epoch 819/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.8827\n",
      "Epoch 820/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.9230\n",
      "Epoch 821/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.9729\n",
      "Epoch 822/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.1005\n",
      "Epoch 823/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.9960\n",
      "Epoch 824/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.1136\n",
      "Epoch 825/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.9886\n",
      "Epoch 826/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.9312\n",
      "Epoch 827/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.9924\n",
      "Epoch 828/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.0150\n",
      "Epoch 829/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.9472\n",
      "Epoch 830/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.9472\n",
      "Epoch 831/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.9698\n",
      "Epoch 832/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.0265\n",
      "Epoch 833/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.9691\n",
      "Epoch 834/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.9503\n",
      "Epoch 835/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.0498\n",
      "Epoch 836/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.0898\n",
      "Epoch 837/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.3515\n",
      "Epoch 838/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2929\n",
      "Epoch 839/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.0317\n",
      "Epoch 840/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.9605\n",
      "Epoch 841/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.3340\n",
      "Epoch 842/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.9123\n",
      "Epoch 843/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.9041\n",
      "Epoch 844/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.8673\n",
      "Epoch 845/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.9057\n",
      "Epoch 846/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.9709\n",
      "Epoch 847/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.0159\n",
      "Epoch 848/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.1800\n",
      "Epoch 849/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 1.0550\n",
      "Epoch 850/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.8980\n",
      "Epoch 851/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.8969\n",
      "Epoch 852/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.9075\n",
      "Epoch 853/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.8951\n",
      "Epoch 854/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.9246\n",
      "Epoch 855/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.9873\n",
      "Epoch 856/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.0425\n",
      "Epoch 857/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.2209\n",
      "Epoch 858/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.2012\n",
      "Epoch 859/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.1139\n",
      "Epoch 860/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.0395\n",
      "Epoch 861/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.9248\n",
      "Epoch 862/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.8345\n",
      "Epoch 863/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.8688\n",
      "Epoch 864/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.9445\n",
      "Epoch 865/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.8910\n",
      "Epoch 866/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.8318\n",
      "Epoch 867/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.8649\n",
      "Epoch 868/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.1886\n",
      "Epoch 869/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.1375\n",
      "Epoch 870/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.9661\n",
      "Epoch 871/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.9421\n",
      "Epoch 872/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.9239\n",
      "Epoch 873/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.9539\n",
      "Epoch 874/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.0504\n",
      "Epoch 875/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.7280\n",
      "Epoch 876/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.1011\n",
      "Epoch 877/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.9056\n",
      "Epoch 878/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.9754\n",
      "Epoch 879/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.9490\n",
      "Epoch 880/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.9536\n",
      "Epoch 881/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.9622\n",
      "Epoch 882/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.9343\n",
      "Epoch 883/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.0424\n",
      "Epoch 884/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.9139\n",
      "Epoch 885/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.9225\n",
      "Epoch 886/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.9559\n",
      "Epoch 887/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.9546\n",
      "Epoch 888/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.9431\n",
      "Epoch 889/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.9092\n",
      "Epoch 890/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.0270\n",
      "Epoch 891/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.9579\n",
      "Epoch 892/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.0396\n",
      "Epoch 893/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.9491\n",
      "Epoch 894/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 1.0052\n",
      "Epoch 895/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.9934\n",
      "Epoch 896/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.9005\n",
      "Epoch 897/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.8928\n",
      "Epoch 898/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.0204\n",
      "Epoch 899/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.9093\n",
      "Epoch 900/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.8388\n",
      "Epoch 901/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.1026\n",
      "Epoch 902/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.9478\n",
      "Epoch 903/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.9058\n",
      "Epoch 904/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.9485\n",
      "Epoch 905/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.0233\n",
      "Epoch 906/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.9371\n",
      "Epoch 907/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.1061\n",
      "Epoch 908/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.0709\n",
      "Epoch 909/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.0695\n",
      "Epoch 910/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.9781\n",
      "Epoch 911/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.0219\n",
      "Epoch 912/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 1.0558\n",
      "Epoch 913/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.1106\n",
      "Epoch 914/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.9092\n",
      "Epoch 915/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.9936\n",
      "Epoch 916/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 1.2118\n",
      "Epoch 917/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.0825\n",
      "Epoch 918/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.9423\n",
      "Epoch 919/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.8572\n",
      "Epoch 920/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.0891\n",
      "Epoch 921/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.9117\n",
      "Epoch 922/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.9590\n",
      "Epoch 923/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 1.0330\n",
      "Epoch 924/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.9701\n",
      "Epoch 925/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.8654\n",
      "Epoch 926/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.8495\n",
      "Epoch 927/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.8976\n",
      "Epoch 928/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.9740\n",
      "Epoch 929/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.0867\n",
      "Epoch 930/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.9423\n",
      "Epoch 931/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.9113\n",
      "Epoch 932/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.9525\n",
      "Epoch 933/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.9132\n",
      "Epoch 934/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.9743\n",
      "Epoch 935/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 1.0910\n",
      "Epoch 936/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.3143\n",
      "Epoch 937/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 1.3979\n",
      "Epoch 938/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.0956\n",
      "Epoch 939/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.9922\n",
      "Epoch 940/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.0110\n",
      "Epoch 941/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.9041\n",
      "Epoch 942/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.0151\n",
      "Epoch 943/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.0157\n",
      "Epoch 944/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.0373\n",
      "Epoch 945/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.8743\n",
      "Epoch 946/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.8970\n",
      "Epoch 947/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.9824\n",
      "Epoch 948/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.1866\n",
      "Epoch 949/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 1.1448\n",
      "Epoch 950/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.9220\n",
      "Epoch 951/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.9103\n",
      "Epoch 952/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.1115\n",
      "Epoch 953/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.0110\n",
      "Epoch 954/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.8807\n",
      "Epoch 955/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.1311\n",
      "Epoch 956/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.1920\n",
      "Epoch 957/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.9412\n",
      "Epoch 958/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.8882\n",
      "Epoch 959/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.9106\n",
      "Epoch 960/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.8571\n",
      "Epoch 961/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.9635\n",
      "Epoch 962/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.9500\n",
      "Epoch 963/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.8843\n",
      "Epoch 964/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.9159\n",
      "Epoch 965/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.8423\n",
      "Epoch 966/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.9364\n",
      "Epoch 967/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.8977\n",
      "Epoch 968/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.8780\n",
      "Epoch 969/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.8740\n",
      "Epoch 970/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.8941\n",
      "Epoch 971/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.9106\n",
      "Epoch 972/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.9352\n",
      "Epoch 973/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.9689\n",
      "Epoch 974/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.0394\n",
      "Epoch 975/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.0219\n",
      "Epoch 976/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.0950\n",
      "Epoch 977/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.0378\n",
      "Epoch 978/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 1.1584\n",
      "Epoch 979/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 1.0471\n",
      "Epoch 980/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.0361\n",
      "Epoch 981/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.1589\n",
      "Epoch 982/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.1424\n",
      "Epoch 983/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.8975\n",
      "Epoch 984/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.0212\n",
      "Epoch 985/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.9727\n",
      "Epoch 986/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.8830\n",
      "Epoch 987/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.8902\n",
      "Epoch 988/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.0195\n",
      "Epoch 989/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 1.3730\n",
      "Epoch 990/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.0631\n",
      "Epoch 991/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.4587\n",
      "Epoch 992/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.0922\n",
      "Epoch 993/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.9496\n",
      "Epoch 994/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 1.0048\n",
      "Epoch 995/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.9632\n",
      "Epoch 996/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.8727\n",
      "Epoch 997/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.9598\n",
      "Epoch 998/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.8927\n",
      "Epoch 999/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.8264\n",
      "Epoch 1000/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.9279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a43cc8e48>"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_FGM = Sequential()\n",
    "NN_FGM.add(Dense(units=32,input_dim=X_train.shape[1],activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_FGM.add(Dense(units=16, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_FGM.add(Dense(units=8, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_FGM.add(Dense(units=1,activation='linear'))\n",
    "NN_FGM.compile(loss='mse', optimizer='adam')\n",
    "NN_FGM.fit(np.array(X_train), np.array(y_train), epochs=1000,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN_predictions</th>\n",
       "      <th>actual</th>\n",
       "      <th>GBR_predictions</th>\n",
       "      <th>LY_FGM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>6.303915</td>\n",
       "      <td>7.9</td>\n",
       "      <td>6.629565</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>6.050366</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5.322610</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>5.538166</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.223823</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>6.811848</td>\n",
       "      <td>7.1</td>\n",
       "      <td>6.905539</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>6.865173</td>\n",
       "      <td>7.2</td>\n",
       "      <td>6.453369</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>5.225861</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.603584</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>5.583111</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5.274851</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>7.108206</td>\n",
       "      <td>6.1</td>\n",
       "      <td>6.796972</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>7.238921</td>\n",
       "      <td>8.1</td>\n",
       "      <td>7.067375</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>7.671750</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.698989</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>6.541543</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6.344752</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>5.369608</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.971896</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>6.573750</td>\n",
       "      <td>5.9</td>\n",
       "      <td>6.179901</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>7.036760</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.877206</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>7.178762</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.610804</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6.415142</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.978629</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>6.818338</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.191301</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>6.616207</td>\n",
       "      <td>8.1</td>\n",
       "      <td>6.255626</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>5.688515</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5.791085</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>6.466700</td>\n",
       "      <td>4.9</td>\n",
       "      <td>6.193049</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>5.299160</td>\n",
       "      <td>7.6</td>\n",
       "      <td>6.191465</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>6.715641</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.595952</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>6.662737</td>\n",
       "      <td>5.6</td>\n",
       "      <td>6.391201</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>6.196372</td>\n",
       "      <td>6.1</td>\n",
       "      <td>6.332418</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>5.345042</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.005439</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>7.287312</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.934808</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>4.531015</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5.686536</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>5.233086</td>\n",
       "      <td>5.9</td>\n",
       "      <td>4.192285</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>6.540187</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.164102</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>5.975669</td>\n",
       "      <td>4.8</td>\n",
       "      <td>6.080561</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>5.330667</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.390679</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.845128</td>\n",
       "      <td>7.2</td>\n",
       "      <td>6.034211</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>7.376894</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.716322</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>5.017659</td>\n",
       "      <td>5.3</td>\n",
       "      <td>6.182060</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>3.006460</td>\n",
       "      <td>4.3</td>\n",
       "      <td>5.091768</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>5.455678</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.501152</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>5.540619</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.261105</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>6.350558</td>\n",
       "      <td>5.2</td>\n",
       "      <td>6.120944</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>5.577633</td>\n",
       "      <td>4.6</td>\n",
       "      <td>6.068082</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>6.964833</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.348588</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>6.167717</td>\n",
       "      <td>7.1</td>\n",
       "      <td>5.871240</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>6.808495</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.812643</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>6.212050</td>\n",
       "      <td>6.1</td>\n",
       "      <td>6.358847</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>6.722794</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.475914</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.651263</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.560643</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>5.041470</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.344018</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>6.603951</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.587478</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>5.109478</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.382660</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>4.337331</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4.525543</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>4.704156</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5.503475</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     NN_predictions  actual  GBR_predictions  LY_FGM\n",
       "319        6.303915     7.9         6.629565     7.1\n",
       "150        6.050366     3.9         5.322610     7.1\n",
       "185        5.538166     6.0         6.223823     7.1\n",
       "296        6.811848     7.1         6.905539     7.0\n",
       "43         6.865173     7.2         6.453369     7.0\n",
       "239        5.225861     3.9         4.603584     7.0\n",
       "338        5.583111     4.8         5.274851     7.0\n",
       "218        7.108206     6.1         6.796972     7.0\n",
       "656        7.238921     8.1         7.067375     7.0\n",
       "325        7.671750     7.0         6.698989     6.9\n",
       "208        6.541543     6.6         6.344752     6.9\n",
       "291        5.369608     4.6         4.971896     6.9\n",
       "614        6.573750     5.9         6.179901     6.9\n",
       "152        7.036760     6.9         6.877206     6.8\n",
       "247        7.178762     6.3         6.610804     6.8\n",
       "22         6.415142     6.9         5.978629     6.8\n",
       "439        6.818338     6.5         6.191301     6.8\n",
       "95         6.616207     8.1         6.255626     6.8\n",
       "441        5.688515     7.7         5.791085     6.8\n",
       "613        6.466700     4.9         6.193049     6.7\n",
       "647        5.299160     7.6         6.191465     6.7\n",
       "372        6.715641     7.0         6.595952     6.5\n",
       "306        6.662737     5.6         6.391201     6.5\n",
       "616        6.196372     6.1         6.332418     6.5\n",
       "243        5.345042     6.2         6.005439     6.5\n",
       "253        7.287312     7.0         6.934808     6.5\n",
       "522        4.531015     4.4         5.686536     6.3\n",
       "445        5.233086     5.9         4.192285     6.3\n",
       "379        6.540187     6.5         6.164102     6.3\n",
       "576        5.975669     4.8         6.080561     6.3\n",
       "400        5.330667     5.2         5.390679     6.3\n",
       "26         5.845128     7.2         6.034211     6.3\n",
       "435        7.376894     6.0         6.716322     6.3\n",
       "507        5.017659     5.3         6.182060     6.2\n",
       "608        3.006460     4.3         5.091768     6.2\n",
       "664        5.455678     4.8         4.501152     6.2\n",
       "153        5.540619     3.8         5.261105     6.2\n",
       "415        6.350558     5.2         6.120944     6.2\n",
       "142        5.577633     4.6         6.068082     6.2\n",
       "53         6.964833     6.5         6.348588     6.2\n",
       "47         6.167717     7.1         5.871240     6.2\n",
       "55         6.808495     6.3         6.812643     6.2\n",
       "210        6.212050     6.1         6.358847     6.1\n",
       "645        6.722794     7.0         6.475914     6.1\n",
       "21         5.651263     5.2         5.560643     6.1\n",
       "285        5.041470     5.3         5.344018     6.1\n",
       "490        6.603951     6.2         6.587478     6.1\n",
       "572        5.109478     5.7         5.382660     6.0\n",
       "244        4.337331     5.8         4.525543     6.0\n",
       "550        4.704156     4.9         5.503475     6.0"
      ]
     },
     "execution_count": 739,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = NN_FGM.predict(X_test)\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.5)\n",
    "gbr.fit(X_train,y_train)\n",
    "gbr_predictions = gbr.predict(X_test)\n",
    "LR = LinearRegression(fit_intercept=True).fit(X_train,y_train)\n",
    "\n",
    "testing = pd.DataFrame(predictions)\n",
    "testing.columns=['NN_predictions']\n",
    "testing['actual'] = y_test.reset_index()['FGM']\n",
    "testing['GBR_predictions']=gbr_predictions\n",
    "testing['LY_FGM']=X_test['FGM_ly'].reset_index()['FGM_ly']\n",
    "testing.sort_values(by='LY_FGM',ascending=False)[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2017FGM = percentages[percentages['season']==2017].drop(['player','team','FGM','FGA','FG_percent','FTM','FTA','Games'],axis=1)\n",
    "#pred_2017blocks = blocks[blocks['season']==2017][['blocks_ly','career_blocks','starter_change']]\n",
    "FGM_2017 = NN_FGM.predict(pred_2017FGM)\n",
    "gbr_FGM_2017 = pd.DataFrame(gbr.predict(pred_2017FGM))\n",
    "LR_FGM_2017 = pd.DataFrame(LR.predict(pred_2017FGM))\n",
    "test_2 =pd.DataFrame(FGM_2017)\n",
    "test_3 = pd.merge(percentages,pred_2017FGM,left_index=True,right_index=True).reset_index()\n",
    "test_3['predictions']=test_2[0]\n",
    "test_3['gbr_pred'] = gbr_FGM_2017[0]\n",
    "test_3['LR_pred'] = LR_FGM_2017[0]\n",
    "test_3['mean_pred'] = (test_3['predictions']+test_3['gbr_pred']+test_3['LR_pred'])/3\n",
    "test_3 = test_3[test_3['Games']>30]\n",
    "test_3[['player','FGM','predictions','LR_pred','gbr_pred','mean_pred','FGM_ly_x']].sort_values(by='FGM_ly_x',ascending=False)[0:50]\n",
    "\n",
    "FGM_2017 = test_3[['player','LR_pred']]\n",
    "FGM_2017.columns = ['player','FGM_prediction']\n",
    "df_2017 = pd.merge(df_2017,FGM_2017, how='left',left_on='player',right_on='player')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE using LR:1.0519173731234364\n",
      "MSE using GB:0.9855825106284372\n",
      "MSE using NN:1.2010804376103144\n",
      "MSE using combo:0.976581075793652\n",
      "MSE using mean:4.2722633136094625\n",
      "MSE using last year stats:1.5276602564102566\n"
     ]
    }
   ],
   "source": [
    "print('MSE using LR:{}'.format(np.mean((test_3['FGM']-test_3['LR_pred'])**2)))\n",
    "print('MSE using GB:{}'.format(np.mean((test_3['FGM']-test_3['gbr_pred'])**2)))\n",
    "print('MSE using NN:{}'.format(np.mean((test_3['FGM']-test_3['predictions'])**2)))\n",
    "print('MSE using combo:{}'.format(np.mean((test_3['FGM']-test_3['mean_pred'])**2)))\n",
    "print('MSE using mean:{}'.format(np.mean((test_3['FGM']-np.mean(test_3['FGM']))**2)))\n",
    "print('MSE using last year stats:{}'.format(np.mean((test_3['FGM']-test_3['FGM_ly_x'])**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['season', 'player', 'age', 'team', 'FGM', 'FGA', 'FG_percent',\n",
       "       'FG_percent_ly', 'FGM_ly', 'FGA_ly', 'FTM', 'FTA', 'FT_percent',\n",
       "       'FT_percent_ly', 'FTM_ly', 'FTA_ly', '3PM_ly', '3PM_change',\n",
       "       'points_ly', 'change_points_ly', 'starter_change', 'C_PF', 'PG',\n",
       "       'SG_SF', 'Games', 'high_usageplayer_added', 'usagemin_opened',\n",
       "       'maxusage_added', 'high_usageplayer_dropped', 'points_opened',\n",
       "       'max_pointsdropped', 'max_pointsadded', 'three_ar_ly', 'change_3ar',\n",
       "       'per_ly', 'change_per', 'usagerank', 'usagerank_ly',\n",
       "       'offensive_winshares', 'offensive_boxplusminus', 'boxplusminus',\n",
       "       'value_overreplacement', 'career_FGM', 'career_FGA', 'career_FGpercent',\n",
       "       'career_FTM', 'career_FTA', 'career_FTPercent', 'yearspro'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentages.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = percentages[(percentages['season']!=2017) & (percentages['Games']>30)].drop(['player','team','FGM','FGA','FG_percent','FTM','FTA','Games'],axis=1)\n",
    "X = percentages[(percentages['season']!=2017) & (percentages['Games']>30)][['FG_percent_ly','career_FGpercent','age','age_squared','yearspro']]\n",
    "y = percentages[(percentages['season']!=2017) & (percentages['Games']>30)]['FG_percent']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1564/1564 [==============================] - 3s 2ms/step - loss: 794.5202\n",
      "Epoch 2/100\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 120.3655\n",
      "Epoch 3/100\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 5.0254\n",
      "Epoch 4/100\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.1606\n",
      "Epoch 5/100\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.1818\n",
      "Epoch 6/100\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 0.1356\n",
      "Epoch 7/100\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 0.0904\n",
      "Epoch 8/100\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 0.0794\n",
      "Epoch 9/100\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.0793\n",
      "Epoch 10/100\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 0.0791\n",
      "Epoch 11/100\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.0789\n",
      "Epoch 12/100\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 0.0788\n",
      "Epoch 13/100\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.0786\n",
      "Epoch 14/100\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 0.0786\n",
      "Epoch 15/100\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.0783\n",
      "Epoch 16/100\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.0782\n",
      "Epoch 17/100\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 0.0779\n",
      "Epoch 18/100\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.0777\n",
      "Epoch 19/100\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.0776\n",
      "Epoch 20/100\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.0773\n",
      "Epoch 21/100\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 0.0770\n",
      "Epoch 22/100\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 0.0768\n",
      "Epoch 23/100\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 0.0766\n",
      "Epoch 24/100\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.0764\n",
      "Epoch 25/100\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.0762\n",
      "Epoch 26/100\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.0759\n",
      "Epoch 27/100\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.0755\n",
      "Epoch 28/100\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 0.0753\n",
      "Epoch 29/100\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.0750\n",
      "Epoch 30/100\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.0749\n",
      "Epoch 31/100\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.0746\n",
      "Epoch 32/100\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 0.0741\n",
      "Epoch 33/100\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 0.0739\n",
      "Epoch 34/100\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 0.0735\n",
      "Epoch 35/100\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.0732\n",
      "Epoch 36/100\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 0.0730\n",
      "Epoch 37/100\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.0726\n",
      "Epoch 38/100\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 0.0724\n",
      "Epoch 39/100\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 0.0720\n",
      "Epoch 40/100\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 0.0717\n",
      "Epoch 41/100\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 0.0714\n",
      "Epoch 42/100\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 0.0709\n",
      "Epoch 43/100\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.0706\n",
      "Epoch 44/100\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.0702\n",
      "Epoch 45/100\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 0.0700\n",
      "Epoch 46/100\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.0695\n",
      "Epoch 47/100\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 0.0691\n",
      "Epoch 48/100\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.0689\n",
      "Epoch 49/100\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.0685\n",
      "Epoch 50/100\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.0680\n",
      "Epoch 51/100\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.0676\n",
      "Epoch 52/100\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 0.0673\n",
      "Epoch 53/100\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.0668\n",
      "Epoch 54/100\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.0664\n",
      "Epoch 55/100\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 0.0661\n",
      "Epoch 56/100\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 0.0656\n",
      "Epoch 57/100\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.0655\n",
      "Epoch 58/100\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.0648\n",
      "Epoch 59/100\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.0645\n",
      "Epoch 60/100\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.0639\n",
      "Epoch 61/100\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.0635\n",
      "Epoch 62/100\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 0.0631\n",
      "Epoch 63/100\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.0631\n",
      "Epoch 64/100\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 0.0623\n",
      "Epoch 65/100\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.0617\n",
      "Epoch 66/100\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 0.0613\n",
      "Epoch 67/100\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 0.0608\n",
      "Epoch 68/100\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 0.0605\n",
      "Epoch 69/100\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 0.0599\n",
      "Epoch 70/100\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 0.0594\n",
      "Epoch 71/100\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.0594\n",
      "Epoch 72/100\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 0.0587\n",
      "Epoch 73/100\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 0.0583\n",
      "Epoch 74/100\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.0577\n",
      "Epoch 75/100\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 0.0574\n",
      "Epoch 76/100\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.0566\n",
      "Epoch 77/100\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 0.0563\n",
      "Epoch 78/100\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 0.0558\n",
      "Epoch 79/100\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 0.0555\n",
      "Epoch 80/100\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 0.0552\n",
      "Epoch 81/100\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 0.0546\n",
      "Epoch 82/100\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 0.0543\n",
      "Epoch 83/100\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 0.0534\n",
      "Epoch 84/100\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 0.0528\n",
      "Epoch 85/100\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.0526\n",
      "Epoch 86/100\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 0.0518\n",
      "Epoch 87/100\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 0.0514\n",
      "Epoch 88/100\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.0508\n",
      "Epoch 89/100\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.0504\n",
      "Epoch 90/100\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 0.0502\n",
      "Epoch 91/100\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 0.0494\n",
      "Epoch 92/100\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 0.0488\n",
      "Epoch 93/100\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 0.0487\n",
      "Epoch 94/100\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 0.0479\n",
      "Epoch 95/100\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 0.0478\n",
      "Epoch 96/100\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 0.0469\n",
      "Epoch 97/100\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 0.0465\n",
      "Epoch 98/100\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 0.0459\n",
      "Epoch 99/100\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 0.0454\n",
      "Epoch 100/100\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 0.0449\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a485ef748>"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_FGP = Sequential()\n",
    "NN_FGP.add(Dense(units=4,input_dim=X_train.shape[1],activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_FGP.add(Dense(units=2, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "#NN_FGP.add(Dense(units=8, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_FGP.add(Dense(units=1,activation='linear'))\n",
    "NN_FGP.compile(loss='mse', optimizer='adam')\n",
    "NN_FGP.fit(np.array(X_train), np.array(y_train), epochs=100,batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN_predictions</th>\n",
       "      <th>actual</th>\n",
       "      <th>GBR_predictions</th>\n",
       "      <th>LY_FGP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>0.222590</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.535434</td>\n",
       "      <td>0.558824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>0.732409</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.564372</td>\n",
       "      <td>0.558442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0.366325</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.532833</td>\n",
       "      <td>0.557895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.580922</td>\n",
       "      <td>0.459459</td>\n",
       "      <td>0.530762</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>0.480744</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.531293</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>0.267103</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.524069</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>0.271997</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.546233</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.351220</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.530591</td>\n",
       "      <td>0.553191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.480767</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.534088</td>\n",
       "      <td>0.553191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.384235</td>\n",
       "      <td>0.662338</td>\n",
       "      <td>0.533141</td>\n",
       "      <td>0.551724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.146280</td>\n",
       "      <td>0.482759</td>\n",
       "      <td>0.519482</td>\n",
       "      <td>0.550000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.368413</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.516154</td>\n",
       "      <td>0.548387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.588597</td>\n",
       "      <td>0.569620</td>\n",
       "      <td>0.533820</td>\n",
       "      <td>0.546667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>0.284470</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.525153</td>\n",
       "      <td>0.546667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>0.375411</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.509176</td>\n",
       "      <td>0.546667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.171719</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.506885</td>\n",
       "      <td>0.545455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.389749</td>\n",
       "      <td>0.504587</td>\n",
       "      <td>0.510225</td>\n",
       "      <td>0.543689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>0.488150</td>\n",
       "      <td>0.610169</td>\n",
       "      <td>0.514375</td>\n",
       "      <td>0.543478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>0.600080</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.508237</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.254827</td>\n",
       "      <td>0.589286</td>\n",
       "      <td>0.505856</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0.450203</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.515705</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.155543</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.505082</td>\n",
       "      <td>0.541667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>0.797168</td>\n",
       "      <td>0.543210</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.540541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.389946</td>\n",
       "      <td>0.577320</td>\n",
       "      <td>0.513291</td>\n",
       "      <td>0.540541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>0.275010</td>\n",
       "      <td>0.530769</td>\n",
       "      <td>0.511603</td>\n",
       "      <td>0.540230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.476059</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.524464</td>\n",
       "      <td>0.540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.180508</td>\n",
       "      <td>0.544444</td>\n",
       "      <td>0.501250</td>\n",
       "      <td>0.539007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.280050</td>\n",
       "      <td>0.557692</td>\n",
       "      <td>0.515618</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>0.173014</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.504330</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0.460414</td>\n",
       "      <td>0.424528</td>\n",
       "      <td>0.515415</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0.353725</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.505732</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.629635</td>\n",
       "      <td>0.407407</td>\n",
       "      <td>0.478538</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.283899</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.508499</td>\n",
       "      <td>0.537313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.596119</td>\n",
       "      <td>0.471545</td>\n",
       "      <td>0.513772</td>\n",
       "      <td>0.537190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>0.287895</td>\n",
       "      <td>0.485981</td>\n",
       "      <td>0.513225</td>\n",
       "      <td>0.537037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>0.535376</td>\n",
       "      <td>0.574468</td>\n",
       "      <td>0.505263</td>\n",
       "      <td>0.537037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.276204</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.500372</td>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>0.280705</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.506793</td>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.781508</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>0.542517</td>\n",
       "      <td>0.535433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>0.370695</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.504867</td>\n",
       "      <td>0.535211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>0.275896</td>\n",
       "      <td>0.462963</td>\n",
       "      <td>0.514679</td>\n",
       "      <td>0.535211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>0.393791</td>\n",
       "      <td>0.494624</td>\n",
       "      <td>0.520618</td>\n",
       "      <td>0.534091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>0.388204</td>\n",
       "      <td>0.577465</td>\n",
       "      <td>0.499277</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.547498</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.515600</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>0.322559</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.504024</td>\n",
       "      <td>0.532110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.597445</td>\n",
       "      <td>0.456790</td>\n",
       "      <td>0.506371</td>\n",
       "      <td>0.531746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>0.441225</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.514661</td>\n",
       "      <td>0.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.287460</td>\n",
       "      <td>0.573171</td>\n",
       "      <td>0.513309</td>\n",
       "      <td>0.530120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>0.471049</td>\n",
       "      <td>0.567416</td>\n",
       "      <td>0.505125</td>\n",
       "      <td>0.529101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.388890</td>\n",
       "      <td>0.452055</td>\n",
       "      <td>0.513411</td>\n",
       "      <td>0.527473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     NN_predictions    actual  GBR_predictions    LY_FGP\n",
       "308        0.222590  0.580645         0.535434  0.558824\n",
       "414        0.732409  0.400000         0.564372  0.558442\n",
       "246        0.366325  0.555556         0.532833  0.557895\n",
       "6          0.580922  0.459459         0.530762  0.555556\n",
       "304        0.480744  0.416667         0.531293  0.555556\n",
       "269        0.267103  0.548387         0.524069  0.555556\n",
       "534        0.271997  0.500000         0.546233  0.555556\n",
       "148        0.351220  0.510638         0.530591  0.553191\n",
       "42         0.480767  0.545455         0.534088  0.553191\n",
       "152        0.384235  0.662338         0.533141  0.551724\n",
       "131        0.146280  0.482759         0.519482  0.550000\n",
       "139        0.368413  0.617647         0.516154  0.548387\n",
       "566        0.588597  0.569620         0.533820  0.546667\n",
       "556        0.284470  0.540541         0.525153  0.546667\n",
       "511        0.375411  0.479167         0.509176  0.546667\n",
       "52         0.171719  0.529412         0.506885  0.545455\n",
       "8          0.389749  0.504587         0.510225  0.543689\n",
       "334        0.488150  0.610169         0.514375  0.543478\n",
       "313        0.600080  0.523810         0.508237  0.542857\n",
       "49         0.254827  0.589286         0.505856  0.542857\n",
       "166        0.450203  0.545455         0.515705  0.541667\n",
       "30         0.155543  0.551724         0.505082  0.541667\n",
       "378        0.797168  0.543210         0.540000  0.540541\n",
       "19         0.389946  0.577320         0.513291  0.540541\n",
       "443        0.275010  0.530769         0.511603  0.540230\n",
       "130        0.476059  0.533333         0.524464  0.540000\n",
       "32         0.180508  0.544444         0.501250  0.539007\n",
       "220        0.280050  0.557692         0.515618  0.538462\n",
       "281        0.173014  0.529412         0.504330  0.538462\n",
       "235        0.460414  0.424528         0.515415  0.538462\n",
       "557        0.353725  0.541667         0.505732  0.538462\n",
       "34         0.629635  0.407407         0.478538  0.538462\n",
       "92         0.283899  0.461538         0.508499  0.537313\n",
       "46         0.596119  0.471545         0.513772  0.537190\n",
       "487        0.287895  0.485981         0.513225  0.537037\n",
       "330        0.535376  0.574468         0.505263  0.537037\n",
       "149        0.276204  0.447368         0.500372  0.535714\n",
       "630        0.280705  0.523810         0.506793  0.535714\n",
       "70         0.781508  0.507812         0.542517  0.535433\n",
       "637        0.370695  0.493827         0.504867  0.535211\n",
       "459        0.275896  0.462963         0.514679  0.535211\n",
       "392        0.393791  0.494624         0.520618  0.534091\n",
       "165        0.388204  0.577465         0.499277  0.533333\n",
       "226        0.547498  0.600000         0.515600  0.533333\n",
       "619        0.322559  0.357143         0.504024  0.532110\n",
       "40         0.597445  0.456790         0.506371  0.531746\n",
       "527        0.441225  0.479167         0.514661  0.531250\n",
       "102        0.287460  0.573171         0.513309  0.530120\n",
       "324        0.471049  0.567416         0.505125  0.529101\n",
       "133        0.388890  0.452055         0.513411  0.527473"
      ]
     },
     "execution_count": 744,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = NN_FGP.predict(X_test)\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.5)\n",
    "gbr.fit(X_train,y_train)\n",
    "gbr_predictions = gbr.predict(X_test)\n",
    "LR = LinearRegression(fit_intercept=True).fit(X_train,y_train)\n",
    "\n",
    "testing = pd.DataFrame(predictions)\n",
    "testing.columns=['NN_predictions']\n",
    "testing['actual'] = y_test.reset_index()['FG_percent']\n",
    "testing['GBR_predictions']=gbr_predictions\n",
    "testing['LY_FGP']=X_test['FG_percent_ly'].reset_index()['FG_percent_ly']\n",
    "testing.sort_values(by='LY_FGP',ascending=False)[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2017FGP = percentages[percentages['season']==2017][['FG_percent_ly','career_FGpercent','age','age_squared','yearspro']]\n",
    "#pred_2017blocks = blocks[blocks['season']==2017][['blocks_ly','career_blocks','starter_change']]\n",
    "FGP_2017 = NN_FGP.predict(pred_2017FGP)\n",
    "gbr_FGP_2017 = pd.DataFrame(gbr.predict(pred_2017FGP))\n",
    "LR_FGP_2017 = pd.DataFrame(LR.predict(pred_2017FGP))\n",
    "test_2 =pd.DataFrame(FGP_2017)\n",
    "test_3 = pd.merge(percentages,pred_2017FGP,left_index=True,right_index=True).reset_index()\n",
    "test_3['predictions']=test_2[0]\n",
    "test_3['gbr_pred'] = gbr_FGP_2017[0]\n",
    "test_3['LR_pred'] = LR_FGP_2017[0]\n",
    "test_3['mean_pred'] = (test_3['predictions']+test_3['gbr_pred']+test_3['LR_pred'])/3\n",
    "test_3 = test_3[test_3['Games']>30]\n",
    "test_3[['player','FG_percent','predictions','LR_pred','gbr_pred','mean_pred','FG_percent_ly_x']].sort_values(by='FG_percent_ly_x',ascending=False)[0:50]\n",
    "\n",
    "FGP_2017 = test_3[['player','LR_pred']]\n",
    "FGP_2017.columns = ['player','FGP_prediction']\n",
    "df_2017 = pd.merge(df_2017,FGP_2017,how='left',left_on='player',right_on='player')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>player</th>\n",
       "      <th>position</th>\n",
       "      <th>age</th>\n",
       "      <th>team</th>\n",
       "      <th>gamesPlayed</th>\n",
       "      <th>gamesStarted</th>\n",
       "      <th>minutes</th>\n",
       "      <th>points</th>\n",
       "      <th>rebounds</th>\n",
       "      <th>...</th>\n",
       "      <th>point_prediction1</th>\n",
       "      <th>rebound_prediction</th>\n",
       "      <th>assist_prediction</th>\n",
       "      <th>steal_prediction</th>\n",
       "      <th>block_predictions</th>\n",
       "      <th>three_prediction</th>\n",
       "      <th>turnover_prediction</th>\n",
       "      <th>FGM_prediction</th>\n",
       "      <th>FGP_prediction</th>\n",
       "      <th>FGA_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>LeBron James</td>\n",
       "      <td>PF</td>\n",
       "      <td>33</td>\n",
       "      <td>CLE</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>36.9</td>\n",
       "      <td>27.5</td>\n",
       "      <td>8.6</td>\n",
       "      <td>...</td>\n",
       "      <td>25.424311</td>\n",
       "      <td>8.361651</td>\n",
       "      <td>7.785282</td>\n",
       "      <td>1.316493</td>\n",
       "      <td>0.620350</td>\n",
       "      <td>1.619547</td>\n",
       "      <td>3.500033</td>\n",
       "      <td>9.511008</td>\n",
       "      <td>0.503469</td>\n",
       "      <td>18.890945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>Khris Middleton</td>\n",
       "      <td>SF</td>\n",
       "      <td>26</td>\n",
       "      <td>MIL</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>36.4</td>\n",
       "      <td>20.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>...</td>\n",
       "      <td>14.198110</td>\n",
       "      <td>3.867137</td>\n",
       "      <td>2.935482</td>\n",
       "      <td>1.208045</td>\n",
       "      <td>0.189757</td>\n",
       "      <td>1.626678</td>\n",
       "      <td>1.800965</td>\n",
       "      <td>5.070777</td>\n",
       "      <td>0.450770</td>\n",
       "      <td>11.249146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>Bradley Beal</td>\n",
       "      <td>SG</td>\n",
       "      <td>24</td>\n",
       "      <td>WAS</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>36.3</td>\n",
       "      <td>22.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>...</td>\n",
       "      <td>21.537629</td>\n",
       "      <td>3.673355</td>\n",
       "      <td>3.480760</td>\n",
       "      <td>1.103869</td>\n",
       "      <td>0.312090</td>\n",
       "      <td>2.677458</td>\n",
       "      <td>2.089476</td>\n",
       "      <td>7.504306</td>\n",
       "      <td>0.462144</td>\n",
       "      <td>16.238027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>Andrew Wiggins</td>\n",
       "      <td>SF</td>\n",
       "      <td>22</td>\n",
       "      <td>MIN</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>36.3</td>\n",
       "      <td>17.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>...</td>\n",
       "      <td>20.374212</td>\n",
       "      <td>3.971672</td>\n",
       "      <td>1.989946</td>\n",
       "      <td>0.970037</td>\n",
       "      <td>0.466647</td>\n",
       "      <td>1.299265</td>\n",
       "      <td>2.113793</td>\n",
       "      <td>7.174905</td>\n",
       "      <td>0.459433</td>\n",
       "      <td>15.616875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>CJ McCollum</td>\n",
       "      <td>SG</td>\n",
       "      <td>26</td>\n",
       "      <td>POR</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>36.1</td>\n",
       "      <td>21.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.895512</td>\n",
       "      <td>3.723528</td>\n",
       "      <td>3.296357</td>\n",
       "      <td>0.918815</td>\n",
       "      <td>0.406112</td>\n",
       "      <td>2.251587</td>\n",
       "      <td>2.086009</td>\n",
       "      <td>7.592408</td>\n",
       "      <td>0.463172</td>\n",
       "      <td>16.392183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017</td>\n",
       "      <td>Jrue Holiday</td>\n",
       "      <td>SG</td>\n",
       "      <td>27</td>\n",
       "      <td>NOP</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>36.1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>13.497200</td>\n",
       "      <td>3.636798</td>\n",
       "      <td>5.483276</td>\n",
       "      <td>1.349885</td>\n",
       "      <td>0.554152</td>\n",
       "      <td>1.459485</td>\n",
       "      <td>2.182341</td>\n",
       "      <td>5.214046</td>\n",
       "      <td>0.447496</td>\n",
       "      <td>11.651596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017</td>\n",
       "      <td>Karl-Anthony Towns</td>\n",
       "      <td>C</td>\n",
       "      <td>22</td>\n",
       "      <td>MIN</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>35.6</td>\n",
       "      <td>21.3</td>\n",
       "      <td>12.3</td>\n",
       "      <td>...</td>\n",
       "      <td>23.845487</td>\n",
       "      <td>11.762938</td>\n",
       "      <td>3.237169</td>\n",
       "      <td>0.910166</td>\n",
       "      <td>1.355832</td>\n",
       "      <td>1.295572</td>\n",
       "      <td>2.605221</td>\n",
       "      <td>9.674044</td>\n",
       "      <td>0.524297</td>\n",
       "      <td>18.451458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017</td>\n",
       "      <td>Russell Westbrook</td>\n",
       "      <td>PG</td>\n",
       "      <td>29</td>\n",
       "      <td>OKC</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>36.4</td>\n",
       "      <td>25.4</td>\n",
       "      <td>10.1</td>\n",
       "      <td>...</td>\n",
       "      <td>30.484011</td>\n",
       "      <td>10.382550</td>\n",
       "      <td>10.778116</td>\n",
       "      <td>1.874924</td>\n",
       "      <td>0.421054</td>\n",
       "      <td>2.360619</td>\n",
       "      <td>4.371149</td>\n",
       "      <td>10.279182</td>\n",
       "      <td>0.433708</td>\n",
       "      <td>23.700673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017</td>\n",
       "      <td>Paul George</td>\n",
       "      <td>SF</td>\n",
       "      <td>27</td>\n",
       "      <td>OKC</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "      <td>36.6</td>\n",
       "      <td>21.9</td>\n",
       "      <td>5.7</td>\n",
       "      <td>...</td>\n",
       "      <td>21.306550</td>\n",
       "      <td>6.517464</td>\n",
       "      <td>3.312959</td>\n",
       "      <td>1.487320</td>\n",
       "      <td>0.402633</td>\n",
       "      <td>2.491622</td>\n",
       "      <td>2.395016</td>\n",
       "      <td>7.258782</td>\n",
       "      <td>0.445078</td>\n",
       "      <td>16.309008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>Giannis Antetokounmpo</td>\n",
       "      <td>PF</td>\n",
       "      <td>23</td>\n",
       "      <td>MIL</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>36.7</td>\n",
       "      <td>26.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.315313</td>\n",
       "      <td>9.424430</td>\n",
       "      <td>5.546198</td>\n",
       "      <td>1.464780</td>\n",
       "      <td>1.654603</td>\n",
       "      <td>0.995816</td>\n",
       "      <td>2.792504</td>\n",
       "      <td>8.677481</td>\n",
       "      <td>0.497889</td>\n",
       "      <td>17.428549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017</td>\n",
       "      <td>Kemba Walker</td>\n",
       "      <td>PG</td>\n",
       "      <td>27</td>\n",
       "      <td>CHA</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>34.2</td>\n",
       "      <td>22.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>...</td>\n",
       "      <td>21.729887</td>\n",
       "      <td>3.850917</td>\n",
       "      <td>5.668683</td>\n",
       "      <td>1.268280</td>\n",
       "      <td>0.318047</td>\n",
       "      <td>2.588984</td>\n",
       "      <td>2.188064</td>\n",
       "      <td>7.337477</td>\n",
       "      <td>0.431911</td>\n",
       "      <td>16.988388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017</td>\n",
       "      <td>Anthony Davis</td>\n",
       "      <td>PF</td>\n",
       "      <td>24</td>\n",
       "      <td>NOP</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>36.4</td>\n",
       "      <td>28.1</td>\n",
       "      <td>11.1</td>\n",
       "      <td>...</td>\n",
       "      <td>24.646544</td>\n",
       "      <td>11.064219</td>\n",
       "      <td>2.022336</td>\n",
       "      <td>1.303702</td>\n",
       "      <td>2.028538</td>\n",
       "      <td>0.726770</td>\n",
       "      <td>2.140279</td>\n",
       "      <td>9.718715</td>\n",
       "      <td>0.497680</td>\n",
       "      <td>19.528025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017</td>\n",
       "      <td>Ben Simmons</td>\n",
       "      <td>PG</td>\n",
       "      <td>21</td>\n",
       "      <td>PHI</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>33.7</td>\n",
       "      <td>15.8</td>\n",
       "      <td>8.1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017</td>\n",
       "      <td>Taj Gibson</td>\n",
       "      <td>PF</td>\n",
       "      <td>32</td>\n",
       "      <td>MIN</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>33.2</td>\n",
       "      <td>12.2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>...</td>\n",
       "      <td>7.886972</td>\n",
       "      <td>6.167922</td>\n",
       "      <td>0.831604</td>\n",
       "      <td>0.435601</td>\n",
       "      <td>0.865953</td>\n",
       "      <td>-0.006386</td>\n",
       "      <td>0.953715</td>\n",
       "      <td>3.392947</td>\n",
       "      <td>0.485476</td>\n",
       "      <td>6.988906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017</td>\n",
       "      <td>DeMar DeRozan</td>\n",
       "      <td>SG</td>\n",
       "      <td>28</td>\n",
       "      <td>TOR</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>33.9</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>...</td>\n",
       "      <td>23.779216</td>\n",
       "      <td>5.099873</td>\n",
       "      <td>3.671525</td>\n",
       "      <td>0.978320</td>\n",
       "      <td>0.266640</td>\n",
       "      <td>0.775972</td>\n",
       "      <td>2.337613</td>\n",
       "      <td>8.568027</td>\n",
       "      <td>0.451272</td>\n",
       "      <td>18.986411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017</td>\n",
       "      <td>Josh Richardson</td>\n",
       "      <td>SF</td>\n",
       "      <td>24</td>\n",
       "      <td>MIA</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>33.2</td>\n",
       "      <td>12.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>10.100105</td>\n",
       "      <td>3.229509</td>\n",
       "      <td>2.290296</td>\n",
       "      <td>0.992644</td>\n",
       "      <td>0.588543</td>\n",
       "      <td>1.451925</td>\n",
       "      <td>1.046828</td>\n",
       "      <td>4.132446</td>\n",
       "      <td>0.421746</td>\n",
       "      <td>9.798425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017</td>\n",
       "      <td>Will Barton</td>\n",
       "      <td>SG</td>\n",
       "      <td>27</td>\n",
       "      <td>DEN</td>\n",
       "      <td>81</td>\n",
       "      <td>40</td>\n",
       "      <td>33.1</td>\n",
       "      <td>15.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.399758</td>\n",
       "      <td>4.022634</td>\n",
       "      <td>2.565067</td>\n",
       "      <td>0.722886</td>\n",
       "      <td>0.398071</td>\n",
       "      <td>1.385873</td>\n",
       "      <td>1.323617</td>\n",
       "      <td>4.468919</td>\n",
       "      <td>0.436407</td>\n",
       "      <td>10.240260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017</td>\n",
       "      <td>Damian Lillard</td>\n",
       "      <td>PG</td>\n",
       "      <td>27</td>\n",
       "      <td>POR</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>36.6</td>\n",
       "      <td>26.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>25.379830</td>\n",
       "      <td>4.814953</td>\n",
       "      <td>6.273397</td>\n",
       "      <td>0.990983</td>\n",
       "      <td>0.292973</td>\n",
       "      <td>2.870581</td>\n",
       "      <td>2.795859</td>\n",
       "      <td>8.550061</td>\n",
       "      <td>0.438990</td>\n",
       "      <td>19.476669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2017</td>\n",
       "      <td>Donovan Mitchell</td>\n",
       "      <td>SG</td>\n",
       "      <td>21</td>\n",
       "      <td>UTA</td>\n",
       "      <td>79</td>\n",
       "      <td>71</td>\n",
       "      <td>33.4</td>\n",
       "      <td>20.5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2017</td>\n",
       "      <td>Harrison Barnes</td>\n",
       "      <td>PF</td>\n",
       "      <td>25</td>\n",
       "      <td>DAL</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>34.2</td>\n",
       "      <td>18.9</td>\n",
       "      <td>6.1</td>\n",
       "      <td>...</td>\n",
       "      <td>15.962947</td>\n",
       "      <td>4.988234</td>\n",
       "      <td>1.422186</td>\n",
       "      <td>0.702676</td>\n",
       "      <td>0.251840</td>\n",
       "      <td>1.116372</td>\n",
       "      <td>1.225539</td>\n",
       "      <td>6.257304</td>\n",
       "      <td>0.460956</td>\n",
       "      <td>13.574638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2017</td>\n",
       "      <td>Andre Drummond</td>\n",
       "      <td>C</td>\n",
       "      <td>24</td>\n",
       "      <td>DET</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>33.7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14.978185</td>\n",
       "      <td>13.050855</td>\n",
       "      <td>1.603879</td>\n",
       "      <td>1.305330</td>\n",
       "      <td>1.196186</td>\n",
       "      <td>0.217655</td>\n",
       "      <td>1.806616</td>\n",
       "      <td>6.041500</td>\n",
       "      <td>0.520594</td>\n",
       "      <td>11.605017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2017</td>\n",
       "      <td>Thaddeus Young</td>\n",
       "      <td>PF</td>\n",
       "      <td>29</td>\n",
       "      <td>IND</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>32.2</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6.3</td>\n",
       "      <td>...</td>\n",
       "      <td>11.356985</td>\n",
       "      <td>6.493423</td>\n",
       "      <td>1.740750</td>\n",
       "      <td>1.268506</td>\n",
       "      <td>0.404301</td>\n",
       "      <td>0.552332</td>\n",
       "      <td>1.218197</td>\n",
       "      <td>4.627681</td>\n",
       "      <td>0.490116</td>\n",
       "      <td>9.442015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2017</td>\n",
       "      <td>Lou Williams</td>\n",
       "      <td>SG</td>\n",
       "      <td>31</td>\n",
       "      <td>LAC</td>\n",
       "      <td>79</td>\n",
       "      <td>19</td>\n",
       "      <td>32.8</td>\n",
       "      <td>22.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>16.289279</td>\n",
       "      <td>2.442583</td>\n",
       "      <td>3.061031</td>\n",
       "      <td>0.911594</td>\n",
       "      <td>0.197135</td>\n",
       "      <td>1.879114</td>\n",
       "      <td>1.909219</td>\n",
       "      <td>5.129581</td>\n",
       "      <td>0.431505</td>\n",
       "      <td>11.887654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2017</td>\n",
       "      <td>E'Twaun Moore</td>\n",
       "      <td>SG</td>\n",
       "      <td>28</td>\n",
       "      <td>NOP</td>\n",
       "      <td>82</td>\n",
       "      <td>80</td>\n",
       "      <td>31.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2.9</td>\n",
       "      <td>...</td>\n",
       "      <td>9.229678</td>\n",
       "      <td>2.939848</td>\n",
       "      <td>1.805649</td>\n",
       "      <td>0.821284</td>\n",
       "      <td>0.409322</td>\n",
       "      <td>1.258333</td>\n",
       "      <td>0.861509</td>\n",
       "      <td>3.792157</td>\n",
       "      <td>0.445388</td>\n",
       "      <td>8.514268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2017</td>\n",
       "      <td>Joe Ingles</td>\n",
       "      <td>SF</td>\n",
       "      <td>30</td>\n",
       "      <td>UTA</td>\n",
       "      <td>82</td>\n",
       "      <td>81</td>\n",
       "      <td>31.4</td>\n",
       "      <td>11.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>...</td>\n",
       "      <td>10.249450</td>\n",
       "      <td>4.238186</td>\n",
       "      <td>2.865207</td>\n",
       "      <td>1.207580</td>\n",
       "      <td>0.144862</td>\n",
       "      <td>1.661616</td>\n",
       "      <td>1.365220</td>\n",
       "      <td>3.741363</td>\n",
       "      <td>0.439140</td>\n",
       "      <td>8.519751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2017</td>\n",
       "      <td>Jamal Murray</td>\n",
       "      <td>PG</td>\n",
       "      <td>20</td>\n",
       "      <td>DEN</td>\n",
       "      <td>81</td>\n",
       "      <td>80</td>\n",
       "      <td>31.7</td>\n",
       "      <td>16.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>...</td>\n",
       "      <td>12.945887</td>\n",
       "      <td>3.887931</td>\n",
       "      <td>3.109745</td>\n",
       "      <td>0.939054</td>\n",
       "      <td>0.460381</td>\n",
       "      <td>1.699873</td>\n",
       "      <td>1.859169</td>\n",
       "      <td>5.044015</td>\n",
       "      <td>0.433626</td>\n",
       "      <td>11.632179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2017</td>\n",
       "      <td>Victor Oladipo</td>\n",
       "      <td>SG</td>\n",
       "      <td>25</td>\n",
       "      <td>IND</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>34.0</td>\n",
       "      <td>23.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>...</td>\n",
       "      <td>15.600713</td>\n",
       "      <td>4.498231</td>\n",
       "      <td>2.787741</td>\n",
       "      <td>1.262484</td>\n",
       "      <td>0.385480</td>\n",
       "      <td>1.750240</td>\n",
       "      <td>1.835617</td>\n",
       "      <td>5.684300</td>\n",
       "      <td>0.442407</td>\n",
       "      <td>12.848583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2017</td>\n",
       "      <td>James Harden</td>\n",
       "      <td>SG</td>\n",
       "      <td>28</td>\n",
       "      <td>HOU</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>35.4</td>\n",
       "      <td>30.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>...</td>\n",
       "      <td>29.653079</td>\n",
       "      <td>8.091593</td>\n",
       "      <td>9.404660</td>\n",
       "      <td>1.583227</td>\n",
       "      <td>0.532181</td>\n",
       "      <td>3.177063</td>\n",
       "      <td>4.602949</td>\n",
       "      <td>9.360777</td>\n",
       "      <td>0.443136</td>\n",
       "      <td>21.123928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2017</td>\n",
       "      <td>Robert Covington</td>\n",
       "      <td>SF</td>\n",
       "      <td>27</td>\n",
       "      <td>PHI</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>31.7</td>\n",
       "      <td>12.6</td>\n",
       "      <td>5.4</td>\n",
       "      <td>...</td>\n",
       "      <td>13.257159</td>\n",
       "      <td>6.141305</td>\n",
       "      <td>1.701040</td>\n",
       "      <td>1.478314</td>\n",
       "      <td>0.753829</td>\n",
       "      <td>2.090852</td>\n",
       "      <td>1.554572</td>\n",
       "      <td>4.578262</td>\n",
       "      <td>0.414166</td>\n",
       "      <td>11.054170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2017</td>\n",
       "      <td>LaMarcus Aldridge</td>\n",
       "      <td>C</td>\n",
       "      <td>32</td>\n",
       "      <td>SAS</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>33.5</td>\n",
       "      <td>23.1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>...</td>\n",
       "      <td>15.486035</td>\n",
       "      <td>7.200820</td>\n",
       "      <td>1.824770</td>\n",
       "      <td>0.600570</td>\n",
       "      <td>1.046773</td>\n",
       "      <td>0.344976</td>\n",
       "      <td>1.344047</td>\n",
       "      <td>6.484094</td>\n",
       "      <td>0.466119</td>\n",
       "      <td>13.910804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>2017</td>\n",
       "      <td>Kendrick Perkins</td>\n",
       "      <td>C</td>\n",
       "      <td>33</td>\n",
       "      <td>CLE</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>2017</td>\n",
       "      <td>Devin Robinson</td>\n",
       "      <td>SF</td>\n",
       "      <td>22</td>\n",
       "      <td>WAS</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>2017</td>\n",
       "      <td>Luol Deng</td>\n",
       "      <td>SF</td>\n",
       "      <td>32</td>\n",
       "      <td>LAL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>2017</td>\n",
       "      <td>Tim Quarterman</td>\n",
       "      <td>SG</td>\n",
       "      <td>23</td>\n",
       "      <td>HOU</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>2017</td>\n",
       "      <td>Josh Smith</td>\n",
       "      <td>PF</td>\n",
       "      <td>32</td>\n",
       "      <td>NOP</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>2017</td>\n",
       "      <td>Matt Williams</td>\n",
       "      <td>SG</td>\n",
       "      <td>24</td>\n",
       "      <td>MIA</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>2017</td>\n",
       "      <td>Nicolas Brussino</td>\n",
       "      <td>SF</td>\n",
       "      <td>24</td>\n",
       "      <td>ATL</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>2017</td>\n",
       "      <td>Derrick Williams</td>\n",
       "      <td>PF</td>\n",
       "      <td>26</td>\n",
       "      <td>LAL</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>2017</td>\n",
       "      <td>David Stockton</td>\n",
       "      <td>PG</td>\n",
       "      <td>26</td>\n",
       "      <td>UTA</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>2017</td>\n",
       "      <td>Ben Moore</td>\n",
       "      <td>PF</td>\n",
       "      <td>22</td>\n",
       "      <td>IND</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>2017</td>\n",
       "      <td>Scotty Hopson</td>\n",
       "      <td>SG</td>\n",
       "      <td>28</td>\n",
       "      <td>DAL</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>2017</td>\n",
       "      <td>Erik McCree</td>\n",
       "      <td>SF</td>\n",
       "      <td>24</td>\n",
       "      <td>UTA</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>2017</td>\n",
       "      <td>Luis Montero</td>\n",
       "      <td>SG</td>\n",
       "      <td>24</td>\n",
       "      <td>DET</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>2017</td>\n",
       "      <td>Vince Hunter</td>\n",
       "      <td>PF</td>\n",
       "      <td>23</td>\n",
       "      <td>MEM</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>2017</td>\n",
       "      <td>Xavier Silas</td>\n",
       "      <td>SG</td>\n",
       "      <td>30</td>\n",
       "      <td>BOS</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>2017</td>\n",
       "      <td>Reggie Hearn</td>\n",
       "      <td>SG</td>\n",
       "      <td>26</td>\n",
       "      <td>DET</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>2017</td>\n",
       "      <td>Jacob Pullen</td>\n",
       "      <td>PG</td>\n",
       "      <td>28</td>\n",
       "      <td>PHI</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>2017</td>\n",
       "      <td>Josh McRoberts</td>\n",
       "      <td>PF</td>\n",
       "      <td>30</td>\n",
       "      <td>DAL</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>2017</td>\n",
       "      <td>Jarell Eddie</td>\n",
       "      <td>SF</td>\n",
       "      <td>26</td>\n",
       "      <td>BOS</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>2017</td>\n",
       "      <td>Gordon Hayward</td>\n",
       "      <td>SF</td>\n",
       "      <td>27</td>\n",
       "      <td>BOS</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>2017</td>\n",
       "      <td>Jeremy Evans</td>\n",
       "      <td>SF</td>\n",
       "      <td>30</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>2017</td>\n",
       "      <td>Anthony Brown</td>\n",
       "      <td>SF</td>\n",
       "      <td>25</td>\n",
       "      <td>MIN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>2017</td>\n",
       "      <td>Justin Patton</td>\n",
       "      <td>C</td>\n",
       "      <td>20</td>\n",
       "      <td>MIN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>2017</td>\n",
       "      <td>PJ Dozier</td>\n",
       "      <td>PG</td>\n",
       "      <td>21</td>\n",
       "      <td>OKC</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>2017</td>\n",
       "      <td>Mindaugas Kuzminskas</td>\n",
       "      <td>SF</td>\n",
       "      <td>28</td>\n",
       "      <td>NYK</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>2017</td>\n",
       "      <td>Edmond Sumner</td>\n",
       "      <td>PG</td>\n",
       "      <td>22</td>\n",
       "      <td>IND</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>2017</td>\n",
       "      <td>Tyler Lydon</td>\n",
       "      <td>PF</td>\n",
       "      <td>21</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>2017</td>\n",
       "      <td>Naz Mitrou-Long</td>\n",
       "      <td>SG</td>\n",
       "      <td>24</td>\n",
       "      <td>UTA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>2017</td>\n",
       "      <td>Chris Boucher</td>\n",
       "      <td>PF</td>\n",
       "      <td>25</td>\n",
       "      <td>GSW</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>2017</td>\n",
       "      <td>Trey McKinney-Jones</td>\n",
       "      <td>SG</td>\n",
       "      <td>27</td>\n",
       "      <td>IND</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     season                 player position  age team  gamesPlayed  \\\n",
       "0      2017           LeBron James       PF   33  CLE           82   \n",
       "1      2017        Khris Middleton       SF   26  MIL           82   \n",
       "2      2017           Bradley Beal       SG   24  WAS           82   \n",
       "3      2017         Andrew Wiggins       SF   22  MIN           82   \n",
       "4      2017            CJ McCollum       SG   26  POR           81   \n",
       "5      2017           Jrue Holiday       SG   27  NOP           81   \n",
       "6      2017     Karl-Anthony Towns        C   22  MIN           82   \n",
       "7      2017      Russell Westbrook       PG   29  OKC           80   \n",
       "8      2017            Paul George       SF   27  OKC           79   \n",
       "9      2017  Giannis Antetokounmpo       PF   23  MIL           75   \n",
       "10     2017           Kemba Walker       PG   27  CHA           80   \n",
       "11     2017          Anthony Davis       PF   24  NOP           75   \n",
       "12     2017            Ben Simmons       PG   21  PHI           81   \n",
       "13     2017             Taj Gibson       PF   32  MIN           82   \n",
       "14     2017          DeMar DeRozan       SG   28  TOR           80   \n",
       "15     2017        Josh Richardson       SF   24  MIA           81   \n",
       "16     2017            Will Barton       SG   27  DEN           81   \n",
       "17     2017         Damian Lillard       PG   27  POR           73   \n",
       "18     2017       Donovan Mitchell       SG   21  UTA           79   \n",
       "19     2017        Harrison Barnes       PF   25  DAL           77   \n",
       "20     2017         Andre Drummond        C   24  DET           78   \n",
       "21     2017         Thaddeus Young       PF   29  IND           81   \n",
       "22     2017           Lou Williams       SG   31  LAC           79   \n",
       "23     2017          E'Twaun Moore       SG   28  NOP           82   \n",
       "24     2017             Joe Ingles       SF   30  UTA           82   \n",
       "25     2017           Jamal Murray       PG   20  DEN           81   \n",
       "26     2017         Victor Oladipo       SG   25  IND           75   \n",
       "27     2017           James Harden       SG   28  HOU           72   \n",
       "28     2017       Robert Covington       SF   27  PHI           80   \n",
       "29     2017      LaMarcus Aldridge        C   32  SAS           75   \n",
       "..      ...                    ...      ...  ...  ...          ...   \n",
       "510    2017       Kendrick Perkins        C   33  CLE            1   \n",
       "511    2017         Devin Robinson       SF   22  WAS            1   \n",
       "512    2017              Luol Deng       SF   32  LAL            1   \n",
       "513    2017         Tim Quarterman       SG   23  HOU            3   \n",
       "514    2017             Josh Smith       PF   32  NOP            3   \n",
       "515    2017          Matt Williams       SG   24  MIA            3   \n",
       "516    2017       Nicolas Brussino       SF   24  ATL            4   \n",
       "517    2017       Derrick Williams       PF   26  LAL            2   \n",
       "518    2017         David Stockton       PG   26  UTA            3   \n",
       "519    2017              Ben Moore       PF   22  IND            2   \n",
       "520    2017          Scotty Hopson       SG   28  DAL            1   \n",
       "521    2017            Erik McCree       SF   24  UTA            4   \n",
       "522    2017           Luis Montero       SG   24  DET            2   \n",
       "523    2017           Vince Hunter       PF   23  MEM            4   \n",
       "524    2017           Xavier Silas       SG   30  BOS            2   \n",
       "525    2017           Reggie Hearn       SG   26  DET            3   \n",
       "526    2017           Jacob Pullen       PG   28  PHI            3   \n",
       "527    2017         Josh McRoberts       PF   30  DAL            2   \n",
       "528    2017           Jarell Eddie       SF   26  BOS            3   \n",
       "529    2017         Gordon Hayward       SF   27  BOS            1   \n",
       "530    2017           Jeremy Evans       SF   30  ATL            1   \n",
       "531    2017          Anthony Brown       SF   25  MIN            1   \n",
       "532    2017          Justin Patton        C   20  MIN            1   \n",
       "533    2017              PJ Dozier       PG   21  OKC            2   \n",
       "534    2017   Mindaugas Kuzminskas       SF   28  NYK            1   \n",
       "535    2017          Edmond Sumner       PG   22  IND            1   \n",
       "536    2017            Tyler Lydon       PF   21  DEN            1   \n",
       "537    2017        Naz Mitrou-Long       SG   24  UTA            1   \n",
       "538    2017          Chris Boucher       PF   25  GSW            1   \n",
       "539    2017    Trey McKinney-Jones       SG   27  IND            1   \n",
       "\n",
       "     gamesStarted  minutes  points  rebounds       ...        \\\n",
       "0              82     36.9    27.5       8.6       ...         \n",
       "1              82     36.4    20.1       5.2       ...         \n",
       "2              82     36.3    22.6       4.4       ...         \n",
       "3              82     36.3    17.7       4.4       ...         \n",
       "4              81     36.1    21.4       4.0       ...         \n",
       "5              81     36.1    19.0       4.5       ...         \n",
       "6              82     35.6    21.3      12.3       ...         \n",
       "7              80     36.4    25.4      10.1       ...         \n",
       "8              79     36.6    21.9       5.7       ...         \n",
       "9              75     36.7    26.9      10.0       ...         \n",
       "10             80     34.2    22.1       3.1       ...         \n",
       "11             75     36.4    28.1      11.1       ...         \n",
       "12             81     33.7    15.8       8.1       ...         \n",
       "13             82     33.2    12.2       7.1       ...         \n",
       "14             80     33.9    23.0       3.9       ...         \n",
       "15             81     33.2    12.9       3.5       ...         \n",
       "16             40     33.1    15.7       5.0       ...         \n",
       "17             73     36.6    26.9       4.5       ...         \n",
       "18             71     33.4    20.5       3.7       ...         \n",
       "19             77     34.2    18.9       6.1       ...         \n",
       "20             78     33.7    15.0      16.0       ...         \n",
       "21             81     32.2    11.8       6.3       ...         \n",
       "22             19     32.8    22.6       2.5       ...         \n",
       "23             80     31.5    12.5       2.9       ...         \n",
       "24             81     31.4    11.5       4.2       ...         \n",
       "25             80     31.7    16.7       3.7       ...         \n",
       "26             75     34.0    23.1       5.2       ...         \n",
       "27             72     35.4    30.4       5.4       ...         \n",
       "28             80     31.7    12.6       5.4       ...         \n",
       "29             75     33.5    23.1       8.5       ...         \n",
       "..            ...      ...     ...       ...       ...         \n",
       "510             0     15.0     3.0       1.0       ...         \n",
       "511             0     13.0     2.0       5.0       ...         \n",
       "512             1     13.0     2.0       0.0       ...         \n",
       "513             0      4.3     1.3       1.0       ...         \n",
       "514             0      4.0     0.7       1.3       ...         \n",
       "515             0      3.7     1.7       0.3       ...         \n",
       "516             0      2.5     0.0       0.8       ...         \n",
       "517             0      4.5     1.0       0.5       ...         \n",
       "518             0      3.0     3.3       0.0       ...         \n",
       "519             0      4.5     0.0       0.5       ...         \n",
       "520             0      8.0     1.0       0.0       ...         \n",
       "521             0      2.0     0.0       0.3       ...         \n",
       "522             0      4.0     0.0       1.0       ...         \n",
       "523             0      1.8     1.5       0.8       ...         \n",
       "524             0      3.5     0.0       1.0       ...         \n",
       "525             0      2.3     1.0       0.0       ...         \n",
       "526             0      2.0     0.7       0.0       ...         \n",
       "527             0      3.0     0.0       0.0       ...         \n",
       "528             0      3.0     0.0       0.5       ...         \n",
       "529             1      5.0     2.0       1.0       ...         \n",
       "530             0      5.0     2.0       1.0       ...         \n",
       "531             0      4.0     3.0       0.0       ...         \n",
       "532             0      4.0     2.0       0.0       ...         \n",
       "533             0      1.5     1.0       0.5       ...         \n",
       "534             0      2.0     0.0       0.0       ...         \n",
       "535             0      2.0     2.0       1.0       ...         \n",
       "536             0      2.0     0.0       0.0       ...         \n",
       "537             0      1.0     3.0       0.0       ...         \n",
       "538             0      1.0     0.0       1.0       ...         \n",
       "539             0      1.0     0.0       0.0       ...         \n",
       "\n",
       "     point_prediction1  rebound_prediction  assist_prediction  \\\n",
       "0            25.424311            8.361651           7.785282   \n",
       "1            14.198110            3.867137           2.935482   \n",
       "2            21.537629            3.673355           3.480760   \n",
       "3            20.374212            3.971672           1.989946   \n",
       "4            20.895512            3.723528           3.296357   \n",
       "5            13.497200            3.636798           5.483276   \n",
       "6            23.845487           11.762938           3.237169   \n",
       "7            30.484011           10.382550          10.778116   \n",
       "8            21.306550            6.517464           3.312959   \n",
       "9            23.315313            9.424430           5.546198   \n",
       "10           21.729887            3.850917           5.668683   \n",
       "11           24.646544           11.064219           2.022336   \n",
       "12                 NaN                 NaN                NaN   \n",
       "13            7.886972            6.167922           0.831604   \n",
       "14           23.779216            5.099873           3.671525   \n",
       "15           10.100105            3.229509           2.290296   \n",
       "16           12.399758            4.022634           2.565067   \n",
       "17           25.379830            4.814953           6.273397   \n",
       "18                 NaN                 NaN                NaN   \n",
       "19           15.962947            4.988234           1.422186   \n",
       "20           14.978185           13.050855           1.603879   \n",
       "21           11.356985            6.493423           1.740750   \n",
       "22           16.289279            2.442583           3.061031   \n",
       "23            9.229678            2.939848           1.805649   \n",
       "24           10.249450            4.238186           2.865207   \n",
       "25           12.945887            3.887931           3.109745   \n",
       "26           15.600713            4.498231           2.787741   \n",
       "27           29.653079            8.091593           9.404660   \n",
       "28           13.257159            6.141305           1.701040   \n",
       "29           15.486035            7.200820           1.824770   \n",
       "..                 ...                 ...                ...   \n",
       "510                NaN                 NaN                NaN   \n",
       "511                NaN                 NaN                NaN   \n",
       "512                NaN                 NaN                NaN   \n",
       "513                NaN                 NaN                NaN   \n",
       "514                NaN                 NaN                NaN   \n",
       "515                NaN                 NaN                NaN   \n",
       "516                NaN                 NaN                NaN   \n",
       "517                NaN                 NaN                NaN   \n",
       "518                NaN                 NaN                NaN   \n",
       "519                NaN                 NaN                NaN   \n",
       "520                NaN                 NaN                NaN   \n",
       "521                NaN                 NaN                NaN   \n",
       "522                NaN                 NaN                NaN   \n",
       "523                NaN                 NaN                NaN   \n",
       "524                NaN                 NaN                NaN   \n",
       "525                NaN                 NaN                NaN   \n",
       "526                NaN                 NaN                NaN   \n",
       "527                NaN                 NaN                NaN   \n",
       "528                NaN                 NaN                NaN   \n",
       "529                NaN                 NaN                NaN   \n",
       "530                NaN                 NaN                NaN   \n",
       "531                NaN                 NaN                NaN   \n",
       "532                NaN                 NaN                NaN   \n",
       "533                NaN                 NaN                NaN   \n",
       "534                NaN                 NaN                NaN   \n",
       "535                NaN                 NaN                NaN   \n",
       "536                NaN                 NaN                NaN   \n",
       "537                NaN                 NaN                NaN   \n",
       "538                NaN                 NaN                NaN   \n",
       "539                NaN                 NaN                NaN   \n",
       "\n",
       "     steal_prediction  block_predictions  three_prediction  \\\n",
       "0            1.316493           0.620350          1.619547   \n",
       "1            1.208045           0.189757          1.626678   \n",
       "2            1.103869           0.312090          2.677458   \n",
       "3            0.970037           0.466647          1.299265   \n",
       "4            0.918815           0.406112          2.251587   \n",
       "5            1.349885           0.554152          1.459485   \n",
       "6            0.910166           1.355832          1.295572   \n",
       "7            1.874924           0.421054          2.360619   \n",
       "8            1.487320           0.402633          2.491622   \n",
       "9            1.464780           1.654603          0.995816   \n",
       "10           1.268280           0.318047          2.588984   \n",
       "11           1.303702           2.028538          0.726770   \n",
       "12                NaN                NaN               NaN   \n",
       "13           0.435601           0.865953         -0.006386   \n",
       "14           0.978320           0.266640          0.775972   \n",
       "15           0.992644           0.588543          1.451925   \n",
       "16           0.722886           0.398071          1.385873   \n",
       "17           0.990983           0.292973          2.870581   \n",
       "18                NaN                NaN               NaN   \n",
       "19           0.702676           0.251840          1.116372   \n",
       "20           1.305330           1.196186          0.217655   \n",
       "21           1.268506           0.404301          0.552332   \n",
       "22           0.911594           0.197135          1.879114   \n",
       "23           0.821284           0.409322          1.258333   \n",
       "24           1.207580           0.144862          1.661616   \n",
       "25           0.939054           0.460381          1.699873   \n",
       "26           1.262484           0.385480          1.750240   \n",
       "27           1.583227           0.532181          3.177063   \n",
       "28           1.478314           0.753829          2.090852   \n",
       "29           0.600570           1.046773          0.344976   \n",
       "..                ...                ...               ...   \n",
       "510               NaN                NaN               NaN   \n",
       "511               NaN                NaN               NaN   \n",
       "512               NaN                NaN               NaN   \n",
       "513               NaN                NaN               NaN   \n",
       "514               NaN                NaN               NaN   \n",
       "515               NaN                NaN               NaN   \n",
       "516               NaN                NaN               NaN   \n",
       "517               NaN                NaN               NaN   \n",
       "518               NaN                NaN               NaN   \n",
       "519               NaN                NaN               NaN   \n",
       "520               NaN                NaN               NaN   \n",
       "521               NaN                NaN               NaN   \n",
       "522               NaN                NaN               NaN   \n",
       "523               NaN                NaN               NaN   \n",
       "524               NaN                NaN               NaN   \n",
       "525               NaN                NaN               NaN   \n",
       "526               NaN                NaN               NaN   \n",
       "527               NaN                NaN               NaN   \n",
       "528               NaN                NaN               NaN   \n",
       "529               NaN                NaN               NaN   \n",
       "530               NaN                NaN               NaN   \n",
       "531               NaN                NaN               NaN   \n",
       "532               NaN                NaN               NaN   \n",
       "533               NaN                NaN               NaN   \n",
       "534               NaN                NaN               NaN   \n",
       "535               NaN                NaN               NaN   \n",
       "536               NaN                NaN               NaN   \n",
       "537               NaN                NaN               NaN   \n",
       "538               NaN                NaN               NaN   \n",
       "539               NaN                NaN               NaN   \n",
       "\n",
       "     turnover_prediction  FGM_prediction  FGP_prediction  FGA_prediction  \n",
       "0               3.500033        9.511008        0.503469       18.890945  \n",
       "1               1.800965        5.070777        0.450770       11.249146  \n",
       "2               2.089476        7.504306        0.462144       16.238027  \n",
       "3               2.113793        7.174905        0.459433       15.616875  \n",
       "4               2.086009        7.592408        0.463172       16.392183  \n",
       "5               2.182341        5.214046        0.447496       11.651596  \n",
       "6               2.605221        9.674044        0.524297       18.451458  \n",
       "7               4.371149       10.279182        0.433708       23.700673  \n",
       "8               2.395016        7.258782        0.445078       16.309008  \n",
       "9               2.792504        8.677481        0.497889       17.428549  \n",
       "10              2.188064        7.337477        0.431911       16.988388  \n",
       "11              2.140279        9.718715        0.497680       19.528025  \n",
       "12                   NaN             NaN             NaN             NaN  \n",
       "13              0.953715        3.392947        0.485476        6.988906  \n",
       "14              2.337613        8.568027        0.451272       18.986411  \n",
       "15              1.046828        4.132446        0.421746        9.798425  \n",
       "16              1.323617        4.468919        0.436407       10.240260  \n",
       "17              2.795859        8.550061        0.438990       19.476669  \n",
       "18                   NaN             NaN             NaN             NaN  \n",
       "19              1.225539        6.257304        0.460956       13.574638  \n",
       "20              1.806616        6.041500        0.520594       11.605017  \n",
       "21              1.218197        4.627681        0.490116        9.442015  \n",
       "22              1.909219        5.129581        0.431505       11.887654  \n",
       "23              0.861509        3.792157        0.445388        8.514268  \n",
       "24              1.365220        3.741363        0.439140        8.519751  \n",
       "25              1.859169        5.044015        0.433626       11.632179  \n",
       "26              1.835617        5.684300        0.442407       12.848583  \n",
       "27              4.602949        9.360777        0.443136       21.123928  \n",
       "28              1.554572        4.578262        0.414166       11.054170  \n",
       "29              1.344047        6.484094        0.466119       13.910804  \n",
       "..                   ...             ...             ...             ...  \n",
       "510                  NaN             NaN             NaN             NaN  \n",
       "511                  NaN             NaN             NaN             NaN  \n",
       "512                  NaN             NaN             NaN             NaN  \n",
       "513                  NaN             NaN             NaN             NaN  \n",
       "514                  NaN             NaN             NaN             NaN  \n",
       "515                  NaN             NaN             NaN             NaN  \n",
       "516                  NaN             NaN             NaN             NaN  \n",
       "517                  NaN             NaN             NaN             NaN  \n",
       "518                  NaN             NaN             NaN             NaN  \n",
       "519                  NaN             NaN             NaN             NaN  \n",
       "520                  NaN             NaN             NaN             NaN  \n",
       "521                  NaN             NaN             NaN             NaN  \n",
       "522                  NaN             NaN             NaN             NaN  \n",
       "523                  NaN             NaN             NaN             NaN  \n",
       "524                  NaN             NaN             NaN             NaN  \n",
       "525                  NaN             NaN             NaN             NaN  \n",
       "526                  NaN             NaN             NaN             NaN  \n",
       "527                  NaN             NaN             NaN             NaN  \n",
       "528                  NaN             NaN             NaN             NaN  \n",
       "529                  NaN             NaN             NaN             NaN  \n",
       "530                  NaN             NaN             NaN             NaN  \n",
       "531                  NaN             NaN             NaN             NaN  \n",
       "532                  NaN             NaN             NaN             NaN  \n",
       "533                  NaN             NaN             NaN             NaN  \n",
       "534                  NaN             NaN             NaN             NaN  \n",
       "535                  NaN             NaN             NaN             NaN  \n",
       "536                  NaN             NaN             NaN             NaN  \n",
       "537                  NaN             NaN             NaN             NaN  \n",
       "538                  NaN             NaN             NaN             NaN  \n",
       "539                  NaN             NaN             NaN             NaN  \n",
       "\n",
       "[540 rows x 31 columns]"
      ]
     },
     "execution_count": 753,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017['FGA_prediction']=df_2017['FGM_prediction']/df_2017['FGP_prediction']\n",
    "df_2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE using LR:0.0022284259597940064\n",
      "MSE using GB:0.0024224232493726457\n",
      "MSE using NN:0.10273045459004024\n",
      "MSE using combo:0.013105491342542686\n",
      "MSE using mean:0.004468180392374211\n",
      "MSE using last year stats:0.0029957528880071352\n"
     ]
    }
   ],
   "source": [
    "print('MSE using LR:{}'.format(np.mean((test_3['FG_percent']-test_3['LR_pred'])**2)))\n",
    "print('MSE using GB:{}'.format(np.mean((test_3['FG_percent']-test_3['gbr_pred'])**2)))\n",
    "print('MSE using NN:{}'.format(np.mean((test_3['FG_percent']-test_3['predictions'])**2)))\n",
    "print('MSE using combo:{}'.format(np.mean((test_3['FG_percent']-test_3['mean_pred'])**2)))\n",
    "print('MSE using mean:{}'.format(np.mean((test_3['FG_percent']-np.mean(test_3['FG_percent']))**2)))\n",
    "print('MSE using last year stats:{}'.format(np.mean((test_3['FG_percent']-test_3['FG_percent_ly_x'])**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = percentages[(percentages['season']!=2017) & (percentages['Games']>30)].drop(['player','team','FGM','FGA','FG_percent','FTM','FTA','Games'],axis=1)\n",
    "y = percentages[(percentages['season']!=2017) & (percentages['Games']>30)]['FTM']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1564/1564 [==============================] - 4s 3ms/step - loss: 1145.5147\n",
      "Epoch 2/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 265.8416\n",
      "Epoch 3/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 129.8761\n",
      "Epoch 4/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 77.9205\n",
      "Epoch 5/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 59.3892\n",
      "Epoch 6/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 47.3370\n",
      "Epoch 7/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 39.6430\n",
      "Epoch 8/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 34.3775\n",
      "Epoch 9/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 28.9606\n",
      "Epoch 10/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 26.2375\n",
      "Epoch 11/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 23.4802\n",
      "Epoch 12/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 21.4413\n",
      "Epoch 13/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 19.8936\n",
      "Epoch 14/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 18.7477\n",
      "Epoch 15/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 17.2787\n",
      "Epoch 16/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 16.1693\n",
      "Epoch 17/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 15.0283\n",
      "Epoch 18/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 14.0034\n",
      "Epoch 19/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 13.1516\n",
      "Epoch 20/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 12.3850\n",
      "Epoch 21/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 11.6690\n",
      "Epoch 22/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 10.9777\n",
      "Epoch 23/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 10.5676\n",
      "Epoch 24/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 10.2201\n",
      "Epoch 25/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 9.4639\n",
      "Epoch 26/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.8985\n",
      "Epoch 27/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 8.5931\n",
      "Epoch 28/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.1174\n",
      "Epoch 29/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.2006\n",
      "Epoch 30/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.6315\n",
      "Epoch 31/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.1767\n",
      "Epoch 32/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.8437\n",
      "Epoch 33/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.5872\n",
      "Epoch 34/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.2510\n",
      "Epoch 35/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.0277\n",
      "Epoch 36/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.7274\n",
      "Epoch 37/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 5.3144\n",
      "Epoch 38/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 5.1352\n",
      "Epoch 39/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 4.9716\n",
      "Epoch 40/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 4.8599\n",
      "Epoch 41/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 4.4652\n",
      "Epoch 42/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 4.2874\n",
      "Epoch 43/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 4.1367\n",
      "Epoch 44/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.9694\n",
      "Epoch 45/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 3.8348\n",
      "Epoch 46/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 3.7170\n",
      "Epoch 47/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 3.6215\n",
      "Epoch 48/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 3.5249\n",
      "Epoch 49/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 3.4208\n",
      "Epoch 50/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.5039\n",
      "Epoch 51/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 3.2755\n",
      "Epoch 52/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 3.2194\n",
      "Epoch 53/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 3.1605\n",
      "Epoch 54/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 3.2037\n",
      "Epoch 55/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 3.0219\n",
      "Epoch 56/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 2.9395\n",
      "Epoch 57/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 2.8827\n",
      "Epoch 58/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.8860\n",
      "Epoch 59/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 2.8645\n",
      "Epoch 60/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 2.7257\n",
      "Epoch 61/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 2.6809\n",
      "Epoch 62/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.6509\n",
      "Epoch 63/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 2.6480\n",
      "Epoch 64/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 2.5853\n",
      "Epoch 65/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 2.5463\n",
      "Epoch 66/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 2.5570\n",
      "Epoch 67/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 2.5183\n",
      "Epoch 68/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 2.4444\n",
      "Epoch 69/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 2.4239\n",
      "Epoch 70/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.4262\n",
      "Epoch 71/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 2.4318\n",
      "Epoch 72/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.3066\n",
      "Epoch 73/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.2616\n",
      "Epoch 74/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 2.2953\n",
      "Epoch 75/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.2359\n",
      "Epoch 76/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.2250\n",
      "Epoch 77/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.1452\n",
      "Epoch 78/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.1606\n",
      "Epoch 79/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 2.1541\n",
      "Epoch 80/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 2.0952\n",
      "Epoch 81/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 2.0903\n",
      "Epoch 82/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.0198\n",
      "Epoch 83/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.9811\n",
      "Epoch 84/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.9591\n",
      "Epoch 85/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 2.0289\n",
      "Epoch 86/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.9687\n",
      "Epoch 87/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.8946\n",
      "Epoch 88/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.8694\n",
      "Epoch 89/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.8497\n",
      "Epoch 90/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.8202\n",
      "Epoch 91/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.8360\n",
      "Epoch 92/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.7730\n",
      "Epoch 93/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.7558\n",
      "Epoch 94/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.7411\n",
      "Epoch 95/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.7386\n",
      "Epoch 96/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.7268\n",
      "Epoch 97/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.7107\n",
      "Epoch 98/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.6716\n",
      "Epoch 99/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.6580\n",
      "Epoch 100/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.6890\n",
      "Epoch 101/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.6492\n",
      "Epoch 102/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.6670\n",
      "Epoch 103/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.6727\n",
      "Epoch 104/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.6253\n",
      "Epoch 105/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.6627\n",
      "Epoch 106/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.6016\n",
      "Epoch 107/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.5422\n",
      "Epoch 108/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.5394\n",
      "Epoch 109/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.5235\n",
      "Epoch 110/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.4902\n",
      "Epoch 111/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.4958\n",
      "Epoch 112/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.4741\n",
      "Epoch 113/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.5022\n",
      "Epoch 114/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.5215\n",
      "Epoch 115/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.5194\n",
      "Epoch 116/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.4926\n",
      "Epoch 117/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.4403\n",
      "Epoch 118/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.4305\n",
      "Epoch 119/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.4213\n",
      "Epoch 120/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.4383\n",
      "Epoch 121/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.4322\n",
      "Epoch 122/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.4370\n",
      "Epoch 123/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.4298\n",
      "Epoch 124/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.3699\n",
      "Epoch 125/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.3696\n",
      "Epoch 126/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.3244\n",
      "Epoch 127/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.3493\n",
      "Epoch 128/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.3309\n",
      "Epoch 129/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.3271\n",
      "Epoch 130/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.3492\n",
      "Epoch 131/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.3234\n",
      "Epoch 132/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.3251\n",
      "Epoch 133/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.3349\n",
      "Epoch 134/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.3276\n",
      "Epoch 135/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.3269\n",
      "Epoch 136/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.3311\n",
      "Epoch 137/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2521\n",
      "Epoch 138/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.2483\n",
      "Epoch 139/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.2909\n",
      "Epoch 140/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2867\n",
      "Epoch 141/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.3342\n",
      "Epoch 142/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.3490\n",
      "Epoch 143/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.2371\n",
      "Epoch 144/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2063\n",
      "Epoch 145/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.2218\n",
      "Epoch 146/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.2139\n",
      "Epoch 147/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2018\n",
      "Epoch 148/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.1992\n",
      "Epoch 149/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.1870\n",
      "Epoch 150/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.1700\n",
      "Epoch 151/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.1873\n",
      "Epoch 152/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.1441\n",
      "Epoch 153/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.1535\n",
      "Epoch 154/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.1479\n",
      "Epoch 155/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.1853\n",
      "Epoch 156/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.1583\n",
      "Epoch 157/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2342\n",
      "Epoch 158/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.2012\n",
      "Epoch 159/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.1295\n",
      "Epoch 160/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.1215\n",
      "Epoch 161/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.1047\n",
      "Epoch 162/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.0849\n",
      "Epoch 163/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.1420\n",
      "Epoch 164/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.1353\n",
      "Epoch 165/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.1647\n",
      "Epoch 166/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.1394\n",
      "Epoch 167/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.0986\n",
      "Epoch 168/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.0902\n",
      "Epoch 169/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.0497\n",
      "Epoch 170/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.0445\n",
      "Epoch 171/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.0509\n",
      "Epoch 172/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.0208\n",
      "Epoch 173/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.0655\n",
      "Epoch 174/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.0783\n",
      "Epoch 175/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.0400\n",
      "Epoch 176/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.0128\n",
      "Epoch 177/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.0009\n",
      "Epoch 178/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.0388\n",
      "Epoch 179/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.0280\n",
      "Epoch 180/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.0573\n",
      "Epoch 181/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.0214\n",
      "Epoch 182/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.0153\n",
      "Epoch 183/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.9824\n",
      "Epoch 184/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.9644\n",
      "Epoch 185/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.9716\n",
      "Epoch 186/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.9818\n",
      "Epoch 187/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.9486\n",
      "Epoch 188/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.9574\n",
      "Epoch 189/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.9631\n",
      "Epoch 190/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.9804\n",
      "Epoch 191/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.9567\n",
      "Epoch 192/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.9552\n",
      "Epoch 193/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.9163\n",
      "Epoch 194/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.9183\n",
      "Epoch 195/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.9574\n",
      "Epoch 196/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.9729\n",
      "Epoch 197/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.9316\n",
      "Epoch 198/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.9313\n",
      "Epoch 199/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.9620\n",
      "Epoch 200/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.0375\n",
      "Epoch 201/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.1705\n",
      "Epoch 202/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.3601\n",
      "Epoch 203/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.0719\n",
      "Epoch 204/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.9547\n",
      "Epoch 205/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.9082\n",
      "Epoch 206/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.8695\n",
      "Epoch 207/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.8369\n",
      "Epoch 208/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.8864\n",
      "Epoch 209/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.8692\n",
      "Epoch 210/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.9106\n",
      "Epoch 211/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.8729\n",
      "Epoch 212/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.8688\n",
      "Epoch 213/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.9893\n",
      "Epoch 214/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.8546\n",
      "Epoch 215/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.8313\n",
      "Epoch 216/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.9039\n",
      "Epoch 217/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.9987\n",
      "Epoch 218/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.1388\n",
      "Epoch 219/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.9044\n",
      "Epoch 220/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.0008\n",
      "Epoch 221/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.8721\n",
      "Epoch 222/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.8421\n",
      "Epoch 223/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.7909\n",
      "Epoch 224/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.8372\n",
      "Epoch 225/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.7953\n",
      "Epoch 226/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.8175\n",
      "Epoch 227/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.8535\n",
      "Epoch 228/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.9035\n",
      "Epoch 229/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.8229\n",
      "Epoch 230/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.8658\n",
      "Epoch 231/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.8232\n",
      "Epoch 232/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.8325\n",
      "Epoch 233/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.7860\n",
      "Epoch 234/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.8604\n",
      "Epoch 235/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.8763\n",
      "Epoch 236/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.8248\n",
      "Epoch 237/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.8468\n",
      "Epoch 238/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.8011\n",
      "Epoch 239/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.8760\n",
      "Epoch 240/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7603\n",
      "Epoch 241/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.7334\n",
      "Epoch 242/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.8166\n",
      "Epoch 243/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.7773\n",
      "Epoch 244/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.9184\n",
      "Epoch 245/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.0593\n",
      "Epoch 246/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.9684\n",
      "Epoch 247/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.8977\n",
      "Epoch 248/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.8523\n",
      "Epoch 249/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7425\n",
      "Epoch 250/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.7656\n",
      "Epoch 251/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.8433\n",
      "Epoch 252/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.8755\n",
      "Epoch 253/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.8649\n",
      "Epoch 254/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.8205\n",
      "Epoch 255/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.7955\n",
      "Epoch 256/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.7232\n",
      "Epoch 257/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.7110\n",
      "Epoch 258/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.7018\n",
      "Epoch 259/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.7219\n",
      "Epoch 260/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.7371\n",
      "Epoch 261/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6940\n",
      "Epoch 262/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.7752\n",
      "Epoch 263/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.8589\n",
      "Epoch 264/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.8248\n",
      "Epoch 265/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.8837\n",
      "Epoch 266/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.7723\n",
      "Epoch 267/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.9052\n",
      "Epoch 268/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.9159\n",
      "Epoch 269/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.8302\n",
      "Epoch 270/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.8733\n",
      "Epoch 271/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.7382\n",
      "Epoch 272/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7415\n",
      "Epoch 273/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6913\n",
      "Epoch 274/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.7543\n",
      "Epoch 275/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7202\n",
      "Epoch 276/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.7065\n",
      "Epoch 277/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.7240\n",
      "Epoch 278/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.7180\n",
      "Epoch 279/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.7459\n",
      "Epoch 280/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.7306\n",
      "Epoch 281/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.6904\n",
      "Epoch 282/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.6770\n",
      "Epoch 283/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.7174\n",
      "Epoch 284/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.9364\n",
      "Epoch 285/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.7677\n",
      "Epoch 286/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.7411\n",
      "Epoch 287/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.7564\n",
      "Epoch 288/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.8053\n",
      "Epoch 289/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.7368\n",
      "Epoch 290/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.7360\n",
      "Epoch 291/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.7339\n",
      "Epoch 292/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.7315\n",
      "Epoch 293/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.7951\n",
      "Epoch 294/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.6815\n",
      "Epoch 295/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.6921\n",
      "Epoch 296/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.6900\n",
      "Epoch 297/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7726\n",
      "Epoch 298/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.7405\n",
      "Epoch 299/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.6862\n",
      "Epoch 300/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7070\n",
      "Epoch 301/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.7275\n",
      "Epoch 302/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6802\n",
      "Epoch 303/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.7202\n",
      "Epoch 304/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7987\n",
      "Epoch 305/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6912\n",
      "Epoch 306/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.7856\n",
      "Epoch 307/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.1741\n",
      "Epoch 308/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.9441\n",
      "Epoch 309/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.9978\n",
      "Epoch 310/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.7818\n",
      "Epoch 311/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.7754\n",
      "Epoch 312/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.7117\n",
      "Epoch 313/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.7069\n",
      "Epoch 314/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.6910\n",
      "Epoch 315/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.6759\n",
      "Epoch 316/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.6378\n",
      "Epoch 317/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.7536\n",
      "Epoch 318/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7693\n",
      "Epoch 319/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7486\n",
      "Epoch 320/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6570\n",
      "Epoch 321/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.6313\n",
      "Epoch 322/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.6640\n",
      "Epoch 323/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.6016\n",
      "Epoch 324/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6127\n",
      "Epoch 325/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.6153\n",
      "Epoch 326/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.6558\n",
      "Epoch 327/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.6605\n",
      "Epoch 328/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6637\n",
      "Epoch 329/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.7197\n",
      "Epoch 330/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.6557\n",
      "Epoch 331/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.6213\n",
      "Epoch 332/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6242\n",
      "Epoch 333/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.0692\n",
      "Epoch 334/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.2693\n",
      "Epoch 335/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.8355\n",
      "Epoch 336/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.8024\n",
      "Epoch 337/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.7217\n",
      "Epoch 338/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6620\n",
      "Epoch 339/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.6262\n",
      "Epoch 340/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.0199\n",
      "Epoch 341/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.6834\n",
      "Epoch 342/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.6437\n",
      "Epoch 343/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6553\n",
      "Epoch 344/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.6917\n",
      "Epoch 345/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.6379\n",
      "Epoch 346/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5950\n",
      "Epoch 347/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.6599\n",
      "Epoch 348/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5863\n",
      "Epoch 349/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.6533\n",
      "Epoch 350/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.7198\n",
      "Epoch 351/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.7724\n",
      "Epoch 352/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5958\n",
      "Epoch 353/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6227\n",
      "Epoch 354/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6411\n",
      "Epoch 355/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6897\n",
      "Epoch 356/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6455\n",
      "Epoch 357/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.6524\n",
      "Epoch 358/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6730\n",
      "Epoch 359/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.6184\n",
      "Epoch 360/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.6516\n",
      "Epoch 361/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.7401\n",
      "Epoch 362/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.7438\n",
      "Epoch 363/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5916\n",
      "Epoch 364/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.6287\n",
      "Epoch 365/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.6071\n",
      "Epoch 366/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.6407\n",
      "Epoch 367/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.7284\n",
      "Epoch 368/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.8391\n",
      "Epoch 369/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.6452\n",
      "Epoch 370/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5513\n",
      "Epoch 371/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6288\n",
      "Epoch 372/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.7057\n",
      "Epoch 373/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.8866\n",
      "Epoch 374/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.8449\n",
      "Epoch 375/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.8056\n",
      "Epoch 376/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.8515\n",
      "Epoch 377/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.7457\n",
      "Epoch 378/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6635\n",
      "Epoch 379/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5858\n",
      "Epoch 380/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5929\n",
      "Epoch 381/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5751\n",
      "Epoch 382/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5607\n",
      "Epoch 383/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5866\n",
      "Epoch 384/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.7258\n",
      "Epoch 385/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7265\n",
      "Epoch 386/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5775\n",
      "Epoch 387/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5622\n",
      "Epoch 388/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.5332\n",
      "Epoch 389/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5616\n",
      "Epoch 390/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5590\n",
      "Epoch 391/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5573\n",
      "Epoch 392/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5683\n",
      "Epoch 393/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6142\n",
      "Epoch 394/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5539\n",
      "Epoch 395/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5623\n",
      "Epoch 396/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5881\n",
      "Epoch 397/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6260\n",
      "Epoch 398/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6292\n",
      "Epoch 399/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.7086\n",
      "Epoch 400/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6482\n",
      "Epoch 401/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.6038\n",
      "Epoch 402/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5644\n",
      "Epoch 403/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5972\n",
      "Epoch 404/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.7002\n",
      "Epoch 405/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.7830\n",
      "Epoch 406/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.7870\n",
      "Epoch 407/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.6235\n",
      "Epoch 408/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.5669\n",
      "Epoch 409/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5994\n",
      "Epoch 410/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5163\n",
      "Epoch 411/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5803\n",
      "Epoch 412/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5671\n",
      "Epoch 413/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5440\n",
      "Epoch 414/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.6312\n",
      "Epoch 415/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.6180\n",
      "Epoch 416/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.6021\n",
      "Epoch 417/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.6016\n",
      "Epoch 418/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6716\n",
      "Epoch 419/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5782\n",
      "Epoch 420/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5568\n",
      "Epoch 421/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.5098\n",
      "Epoch 422/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.5282\n",
      "Epoch 423/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5412\n",
      "Epoch 424/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.6537\n",
      "Epoch 425/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.8861\n",
      "Epoch 426/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 1.0057\n",
      "Epoch 427/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.6592\n",
      "Epoch 428/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.6919\n",
      "Epoch 429/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.6485\n",
      "Epoch 430/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.5572\n",
      "Epoch 431/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.6102\n",
      "Epoch 432/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.5254\n",
      "Epoch 433/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.5816\n",
      "Epoch 434/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.6085\n",
      "Epoch 435/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.5583\n",
      "Epoch 436/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.5390\n",
      "Epoch 437/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.5845\n",
      "Epoch 438/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.5816\n",
      "Epoch 439/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5307\n",
      "Epoch 440/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5092\n",
      "Epoch 441/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5685\n",
      "Epoch 442/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.6321\n",
      "Epoch 443/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5654\n",
      "Epoch 444/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5404\n",
      "Epoch 445/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5961\n",
      "Epoch 446/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7543\n",
      "Epoch 447/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.9097\n",
      "Epoch 448/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.8495\n",
      "Epoch 449/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 1.4334\n",
      "Epoch 450/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.9377\n",
      "Epoch 451/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.6727\n",
      "Epoch 452/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5434\n",
      "Epoch 453/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.5205\n",
      "Epoch 454/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.5543\n",
      "Epoch 455/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.6268\n",
      "Epoch 456/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.6493\n",
      "Epoch 457/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.5752\n",
      "Epoch 458/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.5502\n",
      "Epoch 459/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5566\n",
      "Epoch 460/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5438\n",
      "Epoch 461/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.5226\n",
      "Epoch 462/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.5197\n",
      "Epoch 463/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.5457\n",
      "Epoch 464/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5481\n",
      "Epoch 465/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6093\n",
      "Epoch 466/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7167\n",
      "Epoch 467/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.6751\n",
      "Epoch 468/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7454\n",
      "Epoch 469/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6875\n",
      "Epoch 470/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7742\n",
      "Epoch 471/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5323\n",
      "Epoch 472/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5632\n",
      "Epoch 473/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5998\n",
      "Epoch 474/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.6518\n",
      "Epoch 475/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.7072\n",
      "Epoch 476/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.6954\n",
      "Epoch 477/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.7130\n",
      "Epoch 478/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.7621\n",
      "Epoch 479/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5543\n",
      "Epoch 480/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5090\n",
      "Epoch 481/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5612\n",
      "Epoch 482/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5005\n",
      "Epoch 483/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4863\n",
      "Epoch 484/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5027\n",
      "Epoch 485/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5073\n",
      "Epoch 486/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.5264\n",
      "Epoch 487/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.5849\n",
      "Epoch 488/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6149\n",
      "Epoch 489/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6414\n",
      "Epoch 490/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.6234\n",
      "Epoch 491/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5630\n",
      "Epoch 492/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6912\n",
      "Epoch 493/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.5087\n",
      "Epoch 494/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5094\n",
      "Epoch 495/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6451\n",
      "Epoch 496/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5148\n",
      "Epoch 497/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4894\n",
      "Epoch 498/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4844\n",
      "Epoch 499/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5009\n",
      "Epoch 500/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5374\n",
      "Epoch 501/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.6472\n",
      "Epoch 502/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5521\n",
      "Epoch 503/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5240\n",
      "Epoch 504/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.6162\n",
      "Epoch 505/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5900\n",
      "Epoch 506/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5190\n",
      "Epoch 507/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5654\n",
      "Epoch 508/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5463\n",
      "Epoch 509/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7318\n",
      "Epoch 510/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6479\n",
      "Epoch 511/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5757\n",
      "Epoch 512/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5278\n",
      "Epoch 513/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5421\n",
      "Epoch 514/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5365\n",
      "Epoch 515/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.8580\n",
      "Epoch 516/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.8858\n",
      "Epoch 517/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.6137\n",
      "Epoch 518/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5329\n",
      "Epoch 519/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5476\n",
      "Epoch 520/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5213\n",
      "Epoch 521/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4869\n",
      "Epoch 522/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5125\n",
      "Epoch 523/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5265\n",
      "Epoch 524/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5964\n",
      "Epoch 525/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5575\n",
      "Epoch 526/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5309\n",
      "Epoch 527/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5163\n",
      "Epoch 528/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5128\n",
      "Epoch 529/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5295\n",
      "Epoch 530/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.4827\n",
      "Epoch 531/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5461\n",
      "Epoch 532/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4932\n",
      "Epoch 533/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5007\n",
      "Epoch 534/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.4911\n",
      "Epoch 535/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4738\n",
      "Epoch 536/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5316\n",
      "Epoch 537/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.6248\n",
      "Epoch 538/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6365\n",
      "Epoch 539/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5257\n",
      "Epoch 540/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5532\n",
      "Epoch 541/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5001\n",
      "Epoch 542/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5630\n",
      "Epoch 543/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5180\n",
      "Epoch 544/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5081\n",
      "Epoch 545/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4997\n",
      "Epoch 546/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4864\n",
      "Epoch 547/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5178\n",
      "Epoch 548/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5422\n",
      "Epoch 549/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5764\n",
      "Epoch 550/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4920\n",
      "Epoch 551/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4912\n",
      "Epoch 552/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.6635\n",
      "Epoch 553/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5868\n",
      "Epoch 554/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5298\n",
      "Epoch 555/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4941\n",
      "Epoch 556/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4906\n",
      "Epoch 557/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5231\n",
      "Epoch 558/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.5876\n",
      "Epoch 559/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.5563\n",
      "Epoch 560/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6197\n",
      "Epoch 561/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.7550\n",
      "Epoch 562/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.5711\n",
      "Epoch 563/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5383\n",
      "Epoch 564/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5337\n",
      "Epoch 565/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5134\n",
      "Epoch 566/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5153\n",
      "Epoch 567/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.5766\n",
      "Epoch 568/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6092\n",
      "Epoch 569/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5537\n",
      "Epoch 570/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5314\n",
      "Epoch 571/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5223\n",
      "Epoch 572/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.4889\n",
      "Epoch 573/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5121\n",
      "Epoch 574/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5804\n",
      "Epoch 575/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5479\n",
      "Epoch 576/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5407\n",
      "Epoch 577/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6548\n",
      "Epoch 578/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.7001\n",
      "Epoch 579/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5330\n",
      "Epoch 580/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5279\n",
      "Epoch 581/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5069\n",
      "Epoch 582/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5328\n",
      "Epoch 583/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4962\n",
      "Epoch 584/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5749\n",
      "Epoch 585/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.6102\n",
      "Epoch 586/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4933\n",
      "Epoch 587/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.6311\n",
      "Epoch 588/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.6093\n",
      "Epoch 589/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.6987\n",
      "Epoch 590/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.7823\n",
      "Epoch 591/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6746\n",
      "Epoch 592/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5776\n",
      "Epoch 593/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5332\n",
      "Epoch 594/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5355\n",
      "Epoch 595/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4879\n",
      "Epoch 596/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5099\n",
      "Epoch 597/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4902\n",
      "Epoch 598/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4679\n",
      "Epoch 599/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5154\n",
      "Epoch 600/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4999\n",
      "Epoch 601/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6160\n",
      "Epoch 602/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5125\n",
      "Epoch 603/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5707\n",
      "Epoch 604/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5433\n",
      "Epoch 605/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5223\n",
      "Epoch 606/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5911\n",
      "Epoch 607/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5219\n",
      "Epoch 608/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4580\n",
      "Epoch 609/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5697\n",
      "Epoch 610/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7191\n",
      "Epoch 611/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4708\n",
      "Epoch 612/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5274\n",
      "Epoch 613/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5043\n",
      "Epoch 614/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4472\n",
      "Epoch 615/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4608\n",
      "Epoch 616/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4862\n",
      "Epoch 617/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4873\n",
      "Epoch 618/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.5511\n",
      "Epoch 619/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5323\n",
      "Epoch 620/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4979\n",
      "Epoch 621/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6932\n",
      "Epoch 622/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5721\n",
      "Epoch 623/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5204\n",
      "Epoch 624/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4516\n",
      "Epoch 625/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5306\n",
      "Epoch 626/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.9961\n",
      "Epoch 627/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.7175\n",
      "Epoch 628/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.6642\n",
      "Epoch 629/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5401\n",
      "Epoch 630/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5003\n",
      "Epoch 631/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4992\n",
      "Epoch 632/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4942\n",
      "Epoch 633/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4732\n",
      "Epoch 634/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4654\n",
      "Epoch 635/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4525\n",
      "Epoch 636/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4549\n",
      "Epoch 637/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4779\n",
      "Epoch 638/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4375\n",
      "Epoch 639/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4981\n",
      "Epoch 640/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4628\n",
      "Epoch 641/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4580\n",
      "Epoch 642/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5334\n",
      "Epoch 643/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4885\n",
      "Epoch 644/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5547\n",
      "Epoch 645/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4684\n",
      "Epoch 646/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4713\n",
      "Epoch 647/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5446\n",
      "Epoch 648/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4580\n",
      "Epoch 649/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4356\n",
      "Epoch 650/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4438\n",
      "Epoch 651/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5002\n",
      "Epoch 652/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5173\n",
      "Epoch 653/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4696\n",
      "Epoch 654/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4695\n",
      "Epoch 655/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4852\n",
      "Epoch 656/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5413\n",
      "Epoch 657/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5347\n",
      "Epoch 658/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5328\n",
      "Epoch 659/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4858\n",
      "Epoch 660/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.4589\n",
      "Epoch 661/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4308\n",
      "Epoch 662/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4711\n",
      "Epoch 663/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.6747\n",
      "Epoch 664/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5491\n",
      "Epoch 665/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5011\n",
      "Epoch 666/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4498\n",
      "Epoch 667/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4550\n",
      "Epoch 668/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4824\n",
      "Epoch 669/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5365\n",
      "Epoch 670/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.6901\n",
      "Epoch 671/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5516\n",
      "Epoch 672/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4947\n",
      "Epoch 673/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4664\n",
      "Epoch 674/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4474\n",
      "Epoch 675/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4508\n",
      "Epoch 676/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4686\n",
      "Epoch 677/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5692\n",
      "Epoch 678/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5178\n",
      "Epoch 679/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5594\n",
      "Epoch 680/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.5478\n",
      "Epoch 681/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.5012\n",
      "Epoch 682/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4960\n",
      "Epoch 683/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.4988\n",
      "Epoch 684/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4316\n",
      "Epoch 685/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4802\n",
      "Epoch 686/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4482\n",
      "Epoch 687/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4545\n",
      "Epoch 688/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4733\n",
      "Epoch 689/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.4350\n",
      "Epoch 690/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4408\n",
      "Epoch 691/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.5147\n",
      "Epoch 692/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5288\n",
      "Epoch 693/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5114\n",
      "Epoch 694/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4739\n",
      "Epoch 695/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4931\n",
      "Epoch 696/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5490\n",
      "Epoch 697/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.4702\n",
      "Epoch 698/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5007\n",
      "Epoch 699/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4680\n",
      "Epoch 700/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4518\n",
      "Epoch 701/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4660\n",
      "Epoch 702/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5600\n",
      "Epoch 703/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4923\n",
      "Epoch 704/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.6264\n",
      "Epoch 705/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5538\n",
      "Epoch 706/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5149\n",
      "Epoch 707/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4317\n",
      "Epoch 708/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4728\n",
      "Epoch 709/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4739\n",
      "Epoch 710/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4252\n",
      "Epoch 711/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4326\n",
      "Epoch 712/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4529\n",
      "Epoch 713/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.4605\n",
      "Epoch 714/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4640\n",
      "Epoch 715/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4614\n",
      "Epoch 716/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4985\n",
      "Epoch 717/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.4924\n",
      "Epoch 718/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5062\n",
      "Epoch 719/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4879\n",
      "Epoch 720/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5457\n",
      "Epoch 721/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4782\n",
      "Epoch 722/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4534\n",
      "Epoch 723/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4469\n",
      "Epoch 724/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4749\n",
      "Epoch 725/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4487\n",
      "Epoch 726/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4532\n",
      "Epoch 727/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4339\n",
      "Epoch 728/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.4458\n",
      "Epoch 729/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4637\n",
      "Epoch 730/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4853\n",
      "Epoch 731/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4890\n",
      "Epoch 732/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4574\n",
      "Epoch 733/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5014\n",
      "Epoch 734/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4512\n",
      "Epoch 735/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4267\n",
      "Epoch 736/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4827\n",
      "Epoch 737/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4215\n",
      "Epoch 738/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.4371\n",
      "Epoch 739/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5028\n",
      "Epoch 740/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5416\n",
      "Epoch 741/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5152\n",
      "Epoch 742/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4796\n",
      "Epoch 743/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4410\n",
      "Epoch 744/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4208\n",
      "Epoch 745/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4241\n",
      "Epoch 746/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4354\n",
      "Epoch 747/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4309\n",
      "Epoch 748/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.5433\n",
      "Epoch 749/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5138\n",
      "Epoch 750/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4672\n",
      "Epoch 751/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.4387\n",
      "Epoch 752/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4217\n",
      "Epoch 753/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4781\n",
      "Epoch 754/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4693\n",
      "Epoch 755/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.5284\n",
      "Epoch 756/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5313\n",
      "Epoch 757/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.4396\n",
      "Epoch 758/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5157\n",
      "Epoch 759/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4532\n",
      "Epoch 760/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.4592\n",
      "Epoch 761/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5066\n",
      "Epoch 762/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5082\n",
      "Epoch 763/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.5167\n",
      "Epoch 764/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5039\n",
      "Epoch 765/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4897\n",
      "Epoch 766/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5212\n",
      "Epoch 767/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.5563\n",
      "Epoch 768/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5175\n",
      "Epoch 769/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.7119\n",
      "Epoch 770/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7640\n",
      "Epoch 771/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5817\n",
      "Epoch 772/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5682\n",
      "Epoch 773/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5108\n",
      "Epoch 774/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4567\n",
      "Epoch 775/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4564\n",
      "Epoch 776/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.4662\n",
      "Epoch 777/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4670\n",
      "Epoch 778/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4791\n",
      "Epoch 779/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4560\n",
      "Epoch 780/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4476\n",
      "Epoch 781/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5125\n",
      "Epoch 782/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4605\n",
      "Epoch 783/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5165\n",
      "Epoch 784/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5033\n",
      "Epoch 785/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4585\n",
      "Epoch 786/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.5005\n",
      "Epoch 787/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.4686\n",
      "Epoch 788/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4278\n",
      "Epoch 789/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4166\n",
      "Epoch 790/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.4896\n",
      "Epoch 791/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4565\n",
      "Epoch 792/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4320\n",
      "Epoch 793/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4699\n",
      "Epoch 794/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.5631\n",
      "Epoch 795/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.4848\n",
      "Epoch 796/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4590\n",
      "Epoch 797/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4738\n",
      "Epoch 798/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4566\n",
      "Epoch 799/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.4566\n",
      "Epoch 800/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4776\n",
      "Epoch 801/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4942\n",
      "Epoch 802/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5919\n",
      "Epoch 803/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4808\n",
      "Epoch 804/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4777\n",
      "Epoch 805/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.4551\n",
      "Epoch 806/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4136\n",
      "Epoch 807/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4661\n",
      "Epoch 808/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4470\n",
      "Epoch 809/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.4067\n",
      "Epoch 810/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4327\n",
      "Epoch 811/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4301\n",
      "Epoch 812/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4712\n",
      "Epoch 813/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4232\n",
      "Epoch 814/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4396\n",
      "Epoch 815/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4413\n",
      "Epoch 816/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4321\n",
      "Epoch 817/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4485\n",
      "Epoch 818/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4176\n",
      "Epoch 819/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4534\n",
      "Epoch 820/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5208\n",
      "Epoch 821/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4494\n",
      "Epoch 822/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5465\n",
      "Epoch 823/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5009\n",
      "Epoch 824/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4616\n",
      "Epoch 825/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4451\n",
      "Epoch 826/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5035\n",
      "Epoch 827/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4348\n",
      "Epoch 828/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4062\n",
      "Epoch 829/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.4223\n",
      "Epoch 830/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.4535\n",
      "Epoch 831/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4663\n",
      "Epoch 832/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4961\n",
      "Epoch 833/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5040\n",
      "Epoch 834/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.4689\n",
      "Epoch 835/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6100\n",
      "Epoch 836/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5215\n",
      "Epoch 837/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4624\n",
      "Epoch 838/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4356\n",
      "Epoch 839/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5151\n",
      "Epoch 840/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4727\n",
      "Epoch 841/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4511\n",
      "Epoch 842/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.5315\n",
      "Epoch 843/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4634\n",
      "Epoch 844/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4383\n",
      "Epoch 845/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4460\n",
      "Epoch 846/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4341\n",
      "Epoch 847/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4222\n",
      "Epoch 848/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4512\n",
      "Epoch 849/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4532\n",
      "Epoch 850/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4100\n",
      "Epoch 851/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4219\n",
      "Epoch 852/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.4400\n",
      "Epoch 853/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4535\n",
      "Epoch 854/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4520\n",
      "Epoch 855/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4185\n",
      "Epoch 856/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4449\n",
      "Epoch 857/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4379\n",
      "Epoch 858/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4329\n",
      "Epoch 859/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.4822\n",
      "Epoch 860/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4844\n",
      "Epoch 861/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4324\n",
      "Epoch 862/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4488\n",
      "Epoch 863/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.4119\n",
      "Epoch 864/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4371\n",
      "Epoch 865/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4247\n",
      "Epoch 866/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4706\n",
      "Epoch 867/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.5572\n",
      "Epoch 868/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4865\n",
      "Epoch 869/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4806\n",
      "Epoch 870/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5053\n",
      "Epoch 871/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5354\n",
      "Epoch 872/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.0585\n",
      "Epoch 873/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7613\n",
      "Epoch 874/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.6011\n",
      "Epoch 875/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5138\n",
      "Epoch 876/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4638\n",
      "Epoch 877/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4432\n",
      "Epoch 878/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.4608\n",
      "Epoch 879/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.4676\n",
      "Epoch 880/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4160\n",
      "Epoch 881/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4485\n",
      "Epoch 882/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5347\n",
      "Epoch 883/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.4429\n",
      "Epoch 884/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4521\n",
      "Epoch 885/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4190\n",
      "Epoch 886/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4616\n",
      "Epoch 887/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4618\n",
      "Epoch 888/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4685\n",
      "Epoch 889/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.4400\n",
      "Epoch 890/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4129\n",
      "Epoch 891/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4456\n",
      "Epoch 892/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4530\n",
      "Epoch 893/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4063\n",
      "Epoch 894/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4399\n",
      "Epoch 895/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.4332\n",
      "Epoch 896/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.4452\n",
      "Epoch 897/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4774\n",
      "Epoch 898/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5058\n",
      "Epoch 899/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4792\n",
      "Epoch 900/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4576\n",
      "Epoch 901/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4114\n",
      "Epoch 902/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4137\n",
      "Epoch 903/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4338\n",
      "Epoch 904/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4230\n",
      "Epoch 905/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4604\n",
      "Epoch 906/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4669\n",
      "Epoch 907/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.4529\n",
      "Epoch 908/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5270\n",
      "Epoch 909/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4579\n",
      "Epoch 910/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4544\n",
      "Epoch 911/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4627\n",
      "Epoch 912/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4064\n",
      "Epoch 913/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4179\n",
      "Epoch 914/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4411\n",
      "Epoch 915/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5079\n",
      "Epoch 916/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.4246\n",
      "Epoch 917/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4127\n",
      "Epoch 918/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.3981\n",
      "Epoch 919/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.4306\n",
      "Epoch 920/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.4283\n",
      "Epoch 921/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4363\n",
      "Epoch 922/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4586\n",
      "Epoch 923/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4104\n",
      "Epoch 924/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.4229\n",
      "Epoch 925/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4468\n",
      "Epoch 926/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.4681\n",
      "Epoch 927/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.4090\n",
      "Epoch 928/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.4663\n",
      "Epoch 929/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5567\n",
      "Epoch 930/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.4979\n",
      "Epoch 931/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.5224\n",
      "Epoch 932/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.4452\n",
      "Epoch 933/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.4957\n",
      "Epoch 934/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4380\n",
      "Epoch 935/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.4009\n",
      "Epoch 936/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.4067\n",
      "Epoch 937/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4063\n",
      "Epoch 938/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5025\n",
      "Epoch 939/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.4202\n",
      "Epoch 940/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.4383\n",
      "Epoch 941/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4704\n",
      "Epoch 942/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.4479\n",
      "Epoch 943/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.8029\n",
      "Epoch 944/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.5786\n",
      "Epoch 945/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5100\n",
      "Epoch 946/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.4749\n",
      "Epoch 947/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.4153\n",
      "Epoch 948/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.4297\n",
      "Epoch 949/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.4644\n",
      "Epoch 950/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4364\n",
      "Epoch 951/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4528\n",
      "Epoch 952/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5143\n",
      "Epoch 953/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5589\n",
      "Epoch 954/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4930\n",
      "Epoch 955/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.4438\n",
      "Epoch 956/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.4506\n",
      "Epoch 957/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.4654\n",
      "Epoch 958/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4422\n",
      "Epoch 959/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4198\n",
      "Epoch 960/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4124\n",
      "Epoch 961/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4315\n",
      "Epoch 962/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.4334\n",
      "Epoch 963/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4852\n",
      "Epoch 964/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4973\n",
      "Epoch 965/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4518\n",
      "Epoch 966/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4339\n",
      "Epoch 967/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4257\n",
      "Epoch 968/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4520\n",
      "Epoch 969/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4876\n",
      "Epoch 970/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5126\n",
      "Epoch 971/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5098\n",
      "Epoch 972/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4380\n",
      "Epoch 973/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.4405\n",
      "Epoch 974/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.4380\n",
      "Epoch 975/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.4166\n",
      "Epoch 976/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4065\n",
      "Epoch 977/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.3990\n",
      "Epoch 978/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.4724\n",
      "Epoch 979/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.4368\n",
      "Epoch 980/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.4620\n",
      "Epoch 981/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4189\n",
      "Epoch 982/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4078\n",
      "Epoch 983/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4706\n",
      "Epoch 984/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.4141\n",
      "Epoch 985/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4082\n",
      "Epoch 986/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4153\n",
      "Epoch 987/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.4189\n",
      "Epoch 988/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.4376\n",
      "Epoch 989/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.4183\n",
      "Epoch 990/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4493\n",
      "Epoch 991/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5166\n",
      "Epoch 992/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.6237\n",
      "Epoch 993/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.4647\n",
      "Epoch 994/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4645\n",
      "Epoch 995/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4790\n",
      "Epoch 996/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4700\n",
      "Epoch 997/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5024\n",
      "Epoch 998/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4752\n",
      "Epoch 999/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4248\n",
      "Epoch 1000/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4637\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a471c3f28>"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_FTM = Sequential()\n",
    "NN_FTM.add(Dense(units=32,input_dim=X_train.shape[1],activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_FTM.add(Dense(units=16, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_FTM.add(Dense(units=8, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_FTM.add(Dense(units=1,activation='linear'))\n",
    "NN_FTM.compile(loss='mse', optimizer='adam')\n",
    "NN_FTM.fit(np.array(X_train), np.array(y_train), epochs=1000,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN_predictions</th>\n",
       "      <th>actual</th>\n",
       "      <th>GBR_predictions</th>\n",
       "      <th>LY_FTM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>3.548453</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.845111</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>4.172522</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.028874</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>4.283056</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.467786</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>3.530183</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.312463</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>3.456093</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.680620</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>3.642018</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.650507</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.496129</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.767917</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>4.223295</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.108240</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>4.466782</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.958197</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.250609</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.026464</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.332891</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.674839</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>3.278343</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.221338</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>3.516303</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.826815</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>4.042624</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.658700</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>1.731518</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.019869</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>2.708140</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.814516</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>2.550942</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.119000</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.218105</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.747189</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>3.634316</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.258819</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>3.349377</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.288011</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>3.511990</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.627407</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>2.137129</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.296408</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>3.102288</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.019864</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>3.584357</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.779798</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>1.644619</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.946136</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>3.181100</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.857171</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>2.079876</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.310207</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>2.819727</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.681602</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>3.322252</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.461748</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>2.550320</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.524602</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>3.066116</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.249307</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>2.906101</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.795389</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>3.491971</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.149525</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>3.256012</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.573783</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>3.186298</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.707399</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>2.940968</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3.160651</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>3.198759</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.393136</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2.559011</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.731379</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>2.367561</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.227245</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>3.153676</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.003269</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2.802837</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.650629</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>2.821169</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.027503</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>3.436563</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.114749</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>2.137556</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.699495</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>2.731869</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.947856</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>2.068033</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.404459</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>2.685503</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.902033</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>3.031254</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3.074568</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>3.243732</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.368887</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.817313</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.703980</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     NN_predictions  actual  GBR_predictions  LY_FTM\n",
       "567        3.548453     1.9         3.845111     4.2\n",
       "195        4.172522     3.2         5.028874     4.2\n",
       "228        4.283056     4.8         4.467786     4.1\n",
       "394        3.530183     3.8         4.312463     4.1\n",
       "201        3.456093     2.9         3.680620     4.1\n",
       "320        3.642018     4.0         3.650507     4.1\n",
       "25         2.496129     3.4         2.767917     3.9\n",
       "323        4.223295     5.8         5.108240     3.8\n",
       "302        4.466782     4.6         3.958197     3.8\n",
       "6          3.250609     2.9         4.026464     3.7\n",
       "15         3.332891     2.7         3.674839     3.7\n",
       "158        3.278343     2.9         3.221338     3.7\n",
       "589        3.516303     3.2         3.826815     3.6\n",
       "148        4.042624     3.5         3.658700     3.6\n",
       "505        1.731518     1.3         3.019869     3.5\n",
       "209        2.708140     3.5         3.814516     3.4\n",
       "492        2.550942     2.9         3.119000     3.4\n",
       "21         3.218105     3.9         3.747189     3.4\n",
       "263        3.634316     4.3         3.258819     3.4\n",
       "522        3.349377     3.9         3.288011     3.4\n",
       "563        3.511990     3.4         3.627407     3.4\n",
       "255        2.137129     1.5         2.296408     3.4\n",
       "295        3.102288     1.4         3.019864     3.4\n",
       "223        3.584357     4.2         4.779798     3.4\n",
       "181        1.644619     1.8         2.946136     3.3\n",
       "554        3.181100     2.9         3.857171     3.3\n",
       "284        2.079876     1.2         2.310207     3.3\n",
       "478        2.819727     3.0         3.681602     3.3\n",
       "80         3.322252     4.5         3.461748     3.3\n",
       "459        2.550320     2.6         2.524602     3.2\n",
       "279        3.066116     2.6         3.249307     3.2\n",
       "407        2.906101     2.5         2.795389     3.2\n",
       "326        3.491971     2.9         3.149525     3.2\n",
       "526        3.256012     3.0         3.573783     3.2\n",
       "254        3.186298     3.3         2.707399     3.2\n",
       "486        2.940968     4.2         3.160651     3.2\n",
       "190        3.198759     4.1         3.393136     3.2\n",
       "44         2.559011     2.7         2.731379     3.2\n",
       "235        2.367561     4.8         3.227245     3.2\n",
       "665        3.153676     3.2         3.003269     3.2\n",
       "64         2.802837     3.2         2.650629     3.2\n",
       "647        2.821169     2.2         3.027503     3.2\n",
       "620        3.436563     4.3         3.114749     3.1\n",
       "274        2.137556     2.1         2.699495     3.1\n",
       "557        2.731869     2.9         2.947856     3.1\n",
       "250        2.068033     2.1         2.404459     3.1\n",
       "561        2.685503     2.3         2.902033     3.1\n",
       "389        3.031254     4.2         3.074568     3.1\n",
       "93         3.243732     2.6         2.368887     3.1\n",
       "4          2.817313     1.8         2.703980     3.1"
      ]
     },
     "execution_count": 755,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = NN_FTM.predict(X_test)\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.5)\n",
    "gbr.fit(X_train,y_train)\n",
    "gbr_predictions = gbr.predict(X_test)\n",
    "LR = LinearRegression(fit_intercept=True).fit(X_train,y_train)\n",
    "\n",
    "testing = pd.DataFrame(predictions)\n",
    "testing.columns=['NN_predictions']\n",
    "testing['actual'] = y_test.reset_index()['FTM']\n",
    "testing['GBR_predictions']=gbr_predictions\n",
    "testing['LY_FTM']=X_test['FTM_ly'].reset_index()['FTM_ly']\n",
    "testing.sort_values(by='LY_FTM',ascending=False)[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2017FTM = percentages[percentages['season']==2017].drop(['player','team','FGM','FGA','FG_percent','FTM','FTA','Games'],axis=1)\n",
    "#pred_2017blocks = blocks[blocks['season']==2017][['blocks_ly','career_blocks','starter_change']]\n",
    "FTM_2017 = NN_FTM.predict(pred_2017FTM)\n",
    "gbr_FTM_2017 = pd.DataFrame(gbr.predict(pred_2017FTM))\n",
    "LR_FTM_2017 = pd.DataFrame(LR.predict(pred_2017FTM))\n",
    "test_2 =pd.DataFrame(FTM_2017)\n",
    "test_3 = pd.merge(percentages,pred_2017FTM,left_index=True,right_index=True).reset_index()\n",
    "test_3['predictions']=test_2[0]\n",
    "test_3['gbr_pred'] = gbr_FTM_2017[0]\n",
    "test_3['LR_pred'] = LR_FTM_2017[0]\n",
    "test_3['mean_pred'] = (test_3['predictions']+test_3['gbr_pred']+test_3['LR_pred'])/3\n",
    "test_3 = test_3[test_3['Games']>30]\n",
    "test_3[['player','FTM','predictions','LR_pred','gbr_pred','mean_pred','FTM_ly_x']].sort_values(by='FTM_ly_x',ascending=False)[0:50]\n",
    "\n",
    "FTM_2017 = test_3[['player','LR_pred']]\n",
    "FTM_2017.columns=['player','FTM_predictions']\n",
    "df_2017 = pd.merge(df_2017,FTM_2017,how='left',left_on='player',right_on='player')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE using LR:0.42969927768289096\n",
      "MSE using GB:0.37013599216167975\n",
      "MSE using NN:0.8381163512780285\n",
      "MSE using combo:0.4432261220880955\n",
      "MSE using mean:1.8538198553583185\n",
      "MSE using last year stats:0.6499358974358973\n"
     ]
    }
   ],
   "source": [
    "print('MSE using LR:{}'.format(np.mean((test_3['FTM']-test_3['LR_pred'])**2)))\n",
    "print('MSE using GB:{}'.format(np.mean((test_3['FTM']-test_3['gbr_pred'])**2)))\n",
    "print('MSE using NN:{}'.format(np.mean((test_3['FTM']-test_3['predictions'])**2)))\n",
    "print('MSE using combo:{}'.format(np.mean((test_3['FTM']-test_3['mean_pred'])**2)))\n",
    "print('MSE using mean:{}'.format(np.mean((test_3['FTM']-np.mean(test_3['FTM']))**2)))\n",
    "print('MSE using last year stats:{}'.format(np.mean((test_3['FTM']-test_3['FTM_ly_x'])**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = percentages[(percentages['season']!=2017) & (percentages['Games']>30)][['FT_percent_ly','career_FTPercent','yearspro']]\n",
    "y = percentages[(percentages['season']!=2017) & (percentages['Games']>30)]['FT_percent']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "1564/1564 [==============================] - 3s 2ms/step - loss: 0.1990\n",
      "Epoch 2/250\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 0.0733\n",
      "Epoch 3/250\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.0446\n",
      "Epoch 4/250\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.0297\n",
      "Epoch 5/250\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 0.0224\n",
      "Epoch 6/250\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.0179\n",
      "Epoch 7/250\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 0.0152\n",
      "Epoch 8/250\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 0.0137\n",
      "Epoch 9/250\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 0.0129\n",
      "Epoch 10/250\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.0126\n",
      "Epoch 11/250\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 0.0124\n",
      "Epoch 12/250\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 0.0124\n",
      "Epoch 13/250\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 0.0123\n",
      "Epoch 14/250\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 0.0122\n",
      "Epoch 15/250\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 0.0122\n",
      "Epoch 16/250\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 0.0122\n",
      "Epoch 17/250\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 0.0122\n",
      "Epoch 18/250\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 0.0121\n",
      "Epoch 19/250\n",
      "1564/1564 [==============================] - 0s 76us/step - loss: 0.0121\n",
      "Epoch 20/250\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.0121\n",
      "Epoch 21/250\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 0.0121\n",
      "Epoch 22/250\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 0.0120\n",
      "Epoch 23/250\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 0.0121\n",
      "Epoch 24/250\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.0121\n",
      "Epoch 25/250\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 0.0120\n",
      "Epoch 26/250\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 0.0121\n",
      "Epoch 27/250\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.0121\n",
      "Epoch 28/250\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 0.0121\n",
      "Epoch 29/250\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 0.0121\n",
      "Epoch 30/250\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 0.0121\n",
      "Epoch 31/250\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.0120\n",
      "Epoch 32/250\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 0.0120\n",
      "Epoch 33/250\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 0.0120\n",
      "Epoch 34/250\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 0.0121\n",
      "Epoch 35/250\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 0.0121\n",
      "Epoch 36/250\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.0121\n",
      "Epoch 37/250\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 0.0120\n",
      "Epoch 38/250\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.0120\n",
      "Epoch 39/250\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.0120\n",
      "Epoch 40/250\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.0120\n",
      "Epoch 41/250\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.0121\n",
      "Epoch 42/250\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.0120\n",
      "Epoch 43/250\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 0.0120\n",
      "Epoch 44/250\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 0.0120\n",
      "Epoch 45/250\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 0.0120\n",
      "Epoch 46/250\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 0.0120\n",
      "Epoch 47/250\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.0121\n",
      "Epoch 48/250\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 0.0120\n",
      "Epoch 49/250\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.0120\n",
      "Epoch 50/250\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.0121\n",
      "Epoch 51/250\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 0.0120\n",
      "Epoch 52/250\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 0.0120\n",
      "Epoch 53/250\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 0.0120\n",
      "Epoch 54/250\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 0.0120\n",
      "Epoch 55/250\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 0.0120\n",
      "Epoch 56/250\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.0120\n",
      "Epoch 57/250\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 0.0121\n",
      "Epoch 58/250\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 0.0120\n",
      "Epoch 59/250\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 0.0120\n",
      "Epoch 60/250\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.0119\n",
      "Epoch 61/250\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.0120\n",
      "Epoch 62/250\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 0.0121\n",
      "Epoch 63/250\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 0.0120\n",
      "Epoch 64/250\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 0.0120\n",
      "Epoch 65/250\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 0.0120\n",
      "Epoch 66/250\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.0120\n",
      "Epoch 67/250\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 0.0120\n",
      "Epoch 68/250\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 0.0119\n",
      "Epoch 69/250\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 0.0120\n",
      "Epoch 70/250\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 0.0120\n",
      "Epoch 71/250\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 0.0120\n",
      "Epoch 72/250\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 0.0120\n",
      "Epoch 73/250\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 0.0120\n",
      "Epoch 74/250\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 0.0120\n",
      "Epoch 75/250\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.0120\n",
      "Epoch 76/250\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.0120\n",
      "Epoch 77/250\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 0.0121\n",
      "Epoch 78/250\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.0120\n",
      "Epoch 79/250\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.0120\n",
      "Epoch 80/250\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.0120\n",
      "Epoch 81/250\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 0.0120\n",
      "Epoch 82/250\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.0120\n",
      "Epoch 83/250\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 0.0120\n",
      "Epoch 84/250\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 0.0120\n",
      "Epoch 85/250\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.0120\n",
      "Epoch 86/250\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.0120\n",
      "Epoch 87/250\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 0.0119\n",
      "Epoch 88/250\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.0120\n",
      "Epoch 89/250\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 0.0121\n",
      "Epoch 90/250\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.0119\n",
      "Epoch 91/250\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.0120\n",
      "Epoch 92/250\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 0.0120\n",
      "Epoch 93/250\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 0.0120\n",
      "Epoch 94/250\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 0.0119\n",
      "Epoch 95/250\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 0.0120\n",
      "Epoch 96/250\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.0120\n",
      "Epoch 97/250\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.0121\n",
      "Epoch 98/250\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.0120\n",
      "Epoch 99/250\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 0.0119\n",
      "Epoch 100/250\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 0.0119\n",
      "Epoch 101/250\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.0120\n",
      "Epoch 102/250\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 0.0120\n",
      "Epoch 103/250\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 0.0120\n",
      "Epoch 104/250\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 0.0120\n",
      "Epoch 105/250\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 0.0120\n",
      "Epoch 106/250\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 0.0120\n",
      "Epoch 107/250\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.0119\n",
      "Epoch 108/250\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.0119\n",
      "Epoch 109/250\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.0120\n",
      "Epoch 110/250\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.0119\n",
      "Epoch 111/250\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.0120\n",
      "Epoch 112/250\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 0.0119\n",
      "Epoch 113/250\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 0.0119\n",
      "Epoch 114/250\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.0120\n",
      "Epoch 115/250\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 0.0120\n",
      "Epoch 116/250\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 0.0120\n",
      "Epoch 117/250\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.0120\n",
      "Epoch 118/250\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 0.0119\n",
      "Epoch 119/250\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 0.0124\n",
      "Epoch 120/250\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.0121\n",
      "Epoch 121/250\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 0.0119\n",
      "Epoch 122/250\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 0.0119\n",
      "Epoch 123/250\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.0120\n",
      "Epoch 124/250\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 0.0120\n",
      "Epoch 125/250\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 0.0121\n",
      "Epoch 126/250\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.0119\n",
      "Epoch 127/250\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 0.0120\n",
      "Epoch 128/250\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 0.0122\n",
      "Epoch 129/250\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 0.0120\n",
      "Epoch 130/250\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 0.0120\n",
      "Epoch 131/250\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 0.0120\n",
      "Epoch 132/250\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.0120\n",
      "Epoch 133/250\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.0119\n",
      "Epoch 134/250\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 0.0119\n",
      "Epoch 135/250\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.0120\n",
      "Epoch 136/250\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.0119\n",
      "Epoch 137/250\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 0.0120\n",
      "Epoch 138/250\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.0120\n",
      "Epoch 139/250\n",
      "1564/1564 [==============================] - 0s 77us/step - loss: 0.0120\n",
      "Epoch 140/250\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.0119\n",
      "Epoch 141/250\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 0.0120\n",
      "Epoch 142/250\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.0119\n",
      "Epoch 143/250\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 0.0123\n",
      "Epoch 144/250\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.0122\n",
      "Epoch 145/250\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.0119\n",
      "Epoch 146/250\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.0119\n",
      "Epoch 147/250\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.0119\n",
      "Epoch 148/250\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.0119\n",
      "Epoch 149/250\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.0120\n",
      "Epoch 150/250\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 0.0120\n",
      "Epoch 151/250\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 0.0120\n",
      "Epoch 152/250\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 0.0119\n",
      "Epoch 153/250\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 0.0119\n",
      "Epoch 154/250\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 0.0120\n",
      "Epoch 155/250\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 0.0120\n",
      "Epoch 156/250\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.0119\n",
      "Epoch 157/250\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.0119\n",
      "Epoch 158/250\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.0120\n",
      "Epoch 159/250\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.0119\n",
      "Epoch 160/250\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.0119\n",
      "Epoch 161/250\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 0.0119\n",
      "Epoch 162/250\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 0.0119\n",
      "Epoch 163/250\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 0.0121\n",
      "Epoch 164/250\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 0.0119\n",
      "Epoch 165/250\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.0119\n",
      "Epoch 166/250\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.0120\n",
      "Epoch 167/250\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.0120\n",
      "Epoch 168/250\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 0.0123\n",
      "Epoch 169/250\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 0.0119\n",
      "Epoch 170/250\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.0120\n",
      "Epoch 171/250\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.0120\n",
      "Epoch 172/250\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.0119\n",
      "Epoch 173/250\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.0121\n",
      "Epoch 174/250\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.0119\n",
      "Epoch 175/250\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.0120\n",
      "Epoch 176/250\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 0.0120\n",
      "Epoch 177/250\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 0.0120\n",
      "Epoch 178/250\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.0119\n",
      "Epoch 179/250\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.0119\n",
      "Epoch 180/250\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 0.0120\n",
      "Epoch 181/250\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 0.0121\n",
      "Epoch 182/250\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.0121\n",
      "Epoch 183/250\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.0119\n",
      "Epoch 184/250\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.0120\n",
      "Epoch 185/250\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.0120\n",
      "Epoch 186/250\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.0120\n",
      "Epoch 187/250\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 0.0119\n",
      "Epoch 188/250\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 0.0119\n",
      "Epoch 189/250\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.0120\n",
      "Epoch 190/250\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 0.0119\n",
      "Epoch 191/250\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 0.0119\n",
      "Epoch 192/250\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.0119\n",
      "Epoch 193/250\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 0.0120\n",
      "Epoch 194/250\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.0119\n",
      "Epoch 195/250\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.0119\n",
      "Epoch 196/250\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.0119\n",
      "Epoch 197/250\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 0.0120\n",
      "Epoch 198/250\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 0.0120\n",
      "Epoch 199/250\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.0120\n",
      "Epoch 200/250\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.0122\n",
      "Epoch 201/250\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.0119\n",
      "Epoch 202/250\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.0119\n",
      "Epoch 203/250\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.0122\n",
      "Epoch 204/250\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.0119\n",
      "Epoch 205/250\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 0.0119\n",
      "Epoch 206/250\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 0.0119\n",
      "Epoch 207/250\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.0119\n",
      "Epoch 208/250\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.0119\n",
      "Epoch 209/250\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 0.0120\n",
      "Epoch 210/250\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.0119\n",
      "Epoch 211/250\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 0.0119\n",
      "Epoch 212/250\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 0.0119\n",
      "Epoch 213/250\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.0119\n",
      "Epoch 214/250\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.0120\n",
      "Epoch 215/250\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.0120\n",
      "Epoch 216/250\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.0119\n",
      "Epoch 217/250\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.0119\n",
      "Epoch 218/250\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 0.0119\n",
      "Epoch 219/250\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 0.0119\n",
      "Epoch 220/250\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.0120\n",
      "Epoch 221/250\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 0.0119\n",
      "Epoch 222/250\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 0.0119\n",
      "Epoch 223/250\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 0.0122\n",
      "Epoch 224/250\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 0.0119\n",
      "Epoch 225/250\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.0119\n",
      "Epoch 226/250\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 0.0119\n",
      "Epoch 227/250\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 0.0119\n",
      "Epoch 228/250\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 0.0119\n",
      "Epoch 229/250\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 0.0119\n",
      "Epoch 230/250\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 0.0119\n",
      "Epoch 231/250\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.0120\n",
      "Epoch 232/250\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 0.0120\n",
      "Epoch 233/250\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.0121\n",
      "Epoch 234/250\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.0121\n",
      "Epoch 235/250\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 0.0119\n",
      "Epoch 236/250\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 0.0119\n",
      "Epoch 237/250\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.0120\n",
      "Epoch 238/250\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.0119\n",
      "Epoch 239/250\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.0119\n",
      "Epoch 240/250\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.0120\n",
      "Epoch 241/250\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 0.0119\n",
      "Epoch 242/250\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 0.0119\n",
      "Epoch 243/250\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 0.0119\n",
      "Epoch 244/250\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 0.0119\n",
      "Epoch 245/250\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 0.0119\n",
      "Epoch 246/250\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.0119\n",
      "Epoch 247/250\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.0120\n",
      "Epoch 248/250\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 0.0119\n",
      "Epoch 249/250\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.0119\n",
      "Epoch 250/250\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.0120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a48b66a20>"
      ]
     },
     "execution_count": 550,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_FTP = Sequential()\n",
    "NN_FTP.add(Dense(units=16,input_dim=X_train.shape[1],activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_FTP.add(Dense(units=8, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "#NN_FTP.add(Dense(units=8, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_FTP.add(Dense(units=1,activation='linear'))\n",
    "NN_FTP.compile(loss='mse', optimizer='adam')\n",
    "NN_FTP.fit(np.array(X_train), np.array(y_train), epochs=250,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN_predictions</th>\n",
       "      <th>actual</th>\n",
       "      <th>GBR_predictions</th>\n",
       "      <th>LY_FT_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.778391</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.777349</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.798944</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.818590</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.816416</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.829238</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.797575</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.811832</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>0.792316</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.798686</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>0.771073</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.808686</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>0.866566</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.885882</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>0.836319</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.837255</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>0.840046</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.848401</td>\n",
       "      <td>0.872340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.822531</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.840620</td>\n",
       "      <td>0.872340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>0.847478</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.865147</td>\n",
       "      <td>0.869565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.835217</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.842068</td>\n",
       "      <td>0.869565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>0.799007</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.811990</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.789466</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.796737</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>0.818104</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.820066</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>0.790465</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.825989</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.800016</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.803334</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>0.849482</td>\n",
       "      <td>0.893617</td>\n",
       "      <td>0.889108</td>\n",
       "      <td>0.861111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>0.835913</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.842411</td>\n",
       "      <td>0.860000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>0.825035</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.862427</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>0.829850</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.850813</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>0.801913</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.827789</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>0.832501</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.870596</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>0.745882</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.769743</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.834945</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.837598</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.811701</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.814645</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>0.815677</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.829581</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.813190</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.830876</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>0.819054</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.853340</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.804915</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.814778</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>0.773298</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.780921</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>0.824158</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.824720</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.802293</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.841022</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.811676</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.844236</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>0.790497</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.816888</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>0.777450</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.780921</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.801434</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.821181</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.802526</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.806786</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0.808029</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>0.811233</td>\n",
       "      <td>0.855072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>0.841070</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.850518</td>\n",
       "      <td>0.852941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>0.799946</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.841022</td>\n",
       "      <td>0.851852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>0.783192</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.799824</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>0.839654</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.868039</td>\n",
       "      <td>0.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>0.793706</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.804675</td>\n",
       "      <td>0.849057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>0.787801</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.815975</td>\n",
       "      <td>0.848485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.808531</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.810055</td>\n",
       "      <td>0.847826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>0.840499</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.848957</td>\n",
       "      <td>0.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>0.817894</td>\n",
       "      <td>0.837500</td>\n",
       "      <td>0.828020</td>\n",
       "      <td>0.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>0.769907</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.793724</td>\n",
       "      <td>0.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.829570</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.837153</td>\n",
       "      <td>0.846154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     NN_predictions    actual  GBR_predictions  LY_FT_percent\n",
       "144        0.778391  0.833333         0.777349       0.875000\n",
       "108        0.798944  0.850000         0.818590       0.875000\n",
       "52         0.816416  0.833333         0.829238       0.875000\n",
       "25         0.797575  0.875000         0.811832       0.875000\n",
       "412        0.792316  0.888889         0.798686       0.875000\n",
       "578        0.771073  0.857143         0.808686       0.875000\n",
       "558        0.866566  0.714286         0.885882       0.875000\n",
       "453        0.836319  0.846154         0.837255       0.875000\n",
       "561        0.840046  0.882353         0.848401       0.872340\n",
       "123        0.822531  0.794118         0.840620       0.872340\n",
       "359        0.847478  0.860465         0.865147       0.869565\n",
       "152        0.835217  0.878788         0.842068       0.869565\n",
       "581        0.799007  0.826087         0.811990       0.866667\n",
       "203        0.789466  0.800000         0.796737       0.866667\n",
       "658        0.818104  0.714286         0.820066       0.863636\n",
       "259        0.790465  0.750000         0.825989       0.863636\n",
       "6          0.800016  0.714286         0.803334       0.863636\n",
       "659        0.849482  0.893617         0.889108       0.861111\n",
       "572        0.835913  0.891304         0.842411       0.860000\n",
       "254        0.825035  0.857143         0.862427       0.857143\n",
       "607        0.829850  0.897436         0.850813       0.857143\n",
       "267        0.801913  0.833333         0.827789       0.857143\n",
       "384        0.832501  0.898551         0.870596       0.857143\n",
       "550        0.745882  0.666667         0.769743       0.857143\n",
       "183        0.834945  0.887097         0.837598       0.857143\n",
       "182        0.811701  0.812500         0.814645       0.857143\n",
       "209        0.815677  0.866667         0.829581       0.857143\n",
       "114        0.813190  0.700000         0.830876       0.857143\n",
       "548        0.819054  1.000000         0.853340       0.857143\n",
       "1          0.804915  0.826087         0.814778       0.857143\n",
       "220        0.773298  0.666667         0.780921       0.857143\n",
       "264        0.824158  0.875000         0.824720       0.857143\n",
       "57         0.802293  0.866667         0.841022       0.857143\n",
       "71         0.811676  0.875000         0.844236       0.857143\n",
       "388        0.790497  0.760000         0.816888       0.857143\n",
       "630        0.777450  0.800000         0.780921       0.857143\n",
       "23         0.801434  0.851852         0.821181       0.857143\n",
       "42         0.802526  0.809524         0.806786       0.857143\n",
       "393        0.808029  0.819672         0.811233       0.855072\n",
       "632        0.841070  0.941176         0.850518       0.852941\n",
       "587        0.799946  0.864865         0.841022       0.851852\n",
       "314        0.783192  0.812500         0.799824       0.850000\n",
       "379        0.839654  0.800000         0.868039       0.850000\n",
       "428        0.793706  0.771429         0.804675       0.849057\n",
       "666        0.787801  0.720000         0.815975       0.848485\n",
       "31         0.808531  0.826087         0.810055       0.847826\n",
       "664        0.840499  0.888889         0.848957       0.846154\n",
       "354        0.817894  0.837500         0.828020       0.846154\n",
       "355        0.769907  0.687500         0.793724       0.846154\n",
       "200        0.829570  0.777778         0.837153       0.846154"
      ]
     },
     "execution_count": 761,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = NN_FTP.predict(X_test)\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.5)\n",
    "gbr.fit(X_train,y_train)\n",
    "gbr_predictions = gbr.predict(X_test)\n",
    "LR = LinearRegression(fit_intercept=True).fit(X_train,y_train)\n",
    "\n",
    "testing = pd.DataFrame(predictions)\n",
    "testing.columns=['NN_predictions']\n",
    "testing['actual'] = y_test.reset_index()['FT_percent']\n",
    "testing['GBR_predictions']=gbr_predictions\n",
    "testing['LY_FT_percent']=X_test['FT_percent_ly'].reset_index()['FT_percent_ly']\n",
    "testing.sort_values(by='LY_FT_percent',ascending=False)[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2017FTP = percentages[percentages['season']==2017][['FT_percent_ly','career_FTPercent','yearspro']]\n",
    "#pred_2017blocks = blocks[blocks['season']==2017][['blocks_ly','career_blocks','starter_change']]\n",
    "FTP_2017 = NN_FTP.predict(pred_2017FTP)\n",
    "gbr_FTP_2017 = pd.DataFrame(gbr.predict(pred_2017FTP))\n",
    "LR_FTP_2017 = pd.DataFrame(LR.predict(pred_2017FTP))\n",
    "test_2 =pd.DataFrame(FTP_2017)\n",
    "test_3 = pd.merge(percentages,pred_2017FTP,left_index=True,right_index=True).reset_index()\n",
    "test_3['predictions']=test_2[0]\n",
    "test_3['gbr_pred'] = gbr_FTP_2017[0]\n",
    "test_3['LR_pred'] = LR_FTP_2017[0]\n",
    "test_3['mean_pred'] = (test_3['predictions']+test_3['gbr_pred']+test_3['LR_pred'])/3\n",
    "test_3 = test_3[test_3['Games']>30]\n",
    "test_3[['player','FT_percent','predictions','LR_pred','gbr_pred','mean_pred','FT_percent_ly_x']].sort_values(by='FT_percent_ly_x',ascending=False)[0:50]\n",
    "\n",
    "FTP_2017 = test_3[['player','LR_pred']]\n",
    "FTP_2017.columns=['player','FTP_prediction']\n",
    "df_2017 = pd.merge(df_2017,FTP_2017,how='left',left_on='player',right_on='player')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017['FTA_prediction'] = df_2017['FTM_predictions']/df_2017['FTP_prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE using LR:0.007206602426205597\n",
      "MSE using GB:0.00926956821529641\n",
      "MSE using NN:0.007096646163119528\n",
      "MSE using combo:0.006956002524040147\n",
      "MSE using mean:0.012220424699955452\n",
      "MSE using last year stats:0.01047733460460316\n"
     ]
    }
   ],
   "source": [
    "print('MSE using LR:{}'.format(np.mean((test_3['FT_percent']-test_3['LR_pred'])**2)))\n",
    "print('MSE using GB:{}'.format(np.mean((test_3['FT_percent']-test_3['gbr_pred'])**2)))\n",
    "print('MSE using NN:{}'.format(np.mean((test_3['FT_percent']-test_3['predictions'])**2)))\n",
    "print('MSE using combo:{}'.format(np.mean((test_3['FT_percent']-test_3['mean_pred'])**2)))\n",
    "print('MSE using mean:{}'.format(np.mean((test_3['FT_percent']-np.mean(test_3['FT_percent']))**2)))\n",
    "print('MSE using last year stats:{}'.format(np.mean((test_3['FT_percent']-test_3['FT_percent_ly_x'])**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['season', 'player', 'position', 'age', 'team', 'gamesPlayed',\n",
       "       'gamesStarted', 'minutes', 'points', 'rebounds', 'assists', 'steals',\n",
       "       'blocks', 'turnovers', 'threes_made', 'FGM', 'FGA', 'FTM', 'FTA',\n",
       "       'starter', 'min_rank', 'point_prediction1', 'rebound_prediction',\n",
       "       'assist_prediction', 'steal_prediction', 'block_predictions',\n",
       "       'three_prediction', 'turnover_prediction', 'FGM_prediction',\n",
       "       'FGP_prediction', 'FGA_prediction', 'FTM_predictions', 'FTP_prediction',\n",
       "       'FTA_prediction'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 768,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017['point_prediction2'] = (df_2017['FGM_prediction']*2)+df_2017['FTM_predictions']+df_2017['three_prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_ranker = df_2017[df_2017['point_prediction2'].notna()][['season','player','point_prediction2','rebound_prediction','assist_prediction','steal_prediction','block_predictions','turnover_prediction','three_prediction','FGM_prediction','FGA_prediction','FTM_predictions','FTA_prediction','min_rank']]\n",
    "prediction_ranker.columns=['season','player','points','rebounds','assists','steals','blocks','turnovers','threes_made','FGM','FGA','FTM','FTA','min_rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2017 = Player_ranker(prediction_ranker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2017.get_category_dist()\n",
    "test_2017.assign_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `reset_index` not found.\n"
     ]
    }
   ],
   "source": [
    "test_2017.value.sort_values(by='value_tot',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_ranker2 = test_2017.value.sort_values(by='value_tot',ascending=False).reset_index(drop=True).reset_index()\n",
    "prediction_ranker2['predicted_rank'] = prediction_ranker2['index']+1\n",
    "prediction_ranker2.drop('index',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_ranker = rank_2017.value.sort_values(by='value_tot',ascending=False).reset_index(drop=True).reset_index()\n",
    "actual_ranker['rank'] = actual_ranker['index']+1\n",
    "actual_ranker.drop('index',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_predictions = pd.merge(prediction_ranker2,rank_2017.value,how='inner',left_on='player',right_on='player')\n",
    "compare_predictions = compare_predictions.sort_values(by='value_tot_y',ascending=False).reset_index(drop=True).reset_index()\n",
    "compare_predictions['rank'] = compare_predictions['index']+1\n",
    "compare_predictions.drop('index',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_preds = compare_predictions[['player','rank','predicted_rank','value_tot_x','value_tot_y']][0:200]\n",
    "\n",
    "yahoo_ranks = pd.read_csv('../Yahoo 2017 Ranks.csv', encoding = \"ISO-8859-1\", engine='python')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>player</th>\n",
       "      <th>value_tot</th>\n",
       "      <th>value_points</th>\n",
       "      <th>value_rebounds</th>\n",
       "      <th>value_assists</th>\n",
       "      <th>value_blocks</th>\n",
       "      <th>value_steals</th>\n",
       "      <th>value_turnovers</th>\n",
       "      <th>value_threes</th>\n",
       "      <th>value_fg</th>\n",
       "      <th>value_ft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017</td>\n",
       "      <td>Anthony Davis</td>\n",
       "      <td>13.069292</td>\n",
       "      <td>2.728406</td>\n",
       "      <td>2.327843</td>\n",
       "      <td>-0.323373</td>\n",
       "      <td>4.382346</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>-0.642579</td>\n",
       "      <td>-0.719758</td>\n",
       "      <td>2.572502</td>\n",
       "      <td>1.340136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>2017</td>\n",
       "      <td>Stephen Curry</td>\n",
       "      <td>10.977767</td>\n",
       "      <td>2.415188</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>1.610250</td>\n",
       "      <td>-0.769567</td>\n",
       "      <td>1.647478</td>\n",
       "      <td>-1.635937</td>\n",
       "      <td>3.343394</td>\n",
       "      <td>1.073741</td>\n",
       "      <td>3.291282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2017</td>\n",
       "      <td>Kevin Durant</td>\n",
       "      <td>10.555627</td>\n",
       "      <td>2.415188</td>\n",
       "      <td>0.660945</td>\n",
       "      <td>1.254056</td>\n",
       "      <td>2.665042</td>\n",
       "      <td>-0.545910</td>\n",
       "      <td>-1.635937</td>\n",
       "      <td>1.369863</td>\n",
       "      <td>1.809299</td>\n",
       "      <td>2.563082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2017</td>\n",
       "      <td>James Harden</td>\n",
       "      <td>10.522310</td>\n",
       "      <td>3.152171</td>\n",
       "      <td>0.118234</td>\n",
       "      <td>2.984140</td>\n",
       "      <td>0.303748</td>\n",
       "      <td>2.134898</td>\n",
       "      <td>-3.374314</td>\n",
       "      <td>2.762944</td>\n",
       "      <td>-0.589500</td>\n",
       "      <td>3.029989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017</td>\n",
       "      <td>Karl-Anthony Towns</td>\n",
       "      <td>9.046572</td>\n",
       "      <td>1.475533</td>\n",
       "      <td>2.793024</td>\n",
       "      <td>-0.272488</td>\n",
       "      <td>1.806390</td>\n",
       "      <td>-0.302200</td>\n",
       "      <td>-0.270069</td>\n",
       "      <td>0.208962</td>\n",
       "      <td>2.213129</td>\n",
       "      <td>1.394291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>LeBron James</td>\n",
       "      <td>8.050018</td>\n",
       "      <td>2.617858</td>\n",
       "      <td>1.358716</td>\n",
       "      <td>3.136795</td>\n",
       "      <td>0.733074</td>\n",
       "      <td>1.160059</td>\n",
       "      <td>-3.125975</td>\n",
       "      <td>0.557232</td>\n",
       "      <td>2.935558</td>\n",
       "      <td>-1.323300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>Giannis Antetokounmpo</td>\n",
       "      <td>7.982516</td>\n",
       "      <td>2.507311</td>\n",
       "      <td>1.901427</td>\n",
       "      <td>0.948747</td>\n",
       "      <td>1.806390</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>-1.635937</td>\n",
       "      <td>-0.835849</td>\n",
       "      <td>2.328774</td>\n",
       "      <td>-0.442116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017</td>\n",
       "      <td>Damian Lillard</td>\n",
       "      <td>7.758411</td>\n",
       "      <td>2.507311</td>\n",
       "      <td>-0.230652</td>\n",
       "      <td>1.864674</td>\n",
       "      <td>-0.340241</td>\n",
       "      <td>0.428929</td>\n",
       "      <td>-1.387598</td>\n",
       "      <td>2.066403</td>\n",
       "      <td>-0.920536</td>\n",
       "      <td>3.770119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2017</td>\n",
       "      <td>Chris Paul</td>\n",
       "      <td>7.259998</td>\n",
       "      <td>0.978069</td>\n",
       "      <td>0.118234</td>\n",
       "      <td>2.526177</td>\n",
       "      <td>-0.769567</td>\n",
       "      <td>1.891188</td>\n",
       "      <td>-0.642579</td>\n",
       "      <td>1.369863</td>\n",
       "      <td>-0.176916</td>\n",
       "      <td>1.965529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2017</td>\n",
       "      <td>Jimmy Butler</td>\n",
       "      <td>7.194467</td>\n",
       "      <td>1.641355</td>\n",
       "      <td>0.079468</td>\n",
       "      <td>0.999632</td>\n",
       "      <td>-0.340241</td>\n",
       "      <td>2.622318</td>\n",
       "      <td>-0.145900</td>\n",
       "      <td>-0.139308</td>\n",
       "      <td>0.324360</td>\n",
       "      <td>2.152782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2017</td>\n",
       "      <td>Victor Oladipo</td>\n",
       "      <td>6.742591</td>\n",
       "      <td>1.807176</td>\n",
       "      <td>0.040703</td>\n",
       "      <td>0.694323</td>\n",
       "      <td>0.518411</td>\n",
       "      <td>3.597157</td>\n",
       "      <td>-1.511767</td>\n",
       "      <td>0.905503</td>\n",
       "      <td>0.389094</td>\n",
       "      <td>0.301991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2017</td>\n",
       "      <td>DeMarcus Cousins</td>\n",
       "      <td>6.513379</td>\n",
       "      <td>2.194092</td>\n",
       "      <td>3.025615</td>\n",
       "      <td>1.254056</td>\n",
       "      <td>2.235716</td>\n",
       "      <td>1.647478</td>\n",
       "      <td>-4.119333</td>\n",
       "      <td>1.021593</td>\n",
       "      <td>0.301785</td>\n",
       "      <td>-1.047624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2017</td>\n",
       "      <td>Nikola Jokic</td>\n",
       "      <td>6.424866</td>\n",
       "      <td>0.959645</td>\n",
       "      <td>2.172783</td>\n",
       "      <td>1.610250</td>\n",
       "      <td>0.518411</td>\n",
       "      <td>0.672639</td>\n",
       "      <td>-1.387598</td>\n",
       "      <td>0.208962</td>\n",
       "      <td>0.838766</td>\n",
       "      <td>0.831007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2017</td>\n",
       "      <td>Kyrie Irving</td>\n",
       "      <td>6.159878</td>\n",
       "      <td>2.046696</td>\n",
       "      <td>-0.502008</td>\n",
       "      <td>1.101402</td>\n",
       "      <td>-0.554904</td>\n",
       "      <td>0.428929</td>\n",
       "      <td>-0.766749</td>\n",
       "      <td>1.718133</td>\n",
       "      <td>0.968233</td>\n",
       "      <td>1.720144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>2017</td>\n",
       "      <td>Andre Ingram</td>\n",
       "      <td>5.581832</td>\n",
       "      <td>-0.237954</td>\n",
       "      <td>-0.812129</td>\n",
       "      <td>0.287245</td>\n",
       "      <td>2.021053</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>0.226610</td>\n",
       "      <td>1.369863</td>\n",
       "      <td>0.116338</td>\n",
       "      <td>1.207037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2017</td>\n",
       "      <td>LaMarcus Aldridge</td>\n",
       "      <td>5.370052</td>\n",
       "      <td>1.807176</td>\n",
       "      <td>1.319951</td>\n",
       "      <td>-0.476027</td>\n",
       "      <td>1.377064</td>\n",
       "      <td>-0.789620</td>\n",
       "      <td>0.226610</td>\n",
       "      <td>-1.068029</td>\n",
       "      <td>1.620860</td>\n",
       "      <td>1.352068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>2017</td>\n",
       "      <td>MarShon Brooks</td>\n",
       "      <td>5.131062</td>\n",
       "      <td>1.254438</td>\n",
       "      <td>-0.812129</td>\n",
       "      <td>0.338130</td>\n",
       "      <td>-0.340241</td>\n",
       "      <td>1.647478</td>\n",
       "      <td>-0.766749</td>\n",
       "      <td>1.602043</td>\n",
       "      <td>1.009007</td>\n",
       "      <td>1.199083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017</td>\n",
       "      <td>Paul George</td>\n",
       "      <td>5.126899</td>\n",
       "      <td>1.586081</td>\n",
       "      <td>0.234529</td>\n",
       "      <td>0.185475</td>\n",
       "      <td>-0.125578</td>\n",
       "      <td>2.622318</td>\n",
       "      <td>-1.263428</td>\n",
       "      <td>2.066403</td>\n",
       "      <td>-1.086400</td>\n",
       "      <td>0.907499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>2017</td>\n",
       "      <td>Kristaps Porzingis</td>\n",
       "      <td>4.816889</td>\n",
       "      <td>1.733478</td>\n",
       "      <td>0.583415</td>\n",
       "      <td>-0.883106</td>\n",
       "      <td>3.953020</td>\n",
       "      <td>-0.302200</td>\n",
       "      <td>-0.270069</td>\n",
       "      <td>0.673322</td>\n",
       "      <td>-0.888515</td>\n",
       "      <td>0.217545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017</td>\n",
       "      <td>Jrue Holiday</td>\n",
       "      <td>4.397228</td>\n",
       "      <td>1.051768</td>\n",
       "      <td>-0.230652</td>\n",
       "      <td>1.559365</td>\n",
       "      <td>0.518411</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>-1.139258</td>\n",
       "      <td>0.208962</td>\n",
       "      <td>0.875856</td>\n",
       "      <td>0.149007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>Khris Middleton</td>\n",
       "      <td>4.231094</td>\n",
       "      <td>1.254438</td>\n",
       "      <td>0.040703</td>\n",
       "      <td>0.541669</td>\n",
       "      <td>-0.554904</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>-0.766749</td>\n",
       "      <td>0.557232</td>\n",
       "      <td>0.034790</td>\n",
       "      <td>1.720144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2017</td>\n",
       "      <td>Nikola Vucevic</td>\n",
       "      <td>4.156660</td>\n",
       "      <td>0.591153</td>\n",
       "      <td>1.591307</td>\n",
       "      <td>0.236360</td>\n",
       "      <td>1.162400</td>\n",
       "      <td>0.185219</td>\n",
       "      <td>-0.270069</td>\n",
       "      <td>-0.255398</td>\n",
       "      <td>0.356381</td>\n",
       "      <td>0.559307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2017</td>\n",
       "      <td>Kyle Lowry</td>\n",
       "      <td>4.141570</td>\n",
       "      <td>0.535879</td>\n",
       "      <td>0.195764</td>\n",
       "      <td>2.017329</td>\n",
       "      <td>-0.769567</td>\n",
       "      <td>0.428929</td>\n",
       "      <td>-0.766749</td>\n",
       "      <td>2.066403</td>\n",
       "      <td>-0.765502</td>\n",
       "      <td>1.199083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2017</td>\n",
       "      <td>Otto Porter</td>\n",
       "      <td>4.136911</td>\n",
       "      <td>0.259510</td>\n",
       "      <td>0.505884</td>\n",
       "      <td>-0.476027</td>\n",
       "      <td>-0.125578</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>0.847459</td>\n",
       "      <td>0.557232</td>\n",
       "      <td>0.888985</td>\n",
       "      <td>0.275676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>2017</td>\n",
       "      <td>Kawhi Leonard</td>\n",
       "      <td>4.001655</td>\n",
       "      <td>0.535879</td>\n",
       "      <td>-0.153122</td>\n",
       "      <td>-0.323373</td>\n",
       "      <td>0.947737</td>\n",
       "      <td>2.622318</td>\n",
       "      <td>-0.145900</td>\n",
       "      <td>-0.139308</td>\n",
       "      <td>0.190517</td>\n",
       "      <td>0.466907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>2017</td>\n",
       "      <td>Kevin Love</td>\n",
       "      <td>3.988737</td>\n",
       "      <td>0.793824</td>\n",
       "      <td>1.630072</td>\n",
       "      <td>-0.628682</td>\n",
       "      <td>-0.340241</td>\n",
       "      <td>-0.545910</td>\n",
       "      <td>0.226610</td>\n",
       "      <td>1.137683</td>\n",
       "      <td>-0.085231</td>\n",
       "      <td>1.800614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2017</td>\n",
       "      <td>Andre Drummond</td>\n",
       "      <td>3.805188</td>\n",
       "      <td>0.314784</td>\n",
       "      <td>4.227332</td>\n",
       "      <td>0.032821</td>\n",
       "      <td>2.235716</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>-1.139258</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>1.440481</td>\n",
       "      <td>-3.178068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017</td>\n",
       "      <td>Russell Westbrook</td>\n",
       "      <td>3.763264</td>\n",
       "      <td>2.230942</td>\n",
       "      <td>1.940192</td>\n",
       "      <td>3.747412</td>\n",
       "      <td>-0.554904</td>\n",
       "      <td>2.134898</td>\n",
       "      <td>-3.870994</td>\n",
       "      <td>-0.139308</td>\n",
       "      <td>-0.520390</td>\n",
       "      <td>-1.204585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017</td>\n",
       "      <td>Kemba Walker</td>\n",
       "      <td>3.725170</td>\n",
       "      <td>1.622930</td>\n",
       "      <td>-0.773363</td>\n",
       "      <td>1.355826</td>\n",
       "      <td>-0.554904</td>\n",
       "      <td>0.428929</td>\n",
       "      <td>-0.642579</td>\n",
       "      <td>1.834223</td>\n",
       "      <td>-0.897960</td>\n",
       "      <td>1.352068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2017</td>\n",
       "      <td>Eric Bledsoe</td>\n",
       "      <td>3.653643</td>\n",
       "      <td>0.830673</td>\n",
       "      <td>-0.463243</td>\n",
       "      <td>1.101402</td>\n",
       "      <td>0.089085</td>\n",
       "      <td>2.622318</td>\n",
       "      <td>-1.511767</td>\n",
       "      <td>0.441142</td>\n",
       "      <td>0.360757</td>\n",
       "      <td>0.183276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>2017</td>\n",
       "      <td>Darrun Hilliard</td>\n",
       "      <td>-8.567256</td>\n",
       "      <td>-2.246234</td>\n",
       "      <td>-1.781256</td>\n",
       "      <td>-1.086645</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.008169</td>\n",
       "      <td>1.716648</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.468564</td>\n",
       "      <td>0.038246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>2017</td>\n",
       "      <td>Tim Quarterman</td>\n",
       "      <td>-8.645561</td>\n",
       "      <td>-2.209385</td>\n",
       "      <td>-1.587430</td>\n",
       "      <td>-1.341069</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>1.219968</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.307768</td>\n",
       "      <td>0.563284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>2017</td>\n",
       "      <td>Demetrius Jackson</td>\n",
       "      <td>-8.660268</td>\n",
       "      <td>-2.319932</td>\n",
       "      <td>-1.626195</td>\n",
       "      <td>-1.290185</td>\n",
       "      <td>-0.984230</td>\n",
       "      <td>-1.520749</td>\n",
       "      <td>1.095798</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.482386</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2017</td>\n",
       "      <td>Markel Brown</td>\n",
       "      <td>-8.715761</td>\n",
       "      <td>-2.209385</td>\n",
       "      <td>-1.471135</td>\n",
       "      <td>-1.239300</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>1.468308</td>\n",
       "      <td>-1.184119</td>\n",
       "      <td>-0.629359</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>2017</td>\n",
       "      <td>Josh Smith</td>\n",
       "      <td>-8.748490</td>\n",
       "      <td>-2.319932</td>\n",
       "      <td>-1.471135</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.569694</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>2017</td>\n",
       "      <td>Erik McCree</td>\n",
       "      <td>-8.773341</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.858786</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-1.520749</td>\n",
       "      <td>1.716648</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.436543</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>2017</td>\n",
       "      <td>Xavier Munford</td>\n",
       "      <td>-8.789856</td>\n",
       "      <td>-2.356782</td>\n",
       "      <td>-1.897551</td>\n",
       "      <td>-1.137530</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-1.764459</td>\n",
       "      <td>1.716648</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.496208</td>\n",
       "      <td>-0.122692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>2017</td>\n",
       "      <td>Tyler Lydon</td>\n",
       "      <td>-8.811713</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.975081</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>2017</td>\n",
       "      <td>Trey McKinney-Jones</td>\n",
       "      <td>-8.811713</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.975081</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>2017</td>\n",
       "      <td>Xavier Rathan-Mayes</td>\n",
       "      <td>-8.814577</td>\n",
       "      <td>-1.380278</td>\n",
       "      <td>-1.587430</td>\n",
       "      <td>0.338130</td>\n",
       "      <td>0.089085</td>\n",
       "      <td>0.672639</td>\n",
       "      <td>-0.642579</td>\n",
       "      <td>-1.300209</td>\n",
       "      <td>-2.811382</td>\n",
       "      <td>-2.192553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>2017</td>\n",
       "      <td>Matt Williams</td>\n",
       "      <td>-8.833537</td>\n",
       "      <td>-2.135687</td>\n",
       "      <td>-1.858786</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>1.716648</td>\n",
       "      <td>-1.184119</td>\n",
       "      <td>-0.427098</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>2017</td>\n",
       "      <td>Cole Aldrich</td>\n",
       "      <td>-8.856290</td>\n",
       "      <td>-2.338357</td>\n",
       "      <td>-1.703725</td>\n",
       "      <td>-1.442839</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.008169</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.234282</td>\n",
       "      <td>-0.486792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>2017</td>\n",
       "      <td>Nicolas Brussino</td>\n",
       "      <td>-8.938136</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.664960</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.436543</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>2017</td>\n",
       "      <td>PJ Dozier</td>\n",
       "      <td>-8.985381</td>\n",
       "      <td>-2.264659</td>\n",
       "      <td>-1.781256</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>1.468308</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>0.069110</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>2017</td>\n",
       "      <td>Omer Asik</td>\n",
       "      <td>-9.030298</td>\n",
       "      <td>-2.209385</td>\n",
       "      <td>-0.967189</td>\n",
       "      <td>-1.442839</td>\n",
       "      <td>-0.984230</td>\n",
       "      <td>-2.008169</td>\n",
       "      <td>1.592478</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.018199</td>\n",
       "      <td>-1.460376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>2017</td>\n",
       "      <td>London Perrantes</td>\n",
       "      <td>-9.069214</td>\n",
       "      <td>-2.356782</td>\n",
       "      <td>-1.858786</td>\n",
       "      <td>-1.290185</td>\n",
       "      <td>-0.984230</td>\n",
       "      <td>-2.008169</td>\n",
       "      <td>1.964987</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.597338</td>\n",
       "      <td>-0.406323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>2017</td>\n",
       "      <td>Jacob Pullen</td>\n",
       "      <td>-9.101093</td>\n",
       "      <td>-2.319932</td>\n",
       "      <td>-1.975081</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>1.716648</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.045843</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>2017</td>\n",
       "      <td>Charles Cooke</td>\n",
       "      <td>-9.142223</td>\n",
       "      <td>-2.356782</td>\n",
       "      <td>-1.897551</td>\n",
       "      <td>-1.442839</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.008169</td>\n",
       "      <td>1.964987</td>\n",
       "      <td>-1.416299</td>\n",
       "      <td>-0.583516</td>\n",
       "      <td>-0.203161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>2017</td>\n",
       "      <td>Nate Wolters</td>\n",
       "      <td>-9.152010</td>\n",
       "      <td>-2.375206</td>\n",
       "      <td>-1.820021</td>\n",
       "      <td>-1.391954</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.670825</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>2017</td>\n",
       "      <td>Derrick Williams</td>\n",
       "      <td>-9.237618</td>\n",
       "      <td>-2.264659</td>\n",
       "      <td>-1.781256</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.803976</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>2017</td>\n",
       "      <td>Josh McRoberts</td>\n",
       "      <td>-9.248257</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.975081</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.436543</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>2017</td>\n",
       "      <td>Nick Collison</td>\n",
       "      <td>-9.288480</td>\n",
       "      <td>-2.061988</td>\n",
       "      <td>-1.471135</td>\n",
       "      <td>-1.341069</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>1.468308</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>0.560941</td>\n",
       "      <td>-1.460376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>2017</td>\n",
       "      <td>Chris Boucher</td>\n",
       "      <td>-9.297149</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.587430</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.873086</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>2017</td>\n",
       "      <td>Kyle Singler</td>\n",
       "      <td>-9.322633</td>\n",
       "      <td>-2.098837</td>\n",
       "      <td>-1.664960</td>\n",
       "      <td>-1.391954</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.008169</td>\n",
       "      <td>1.716648</td>\n",
       "      <td>-1.300209</td>\n",
       "      <td>-0.440920</td>\n",
       "      <td>-0.935338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>2017</td>\n",
       "      <td>Vander Blue</td>\n",
       "      <td>-9.478457</td>\n",
       "      <td>-2.338357</td>\n",
       "      <td>-1.897551</td>\n",
       "      <td>-1.188415</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-1.764459</td>\n",
       "      <td>1.344138</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.496208</td>\n",
       "      <td>-0.406323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>2017</td>\n",
       "      <td>Aaron Jackson</td>\n",
       "      <td>-9.982955</td>\n",
       "      <td>-0.974937</td>\n",
       "      <td>-0.812129</td>\n",
       "      <td>-0.984876</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>0.847459</td>\n",
       "      <td>-0.371488</td>\n",
       "      <td>-2.204598</td>\n",
       "      <td>-2.031614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>2017</td>\n",
       "      <td>Luis Montero</td>\n",
       "      <td>-10.102304</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.587430</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>0.847459</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.436543</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>2017</td>\n",
       "      <td>Chinanu Onuaku</td>\n",
       "      <td>-10.337018</td>\n",
       "      <td>-1.711921</td>\n",
       "      <td>-0.424478</td>\n",
       "      <td>-0.984876</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>-1.635937</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.596646</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>2017</td>\n",
       "      <td>Mindaugas Kuzminskas</td>\n",
       "      <td>-10.557886</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.975081</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-1.746172</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>2017</td>\n",
       "      <td>Scotty Hopson</td>\n",
       "      <td>-12.265018</td>\n",
       "      <td>-2.264659</td>\n",
       "      <td>-1.975081</td>\n",
       "      <td>-0.984876</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>0.847459</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.873086</td>\n",
       "      <td>-2.031614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     season                 player  value_tot  value_points  value_rebounds  \\\n",
       "11     2017          Anthony Davis  13.069292      2.728406        2.327843   \n",
       "161    2017          Stephen Curry  10.977767      2.415188        0.001938   \n",
       "47     2017           Kevin Durant  10.555627      2.415188        0.660945   \n",
       "27     2017           James Harden  10.522310      3.152171        0.118234   \n",
       "6      2017     Karl-Anthony Towns   9.046572      1.475533        2.793024   \n",
       "0      2017           LeBron James   8.050018      2.617858        1.358716   \n",
       "9      2017  Giannis Antetokounmpo   7.982516      2.507311        1.901427   \n",
       "17     2017         Damian Lillard   7.758411      2.507311       -0.230652   \n",
       "120    2017             Chris Paul   7.259998      0.978069        0.118234   \n",
       "68     2017           Jimmy Butler   7.194467      1.641355        0.079468   \n",
       "26     2017         Victor Oladipo   6.742591      1.807176        0.040703   \n",
       "137    2017       DeMarcus Cousins   6.513379      2.194092        3.025615   \n",
       "38     2017           Nikola Jokic   6.424866      0.959645        2.172783   \n",
       "109    2017           Kyrie Irving   6.159878      2.046696       -0.502008   \n",
       "473    2017           Andre Ingram   5.581832     -0.237954       -0.812129   \n",
       "29     2017      LaMarcus Aldridge   5.370052      1.807176        1.319951   \n",
       "418    2017         MarShon Brooks   5.131062      1.254438       -0.812129   \n",
       "8      2017            Paul George   5.126899      1.586081        0.234529   \n",
       "171    2017     Kristaps Porzingis   4.816889      1.733478        0.583415   \n",
       "5      2017           Jrue Holiday   4.397228      1.051768       -0.230652   \n",
       "1      2017        Khris Middleton   4.231094      1.254438        0.040703   \n",
       "147    2017         Nikola Vucevic   4.156660      0.591153        1.591307   \n",
       "30     2017             Kyle Lowry   4.141570      0.535879        0.195764   \n",
       "40     2017            Otto Porter   4.136911      0.259510        0.505884   \n",
       "413    2017          Kawhi Leonard   4.001655      0.535879       -0.153122   \n",
       "155    2017             Kevin Love   3.988737      0.793824        1.630072   \n",
       "20     2017         Andre Drummond   3.805188      0.314784        4.227332   \n",
       "7      2017      Russell Westbrook   3.763264      2.230942        1.940192   \n",
       "10     2017           Kemba Walker   3.725170      1.622930       -0.773363   \n",
       "61     2017           Eric Bledsoe   3.653643      0.830673       -0.463243   \n",
       "..      ...                    ...        ...           ...             ...   \n",
       "456    2017        Darrun Hilliard  -8.567256     -2.246234       -1.781256   \n",
       "513    2017         Tim Quarterman  -8.645561     -2.209385       -1.587430   \n",
       "475    2017      Demetrius Jackson  -8.660268     -2.319932       -1.626195   \n",
       "497    2017           Markel Brown  -8.715761     -2.209385       -1.471135   \n",
       "514    2017             Josh Smith  -8.748490     -2.319932       -1.471135   \n",
       "521    2017            Erik McCree  -8.773341     -2.448905       -1.858786   \n",
       "506    2017         Xavier Munford  -8.789856     -2.356782       -1.897551   \n",
       "536    2017            Tyler Lydon  -8.811713     -2.448905       -1.975081   \n",
       "539    2017    Trey McKinney-Jones  -8.811713     -2.448905       -1.975081   \n",
       "447    2017    Xavier Rathan-Mayes  -8.814577     -1.380278       -1.587430   \n",
       "515    2017          Matt Williams  -8.833537     -2.135687       -1.858786   \n",
       "483    2017           Cole Aldrich  -8.856290     -2.338357       -1.703725   \n",
       "516    2017       Nicolas Brussino  -8.938136     -2.448905       -1.664960   \n",
       "533    2017              PJ Dozier  -8.985381     -2.264659       -1.781256   \n",
       "443    2017              Omer Asik  -9.030298     -2.209385       -0.967189   \n",
       "472    2017       London Perrantes  -9.069214     -2.356782       -1.858786   \n",
       "526    2017           Jacob Pullen  -9.101093     -2.319932       -1.975081   \n",
       "491    2017          Charles Cooke  -9.142223     -2.356782       -1.897551   \n",
       "508    2017           Nate Wolters  -9.152010     -2.375206       -1.820021   \n",
       "517    2017       Derrick Williams  -9.237618     -2.264659       -1.781256   \n",
       "527    2017         Josh McRoberts  -9.248257     -2.448905       -1.975081   \n",
       "466    2017          Nick Collison  -9.288480     -2.061988       -1.471135   \n",
       "538    2017          Chris Boucher  -9.297149     -2.448905       -1.587430   \n",
       "478    2017           Kyle Singler  -9.322633     -2.098837       -1.664960   \n",
       "484    2017            Vander Blue  -9.478457     -2.338357       -1.897551   \n",
       "493    2017          Aaron Jackson  -9.982955     -0.974937       -0.812129   \n",
       "522    2017           Luis Montero -10.102304     -2.448905       -1.587430   \n",
       "505    2017         Chinanu Onuaku -10.337018     -1.711921       -0.424478   \n",
       "534    2017   Mindaugas Kuzminskas -10.557886     -2.448905       -1.975081   \n",
       "520    2017          Scotty Hopson -12.265018     -2.264659       -1.975081   \n",
       "\n",
       "     value_assists  value_blocks  value_steals  value_turnovers  value_threes  \\\n",
       "11       -0.323373      4.382346      1.403769        -0.642579     -0.719758   \n",
       "161       1.610250     -0.769567      1.647478        -1.635937      3.343394   \n",
       "47        1.254056      2.665042     -0.545910        -1.635937      1.369863   \n",
       "27        2.984140      0.303748      2.134898        -3.374314      2.762944   \n",
       "6        -0.272488      1.806390     -0.302200        -0.270069      0.208962   \n",
       "0         3.136795      0.733074      1.160059        -3.125975      0.557232   \n",
       "9         0.948747      1.806390      1.403769        -1.635937     -0.835849   \n",
       "17        1.864674     -0.340241      0.428929        -1.387598      2.066403   \n",
       "120       2.526177     -0.769567      1.891188        -0.642579      1.369863   \n",
       "68        0.999632     -0.340241      2.622318        -0.145900     -0.139308   \n",
       "26        0.694323      0.518411      3.597157        -1.511767      0.905503   \n",
       "137       1.254056      2.235716      1.647478        -4.119333      1.021593   \n",
       "38        1.610250      0.518411      0.672639        -1.387598      0.208962   \n",
       "109       1.101402     -0.554904      0.428929        -0.766749      1.718133   \n",
       "473       0.287245      2.021053      1.403769         0.226610      1.369863   \n",
       "29       -0.476027      1.377064     -0.789620         0.226610     -1.068029   \n",
       "418       0.338130     -0.340241      1.647478        -0.766749      1.602043   \n",
       "8         0.185475     -0.125578      2.622318        -1.263428      2.066403   \n",
       "171      -0.883106      3.953020     -0.302200        -0.270069      0.673322   \n",
       "5         1.559365      0.518411      1.403769        -1.139258      0.208962   \n",
       "1         0.541669     -0.554904      1.403769        -0.766749      0.557232   \n",
       "147       0.236360      1.162400      0.185219        -0.270069     -0.255398   \n",
       "30        2.017329     -0.769567      0.428929        -0.766749      2.066403   \n",
       "40       -0.476027     -0.125578      1.403769         0.847459      0.557232   \n",
       "413      -0.323373      0.947737      2.622318        -0.145900     -0.139308   \n",
       "155      -0.628682     -0.340241     -0.545910         0.226610      1.137683   \n",
       "20        0.032821      2.235716      1.403769        -1.139258     -1.532389   \n",
       "7         3.747412     -0.554904      2.134898        -3.870994     -0.139308   \n",
       "10        1.355826     -0.554904      0.428929        -0.642579      1.834223   \n",
       "61        1.101402      0.089085      2.622318        -1.511767      0.441142   \n",
       "..             ...           ...           ...              ...           ...   \n",
       "456      -1.086645     -1.198893     -2.008169         1.716648     -1.532389   \n",
       "513      -1.341069     -1.198893     -2.251879         1.219968     -1.532389   \n",
       "475      -1.290185     -0.984230     -1.520749         1.095798     -1.532389   \n",
       "497      -1.239300     -1.198893     -2.251879         1.468308     -1.184119   \n",
       "514      -1.493724     -1.198893     -2.251879         2.089157     -1.532389   \n",
       "521      -1.493724     -1.198893     -1.520749         1.716648     -1.532389   \n",
       "506      -1.137530     -1.198893     -1.764459         1.716648     -1.532389   \n",
       "536      -1.493724     -1.198893     -2.251879         2.089157     -1.532389   \n",
       "539      -1.493724     -1.198893     -2.251879         2.089157     -1.532389   \n",
       "447       0.338130      0.089085      0.672639        -0.642579     -1.300209   \n",
       "515      -1.493724     -1.198893     -2.251879         1.716648     -1.184119   \n",
       "483      -1.442839     -1.198893     -2.008169         2.089157     -1.532389   \n",
       "516      -1.493724     -1.198893     -2.251879         2.089157     -1.532389   \n",
       "533      -1.493724     -1.198893     -2.251879         1.468308     -1.532389   \n",
       "443      -1.442839     -0.984230     -2.008169         1.592478     -1.532389   \n",
       "472      -1.290185     -0.984230     -2.008169         1.964987     -1.532389   \n",
       "526      -1.493724     -1.198893     -2.251879         1.716648     -1.532389   \n",
       "491      -1.442839     -1.198893     -2.008169         1.964987     -1.416299   \n",
       "508      -1.391954     -1.198893     -2.251879         2.089157     -1.532389   \n",
       "517      -1.493724     -1.198893     -2.251879         2.089157     -1.532389   \n",
       "527      -1.493724     -1.198893     -2.251879         2.089157     -1.532389   \n",
       "466      -1.341069     -1.198893     -2.251879         1.468308     -1.532389   \n",
       "538      -1.493724     -1.198893     -2.251879         2.089157     -1.532389   \n",
       "478      -1.391954     -1.198893     -2.008169         1.716648     -1.300209   \n",
       "484      -1.188415     -1.198893     -1.764459         1.344138     -1.532389   \n",
       "493      -0.984876     -1.198893     -2.251879         0.847459     -0.371488   \n",
       "522      -1.493724     -1.198893     -2.251879         0.847459     -1.532389   \n",
       "505      -0.984876     -1.198893     -2.251879        -1.635937     -1.532389   \n",
       "534      -1.493724     -1.198893     -2.251879         2.089157     -1.532389   \n",
       "520      -0.984876     -1.198893     -2.251879         0.847459     -1.532389   \n",
       "\n",
       "     value_fg  value_ft  \n",
       "11   2.572502  1.340136  \n",
       "161  1.073741  3.291282  \n",
       "47   1.809299  2.563082  \n",
       "27  -0.589500  3.029989  \n",
       "6    2.213129  1.394291  \n",
       "0    2.935558 -1.323300  \n",
       "9    2.328774 -0.442116  \n",
       "17  -0.920536  3.770119  \n",
       "120 -0.176916  1.965529  \n",
       "68   0.324360  2.152782  \n",
       "26   0.389094  0.301991  \n",
       "137  0.301785 -1.047624  \n",
       "38   0.838766  0.831007  \n",
       "109  0.968233  1.720144  \n",
       "473  0.116338  1.207037  \n",
       "29   1.620860  1.352068  \n",
       "418  1.009007  1.199083  \n",
       "8   -1.086400  0.907499  \n",
       "171 -0.888515  0.217545  \n",
       "5    0.875856  0.149007  \n",
       "1    0.034790  1.720144  \n",
       "147  0.356381  0.559307  \n",
       "30  -0.765502  1.199083  \n",
       "40   0.888985  0.275676  \n",
       "413  0.190517  0.466907  \n",
       "155 -0.085231  1.800614  \n",
       "20   1.440481 -3.178068  \n",
       "7   -0.520390 -1.204585  \n",
       "10  -0.897960  1.352068  \n",
       "61   0.360757  0.183276  \n",
       "..        ...       ...  \n",
       "456 -0.468564  0.038246  \n",
       "513 -0.307768  0.563284  \n",
       "475 -0.482386  0.000000  \n",
       "497 -0.629359  0.000000  \n",
       "514 -0.569694  0.000000  \n",
       "521 -0.436543  0.000000  \n",
       "506 -0.496208 -0.122692  \n",
       "536  0.000000  0.000000  \n",
       "539  0.000000  0.000000  \n",
       "447 -2.811382 -2.192553  \n",
       "515 -0.427098  0.000000  \n",
       "483 -0.234282 -0.486792  \n",
       "516 -0.436543  0.000000  \n",
       "533  0.069110  0.000000  \n",
       "443 -0.018199 -1.460376  \n",
       "472 -0.597338 -0.406323  \n",
       "526 -0.045843  0.000000  \n",
       "491 -0.583516 -0.203161  \n",
       "508 -0.670825  0.000000  \n",
       "517 -0.803976  0.000000  \n",
       "527 -0.436543  0.000000  \n",
       "466  0.560941 -1.460376  \n",
       "538 -0.873086  0.000000  \n",
       "478 -0.440920 -0.935338  \n",
       "484 -0.496208 -0.406323  \n",
       "493 -2.204598 -2.031614  \n",
       "522 -0.436543  0.000000  \n",
       "505 -0.596646  0.000000  \n",
       "534 -1.746172  0.000000  \n",
       "520 -0.873086 -2.031614  \n",
       "\n",
       "[540 rows x 12 columns]"
      ]
     },
     "execution_count": 842,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_2017.value.sort_values(by='value_tot',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combined Rank</th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>Andy Behrens</th>\n",
       "      <th>Dahlton Del Don</th>\n",
       "      <th>Yahoo Staff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Kevin Durant</td>\n",
       "      <td>GSW</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Russell Westbrook</td>\n",
       "      <td>OKC</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>James Harden</td>\n",
       "      <td>HOU</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Stephen Curry</td>\n",
       "      <td>GSW</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Giannis Antetokounmpo</td>\n",
       "      <td>MIL</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Combined Rank                 PLAYER  TEAM  Andy Behrens  Dahlton Del Don  \\\n",
       "0              1           Kevin Durant  GSW            1.0              1.0   \n",
       "1              2      Russell Westbrook  OKC            2.0              5.0   \n",
       "2              3           James Harden  HOU            6.0              2.0   \n",
       "3              4          Stephen Curry  GSW            3.0              6.0   \n",
       "4              5  Giannis Antetokounmpo  MIL            9.0              3.0   \n",
       "\n",
       "   Yahoo Staff  \n",
       "0          5.0  \n",
       "1          1.0  \n",
       "2          3.0  \n",
       "3          4.0  \n",
       "4          2.0  "
      ]
     },
     "execution_count": 841,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yahoo_ranks['PLAYER']=yahoo_ranks['PLAYER'].str.replace('Ê','')\n",
    "yahoo_ranks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>rank</th>\n",
       "      <th>predicted_rank</th>\n",
       "      <th>value_tot_x</th>\n",
       "      <th>value_tot_y</th>\n",
       "      <th>Combined Rank</th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>Andy Behrens</th>\n",
       "      <th>Dahlton Del Don</th>\n",
       "      <th>Yahoo Staff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anthony Davis</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9.828537</td>\n",
       "      <td>13.069292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stephen Curry</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>9.725957</td>\n",
       "      <td>10.977767</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kevin Durant</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>10.200421</td>\n",
       "      <td>10.555627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>James Harden</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9.923810</td>\n",
       "      <td>10.522310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Karl-Anthony Towns</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>9.059942</td>\n",
       "      <td>9.046572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LeBron James</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>7.143940</td>\n",
       "      <td>8.050018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Giannis Antetokounmpo</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8.834420</td>\n",
       "      <td>7.982516</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Damian Lillard</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>5.645785</td>\n",
       "      <td>7.758411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chris Paul</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>7.458537</td>\n",
       "      <td>7.259998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jimmy Butler</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>6.556113</td>\n",
       "      <td>7.194467</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Victor Oladipo</td>\n",
       "      <td>11</td>\n",
       "      <td>49</td>\n",
       "      <td>1.327245</td>\n",
       "      <td>6.742591</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DeMarcus Cousins</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>5.831741</td>\n",
       "      <td>6.513379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Nikola Jokic</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>6.219954</td>\n",
       "      <td>6.424866</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Kyrie Irving</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>4.968418</td>\n",
       "      <td>6.159878</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LaMarcus Aldridge</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>1.265590</td>\n",
       "      <td>5.370052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Paul George</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>5.134307</td>\n",
       "      <td>5.126899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kristaps Porzingis</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>4.703755</td>\n",
       "      <td>4.816889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Jrue Holiday</td>\n",
       "      <td>18</td>\n",
       "      <td>44</td>\n",
       "      <td>1.900394</td>\n",
       "      <td>4.397228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Khris Middleton</td>\n",
       "      <td>19</td>\n",
       "      <td>55</td>\n",
       "      <td>1.079365</td>\n",
       "      <td>4.231094</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Nikola Vucevic</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>2.531134</td>\n",
       "      <td>4.156660</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Kyle Lowry</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>5.324634</td>\n",
       "      <td>4.141570</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Otto Porter</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>4.121816</td>\n",
       "      <td>4.136911</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Kevin Love</td>\n",
       "      <td>23</td>\n",
       "      <td>41</td>\n",
       "      <td>2.517008</td>\n",
       "      <td>3.988737</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Andre Drummond</td>\n",
       "      <td>24</td>\n",
       "      <td>38</td>\n",
       "      <td>2.589160</td>\n",
       "      <td>3.805188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Russell Westbrook</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>10.240059</td>\n",
       "      <td>3.763264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Kemba Walker</td>\n",
       "      <td>26</td>\n",
       "      <td>23</td>\n",
       "      <td>4.185227</td>\n",
       "      <td>3.725170</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Eric Bledsoe</td>\n",
       "      <td>27</td>\n",
       "      <td>34</td>\n",
       "      <td>2.860083</td>\n",
       "      <td>3.653643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Joel Embiid</td>\n",
       "      <td>28</td>\n",
       "      <td>21</td>\n",
       "      <td>4.887053</td>\n",
       "      <td>3.553557</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Rudy Gobert</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>6.011024</td>\n",
       "      <td>3.474873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Draymond Green</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>5.318157</td>\n",
       "      <td>3.435896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Robin Lopez</td>\n",
       "      <td>171</td>\n",
       "      <td>112</td>\n",
       "      <td>-0.538379</td>\n",
       "      <td>-2.513065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Jae Crowder</td>\n",
       "      <td>172</td>\n",
       "      <td>83</td>\n",
       "      <td>0.176414</td>\n",
       "      <td>-2.515449</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Cory Joseph</td>\n",
       "      <td>173</td>\n",
       "      <td>191</td>\n",
       "      <td>-2.561692</td>\n",
       "      <td>-2.520356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Maurice Harkless</td>\n",
       "      <td>174</td>\n",
       "      <td>104</td>\n",
       "      <td>-0.234525</td>\n",
       "      <td>-2.539700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Dejounte Murray</td>\n",
       "      <td>175</td>\n",
       "      <td>285</td>\n",
       "      <td>-4.935946</td>\n",
       "      <td>-2.547384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Shabazz Napier</td>\n",
       "      <td>176</td>\n",
       "      <td>284</td>\n",
       "      <td>-4.901944</td>\n",
       "      <td>-2.598822</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Andre Roberson</td>\n",
       "      <td>177</td>\n",
       "      <td>108</td>\n",
       "      <td>-0.398282</td>\n",
       "      <td>-2.627905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Tyus Jones</td>\n",
       "      <td>178</td>\n",
       "      <td>199</td>\n",
       "      <td>-2.735979</td>\n",
       "      <td>-2.636447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>James Ennis</td>\n",
       "      <td>179</td>\n",
       "      <td>213</td>\n",
       "      <td>-3.169800</td>\n",
       "      <td>-2.650949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Luc Mbah a Moute</td>\n",
       "      <td>180</td>\n",
       "      <td>293</td>\n",
       "      <td>-5.265555</td>\n",
       "      <td>-2.652474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Tyson Chandler</td>\n",
       "      <td>181</td>\n",
       "      <td>141</td>\n",
       "      <td>-1.293568</td>\n",
       "      <td>-2.690522</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Marcus Smart</td>\n",
       "      <td>182</td>\n",
       "      <td>73</td>\n",
       "      <td>0.539673</td>\n",
       "      <td>-2.697004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Andre Iguodala</td>\n",
       "      <td>183</td>\n",
       "      <td>103</td>\n",
       "      <td>-0.213612</td>\n",
       "      <td>-2.702815</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Quinn Cook</td>\n",
       "      <td>184</td>\n",
       "      <td>261</td>\n",
       "      <td>-4.187999</td>\n",
       "      <td>-2.743507</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Wesley Johnson</td>\n",
       "      <td>185</td>\n",
       "      <td>235</td>\n",
       "      <td>-3.545917</td>\n",
       "      <td>-2.752677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Jonathon Simmons</td>\n",
       "      <td>186</td>\n",
       "      <td>189</td>\n",
       "      <td>-2.540725</td>\n",
       "      <td>-2.779381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Dwyane Wade</td>\n",
       "      <td>187</td>\n",
       "      <td>133</td>\n",
       "      <td>-1.206774</td>\n",
       "      <td>-2.796991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Frank Kaminsky</td>\n",
       "      <td>188</td>\n",
       "      <td>146</td>\n",
       "      <td>-1.445401</td>\n",
       "      <td>-2.797919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Stanley Johnson</td>\n",
       "      <td>189</td>\n",
       "      <td>137</td>\n",
       "      <td>-1.251221</td>\n",
       "      <td>-2.873479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>Garrett Temple</td>\n",
       "      <td>190</td>\n",
       "      <td>170</td>\n",
       "      <td>-2.244374</td>\n",
       "      <td>-2.876957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Justise Winslow</td>\n",
       "      <td>191</td>\n",
       "      <td>232</td>\n",
       "      <td>-3.455369</td>\n",
       "      <td>-2.938563</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Nemanja Bjelica</td>\n",
       "      <td>192</td>\n",
       "      <td>243</td>\n",
       "      <td>-3.768501</td>\n",
       "      <td>-2.956512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>J.R. Smith</td>\n",
       "      <td>193</td>\n",
       "      <td>142</td>\n",
       "      <td>-1.300404</td>\n",
       "      <td>-2.958959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Tony Snell</td>\n",
       "      <td>194</td>\n",
       "      <td>167</td>\n",
       "      <td>-2.162951</td>\n",
       "      <td>-2.963949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>C.J. Miles</td>\n",
       "      <td>195</td>\n",
       "      <td>138</td>\n",
       "      <td>-1.259531</td>\n",
       "      <td>-3.001869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Ed Davis</td>\n",
       "      <td>196</td>\n",
       "      <td>255</td>\n",
       "      <td>-4.024634</td>\n",
       "      <td>-3.006733</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Jerian Grant</td>\n",
       "      <td>197</td>\n",
       "      <td>200</td>\n",
       "      <td>-2.741861</td>\n",
       "      <td>-3.018571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Richaun Holmes</td>\n",
       "      <td>198</td>\n",
       "      <td>96</td>\n",
       "      <td>-0.107400</td>\n",
       "      <td>-3.068791</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Avery Bradley</td>\n",
       "      <td>199</td>\n",
       "      <td>64</td>\n",
       "      <td>0.769895</td>\n",
       "      <td>-3.112203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Jerami Grant</td>\n",
       "      <td>200</td>\n",
       "      <td>165</td>\n",
       "      <td>-2.062593</td>\n",
       "      <td>-3.142402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    player  rank  predicted_rank  value_tot_x  value_tot_y  \\\n",
       "0            Anthony Davis     1               4     9.828537    13.069292   \n",
       "1            Stephen Curry     2               5     9.725957    10.977767   \n",
       "2             Kevin Durant     3               2    10.200421    10.555627   \n",
       "3             James Harden     4               3     9.923810    10.522310   \n",
       "4       Karl-Anthony Towns     5               6     9.059942     9.046572   \n",
       "5             LeBron James     6               9     7.143940     8.050018   \n",
       "6    Giannis Antetokounmpo     7               7     8.834420     7.982516   \n",
       "7           Damian Lillard     8              14     5.645785     7.758411   \n",
       "8               Chris Paul     9               8     7.458537     7.259998   \n",
       "9             Jimmy Butler    10              10     6.556113     7.194467   \n",
       "10          Victor Oladipo    11              49     1.327245     6.742591   \n",
       "11        DeMarcus Cousins    12              13     5.831741     6.513379   \n",
       "12            Nikola Jokic    13              11     6.219954     6.424866   \n",
       "13            Kyrie Irving    14              20     4.968418     6.159878   \n",
       "14       LaMarcus Aldridge    15              50     1.265590     5.370052   \n",
       "15             Paul George    16              19     5.134307     5.126899   \n",
       "16      Kristaps Porzingis    17              22     4.703755     4.816889   \n",
       "17            Jrue Holiday    18              44     1.900394     4.397228   \n",
       "18         Khris Middleton    19              55     1.079365     4.231094   \n",
       "19          Nikola Vucevic    20              40     2.531134     4.156660   \n",
       "20              Kyle Lowry    21              16     5.324634     4.141570   \n",
       "21             Otto Porter    22              24     4.121816     4.136911   \n",
       "22              Kevin Love    23              41     2.517008     3.988737   \n",
       "23          Andre Drummond    24              38     2.589160     3.805188   \n",
       "24       Russell Westbrook    25               1    10.240059     3.763264   \n",
       "25            Kemba Walker    26              23     4.185227     3.725170   \n",
       "26            Eric Bledsoe    27              34     2.860083     3.653643   \n",
       "27             Joel Embiid    28              21     4.887053     3.553557   \n",
       "28             Rudy Gobert    29              12     6.011024     3.474873   \n",
       "29          Draymond Green    30              17     5.318157     3.435896   \n",
       "..                     ...   ...             ...          ...          ...   \n",
       "170            Robin Lopez   171             112    -0.538379    -2.513065   \n",
       "171            Jae Crowder   172              83     0.176414    -2.515449   \n",
       "172            Cory Joseph   173             191    -2.561692    -2.520356   \n",
       "173       Maurice Harkless   174             104    -0.234525    -2.539700   \n",
       "174        Dejounte Murray   175             285    -4.935946    -2.547384   \n",
       "175         Shabazz Napier   176             284    -4.901944    -2.598822   \n",
       "176         Andre Roberson   177             108    -0.398282    -2.627905   \n",
       "177             Tyus Jones   178             199    -2.735979    -2.636447   \n",
       "178            James Ennis   179             213    -3.169800    -2.650949   \n",
       "179       Luc Mbah a Moute   180             293    -5.265555    -2.652474   \n",
       "180         Tyson Chandler   181             141    -1.293568    -2.690522   \n",
       "181           Marcus Smart   182              73     0.539673    -2.697004   \n",
       "182         Andre Iguodala   183             103    -0.213612    -2.702815   \n",
       "183             Quinn Cook   184             261    -4.187999    -2.743507   \n",
       "184         Wesley Johnson   185             235    -3.545917    -2.752677   \n",
       "185       Jonathon Simmons   186             189    -2.540725    -2.779381   \n",
       "186            Dwyane Wade   187             133    -1.206774    -2.796991   \n",
       "187         Frank Kaminsky   188             146    -1.445401    -2.797919   \n",
       "188        Stanley Johnson   189             137    -1.251221    -2.873479   \n",
       "189         Garrett Temple   190             170    -2.244374    -2.876957   \n",
       "190        Justise Winslow   191             232    -3.455369    -2.938563   \n",
       "191        Nemanja Bjelica   192             243    -3.768501    -2.956512   \n",
       "192             J.R. Smith   193             142    -1.300404    -2.958959   \n",
       "193             Tony Snell   194             167    -2.162951    -2.963949   \n",
       "194             C.J. Miles   195             138    -1.259531    -3.001869   \n",
       "195               Ed Davis   196             255    -4.024634    -3.006733   \n",
       "196           Jerian Grant   197             200    -2.741861    -3.018571   \n",
       "197         Richaun Holmes   198              96    -0.107400    -3.068791   \n",
       "198          Avery Bradley   199              64     0.769895    -3.112203   \n",
       "199           Jerami Grant   200             165    -2.062593    -3.142402   \n",
       "\n",
       "     Combined Rank PLAYER TEAM  Andy Behrens  Dahlton Del Don  Yahoo Staff  \n",
       "0              NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "1              NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "2              NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "3              NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "4              NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "5              NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "6              NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "7              NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "8              NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "9              NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "10             NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "11             NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "12             NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "13             NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "14             NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "15             NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "16             NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "17             NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "18             NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "19             NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "20             NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "21             NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "22             NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "23             NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "24             NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "25             NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "26             NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "27             NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "28             NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "29             NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "..             ...    ...  ...           ...              ...          ...  \n",
       "170            NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "171            NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "172            NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "173            NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "174            NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "175            NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "176            NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "177            NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "178            NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "179            NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "180            NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "181            NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "182            NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "183            NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "184            NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "185            NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "186            NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "187            NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "188            NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "189            NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "190            NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "191            NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "192            NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "193            NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "194            NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "195            NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "196            NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "197            NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "198            NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "199            NaN    NaN  NaN           NaN              NaN          NaN  \n",
       "\n",
       "[200 rows x 11 columns]"
      ]
     },
     "execution_count": 840,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(rank_preds,yahoo_ranks,how='left',left_on='player',right_on='PLAYER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
