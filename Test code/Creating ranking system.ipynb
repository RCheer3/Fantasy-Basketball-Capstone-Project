{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "import psycopg2 as pg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from Player_rank import Player_ranker\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nHere we're loading in all of the traditional Fantasy basketball stats into SQL, using window function to get a ranking by minutes\\n\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Here we're loading in all of the traditional Fantasy basketball stats into SQL, using window function to get a ranking by minutes\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"IF you have open connections run the following in the psql command prompt:\\n\\nSELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname = 'nba_capstone';\\n\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''IF you have open connections run the following in the psql command prompt:\n",
    "\n",
    "SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname = 'nba_capstone';\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pg2.connect(dbname = 'postgres',host='localhost')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.autocommit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Note for some reason you can not access the database if it is not all lowercase'''\n",
    "\n",
    "cur.execute('DROP DATABASE IF EXISTS nba_capstone;')  # Makes sure there is not already a class_example database and removes is if there is\n",
    "cur.execute('CREATE DATABASE nba_capstone;')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pg2.connect(dbname = 'nba_capstone',host='localhost')\n",
    "conn.autocommit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "        CREATE TABLE NBA_stats (\n",
    "            Season integer, \n",
    "            Player varchar(50), \n",
    "            Pos varchar(10),\n",
    "            Age int,\n",
    "            Tm varchar(15),\n",
    "            G int,\n",
    "            GS int,\n",
    "            MP float,\n",
    "            FG float,\n",
    "            FGA float,\n",
    "            FG_Percentage float,\n",
    "            Threes_Made float,\n",
    "            Threes_Attempted float,\n",
    "            Three_Percentage float,\n",
    "            Twos_Made float,\n",
    "            Twos_Attempted float,\n",
    "            Twos_Percentage float,\n",
    "            eff_FG_Percentage float,\n",
    "            FTM float,\n",
    "            FTA float,\n",
    "            FT_Percentage float,\n",
    "            ORB float,\n",
    "            DRB float,\n",
    "            Rebounds float,\n",
    "            AST float,\n",
    "            STL float,\n",
    "            BLK float,\n",
    "            TOV float,\n",
    "            Fouls float,\n",
    "            Points float\n",
    "        );\n",
    "        '''\n",
    "\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# current_directory_path = os.getcwd()\n",
    "# current_directory_path\n",
    "\n",
    "query = '''\n",
    "        COPY NBA_stats \n",
    "        FROM '/Users/rcheer/Desktop/Galvanize/Capstone/Fantasy-Basketball-Capstone-Project/NBA stats.csv' \n",
    "        DELIMITER ',' \n",
    "        CSV HEADER;\n",
    "        '''\n",
    "\n",
    "\n",
    "\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "        CREATE TABLE nba_advanced (\n",
    "            Season integer, \n",
    "            Player varchar(50), \n",
    "            Pos varchar(10),\n",
    "            Age int,\n",
    "            Tm varchar(15),\n",
    "            G int,\n",
    "            total_MP float,\n",
    "            PER float,\n",
    "            True_Shooting float,\n",
    "            Three_Attempt_Rate float,\n",
    "            FT_rate float,\n",
    "            ORB_Percentage float,\n",
    "            DRB_Percentage float,\n",
    "            Rebound_Percentage float,\n",
    "            Assist_Percentage float,\n",
    "            Steal_Percentage float,\n",
    "            Block_Percentage float,\n",
    "            Turnover_Percentage float,\n",
    "            Usage_Percentage float,\n",
    "            Offensive_WinShares float,\n",
    "            Defensive_WinShares float,\n",
    "            WinShares float,\n",
    "            WinShares_Per48 float,\n",
    "            Offensive_BoxPlusMinus float,\n",
    "            Defensive_BoxPlusMinus float,\n",
    "            BoxPlusMinus float,\n",
    "            Value_overReplacement float\n",
    "        );\n",
    "        '''\n",
    "\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "        COPY nba_advanced \n",
    "        FROM '/Users/rcheer/Desktop/Galvanize/Capstone/Fantasy-Basketball-Capstone-Project/NBA Advanced.csv' \n",
    "        DELIMITER ',' \n",
    "        CSV HEADER;\n",
    "        '''\n",
    "\n",
    "\n",
    "\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "save for later\n",
    "d.points,d.rebounds,d.ast,d.stl,d.blk,d.tov,d.fg_percentage,d.FT_percentage\n",
    "'''\n",
    "\n",
    "\n",
    "query1 = '''\n",
    "            update nba_stats set Tm = 'NOP' where Tm = 'NOH';\n",
    "            update nba_advanced set Tm = 'NOP' where Tm = 'NOH';\n",
    "            update nba_stats set Tm = 'CHA' where Tm = 'CHO';\n",
    "            update nba_advanced set Tm = 'CHA' where Tm = 'CHO';\n",
    "            \n",
    "            DROP TABLE IF EXISTS players;\n",
    "            CREATE TABLE players AS\n",
    "            select season,player,max(G) as Games from NBA_stats where Tm!='TOT' group by season,player;\n",
    "            \n",
    "            DROP TABLE IF EXISTS y_predictions;\n",
    "            CREATE TABLE y_predictions AS\n",
    "            select d.season,d.player,d.pos,d.age,MAX(case when p.player is not null then d.Tm else NULL end) as StartingTeam,SUM(G) as Games,SUM(GS) as GS,\n",
    "            max(MP) as minutes\n",
    "            from NBA_stats d\n",
    "            left join players p\n",
    "                on d.season = p.season\n",
    "                and d.player = p.player\n",
    "                and d.G = p.Games\n",
    "            where d.Tm!='TOT'\n",
    "            group by d.season,d.player,d.pos,d.age;\n",
    "            \n",
    "            update y_predictions set StartingTeam = 'NOP' where startingTeam = 'NOH';\n",
    "            update y_predictions set StartingTeam = 'CHA' where startingTeam = 'CHO';\n",
    "            \n",
    "            DROP TABLE IF EXISTS rank_by_minutes;\n",
    "            CREATE TABLE rank_by_minutes AS\n",
    "            select y.*,n.points,n.rebounds,n.ast,n.stl,n.blk,n.tov,n.threes_made,n.fg,n.fga,n.ftm,n.fta,\n",
    "            case when cast(y.GS as float)/y.Games >0.6 then 1 else 0 end as starter,\n",
    "            row_number() over(partition by n.season order by MP*G desc) as min_rank from NBA_stats n\n",
    "            inner join y_predictions y\n",
    "                ON n.player = y.player\n",
    "                and n.season = y.season\n",
    "                and n.Tm=y.startingTeam;\n",
    "            \n",
    "            select * from rank_by_minutes        \n",
    "                \n",
    "        '''\n",
    "cur.execute(query1)\n",
    "data = cur.fetchall()\n",
    "df = pd.DataFrame(np.array(data))\n",
    "df.columns = ['season','player','position','age','team','gamesPlayed','gamesStarted','minutes'\n",
    "              ,'points','rebounds','assists','steals','blocks','turnovers','threes_made','FGM','FGA','FTM','FTA','starter','min_rank']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['min_rank']=pd.to_numeric(df['min_rank'])\n",
    "df['points']=pd.to_numeric(df['points'])\n",
    "df['rebounds']=pd.to_numeric(df['rebounds'])\n",
    "df['assists']=pd.to_numeric(df['assists'])\n",
    "df['steals']=pd.to_numeric(df['steals'])\n",
    "df['blocks']=pd.to_numeric(df['blocks'])\n",
    "df['turnovers']=pd.to_numeric(df['turnovers'])\n",
    "df['threes_made']=pd.to_numeric(df['threes_made'])\n",
    "df['FGM']=pd.to_numeric(df['FGM'])\n",
    "df['FGA']=pd.to_numeric(df['FGA'])\n",
    "df['FTM']=pd.to_numeric(df['FTM'])\n",
    "df['FTA']=pd.to_numeric(df['FTA'])\n",
    "df['gamesPlayed']=pd.to_numeric(df['gamesPlayed'])\n",
    "df['gamesStarted']=pd.to_numeric(df['gamesStarted'])\n",
    "df['minutes']=pd.to_numeric(df['minutes'])\n",
    "df['age']=pd.to_numeric(df['age'])\n",
    "df['season']=pd.to_numeric(df['season'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>mean_points</th>\n",
       "      <th>mean_rebounds</th>\n",
       "      <th>mean_assists</th>\n",
       "      <th>mean_steals</th>\n",
       "      <th>mean_blocks</th>\n",
       "      <th>mean_turnovers</th>\n",
       "      <th>mean_threes_made</th>\n",
       "      <th>mean_fgm</th>\n",
       "      <th>mean_fga</th>\n",
       "      <th>mean_ftm</th>\n",
       "      <th>mean_fta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>13.3005</td>\n",
       "      <td>5.1235</td>\n",
       "      <td>2.7870</td>\n",
       "      <td>0.9150</td>\n",
       "      <td>0.5690</td>\n",
       "      <td>1.7035</td>\n",
       "      <td>0.8780</td>\n",
       "      <td>4.9095</td>\n",
       "      <td>10.5850</td>\n",
       "      <td>2.5990</td>\n",
       "      <td>3.3115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>12.9850</td>\n",
       "      <td>5.1080</td>\n",
       "      <td>2.8490</td>\n",
       "      <td>0.9120</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>1.6965</td>\n",
       "      <td>0.8265</td>\n",
       "      <td>4.8530</td>\n",
       "      <td>10.4370</td>\n",
       "      <td>2.4600</td>\n",
       "      <td>3.1825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>12.9225</td>\n",
       "      <td>5.0185</td>\n",
       "      <td>2.8135</td>\n",
       "      <td>0.9085</td>\n",
       "      <td>0.5685</td>\n",
       "      <td>1.6790</td>\n",
       "      <td>0.8380</td>\n",
       "      <td>4.7955</td>\n",
       "      <td>10.3525</td>\n",
       "      <td>2.4955</td>\n",
       "      <td>3.2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>12.1830</td>\n",
       "      <td>4.8915</td>\n",
       "      <td>2.6840</td>\n",
       "      <td>0.9225</td>\n",
       "      <td>0.5725</td>\n",
       "      <td>1.6805</td>\n",
       "      <td>0.8030</td>\n",
       "      <td>4.5925</td>\n",
       "      <td>10.1180</td>\n",
       "      <td>2.1955</td>\n",
       "      <td>2.8590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012</td>\n",
       "      <td>12.5550</td>\n",
       "      <td>5.0520</td>\n",
       "      <td>2.8840</td>\n",
       "      <td>0.9585</td>\n",
       "      <td>0.6125</td>\n",
       "      <td>1.7410</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>4.7285</td>\n",
       "      <td>10.3275</td>\n",
       "      <td>2.2150</td>\n",
       "      <td>2.8920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013</td>\n",
       "      <td>13.0510</td>\n",
       "      <td>5.1265</td>\n",
       "      <td>2.8310</td>\n",
       "      <td>0.9505</td>\n",
       "      <td>0.5420</td>\n",
       "      <td>1.7375</td>\n",
       "      <td>0.9715</td>\n",
       "      <td>4.8545</td>\n",
       "      <td>10.5425</td>\n",
       "      <td>2.3790</td>\n",
       "      <td>3.1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014</td>\n",
       "      <td>12.3805</td>\n",
       "      <td>4.9890</td>\n",
       "      <td>2.7145</td>\n",
       "      <td>0.9230</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>1.6315</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>4.6260</td>\n",
       "      <td>10.1940</td>\n",
       "      <td>2.1725</td>\n",
       "      <td>2.8505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015</td>\n",
       "      <td>12.8715</td>\n",
       "      <td>5.1935</td>\n",
       "      <td>2.7720</td>\n",
       "      <td>0.9530</td>\n",
       "      <td>0.5900</td>\n",
       "      <td>1.6785</td>\n",
       "      <td>1.0530</td>\n",
       "      <td>4.7645</td>\n",
       "      <td>10.4595</td>\n",
       "      <td>2.2840</td>\n",
       "      <td>2.9900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>13.3550</td>\n",
       "      <td>5.0420</td>\n",
       "      <td>2.8950</td>\n",
       "      <td>0.9230</td>\n",
       "      <td>0.5340</td>\n",
       "      <td>1.6195</td>\n",
       "      <td>1.2170</td>\n",
       "      <td>4.8980</td>\n",
       "      <td>10.6355</td>\n",
       "      <td>2.3385</td>\n",
       "      <td>2.9850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>13.2915</td>\n",
       "      <td>5.0950</td>\n",
       "      <td>2.9355</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.5585</td>\n",
       "      <td>1.6825</td>\n",
       "      <td>1.3200</td>\n",
       "      <td>4.9175</td>\n",
       "      <td>10.6135</td>\n",
       "      <td>2.1395</td>\n",
       "      <td>2.7465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  mean_points  mean_rebounds  mean_assists  mean_steals  mean_blocks  \\\n",
       "0    2008      13.3005         5.1235        2.7870       0.9150       0.5690   \n",
       "1    2009      12.9850         5.1080        2.8490       0.9120       0.5600   \n",
       "2    2010      12.9225         5.0185        2.8135       0.9085       0.5685   \n",
       "3    2011      12.1830         4.8915        2.6840       0.9225       0.5725   \n",
       "4    2012      12.5550         5.0520        2.8840       0.9585       0.6125   \n",
       "5    2013      13.0510         5.1265        2.8310       0.9505       0.5420   \n",
       "6    2014      12.3805         4.9890        2.7145       0.9230       0.5390   \n",
       "7    2015      12.8715         5.1935        2.7720       0.9530       0.5900   \n",
       "8    2016      13.3550         5.0420        2.8950       0.9230       0.5340   \n",
       "9    2017      13.2915         5.0950        2.9355       0.9240       0.5585   \n",
       "\n",
       "   mean_turnovers  mean_threes_made  mean_fgm  mean_fga  mean_ftm  mean_fta  \n",
       "0          1.7035            0.8780    4.9095   10.5850    2.5990    3.3115  \n",
       "1          1.6965            0.8265    4.8530   10.4370    2.4600    3.1825  \n",
       "2          1.6790            0.8380    4.7955   10.3525    2.4955    3.2005  \n",
       "3          1.6805            0.8030    4.5925   10.1180    2.1955    2.8590  \n",
       "4          1.7410            0.8800    4.7285   10.3275    2.2150    2.8920  \n",
       "5          1.7375            0.9715    4.8545   10.5425    2.3790    3.1020  \n",
       "6          1.6315            0.9600    4.6260   10.1940    2.1725    2.8505  \n",
       "7          1.6785            1.0530    4.7645   10.4595    2.2840    2.9900  \n",
       "8          1.6195            1.2170    4.8980   10.6355    2.3385    2.9850  \n",
       "9          1.6825            1.3200    4.9175   10.6135    2.1395    2.7465  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = Player_ranker(df)\n",
    "test.get_category_dist()\n",
    "test.cat_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.assign_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_copy = test.value.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>player</th>\n",
       "      <th>value_tot</th>\n",
       "      <th>value_points</th>\n",
       "      <th>value_rebounds</th>\n",
       "      <th>value_assists</th>\n",
       "      <th>value_blocks</th>\n",
       "      <th>value_steals</th>\n",
       "      <th>value_turnovers</th>\n",
       "      <th>value_threes</th>\n",
       "      <th>value_fg</th>\n",
       "      <th>value_ft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>Andre Iguodala</td>\n",
       "      <td>1.569149</td>\n",
       "      <td>1.022902</td>\n",
       "      <td>0.233549</td>\n",
       "      <td>1.209232</td>\n",
       "      <td>-0.313073</td>\n",
       "      <td>1.720216</td>\n",
       "      <td>-1.392654</td>\n",
       "      <td>0.164932</td>\n",
       "      <td>0.201353</td>\n",
       "      <td>-1.277308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>Joe Johnson</td>\n",
       "      <td>2.248938</td>\n",
       "      <td>1.506499</td>\n",
       "      <td>-0.293101</td>\n",
       "      <td>1.449827</td>\n",
       "      <td>-0.683573</td>\n",
       "      <td>0.464584</td>\n",
       "      <td>-1.113145</td>\n",
       "      <td>1.381647</td>\n",
       "      <td>-1.036752</td>\n",
       "      <td>0.572951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>O.J. Mayo</td>\n",
       "      <td>0.491912</td>\n",
       "      <td>0.967102</td>\n",
       "      <td>-0.536170</td>\n",
       "      <td>0.198732</td>\n",
       "      <td>-0.683573</td>\n",
       "      <td>0.464584</td>\n",
       "      <td>-1.532409</td>\n",
       "      <td>1.246456</td>\n",
       "      <td>-0.633993</td>\n",
       "      <td>1.001183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008</td>\n",
       "      <td>Antawn Jamison</td>\n",
       "      <td>3.459954</td>\n",
       "      <td>1.655298</td>\n",
       "      <td>1.529918</td>\n",
       "      <td>-0.426816</td>\n",
       "      <td>-0.498323</td>\n",
       "      <td>0.715710</td>\n",
       "      <td>0.284401</td>\n",
       "      <td>0.705694</td>\n",
       "      <td>0.083254</td>\n",
       "      <td>-0.589183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>Raymond Felton</td>\n",
       "      <td>-0.135656</td>\n",
       "      <td>0.167306</td>\n",
       "      <td>-0.536170</td>\n",
       "      <td>1.882899</td>\n",
       "      <td>-0.313073</td>\n",
       "      <td>1.469090</td>\n",
       "      <td>-1.532409</td>\n",
       "      <td>-0.240639</td>\n",
       "      <td>-1.364914</td>\n",
       "      <td>0.332253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season          player  value_tot  value_points  value_rebounds  \\\n",
       "0    2008  Andre Iguodala   1.569149      1.022902        0.233549   \n",
       "1    2008     Joe Johnson   2.248938      1.506499       -0.293101   \n",
       "2    2008       O.J. Mayo   0.491912      0.967102       -0.536170   \n",
       "3    2008  Antawn Jamison   3.459954      1.655298        1.529918   \n",
       "4    2008  Raymond Felton  -0.135656      0.167306       -0.536170   \n",
       "\n",
       "   value_assists  value_blocks  value_steals  value_turnovers  value_threes  \\\n",
       "0       1.209232     -0.313073      1.720216        -1.392654      0.164932   \n",
       "1       1.449827     -0.683573      0.464584        -1.113145      1.381647   \n",
       "2       0.198732     -0.683573      0.464584        -1.532409      1.246456   \n",
       "3      -0.426816     -0.498323      0.715710         0.284401      0.705694   \n",
       "4       1.882899     -0.313073      1.469090        -1.532409     -0.240639   \n",
       "\n",
       "   value_fg  value_ft  \n",
       "0  0.201353 -1.277308  \n",
       "1 -1.036752  0.572951  \n",
       "2 -0.633993  1.001183  \n",
       "3  0.083254 -0.589183  \n",
       "4 -1.364914  0.332253  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy value data back into SQL\n",
    "engine = create_engine(\"postgresql://@localhost/nba_capstone\")\n",
    "\n",
    "value_copy.to_sql(name='value', con=engine, if_exists = 'replace', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "        DROP TABLE IF EXISTS player_value;\n",
    "        CREATE TABLE player_value AS\n",
    "        select ROW_NUMBER() OVER(PARTITION BY season ORDER BY value_tot DESC),* from value;\n",
    "        \n",
    "        DROP TABLE IF EXISTS value;\n",
    "        \n",
    "        select * from player_value;\n",
    "        \n",
    "        '''\n",
    "\n",
    "\n",
    "cur.execute(query)\n",
    "ranking_data = cur.fetchall()\n",
    "df_2 = pd.DataFrame(np.array(ranking_data))\n",
    "cols_value = ['playerrank']\n",
    "for item in (list(value_copy.columns)):\n",
    "    cols_value.append(item)\n",
    "cols_value\n",
    "df_2.columns=cols_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_2.columns:\n",
    "    if i!='player':\n",
    "        df_2[i]=pd.to_numeric(df_2[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_2.columns:\n",
    "    if i!='player':\n",
    "        df_2[i]=pd.to_numeric(df_2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playerrank</th>\n",
       "      <th>season</th>\n",
       "      <th>player</th>\n",
       "      <th>value_tot</th>\n",
       "      <th>value_points</th>\n",
       "      <th>value_rebounds</th>\n",
       "      <th>value_assists</th>\n",
       "      <th>value_blocks</th>\n",
       "      <th>value_steals</th>\n",
       "      <th>value_turnovers</th>\n",
       "      <th>value_threes</th>\n",
       "      <th>value_fg</th>\n",
       "      <th>value_ft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>Chris Paul</td>\n",
       "      <td>10.649584</td>\n",
       "      <td>1.766898</td>\n",
       "      <td>0.152526</td>\n",
       "      <td>3.952019</td>\n",
       "      <td>-0.868823</td>\n",
       "      <td>4.733733</td>\n",
       "      <td>-1.811918</td>\n",
       "      <td>-0.105449</td>\n",
       "      <td>1.195183</td>\n",
       "      <td>1.635414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>LeBron James</td>\n",
       "      <td>8.708530</td>\n",
       "      <td>2.808492</td>\n",
       "      <td>1.003268</td>\n",
       "      <td>2.123494</td>\n",
       "      <td>0.983678</td>\n",
       "      <td>1.971343</td>\n",
       "      <td>-1.811918</td>\n",
       "      <td>0.976075</td>\n",
       "      <td>0.888138</td>\n",
       "      <td>-0.234041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2008</td>\n",
       "      <td>Dwyane Wade</td>\n",
       "      <td>8.419529</td>\n",
       "      <td>3.143291</td>\n",
       "      <td>-0.050032</td>\n",
       "      <td>2.267852</td>\n",
       "      <td>1.354178</td>\n",
       "      <td>3.226975</td>\n",
       "      <td>-2.370936</td>\n",
       "      <td>0.300123</td>\n",
       "      <td>1.126183</td>\n",
       "      <td>-0.578103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "      <td>Danny Granger</td>\n",
       "      <td>6.463654</td>\n",
       "      <td>2.324895</td>\n",
       "      <td>-0.009520</td>\n",
       "      <td>-0.041864</td>\n",
       "      <td>1.539428</td>\n",
       "      <td>0.213457</td>\n",
       "      <td>-1.113145</td>\n",
       "      <td>2.463170</td>\n",
       "      <td>-0.678128</td>\n",
       "      <td>1.765360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2008</td>\n",
       "      <td>Dirk Nowitzki</td>\n",
       "      <td>6.094625</td>\n",
       "      <td>2.343495</td>\n",
       "      <td>1.327360</td>\n",
       "      <td>-0.186221</td>\n",
       "      <td>0.427928</td>\n",
       "      <td>-0.288795</td>\n",
       "      <td>-0.274618</td>\n",
       "      <td>-0.105449</td>\n",
       "      <td>0.611555</td>\n",
       "      <td>2.239370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   playerrank  season         player  value_tot  value_points  value_rebounds  \\\n",
       "0           1    2008     Chris Paul  10.649584      1.766898        0.152526   \n",
       "1           2    2008   LeBron James   8.708530      2.808492        1.003268   \n",
       "2           3    2008    Dwyane Wade   8.419529      3.143291       -0.050032   \n",
       "3           4    2008  Danny Granger   6.463654      2.324895       -0.009520   \n",
       "4           5    2008  Dirk Nowitzki   6.094625      2.343495        1.327360   \n",
       "\n",
       "   value_assists  value_blocks  value_steals  value_turnovers  value_threes  \\\n",
       "0       3.952019     -0.868823      4.733733        -1.811918     -0.105449   \n",
       "1       2.123494      0.983678      1.971343        -1.811918      0.976075   \n",
       "2       2.267852      1.354178      3.226975        -2.370936      0.300123   \n",
       "3      -0.041864      1.539428      0.213457        -1.113145      2.463170   \n",
       "4      -0.186221      0.427928     -0.288795        -0.274618     -0.105449   \n",
       "\n",
       "   value_fg  value_ft  \n",
       "0  1.195183  1.635414  \n",
       "1  0.888138 -0.234041  \n",
       "2  1.126183 -0.578103  \n",
       "3 -0.678128  1.765360  \n",
       "4  0.611555  2.239370  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playerrank</th>\n",
       "      <th>season</th>\n",
       "      <th>player</th>\n",
       "      <th>value_tot</th>\n",
       "      <th>value_points</th>\n",
       "      <th>value_rebounds</th>\n",
       "      <th>value_assists</th>\n",
       "      <th>value_blocks</th>\n",
       "      <th>value_steals</th>\n",
       "      <th>value_turnovers</th>\n",
       "      <th>value_threes</th>\n",
       "      <th>value_fg</th>\n",
       "      <th>value_ft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4219</th>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>Anthony Davis</td>\n",
       "      <td>13.069292</td>\n",
       "      <td>2.728406</td>\n",
       "      <td>2.327843</td>\n",
       "      <td>-0.323373</td>\n",
       "      <td>4.382346</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>-0.642579</td>\n",
       "      <td>-0.719758</td>\n",
       "      <td>2.572502</td>\n",
       "      <td>1.340136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4220</th>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>Stephen Curry</td>\n",
       "      <td>10.977767</td>\n",
       "      <td>2.415188</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>1.610250</td>\n",
       "      <td>-0.769567</td>\n",
       "      <td>1.647478</td>\n",
       "      <td>-1.635937</td>\n",
       "      <td>3.343394</td>\n",
       "      <td>1.073741</td>\n",
       "      <td>3.291282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4221</th>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>Kevin Durant</td>\n",
       "      <td>10.555627</td>\n",
       "      <td>2.415188</td>\n",
       "      <td>0.660945</td>\n",
       "      <td>1.254056</td>\n",
       "      <td>2.665042</td>\n",
       "      <td>-0.545910</td>\n",
       "      <td>-1.635937</td>\n",
       "      <td>1.369863</td>\n",
       "      <td>1.809299</td>\n",
       "      <td>2.563082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4222</th>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>James Harden</td>\n",
       "      <td>10.522310</td>\n",
       "      <td>3.152171</td>\n",
       "      <td>0.118234</td>\n",
       "      <td>2.984140</td>\n",
       "      <td>0.303748</td>\n",
       "      <td>2.134898</td>\n",
       "      <td>-3.374314</td>\n",
       "      <td>2.762944</td>\n",
       "      <td>-0.589500</td>\n",
       "      <td>3.029989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4223</th>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "      <td>Karl-Anthony Towns</td>\n",
       "      <td>9.046572</td>\n",
       "      <td>1.475533</td>\n",
       "      <td>2.793024</td>\n",
       "      <td>-0.272488</td>\n",
       "      <td>1.806390</td>\n",
       "      <td>-0.302200</td>\n",
       "      <td>-0.270069</td>\n",
       "      <td>0.208962</td>\n",
       "      <td>2.213129</td>\n",
       "      <td>1.394291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4224</th>\n",
       "      <td>6</td>\n",
       "      <td>2017</td>\n",
       "      <td>LeBron James</td>\n",
       "      <td>8.050018</td>\n",
       "      <td>2.617858</td>\n",
       "      <td>1.358716</td>\n",
       "      <td>3.136795</td>\n",
       "      <td>0.733074</td>\n",
       "      <td>1.160059</td>\n",
       "      <td>-3.125975</td>\n",
       "      <td>0.557232</td>\n",
       "      <td>2.935558</td>\n",
       "      <td>-1.323300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4225</th>\n",
       "      <td>7</td>\n",
       "      <td>2017</td>\n",
       "      <td>Giannis Antetokounmpo</td>\n",
       "      <td>7.982516</td>\n",
       "      <td>2.507311</td>\n",
       "      <td>1.901427</td>\n",
       "      <td>0.948747</td>\n",
       "      <td>1.806390</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>-1.635937</td>\n",
       "      <td>-0.835849</td>\n",
       "      <td>2.328774</td>\n",
       "      <td>-0.442116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4226</th>\n",
       "      <td>8</td>\n",
       "      <td>2017</td>\n",
       "      <td>Damian Lillard</td>\n",
       "      <td>7.758411</td>\n",
       "      <td>2.507311</td>\n",
       "      <td>-0.230652</td>\n",
       "      <td>1.864674</td>\n",
       "      <td>-0.340241</td>\n",
       "      <td>0.428929</td>\n",
       "      <td>-1.387598</td>\n",
       "      <td>2.066403</td>\n",
       "      <td>-0.920536</td>\n",
       "      <td>3.770119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4227</th>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "      <td>Chris Paul</td>\n",
       "      <td>7.259998</td>\n",
       "      <td>0.978069</td>\n",
       "      <td>0.118234</td>\n",
       "      <td>2.526177</td>\n",
       "      <td>-0.769567</td>\n",
       "      <td>1.891188</td>\n",
       "      <td>-0.642579</td>\n",
       "      <td>1.369863</td>\n",
       "      <td>-0.176916</td>\n",
       "      <td>1.965529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4228</th>\n",
       "      <td>10</td>\n",
       "      <td>2017</td>\n",
       "      <td>Jimmy Butler</td>\n",
       "      <td>7.194467</td>\n",
       "      <td>1.641355</td>\n",
       "      <td>0.079468</td>\n",
       "      <td>0.999632</td>\n",
       "      <td>-0.340241</td>\n",
       "      <td>2.622318</td>\n",
       "      <td>-0.145900</td>\n",
       "      <td>-0.139308</td>\n",
       "      <td>0.324360</td>\n",
       "      <td>2.152782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4229</th>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>Victor Oladipo</td>\n",
       "      <td>6.742591</td>\n",
       "      <td>1.807176</td>\n",
       "      <td>0.040703</td>\n",
       "      <td>0.694323</td>\n",
       "      <td>0.518411</td>\n",
       "      <td>3.597157</td>\n",
       "      <td>-1.511767</td>\n",
       "      <td>0.905503</td>\n",
       "      <td>0.389094</td>\n",
       "      <td>0.301991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4230</th>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>DeMarcus Cousins</td>\n",
       "      <td>6.513379</td>\n",
       "      <td>2.194092</td>\n",
       "      <td>3.025615</td>\n",
       "      <td>1.254056</td>\n",
       "      <td>2.235716</td>\n",
       "      <td>1.647478</td>\n",
       "      <td>-4.119333</td>\n",
       "      <td>1.021593</td>\n",
       "      <td>0.301785</td>\n",
       "      <td>-1.047624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4231</th>\n",
       "      <td>13</td>\n",
       "      <td>2017</td>\n",
       "      <td>Nikola Jokic</td>\n",
       "      <td>6.424866</td>\n",
       "      <td>0.959645</td>\n",
       "      <td>2.172783</td>\n",
       "      <td>1.610250</td>\n",
       "      <td>0.518411</td>\n",
       "      <td>0.672639</td>\n",
       "      <td>-1.387598</td>\n",
       "      <td>0.208962</td>\n",
       "      <td>0.838766</td>\n",
       "      <td>0.831007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4232</th>\n",
       "      <td>14</td>\n",
       "      <td>2017</td>\n",
       "      <td>Kyrie Irving</td>\n",
       "      <td>6.159878</td>\n",
       "      <td>2.046696</td>\n",
       "      <td>-0.502008</td>\n",
       "      <td>1.101402</td>\n",
       "      <td>-0.554904</td>\n",
       "      <td>0.428929</td>\n",
       "      <td>-0.766749</td>\n",
       "      <td>1.718133</td>\n",
       "      <td>0.968233</td>\n",
       "      <td>1.720144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4233</th>\n",
       "      <td>15</td>\n",
       "      <td>2017</td>\n",
       "      <td>Andre Ingram</td>\n",
       "      <td>5.581832</td>\n",
       "      <td>-0.237954</td>\n",
       "      <td>-0.812129</td>\n",
       "      <td>0.287245</td>\n",
       "      <td>2.021053</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>0.226610</td>\n",
       "      <td>1.369863</td>\n",
       "      <td>0.116338</td>\n",
       "      <td>1.207037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234</th>\n",
       "      <td>16</td>\n",
       "      <td>2017</td>\n",
       "      <td>LaMarcus Aldridge</td>\n",
       "      <td>5.370052</td>\n",
       "      <td>1.807176</td>\n",
       "      <td>1.319951</td>\n",
       "      <td>-0.476027</td>\n",
       "      <td>1.377064</td>\n",
       "      <td>-0.789620</td>\n",
       "      <td>0.226610</td>\n",
       "      <td>-1.068029</td>\n",
       "      <td>1.620860</td>\n",
       "      <td>1.352068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4235</th>\n",
       "      <td>17</td>\n",
       "      <td>2017</td>\n",
       "      <td>MarShon Brooks</td>\n",
       "      <td>5.131062</td>\n",
       "      <td>1.254438</td>\n",
       "      <td>-0.812129</td>\n",
       "      <td>0.338130</td>\n",
       "      <td>-0.340241</td>\n",
       "      <td>1.647478</td>\n",
       "      <td>-0.766749</td>\n",
       "      <td>1.602043</td>\n",
       "      <td>1.009007</td>\n",
       "      <td>1.199083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4236</th>\n",
       "      <td>18</td>\n",
       "      <td>2017</td>\n",
       "      <td>Paul George</td>\n",
       "      <td>5.126899</td>\n",
       "      <td>1.586081</td>\n",
       "      <td>0.234529</td>\n",
       "      <td>0.185475</td>\n",
       "      <td>-0.125578</td>\n",
       "      <td>2.622318</td>\n",
       "      <td>-1.263428</td>\n",
       "      <td>2.066403</td>\n",
       "      <td>-1.086400</td>\n",
       "      <td>0.907499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4237</th>\n",
       "      <td>19</td>\n",
       "      <td>2017</td>\n",
       "      <td>Kristaps Porzingis</td>\n",
       "      <td>4.816889</td>\n",
       "      <td>1.733478</td>\n",
       "      <td>0.583415</td>\n",
       "      <td>-0.883106</td>\n",
       "      <td>3.953020</td>\n",
       "      <td>-0.302200</td>\n",
       "      <td>-0.270069</td>\n",
       "      <td>0.673322</td>\n",
       "      <td>-0.888515</td>\n",
       "      <td>0.217545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4238</th>\n",
       "      <td>20</td>\n",
       "      <td>2017</td>\n",
       "      <td>Jrue Holiday</td>\n",
       "      <td>4.397228</td>\n",
       "      <td>1.051768</td>\n",
       "      <td>-0.230652</td>\n",
       "      <td>1.559365</td>\n",
       "      <td>0.518411</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>-1.139258</td>\n",
       "      <td>0.208962</td>\n",
       "      <td>0.875856</td>\n",
       "      <td>0.149007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4239</th>\n",
       "      <td>21</td>\n",
       "      <td>2017</td>\n",
       "      <td>Khris Middleton</td>\n",
       "      <td>4.231094</td>\n",
       "      <td>1.254438</td>\n",
       "      <td>0.040703</td>\n",
       "      <td>0.541669</td>\n",
       "      <td>-0.554904</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>-0.766749</td>\n",
       "      <td>0.557232</td>\n",
       "      <td>0.034790</td>\n",
       "      <td>1.720144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4240</th>\n",
       "      <td>22</td>\n",
       "      <td>2017</td>\n",
       "      <td>Nikola Vucevic</td>\n",
       "      <td>4.156660</td>\n",
       "      <td>0.591153</td>\n",
       "      <td>1.591307</td>\n",
       "      <td>0.236360</td>\n",
       "      <td>1.162400</td>\n",
       "      <td>0.185219</td>\n",
       "      <td>-0.270069</td>\n",
       "      <td>-0.255398</td>\n",
       "      <td>0.356381</td>\n",
       "      <td>0.559307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4241</th>\n",
       "      <td>23</td>\n",
       "      <td>2017</td>\n",
       "      <td>Kyle Lowry</td>\n",
       "      <td>4.141570</td>\n",
       "      <td>0.535879</td>\n",
       "      <td>0.195764</td>\n",
       "      <td>2.017329</td>\n",
       "      <td>-0.769567</td>\n",
       "      <td>0.428929</td>\n",
       "      <td>-0.766749</td>\n",
       "      <td>2.066403</td>\n",
       "      <td>-0.765502</td>\n",
       "      <td>1.199083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4242</th>\n",
       "      <td>24</td>\n",
       "      <td>2017</td>\n",
       "      <td>Otto Porter</td>\n",
       "      <td>4.136911</td>\n",
       "      <td>0.259510</td>\n",
       "      <td>0.505884</td>\n",
       "      <td>-0.476027</td>\n",
       "      <td>-0.125578</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>0.847459</td>\n",
       "      <td>0.557232</td>\n",
       "      <td>0.888985</td>\n",
       "      <td>0.275676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4243</th>\n",
       "      <td>25</td>\n",
       "      <td>2017</td>\n",
       "      <td>Kawhi Leonard</td>\n",
       "      <td>4.001655</td>\n",
       "      <td>0.535879</td>\n",
       "      <td>-0.153122</td>\n",
       "      <td>-0.323373</td>\n",
       "      <td>0.947737</td>\n",
       "      <td>2.622318</td>\n",
       "      <td>-0.145900</td>\n",
       "      <td>-0.139308</td>\n",
       "      <td>0.190517</td>\n",
       "      <td>0.466907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4244</th>\n",
       "      <td>26</td>\n",
       "      <td>2017</td>\n",
       "      <td>Kevin Love</td>\n",
       "      <td>3.988737</td>\n",
       "      <td>0.793824</td>\n",
       "      <td>1.630072</td>\n",
       "      <td>-0.628682</td>\n",
       "      <td>-0.340241</td>\n",
       "      <td>-0.545910</td>\n",
       "      <td>0.226610</td>\n",
       "      <td>1.137683</td>\n",
       "      <td>-0.085231</td>\n",
       "      <td>1.800614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4245</th>\n",
       "      <td>27</td>\n",
       "      <td>2017</td>\n",
       "      <td>Andre Drummond</td>\n",
       "      <td>3.805188</td>\n",
       "      <td>0.314784</td>\n",
       "      <td>4.227332</td>\n",
       "      <td>0.032821</td>\n",
       "      <td>2.235716</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>-1.139258</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>1.440481</td>\n",
       "      <td>-3.178068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4246</th>\n",
       "      <td>28</td>\n",
       "      <td>2017</td>\n",
       "      <td>Russell Westbrook</td>\n",
       "      <td>3.763264</td>\n",
       "      <td>2.230942</td>\n",
       "      <td>1.940192</td>\n",
       "      <td>3.747412</td>\n",
       "      <td>-0.554904</td>\n",
       "      <td>2.134898</td>\n",
       "      <td>-3.870994</td>\n",
       "      <td>-0.139308</td>\n",
       "      <td>-0.520390</td>\n",
       "      <td>-1.204585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4247</th>\n",
       "      <td>29</td>\n",
       "      <td>2017</td>\n",
       "      <td>Kemba Walker</td>\n",
       "      <td>3.725170</td>\n",
       "      <td>1.622930</td>\n",
       "      <td>-0.773363</td>\n",
       "      <td>1.355826</td>\n",
       "      <td>-0.554904</td>\n",
       "      <td>0.428929</td>\n",
       "      <td>-0.642579</td>\n",
       "      <td>1.834223</td>\n",
       "      <td>-0.897960</td>\n",
       "      <td>1.352068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4248</th>\n",
       "      <td>30</td>\n",
       "      <td>2017</td>\n",
       "      <td>Eric Bledsoe</td>\n",
       "      <td>3.653643</td>\n",
       "      <td>0.830673</td>\n",
       "      <td>-0.463243</td>\n",
       "      <td>1.101402</td>\n",
       "      <td>0.089085</td>\n",
       "      <td>2.622318</td>\n",
       "      <td>-1.511767</td>\n",
       "      <td>0.441142</td>\n",
       "      <td>0.360757</td>\n",
       "      <td>0.183276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4729</th>\n",
       "      <td>511</td>\n",
       "      <td>2017</td>\n",
       "      <td>Darrun Hilliard</td>\n",
       "      <td>-8.567256</td>\n",
       "      <td>-2.246234</td>\n",
       "      <td>-1.781256</td>\n",
       "      <td>-1.086645</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.008169</td>\n",
       "      <td>1.716648</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.468564</td>\n",
       "      <td>0.038246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4730</th>\n",
       "      <td>512</td>\n",
       "      <td>2017</td>\n",
       "      <td>Tim Quarterman</td>\n",
       "      <td>-8.645561</td>\n",
       "      <td>-2.209385</td>\n",
       "      <td>-1.587430</td>\n",
       "      <td>-1.341069</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>1.219968</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.307768</td>\n",
       "      <td>0.563284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4731</th>\n",
       "      <td>513</td>\n",
       "      <td>2017</td>\n",
       "      <td>Demetrius Jackson</td>\n",
       "      <td>-8.660268</td>\n",
       "      <td>-2.319932</td>\n",
       "      <td>-1.626195</td>\n",
       "      <td>-1.290185</td>\n",
       "      <td>-0.984230</td>\n",
       "      <td>-1.520749</td>\n",
       "      <td>1.095798</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.482386</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4732</th>\n",
       "      <td>514</td>\n",
       "      <td>2017</td>\n",
       "      <td>Markel Brown</td>\n",
       "      <td>-8.715761</td>\n",
       "      <td>-2.209385</td>\n",
       "      <td>-1.471135</td>\n",
       "      <td>-1.239300</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>1.468308</td>\n",
       "      <td>-1.184119</td>\n",
       "      <td>-0.629359</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4733</th>\n",
       "      <td>515</td>\n",
       "      <td>2017</td>\n",
       "      <td>Josh Smith</td>\n",
       "      <td>-8.748490</td>\n",
       "      <td>-2.319932</td>\n",
       "      <td>-1.471135</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.569694</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4734</th>\n",
       "      <td>516</td>\n",
       "      <td>2017</td>\n",
       "      <td>Erik McCree</td>\n",
       "      <td>-8.773341</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.858786</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-1.520749</td>\n",
       "      <td>1.716648</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.436543</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4735</th>\n",
       "      <td>517</td>\n",
       "      <td>2017</td>\n",
       "      <td>Xavier Munford</td>\n",
       "      <td>-8.789856</td>\n",
       "      <td>-2.356782</td>\n",
       "      <td>-1.897551</td>\n",
       "      <td>-1.137530</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-1.764459</td>\n",
       "      <td>1.716648</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.496208</td>\n",
       "      <td>-0.122692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4736</th>\n",
       "      <td>518</td>\n",
       "      <td>2017</td>\n",
       "      <td>Tyler Lydon</td>\n",
       "      <td>-8.811713</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.975081</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4737</th>\n",
       "      <td>519</td>\n",
       "      <td>2017</td>\n",
       "      <td>Trey McKinney-Jones</td>\n",
       "      <td>-8.811713</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.975081</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4738</th>\n",
       "      <td>520</td>\n",
       "      <td>2017</td>\n",
       "      <td>Xavier Rathan-Mayes</td>\n",
       "      <td>-8.814577</td>\n",
       "      <td>-1.380278</td>\n",
       "      <td>-1.587430</td>\n",
       "      <td>0.338130</td>\n",
       "      <td>0.089085</td>\n",
       "      <td>0.672639</td>\n",
       "      <td>-0.642579</td>\n",
       "      <td>-1.300209</td>\n",
       "      <td>-2.811382</td>\n",
       "      <td>-2.192553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4739</th>\n",
       "      <td>521</td>\n",
       "      <td>2017</td>\n",
       "      <td>Matt Williams</td>\n",
       "      <td>-8.833537</td>\n",
       "      <td>-2.135687</td>\n",
       "      <td>-1.858786</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>1.716648</td>\n",
       "      <td>-1.184119</td>\n",
       "      <td>-0.427098</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4740</th>\n",
       "      <td>522</td>\n",
       "      <td>2017</td>\n",
       "      <td>Cole Aldrich</td>\n",
       "      <td>-8.856290</td>\n",
       "      <td>-2.338357</td>\n",
       "      <td>-1.703725</td>\n",
       "      <td>-1.442839</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.008169</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.234282</td>\n",
       "      <td>-0.486792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4741</th>\n",
       "      <td>523</td>\n",
       "      <td>2017</td>\n",
       "      <td>Nicolas Brussino</td>\n",
       "      <td>-8.938136</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.664960</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.436543</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4742</th>\n",
       "      <td>524</td>\n",
       "      <td>2017</td>\n",
       "      <td>PJ Dozier</td>\n",
       "      <td>-8.985381</td>\n",
       "      <td>-2.264659</td>\n",
       "      <td>-1.781256</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>1.468308</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>0.069110</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4743</th>\n",
       "      <td>525</td>\n",
       "      <td>2017</td>\n",
       "      <td>Omer Asik</td>\n",
       "      <td>-9.030298</td>\n",
       "      <td>-2.209385</td>\n",
       "      <td>-0.967189</td>\n",
       "      <td>-1.442839</td>\n",
       "      <td>-0.984230</td>\n",
       "      <td>-2.008169</td>\n",
       "      <td>1.592478</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.018199</td>\n",
       "      <td>-1.460376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4744</th>\n",
       "      <td>526</td>\n",
       "      <td>2017</td>\n",
       "      <td>London Perrantes</td>\n",
       "      <td>-9.069214</td>\n",
       "      <td>-2.356782</td>\n",
       "      <td>-1.858786</td>\n",
       "      <td>-1.290185</td>\n",
       "      <td>-0.984230</td>\n",
       "      <td>-2.008169</td>\n",
       "      <td>1.964987</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.597338</td>\n",
       "      <td>-0.406323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4745</th>\n",
       "      <td>527</td>\n",
       "      <td>2017</td>\n",
       "      <td>Jacob Pullen</td>\n",
       "      <td>-9.101093</td>\n",
       "      <td>-2.319932</td>\n",
       "      <td>-1.975081</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>1.716648</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.045843</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4746</th>\n",
       "      <td>528</td>\n",
       "      <td>2017</td>\n",
       "      <td>Charles Cooke</td>\n",
       "      <td>-9.142223</td>\n",
       "      <td>-2.356782</td>\n",
       "      <td>-1.897551</td>\n",
       "      <td>-1.442839</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.008169</td>\n",
       "      <td>1.964987</td>\n",
       "      <td>-1.416299</td>\n",
       "      <td>-0.583516</td>\n",
       "      <td>-0.203161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4747</th>\n",
       "      <td>529</td>\n",
       "      <td>2017</td>\n",
       "      <td>Nate Wolters</td>\n",
       "      <td>-9.152010</td>\n",
       "      <td>-2.375206</td>\n",
       "      <td>-1.820021</td>\n",
       "      <td>-1.391954</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.670825</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4748</th>\n",
       "      <td>530</td>\n",
       "      <td>2017</td>\n",
       "      <td>Derrick Williams</td>\n",
       "      <td>-9.237618</td>\n",
       "      <td>-2.264659</td>\n",
       "      <td>-1.781256</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.803976</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4749</th>\n",
       "      <td>531</td>\n",
       "      <td>2017</td>\n",
       "      <td>Josh McRoberts</td>\n",
       "      <td>-9.248257</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.975081</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.436543</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4750</th>\n",
       "      <td>532</td>\n",
       "      <td>2017</td>\n",
       "      <td>Nick Collison</td>\n",
       "      <td>-9.288480</td>\n",
       "      <td>-2.061988</td>\n",
       "      <td>-1.471135</td>\n",
       "      <td>-1.341069</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>1.468308</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>0.560941</td>\n",
       "      <td>-1.460376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4751</th>\n",
       "      <td>533</td>\n",
       "      <td>2017</td>\n",
       "      <td>Chris Boucher</td>\n",
       "      <td>-9.297149</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.587430</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.873086</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4752</th>\n",
       "      <td>534</td>\n",
       "      <td>2017</td>\n",
       "      <td>Kyle Singler</td>\n",
       "      <td>-9.322633</td>\n",
       "      <td>-2.098837</td>\n",
       "      <td>-1.664960</td>\n",
       "      <td>-1.391954</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.008169</td>\n",
       "      <td>1.716648</td>\n",
       "      <td>-1.300209</td>\n",
       "      <td>-0.440920</td>\n",
       "      <td>-0.935338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4753</th>\n",
       "      <td>535</td>\n",
       "      <td>2017</td>\n",
       "      <td>Vander Blue</td>\n",
       "      <td>-9.478457</td>\n",
       "      <td>-2.338357</td>\n",
       "      <td>-1.897551</td>\n",
       "      <td>-1.188415</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-1.764459</td>\n",
       "      <td>1.344138</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.496208</td>\n",
       "      <td>-0.406323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4754</th>\n",
       "      <td>536</td>\n",
       "      <td>2017</td>\n",
       "      <td>Aaron Jackson</td>\n",
       "      <td>-9.982955</td>\n",
       "      <td>-0.974937</td>\n",
       "      <td>-0.812129</td>\n",
       "      <td>-0.984876</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>0.847459</td>\n",
       "      <td>-0.371488</td>\n",
       "      <td>-2.204598</td>\n",
       "      <td>-2.031614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4755</th>\n",
       "      <td>537</td>\n",
       "      <td>2017</td>\n",
       "      <td>Luis Montero</td>\n",
       "      <td>-10.102304</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.587430</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>0.847459</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.436543</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4756</th>\n",
       "      <td>538</td>\n",
       "      <td>2017</td>\n",
       "      <td>Chinanu Onuaku</td>\n",
       "      <td>-10.337018</td>\n",
       "      <td>-1.711921</td>\n",
       "      <td>-0.424478</td>\n",
       "      <td>-0.984876</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>-1.635937</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.596646</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4757</th>\n",
       "      <td>539</td>\n",
       "      <td>2017</td>\n",
       "      <td>Mindaugas Kuzminskas</td>\n",
       "      <td>-10.557886</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.975081</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-1.746172</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4758</th>\n",
       "      <td>540</td>\n",
       "      <td>2017</td>\n",
       "      <td>Scotty Hopson</td>\n",
       "      <td>-12.265018</td>\n",
       "      <td>-2.264659</td>\n",
       "      <td>-1.975081</td>\n",
       "      <td>-0.984876</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>0.847459</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.873086</td>\n",
       "      <td>-2.031614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      playerrank  season                 player  value_tot  value_points  \\\n",
       "4219           1    2017          Anthony Davis  13.069292      2.728406   \n",
       "4220           2    2017          Stephen Curry  10.977767      2.415188   \n",
       "4221           3    2017           Kevin Durant  10.555627      2.415188   \n",
       "4222           4    2017           James Harden  10.522310      3.152171   \n",
       "4223           5    2017     Karl-Anthony Towns   9.046572      1.475533   \n",
       "4224           6    2017           LeBron James   8.050018      2.617858   \n",
       "4225           7    2017  Giannis Antetokounmpo   7.982516      2.507311   \n",
       "4226           8    2017         Damian Lillard   7.758411      2.507311   \n",
       "4227           9    2017             Chris Paul   7.259998      0.978069   \n",
       "4228          10    2017           Jimmy Butler   7.194467      1.641355   \n",
       "4229          11    2017         Victor Oladipo   6.742591      1.807176   \n",
       "4230          12    2017       DeMarcus Cousins   6.513379      2.194092   \n",
       "4231          13    2017           Nikola Jokic   6.424866      0.959645   \n",
       "4232          14    2017           Kyrie Irving   6.159878      2.046696   \n",
       "4233          15    2017           Andre Ingram   5.581832     -0.237954   \n",
       "4234          16    2017      LaMarcus Aldridge   5.370052      1.807176   \n",
       "4235          17    2017         MarShon Brooks   5.131062      1.254438   \n",
       "4236          18    2017            Paul George   5.126899      1.586081   \n",
       "4237          19    2017     Kristaps Porzingis   4.816889      1.733478   \n",
       "4238          20    2017           Jrue Holiday   4.397228      1.051768   \n",
       "4239          21    2017        Khris Middleton   4.231094      1.254438   \n",
       "4240          22    2017         Nikola Vucevic   4.156660      0.591153   \n",
       "4241          23    2017             Kyle Lowry   4.141570      0.535879   \n",
       "4242          24    2017            Otto Porter   4.136911      0.259510   \n",
       "4243          25    2017          Kawhi Leonard   4.001655      0.535879   \n",
       "4244          26    2017             Kevin Love   3.988737      0.793824   \n",
       "4245          27    2017         Andre Drummond   3.805188      0.314784   \n",
       "4246          28    2017      Russell Westbrook   3.763264      2.230942   \n",
       "4247          29    2017           Kemba Walker   3.725170      1.622930   \n",
       "4248          30    2017           Eric Bledsoe   3.653643      0.830673   \n",
       "...          ...     ...                    ...        ...           ...   \n",
       "4729         511    2017        Darrun Hilliard  -8.567256     -2.246234   \n",
       "4730         512    2017         Tim Quarterman  -8.645561     -2.209385   \n",
       "4731         513    2017      Demetrius Jackson  -8.660268     -2.319932   \n",
       "4732         514    2017           Markel Brown  -8.715761     -2.209385   \n",
       "4733         515    2017             Josh Smith  -8.748490     -2.319932   \n",
       "4734         516    2017            Erik McCree  -8.773341     -2.448905   \n",
       "4735         517    2017         Xavier Munford  -8.789856     -2.356782   \n",
       "4736         518    2017            Tyler Lydon  -8.811713     -2.448905   \n",
       "4737         519    2017    Trey McKinney-Jones  -8.811713     -2.448905   \n",
       "4738         520    2017    Xavier Rathan-Mayes  -8.814577     -1.380278   \n",
       "4739         521    2017          Matt Williams  -8.833537     -2.135687   \n",
       "4740         522    2017           Cole Aldrich  -8.856290     -2.338357   \n",
       "4741         523    2017       Nicolas Brussino  -8.938136     -2.448905   \n",
       "4742         524    2017              PJ Dozier  -8.985381     -2.264659   \n",
       "4743         525    2017              Omer Asik  -9.030298     -2.209385   \n",
       "4744         526    2017       London Perrantes  -9.069214     -2.356782   \n",
       "4745         527    2017           Jacob Pullen  -9.101093     -2.319932   \n",
       "4746         528    2017          Charles Cooke  -9.142223     -2.356782   \n",
       "4747         529    2017           Nate Wolters  -9.152010     -2.375206   \n",
       "4748         530    2017       Derrick Williams  -9.237618     -2.264659   \n",
       "4749         531    2017         Josh McRoberts  -9.248257     -2.448905   \n",
       "4750         532    2017          Nick Collison  -9.288480     -2.061988   \n",
       "4751         533    2017          Chris Boucher  -9.297149     -2.448905   \n",
       "4752         534    2017           Kyle Singler  -9.322633     -2.098837   \n",
       "4753         535    2017            Vander Blue  -9.478457     -2.338357   \n",
       "4754         536    2017          Aaron Jackson  -9.982955     -0.974937   \n",
       "4755         537    2017           Luis Montero -10.102304     -2.448905   \n",
       "4756         538    2017         Chinanu Onuaku -10.337018     -1.711921   \n",
       "4757         539    2017   Mindaugas Kuzminskas -10.557886     -2.448905   \n",
       "4758         540    2017          Scotty Hopson -12.265018     -2.264659   \n",
       "\n",
       "      value_rebounds  value_assists  value_blocks  value_steals  \\\n",
       "4219        2.327843      -0.323373      4.382346      1.403769   \n",
       "4220        0.001938       1.610250     -0.769567      1.647478   \n",
       "4221        0.660945       1.254056      2.665042     -0.545910   \n",
       "4222        0.118234       2.984140      0.303748      2.134898   \n",
       "4223        2.793024      -0.272488      1.806390     -0.302200   \n",
       "4224        1.358716       3.136795      0.733074      1.160059   \n",
       "4225        1.901427       0.948747      1.806390      1.403769   \n",
       "4226       -0.230652       1.864674     -0.340241      0.428929   \n",
       "4227        0.118234       2.526177     -0.769567      1.891188   \n",
       "4228        0.079468       0.999632     -0.340241      2.622318   \n",
       "4229        0.040703       0.694323      0.518411      3.597157   \n",
       "4230        3.025615       1.254056      2.235716      1.647478   \n",
       "4231        2.172783       1.610250      0.518411      0.672639   \n",
       "4232       -0.502008       1.101402     -0.554904      0.428929   \n",
       "4233       -0.812129       0.287245      2.021053      1.403769   \n",
       "4234        1.319951      -0.476027      1.377064     -0.789620   \n",
       "4235       -0.812129       0.338130     -0.340241      1.647478   \n",
       "4236        0.234529       0.185475     -0.125578      2.622318   \n",
       "4237        0.583415      -0.883106      3.953020     -0.302200   \n",
       "4238       -0.230652       1.559365      0.518411      1.403769   \n",
       "4239        0.040703       0.541669     -0.554904      1.403769   \n",
       "4240        1.591307       0.236360      1.162400      0.185219   \n",
       "4241        0.195764       2.017329     -0.769567      0.428929   \n",
       "4242        0.505884      -0.476027     -0.125578      1.403769   \n",
       "4243       -0.153122      -0.323373      0.947737      2.622318   \n",
       "4244        1.630072      -0.628682     -0.340241     -0.545910   \n",
       "4245        4.227332       0.032821      2.235716      1.403769   \n",
       "4246        1.940192       3.747412     -0.554904      2.134898   \n",
       "4247       -0.773363       1.355826     -0.554904      0.428929   \n",
       "4248       -0.463243       1.101402      0.089085      2.622318   \n",
       "...              ...            ...           ...           ...   \n",
       "4729       -1.781256      -1.086645     -1.198893     -2.008169   \n",
       "4730       -1.587430      -1.341069     -1.198893     -2.251879   \n",
       "4731       -1.626195      -1.290185     -0.984230     -1.520749   \n",
       "4732       -1.471135      -1.239300     -1.198893     -2.251879   \n",
       "4733       -1.471135      -1.493724     -1.198893     -2.251879   \n",
       "4734       -1.858786      -1.493724     -1.198893     -1.520749   \n",
       "4735       -1.897551      -1.137530     -1.198893     -1.764459   \n",
       "4736       -1.975081      -1.493724     -1.198893     -2.251879   \n",
       "4737       -1.975081      -1.493724     -1.198893     -2.251879   \n",
       "4738       -1.587430       0.338130      0.089085      0.672639   \n",
       "4739       -1.858786      -1.493724     -1.198893     -2.251879   \n",
       "4740       -1.703725      -1.442839     -1.198893     -2.008169   \n",
       "4741       -1.664960      -1.493724     -1.198893     -2.251879   \n",
       "4742       -1.781256      -1.493724     -1.198893     -2.251879   \n",
       "4743       -0.967189      -1.442839     -0.984230     -2.008169   \n",
       "4744       -1.858786      -1.290185     -0.984230     -2.008169   \n",
       "4745       -1.975081      -1.493724     -1.198893     -2.251879   \n",
       "4746       -1.897551      -1.442839     -1.198893     -2.008169   \n",
       "4747       -1.820021      -1.391954     -1.198893     -2.251879   \n",
       "4748       -1.781256      -1.493724     -1.198893     -2.251879   \n",
       "4749       -1.975081      -1.493724     -1.198893     -2.251879   \n",
       "4750       -1.471135      -1.341069     -1.198893     -2.251879   \n",
       "4751       -1.587430      -1.493724     -1.198893     -2.251879   \n",
       "4752       -1.664960      -1.391954     -1.198893     -2.008169   \n",
       "4753       -1.897551      -1.188415     -1.198893     -1.764459   \n",
       "4754       -0.812129      -0.984876     -1.198893     -2.251879   \n",
       "4755       -1.587430      -1.493724     -1.198893     -2.251879   \n",
       "4756       -0.424478      -0.984876     -1.198893     -2.251879   \n",
       "4757       -1.975081      -1.493724     -1.198893     -2.251879   \n",
       "4758       -1.975081      -0.984876     -1.198893     -2.251879   \n",
       "\n",
       "      value_turnovers  value_threes  value_fg  value_ft  \n",
       "4219        -0.642579     -0.719758  2.572502  1.340136  \n",
       "4220        -1.635937      3.343394  1.073741  3.291282  \n",
       "4221        -1.635937      1.369863  1.809299  2.563082  \n",
       "4222        -3.374314      2.762944 -0.589500  3.029989  \n",
       "4223        -0.270069      0.208962  2.213129  1.394291  \n",
       "4224        -3.125975      0.557232  2.935558 -1.323300  \n",
       "4225        -1.635937     -0.835849  2.328774 -0.442116  \n",
       "4226        -1.387598      2.066403 -0.920536  3.770119  \n",
       "4227        -0.642579      1.369863 -0.176916  1.965529  \n",
       "4228        -0.145900     -0.139308  0.324360  2.152782  \n",
       "4229        -1.511767      0.905503  0.389094  0.301991  \n",
       "4230        -4.119333      1.021593  0.301785 -1.047624  \n",
       "4231        -1.387598      0.208962  0.838766  0.831007  \n",
       "4232        -0.766749      1.718133  0.968233  1.720144  \n",
       "4233         0.226610      1.369863  0.116338  1.207037  \n",
       "4234         0.226610     -1.068029  1.620860  1.352068  \n",
       "4235        -0.766749      1.602043  1.009007  1.199083  \n",
       "4236        -1.263428      2.066403 -1.086400  0.907499  \n",
       "4237        -0.270069      0.673322 -0.888515  0.217545  \n",
       "4238        -1.139258      0.208962  0.875856  0.149007  \n",
       "4239        -0.766749      0.557232  0.034790  1.720144  \n",
       "4240        -0.270069     -0.255398  0.356381  0.559307  \n",
       "4241        -0.766749      2.066403 -0.765502  1.199083  \n",
       "4242         0.847459      0.557232  0.888985  0.275676  \n",
       "4243        -0.145900     -0.139308  0.190517  0.466907  \n",
       "4244         0.226610      1.137683 -0.085231  1.800614  \n",
       "4245        -1.139258     -1.532389  1.440481 -3.178068  \n",
       "4246        -3.870994     -0.139308 -0.520390 -1.204585  \n",
       "4247        -0.642579      1.834223 -0.897960  1.352068  \n",
       "4248        -1.511767      0.441142  0.360757  0.183276  \n",
       "...               ...           ...       ...       ...  \n",
       "4729         1.716648     -1.532389 -0.468564  0.038246  \n",
       "4730         1.219968     -1.532389 -0.307768  0.563284  \n",
       "4731         1.095798     -1.532389 -0.482386  0.000000  \n",
       "4732         1.468308     -1.184119 -0.629359  0.000000  \n",
       "4733         2.089157     -1.532389 -0.569694  0.000000  \n",
       "4734         1.716648     -1.532389 -0.436543  0.000000  \n",
       "4735         1.716648     -1.532389 -0.496208 -0.122692  \n",
       "4736         2.089157     -1.532389  0.000000  0.000000  \n",
       "4737         2.089157     -1.532389  0.000000  0.000000  \n",
       "4738        -0.642579     -1.300209 -2.811382 -2.192553  \n",
       "4739         1.716648     -1.184119 -0.427098  0.000000  \n",
       "4740         2.089157     -1.532389 -0.234282 -0.486792  \n",
       "4741         2.089157     -1.532389 -0.436543  0.000000  \n",
       "4742         1.468308     -1.532389  0.069110  0.000000  \n",
       "4743         1.592478     -1.532389 -0.018199 -1.460376  \n",
       "4744         1.964987     -1.532389 -0.597338 -0.406323  \n",
       "4745         1.716648     -1.532389 -0.045843  0.000000  \n",
       "4746         1.964987     -1.416299 -0.583516 -0.203161  \n",
       "4747         2.089157     -1.532389 -0.670825  0.000000  \n",
       "4748         2.089157     -1.532389 -0.803976  0.000000  \n",
       "4749         2.089157     -1.532389 -0.436543  0.000000  \n",
       "4750         1.468308     -1.532389  0.560941 -1.460376  \n",
       "4751         2.089157     -1.532389 -0.873086  0.000000  \n",
       "4752         1.716648     -1.300209 -0.440920 -0.935338  \n",
       "4753         1.344138     -1.532389 -0.496208 -0.406323  \n",
       "4754         0.847459     -0.371488 -2.204598 -2.031614  \n",
       "4755         0.847459     -1.532389 -0.436543  0.000000  \n",
       "4756        -1.635937     -1.532389 -0.596646  0.000000  \n",
       "4757         2.089157     -1.532389 -1.746172  0.000000  \n",
       "4758         0.847459     -1.532389 -0.873086 -2.031614  \n",
       "\n",
       "[540 rows x 13 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2[df_2['season']==2017].sort_values(by='playerrank', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Creating all teammate based changes\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "query = '''\n",
    "        DROP TABLE IF EXISTS adv_top10min;\n",
    "        CREATE TEMPORARY TABLE adv_top10min as \n",
    "        select a.*,usage_percentage*total_MP/G as usage_withMins,row_number() over(partition by a.season,tm order by usage_percentage*total_MP/G desc) as usage_rank\n",
    "        from(select *,row_number() over(partition by season,tm order by total_MP desc) as min_rank from nba_advanced) a\n",
    "        inner join y_predictions y\n",
    "                ON a.player = y.player\n",
    "                and a.season = y.season\n",
    "                and a.Tm=y.startingTeam\n",
    "        where min_rank<=10;\n",
    "        \n",
    "        DROP TABLE IF EXISTS Change_Teams;\n",
    "        CREATE TABLE Change_Teams AS\n",
    "        select na.tm as old_team,na2.tm as new_team,na2.player,na2.pos,p.season,na.usage_withMins,\n",
    "        n.points,n.rebounds,n.ast,n.threes_made,na.usage_rank \n",
    "        from player_value p\n",
    "        inner join adv_top10min na\n",
    "            on p.player = na.player\n",
    "            and p.season = na.season+1\n",
    "        inner join adv_top10min na2\n",
    "            on na2.player = na.player\n",
    "            and na2.season = p.season\n",
    "            and na2.tm != na.tm\n",
    "        inner join rank_by_minutes n\n",
    "            ON N.player = na.player\n",
    "            and n.season = na.season;\n",
    "        \n",
    "        \n",
    "        \n",
    "        DROP TABLE IF EXISTS incoming_by_team;\n",
    "        CREATE TABLE incoming_by_team AS\n",
    "        select new_team,season,SUM(case when usage_withmins >1000 then 1 else 0 end) as high_usageplayer_added,\n",
    "        SUM(usage_withmins) as usagemin_added, MAX(usage_withmins) as max_usageadded,\n",
    "        SUM(points) as points_added, MAX(points) as max_pointsadded,SUM(rebounds) as rebounds_added,\n",
    "        MAX(rebounds) as max_reboundsadded, SUM(ast) as ast_added, MAX(ast) as max_astadded,\n",
    "        SUM(threes_made) as threes_added, MAX(threes_made) as max_threesadded \n",
    "        from change_teams\n",
    "        group by new_team,season;\n",
    "        \n",
    "        DROP TABLE IF EXISTS outgoing_by_team;\n",
    "        CREATE TABLE outgoing_by_team AS\n",
    "        select old_team,season,SUM(case when usage_withmins >1000 then 1 else 0 end) as high_usageplayer_dropped,\n",
    "        SUM(usage_withmins) as usagemin_dropped, MAX(usage_withmins) as max_usagedropped,\n",
    "        SUM(points) as points_dropped, MAX(points) as max_pointsdropped,SUM(rebounds) as rebounds_dropped,\n",
    "        MAX(rebounds) as max_reboundsdropped, SUM(ast) as ast_dropped, MAX(ast) as max_astdropped,\n",
    "        SUM(threes_made) as threes_dropped, MAX(threes_made) as max_threesdropped\n",
    "        from change_teams\n",
    "        group by old_team,season;\n",
    "        \n",
    "        DROP TABLE IF EXISTS Team_Changes;\n",
    "        CREATE TABLE Team_Changes AS\n",
    "        select c.new_team as team, c.season,c.high_usageplayer_added,o.usagemin_dropped-c.usagemin_added as usagemin_opened,\n",
    "        c.max_usageadded,o.high_usageplayer_dropped,o.max_usagedropped,\n",
    "        o.points_dropped-c.points_added as points_opened,max_pointsdropped,max_pointsadded,\n",
    "        o.rebounds_dropped-c.rebounds_added as rebounds_opened,max_reboundsdropped,max_reboundsadded,\n",
    "        o.ast_dropped-c.ast_added as ast_opened,max_astdropped,max_astadded,\n",
    "        o.threes_dropped-c.threes_added as threes_opened,max_threesdropped,max_threesadded\n",
    "        from incoming_by_team c\n",
    "        inner join outgoing_by_team o\n",
    "            ON o.old_team = c.new_team\n",
    "            and o.season = c.season;\n",
    "            \n",
    "        DROP TABLE IF EXISTS Team_maxes;\n",
    "        CREATE TABLE Team_maxes AS\n",
    "        select R.season,R.startingTeam,MAX(R2.points) as pts, max(r2.rebounds) as reb, max(r2.ast) as ast,\n",
    "        MAX(R2.Tov) as TO,MAX(r2.FGA) as shot_attempts, cast(NULL as float) as max_usage \n",
    "        from rank_by_minutes R\n",
    "        inner join rank_by_minutes R2\n",
    "            ON R2.startingTeam = R.startingTeam\n",
    "            and R2.season+1 = R.season\n",
    "        group by R.season,R.startingTeam;\n",
    "        \n",
    "        \n",
    "        update Team_maxes T\n",
    "        set max_usage = usage\n",
    "        from\n",
    "        (select T.season,T.startingTeam,T.pts,t.reb,t.ast,t.TO,MAX(a.usage_percentage) as usage from Team_maxes T\n",
    "        inner join adv_top10min a\n",
    "            ON a.season+1 = t.season\n",
    "            and a.tm = t.startingteam\n",
    "        group by T.season,T.startingTeam,T.pts,t.reb,t.ast,t.TO) A\n",
    "        WHERE A.season = T.season and  A.startingTeam = T.startingTeam;\n",
    "        \n",
    "        \n",
    "        \n",
    "        '''\n",
    "\n",
    "\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Get player based data\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "query = '''\n",
    "        DROP TABLE IF EXISTS player_stats;\n",
    "        CREATE TABLE player_stats AS\n",
    "        select r.*,r2.starter as starter_ly,r3.points-r2.points as change_points_ly,r2.points as points_ly\n",
    "        ,r3.rebounds-r2.rebounds as change_reb_ly, r2.rebounds as rebounds_ly,\n",
    "        r3.ast-r2.ast as change_ast_ly, r2.ast as ast_ly,r3.stl-r2.stl as change_stl_ly,r2.stl as stl_ly,\n",
    "        r3.blk-r2.blk as change_blk_ly, r2.blk as blk_ly,r3.tov-r2.tov as change_tov_ly,r2.tov as tov_ly\n",
    "        from rank_by_minutes r\n",
    "        left join rank_by_minutes r2\n",
    "            on r.player = r2.player\n",
    "            and r.season = r2.season+1\n",
    "        left join rank_by_minutes r3\n",
    "            ON r3.player = r2.player\n",
    "            and r3.season+1 = r2.season;\n",
    "        \n",
    "        DROP TABLE IF EXISTS player_advstats;\n",
    "        CREATE TABLE player_advstats AS\n",
    "        select y.player,y.season,y.startingteam,a.per as per_ly, a2.per-a.per as change_per,a.three_attempt_rate as threeAR_ly,\n",
    "        a2.three_attempt_rate-a.three_attempt_rate as change_3AR, a.rebound_percentage as reb_perc_ly, a2.rebound_percentage-a.rebound_percentage as change_reb_perc\n",
    "        ,a.assist_percentage as ast_perc_ly, a2.assist_percentage-a.assist_percentage as change_assist_perc\n",
    "        ,a.steal_percentage as stl_perc_ly, a2.steal_percentage-a.steal_percentage as change_stl_perc_ly\n",
    "        ,a.block_percentage as blk_perc_ly, a2.block_percentage-a.block_percentage as change_blk_perc_ly\n",
    "        ,a.turnover_percentage as TO_perc_ly, a2.turnover_percentage-a.turnover_percentage as change_turnover_perc_ly,\n",
    "        rank() over(partition by y.season,y.startingTeam order by a.usage_percentage) as usagerank,\n",
    "        rank() over(partition by y.season,a.tm order by a.usage_percentage) as usagerank_ly,\n",
    "        a.offensive_winshares,\n",
    "        a.defensive_winshares,a.winshares,a.winshares_per48,a.offensive_boxplusminus,a.defensive_boxplusminus,\n",
    "        a.boxplusminus,a.value_overreplacement        \n",
    "        from y_predictions y\n",
    "        left join nba_advanced a\n",
    "            ON a.player = y.player\n",
    "            and a.season+1 = y.season\n",
    "        left join nba_advanced a2\n",
    "            ON a2.player = a.player\n",
    "            and a2.season+1 = a.season;\n",
    "    \n",
    "        \n",
    "        DROP TABLE IF EXISTS player_careerstats;\n",
    "        CREATE TABLE player_careerstats AS\n",
    "        select r.player,r.season,SUM(case when r2.player is not null then 1 else 0 end) as YearsPro, avg(r2.points) as career_points\n",
    "        ,avg(r2.rebounds) as career_rebounds,avg(r2.ast) as career_ast, avg(r2.stl) as career_stl, avg(r2.blk) as career_blk\n",
    "        ,avg(r2.tov) as career_TO, avg(r2.threes_made) as career_threesmade,avg(r2.ftm) as career_ftm,avg(r2.fta) as career_fta\n",
    "        ,avg(r2.fga) as career_fga, avg(r2.fg) as career_fgm\n",
    "        from rank_by_minutes r\n",
    "        inner join rank_by_minutes r2\n",
    "            ON r.player = r2.player\n",
    "            and r.season > r2.season\n",
    "        group by r.player,r.season;\n",
    "       \n",
    "        '''\n",
    "\n",
    "\n",
    "cur.execute(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    " query= '''\n",
    "        \n",
    "        DROP TABLE IF EXISTS points_pred;\n",
    "        CREATE TABLE points_pred(\n",
    "        season int, --these come from player_stats\n",
    "        player varchar(50),\n",
    "        Age int,\n",
    "        team varchar(50),\n",
    "        points float, -- these come from player_stats\n",
    "        points_ly float,\n",
    "        change_points_ly float,\n",
    "        starter_change int,\n",
    "        C_PF int,\n",
    "        PG int,\n",
    "        SG_SF int,\n",
    "        \n",
    "         -- these come from team_changes\n",
    "        high_usageplayer_added int,\n",
    "        usagemin_opened float,\n",
    "        maxusage_added float,\n",
    "        high_usageplayer_dropped int,\n",
    "        points_opened float,\n",
    "        max_pointsdropped float,\n",
    "        max_pointsadded float,\n",
    "        \n",
    "        three_ar_ly float, -- from player_advstats\n",
    "        change_3ar float,\n",
    "        per_ly float,\n",
    "        change_per float,\n",
    "        usagerank float,\n",
    "        usagerank_ly float,\n",
    "        offensive_winshares float,\n",
    "        offensive_boxplusminus float,\n",
    "        boxplusminus float,\n",
    "        value_overreplacement float,\n",
    "        \n",
    "        career_points float,\n",
    "        yearspro int\n",
    "        );\n",
    "        \n",
    "        INSERT INTO points_pred(season,player,age,team,points,points_ly,change_points_ly,starter_change,C_PF,PG,SG_SF)\n",
    "        SELECT season,player,age,startingteam,points,points_ly,change_points_ly,starter-starter_ly,\n",
    "        case when pos in ('C','PF') then 1 else 0 end,case when pos='PG' then 1 else 0 end,case when pos in('SG','SF') then 1 else 0 end from player_stats;\n",
    "        \n",
    "        update points_pred pp\n",
    "        set high_usageplayer_added = tc.high_usageplayer_added,usagemin_opened=tc.usagemin_opened,\n",
    "        maxusage_added=tc.max_usageadded,high_usageplayer_dropped=tc.high_usageplayer_dropped,points_opened=tc.points_opened,\n",
    "        max_pointsdropped=tc.max_pointsdropped,max_pointsadded=tc.max_pointsadded\n",
    "        from team_changes tc\n",
    "        where tc.team = pp.team and pp.season=tc.season;\n",
    "        \n",
    "        update points_pred pp\n",
    "        set three_ar_ly = pa.threear_ly,change_3ar=pa.change_3ar,per_ly=pa.per_ly,change_per=pa.change_per,\n",
    "        usagerank=pa.usagerank,usagerank_ly=pa.usagerank_ly,offensive_winshares=pa.offensive_winshares,\n",
    "        offensive_boxplusminus=pa.offensive_boxplusminus,boxplusminus=pa.boxplusminus,value_overreplacement=pa.value_overreplacement\n",
    "        from player_advstats pa\n",
    "        where pp.player = pa.player and pp.season = pa.season and pp.team = pa.startingteam;\n",
    "        \n",
    "        update points_pred pp\n",
    "        set career_points = pc.career_points, yearspro = pc.yearspro\n",
    "        from player_careerstats pc\n",
    "        where pp.player = pc.player and pp.season = pc.season;\n",
    "        \n",
    "        \n",
    "        select * from points_pred where season>2009\n",
    "        '''\n",
    "\n",
    "\n",
    "cur.execute(query)\n",
    "data = cur.fetchall()\n",
    "points_df = pd.DataFrame(np.array(data))\n",
    "points_df.columns = ['season','player','age','team','points','points_ly','change_points_ly','starter_change','C_PF','PG','SG_SF','high_usageplayer_added','usagemin_opened','maxusage_added','high_usageplayer_dropped','points_opened','max_pointsdropped',\n",
    "                    'max_pointsadded','three_ar_ly','change_3ar','per_ly','change_per','usagerank','usagerank_ly','offensive_winshares','offensive_boxplusminus','boxplusminus','value_overreplacement','career_points','yearspro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rookies = points_df[points_df['points_ly'].isna()]\n",
    "rookies.sort_values(by='points',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = points_df[points_df['points_ly'].notna()]\n",
    "for i in players.columns:\n",
    "    if i not in(['player','team']):\n",
    "        players[i]=pd.to_numeric(players[i])\n",
    "players = players.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = players[players['season']!=2017]['points']\n",
    "X = players[players['season']!=2017].drop(['points','player','season','team'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor,RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function connection.close>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.close()\n",
    "conn.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression error: 0.7706184121337402\n",
      "GradientBoost error: 0.7695143834691159\n",
      "RandomForest error: 0.7068402746139153\n"
     ]
    }
   ],
   "source": [
    "r2_lr = np.mean(cross_val_score(LinearRegression(),X_train,y_train,cv=10,n_jobs=-1))\n",
    "print('Linear Regression error: {}'.format(r2_lr))\n",
    "\n",
    "r2_gb = np.mean(cross_val_score(GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.5),X_train,y_train,cv=5,n_jobs=-1))\n",
    "print('GradientBoost error: {}'.format(r2_gb))\n",
    "\n",
    "r2_rf = np.mean(cross_val_score(RandomForestRegressor(n_estimators=1000,max_depth = 3,max_features=0.5),X_train,y_train,cv=5,n_jobs=-1))\n",
    "print('RandomForest error: {}'.format(r2_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7495924120019375, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7476594944544669, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7943399658158287, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7190431458804185, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7222216933630867, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7627053638805009, total=   0.6s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7502206778411044, total=   0.6s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000, score=0.8045909017875303, total=   0.6s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7293798119305249, total=   0.6s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7300588658432952, total=   0.6s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7724619977012069, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7526974885743176, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000, score=0.810172956048633, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7464345262995764, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7359319991432365, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000, score=0.7714118315177116, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000, score=0.7484088434769929, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000, score=0.809351530051144, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000, score=0.7396221339062757, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000, score=0.7360800496568037, total=   1.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7782412972206614, total=   0.7s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7534142959553877, total=   0.7s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000, score=0.8076397951828361, total=   0.7s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7526210846094401, total=   0.8s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000, score=0.739283943797602, total=   0.8s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000, score=0.7718861303857902, total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000, score=0.7502934336936846, total=   1.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000, score=0.8069350259476348, total=   1.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000, score=0.7376255382516397, total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000, score=0.737654204563374, total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7626771339183323, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7465049831143591, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000, score=0.8018587343434184, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7303094382099727, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7286900382983863, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7601056582996399, total=   1.0s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7428013575185071, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000, score=0.8003830497626752, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7290513105397022, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7293391964796927, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7770393060223986, total=   1.0s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7515317599698752, total=   1.0s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000, score=0.8057791616339796, total=   1.2s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7403035333377772, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7380020790437171, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7661440685290489, total=   1.7s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7396205227844399, total=   1.7s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000, score=0.802302081648347, total=   1.7s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7295044347022633, total=   1.8s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7316890912641884, total=   1.8s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7715801807194493, total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7457471806092637, total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000, score=0.8033399817639613, total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000, score=0.744422152544153, total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7393631477275849, total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7603685317760063, total=   2.7s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7374521750249801, total=   2.7s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7991477867900119, total=   2.8s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7310660946972016, total=   2.7s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000, score=0.73103055543112, total=   2.7s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7562111426304283, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7480430230577373, total=   0.8s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7967011623928267, total=   0.8s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7257278038368107, total=   0.8s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7256501733403956, total=   0.8s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7461836284262331, total=   1.5s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7426505957356664, total=   1.5s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7943318467730048, total=   1.5s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7163064966131981, total=   1.5s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7268958591275507, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7642667464108575, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7472279720786172, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000, score=0.8051508686829824, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000, score=0.730024428630686, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7321632082347167, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7570609920410137, total=   3.2s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7422406018737014, total=   3.1s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000, score=0.8025975188997343, total=   3.1s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7321555092651384, total=   3.1s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7271797914893012, total=   3.1s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7624550271802718, total=   2.8s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7422698693042158, total=   2.8s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000, score=0.80269818476494, total=   2.6s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7366475381642718, total=   2.7s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7304025880552752, total=   2.6s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7579714310310804, total=   5.0s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7381936611530922, total=   5.0s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7997123433740743, total=   4.9s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000, score=0.729932346775635, total=   4.9s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000, score=0.721586215979279, total=   4.9s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000, score=0.737095505582872, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7391002109576411, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7821762588610093, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7153281788280829, total=   1.8s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7123294115378661, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7394600909167903, total=   3.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7397868483744654, total=   3.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7868843929850418, total=   3.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7230768853387237, total=   3.1s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7163275204374132, total=   3.1s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7546220342493819, total=   3.9s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7452179324783312, total=   3.9s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7971776444927601, total=   3.9s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7299268435231488, total=   3.9s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000, score=0.721997645297602, total=   3.8s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7537602466103849, total=   6.7s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7453613935960759, total=   6.9s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7963422967116403, total=   7.3s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000, score=0.731775920024456, total=   7.0s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7192168588867147, total=   7.3s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7521194216181062, total=   6.8s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000, score=0.73591294700449, total=   6.6s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000, score=0.8000873197537989, total=   6.5s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7281733634094683, total=   6.7s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7275044178926261, total=   6.4s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7545468244722808, total=  11.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7373252340416532, total=  11.3s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000, score=0.8003975458072936, total=  11.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7251717171625662, total=  11.6s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7249564186650879, total=  11.5s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000, score=0.752286846835078, total=   0.3s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7344522867350258, total=   0.3s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000, score=0.8002626878951357, total=   0.3s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000, score=0.703864233587904, total=   0.3s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7235337227035721, total=   0.3s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7393922487573352, total=   0.6s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7125520140158332, total=   0.6s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000, score=0.79302259406663, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7073971620006783, total=   0.6s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7119012948136328, total=   0.6s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7559099138338337, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7319007998160488, total=   0.4s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7992056979535583, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7203937644737937, total=   0.4s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000, score=0.721137441584053, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000, score=0.7385908644620797, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000, score=0.7092442173441982, total=   0.9s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000, score=0.7851112072120722, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000, score=0.6894879510843741, total=   0.9s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000, score=0.7074554670306207, total=   0.9s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7466439072911673, total=   0.7s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7257824680827822, total=   0.7s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000, score=0.8005423190440591, total=   0.7s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7147742701837227, total=   0.7s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7219265556585865, total=   0.7s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000, score=0.729322513231452, total=   1.4s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000, score=0.7082251376147489, total=   1.4s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000, score=0.786368296727049, total=   1.4s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000, score=0.6927225064421316, total=   1.4s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000, score=0.7021674528402333, total=   1.4s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000, score=0.735987099698128, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7163199673523517, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7837932451898368, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7048473971269863, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7286024372293955, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7434888704202895, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7199128185929571, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7876007854609404, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000, score=0.6945420460139555, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7055204482159698, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7510237368472615, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7303682814183251, total=   0.9s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7875888975676699, total=   0.9s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7086265574189083, total=   0.9s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7244035036909662, total=   0.9s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7393223717485395, total=   1.8s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7229888788680818, total=   1.8s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7914514342873987, total=   1.9s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7119477121686841, total=   1.8s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7131420118957748, total=   1.8s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7483604041973191, total=   1.4s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000, score=0.722014021511503, total=   1.4s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7873754260611263, total=   1.5s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7146158970835647, total=   1.4s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7223065561849062, total=   1.4s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7445193304153469, total=   2.9s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7268449941649757, total=   2.9s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7910472172522893, total=   2.8s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7076979390667831, total=   2.9s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7155123783998669, total=   3.1s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7508683171448276, total=   0.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7369347684284189, total=   0.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7868665407329936, total=   0.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7051506815535404, total=   0.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7168202672140183, total=   0.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7403865965978269, total=   1.5s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7394960864825679, total=   1.5s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7866143604997458, total=   1.5s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000, score=0.70787989008121, total=   1.5s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000, score=0.708104263057199, total=   1.5s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7527646705276453, total=   1.6s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7306964803031681, total=   1.6s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7968111012770279, total=   1.6s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7207640091874379, total=   1.6s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7215776096779543, total=   1.6s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7532871973495969, total=   2.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7300993993125191, total=   2.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7962722790974893, total=   2.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7249697944914697, total=   2.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7245997112925274, total=   2.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7450880758859164, total=   2.4s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7219047273998561, total=   2.4s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7968425632753985, total=   2.5s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7228328199892681, total=   2.5s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7210661583696008, total=   2.5s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7490806201728469, total=   4.3s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7251426220404611, total=   4.4s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7987682411300973, total=   4.4s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7209759908921514, total=   4.6s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7279667359080849, total=   4.7s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7177709865279249, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7284447966563368, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7781155952166244, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7134790895649794, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7022702697577334, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7278511082439557, total=   1.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7282186855102353, total=   1.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000, score=0.771979995001921, total=   1.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7168075035305853, total=   1.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7107626870256414, total=   1.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7485030109277822, total=   2.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7434980023515272, total=   2.0s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7896427314684267, total=   2.0s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7194799449885727, total=   2.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7233966325426893, total=   2.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7397012993381731, total=   2.2s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7369431862597071, total=   2.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7890744709242321, total=   2.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7174973044650194, total=   2.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7198864632305905, total=   2.2s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7494867760789095, total=   3.3s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7325835434169372, total=   3.4s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7991469983980578, total=   3.3s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7226740586690906, total=   3.4s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7216717811919983, total=   3.4s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7487770435984751, total=   3.5s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7330375830969063, total=   3.5s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7975796905296982, total=   3.4s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7222503677852579, total=   3.4s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7095453234854497, total=   3.5s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7400927184551788, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7051763260749899, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7863782256378044, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000, score=0.6903610883360561, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000, score=0.709880163506944, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7238648057886273, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7015505815972904, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000, score=0.771189774211563, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000, score=0.6774645909887353, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000, score=0.6983061932376536, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7346831372833165, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000, score=0.6977042165981303, total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7876122507583366, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000, score=0.690826704359533, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7044378218776257, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000, score=0.7191456328307622, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000, score=0.6950523653128976, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000, score=0.770112856119971, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000, score=0.6671644457002963, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000, score=0.6967486575476491, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7239935260934496, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000, score=0.6968332954089733, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7912071424581322, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000, score=0.6787669355629476, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7036425895595, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000, score=0.7107280285375973, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000, score=0.6906934320836046, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000, score=0.7684853436032557, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000, score=0.6733068186415727, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000, score=0.6881659954174325, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000, score=0.73062496919834, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7112315806878475, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7889885476586568, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000, score=0.6938845522487078, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7078837587072513, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7355003080703729, total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7127437181038732, total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7818553463982422, total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000, score=0.6858339349017537, total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7021546186806401, total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7417695496650021, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7099484489978046, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7923173090695046, total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000, score=0.6985217244130694, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7017796878802254, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7366849469695127, total=   1.8s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000, score=0.710631893814357, total=   1.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7701324326286275, total=   1.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000, score=0.6971844661677287, total=   1.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000, score=0.710067350050307, total=   1.8s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7378688585097068, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000, score=0.723908544033475, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7861375811253967, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7083898379004534, total=   1.5s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7020346355186942, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7436745379932068, total=   3.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000, score=0.721390374669193, total=   3.1s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7899364619877614, total=   2.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7023376993387401, total=   2.8s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7078778010172415, total=   2.9s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7332085221187111, total=   0.8s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7260121075747383, total=   0.8s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7757299189069455, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7071261929320487, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7061625505249256, total=   0.8s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7394025958553498, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7376728682711406, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7813160199839769, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000, score=0.699058564582554, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7095696708273942, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7501109680043165, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7320737587546198, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7871169906244867, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7234201757710497, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7194652481909605, total=   1.5s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7418655595748486, total=   1.5s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7244626202046608, total=   1.5s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7834005945928676, total=   1.5s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7241832829411852, total=   1.5s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7227272210830801, total=   1.5s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7453695426305416, total=   2.2s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7308966989776801, total=   2.3s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7894149280812881, total=   2.2s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7252913188700597, total=   2.2s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7107156873553534, total=   2.3s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7499877423621176, total=   2.3s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7295974357531997, total=   2.4s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000, score=0.8033482037577244, total=   2.4s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000, score=0.708724944503413, total=   2.4s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7096245120460201, total=   2.3s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7245899828276123, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7213787716744793, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000, score=0.771114043249621, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000, score=0.6951395793983591, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000, score=0.6866123757502176, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7083380746262937, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7218458017159783, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7729539221198265, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000, score=0.6786220787087511, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000, score=0.6924059206715347, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7461429399331911, total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7335854835740997, total=   1.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7882061664132022, total=   1.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000, score=0.715496985489933, total=   1.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7125187406617058, total=   1.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7351299096149566, total=   1.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7332982267329171, total=   1.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7847242825214382, total=   1.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7182262515857962, total=   1.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7061579918019316, total=   1.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7342673085994973, total=   1.8s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7324242118013593, total=   1.8s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7848016999949579, total=   1.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7116218347626846, total=   1.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7100725360014587, total=   1.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7420754701332148, total=   1.8s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7149834059138893, total=   1.8s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7906294839563833, total=   1.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7086771799125724, total=   1.8s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7012909195205025, total=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed: 11.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'learning_rate': [0.01, 0.05, 0.1], 'n_estimators': [1000, 2000], 'max_depth': [3, 5, 7, 10], 'max_features': [0.1, 0.3, 0.5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'learning_rate':[0.01,0.05,0.1], 'n_estimators':[1000,2000],'max_depth':[3,5,7,10],'max_features':[0.1,0.3,0.5]}\n",
    "\n",
    "clf = GridSearchCV(GradientBoostingRegressor(), parameters, cv=5,verbose=3)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.01, loss='ls', max_depth=3, max_features=0.5,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=1000, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model, Input\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.stats as scs\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=16,input_dim= 26,activation='relu'))\n",
    "#model.add(Dense(units=8, activation='relu'))\n",
    "#model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(units=8, activation='relu'))\n",
    "#model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(units=4, activation='relu'))\n",
    "#model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(units=1,activation='linear'))\n",
    "model.compile(loss='mse', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "1883/1883 [==============================] - 0s 242us/step - loss: 416.2584\n",
      "Epoch 2/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 209.1091\n",
      "Epoch 3/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 165.5059\n",
      "Epoch 4/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 139.0482\n",
      "Epoch 5/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 130.5637\n",
      "Epoch 6/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 127.7999\n",
      "Epoch 7/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 122.4804\n",
      "Epoch 8/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 112.3718\n",
      "Epoch 9/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 108.7543\n",
      "Epoch 10/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 99.5249\n",
      "Epoch 11/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 87.9469\n",
      "Epoch 12/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 80.6404\n",
      "Epoch 13/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 79.1041\n",
      "Epoch 14/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 75.4520\n",
      "Epoch 15/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 73.9179\n",
      "Epoch 16/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 66.9681\n",
      "Epoch 17/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 64.8751\n",
      "Epoch 18/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 61.9715\n",
      "Epoch 19/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 59.2301\n",
      "Epoch 20/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 57.9251\n",
      "Epoch 21/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 53.7750\n",
      "Epoch 22/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 54.8898\n",
      "Epoch 23/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 51.6061\n",
      "Epoch 24/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 50.7308\n",
      "Epoch 25/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 49.9111\n",
      "Epoch 26/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 45.1340\n",
      "Epoch 27/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 43.6889\n",
      "Epoch 28/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 43.3193\n",
      "Epoch 29/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 40.4162\n",
      "Epoch 30/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 39.6851\n",
      "Epoch 31/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 39.1624\n",
      "Epoch 32/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 39.9786\n",
      "Epoch 33/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 40.6373\n",
      "Epoch 34/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 39.5659\n",
      "Epoch 35/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 38.3132\n",
      "Epoch 36/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 36.7418\n",
      "Epoch 37/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 37.0447\n",
      "Epoch 38/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 36.9522\n",
      "Epoch 39/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 37.5016\n",
      "Epoch 40/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 36.1982\n",
      "Epoch 41/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 35.7108\n",
      "Epoch 42/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 34.8462\n",
      "Epoch 43/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 35.3763\n",
      "Epoch 44/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 37.0695\n",
      "Epoch 45/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 34.8651\n",
      "Epoch 46/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 37.3951\n",
      "Epoch 47/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 32.4107\n",
      "Epoch 48/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 33.5408\n",
      "Epoch 49/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 33.6562\n",
      "Epoch 50/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 32.8563\n",
      "Epoch 51/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 30.4339\n",
      "Epoch 52/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 32.6144\n",
      "Epoch 53/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 31.0616\n",
      "Epoch 54/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 32.5074\n",
      "Epoch 55/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 28.2591\n",
      "Epoch 56/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 28.6740\n",
      "Epoch 57/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 28.1219\n",
      "Epoch 58/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 28.4771\n",
      "Epoch 59/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 29.8842\n",
      "Epoch 60/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 24.6296\n",
      "Epoch 61/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 26.2551\n",
      "Epoch 62/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 25.6514\n",
      "Epoch 63/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 24.4705\n",
      "Epoch 64/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 25.0336\n",
      "Epoch 65/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 21.8220\n",
      "Epoch 66/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 22.6757\n",
      "Epoch 67/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 23.5564\n",
      "Epoch 68/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 22.6927\n",
      "Epoch 69/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 21.5480\n",
      "Epoch 70/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 20.7967\n",
      "Epoch 71/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 19.6646\n",
      "Epoch 72/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 21.1104\n",
      "Epoch 73/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 19.5940\n",
      "Epoch 74/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 20.0130\n",
      "Epoch 75/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 19.4128\n",
      "Epoch 76/2000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 19.3334\n",
      "Epoch 77/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 21.0955\n",
      "Epoch 78/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 18.8139\n",
      "Epoch 79/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 20.4475\n",
      "Epoch 80/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 19.3932\n",
      "Epoch 81/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 20.0326\n",
      "Epoch 82/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 18.7078\n",
      "Epoch 83/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 18.7506\n",
      "Epoch 84/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 18.9975\n",
      "Epoch 85/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 18.4838\n",
      "Epoch 86/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 20.5150\n",
      "Epoch 87/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 19.8332\n",
      "Epoch 88/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 18.4762\n",
      "Epoch 89/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 18.1751\n",
      "Epoch 90/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 17.1228\n",
      "Epoch 91/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 17.6576\n",
      "Epoch 92/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 17.3178\n",
      "Epoch 93/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 17.9356\n",
      "Epoch 94/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 18.0666\n",
      "Epoch 95/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 16.7367\n",
      "Epoch 96/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 18.0549\n",
      "Epoch 97/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 19.0435\n",
      "Epoch 98/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 17.5195\n",
      "Epoch 99/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 17.1896\n",
      "Epoch 100/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 17.1973\n",
      "Epoch 101/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 17.1263\n",
      "Epoch 102/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 18.3989\n",
      "Epoch 103/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 18.0050\n",
      "Epoch 104/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 17.1966\n",
      "Epoch 105/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 17.2085\n",
      "Epoch 106/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 16.7218\n",
      "Epoch 107/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 17.5295\n",
      "Epoch 108/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 16.3687\n",
      "Epoch 109/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 16.7246\n",
      "Epoch 110/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 17.5327\n",
      "Epoch 111/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 15.7298\n",
      "Epoch 112/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 16.8052\n",
      "Epoch 113/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 15.7246\n",
      "Epoch 114/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 16.5653\n",
      "Epoch 115/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 16.3377\n",
      "Epoch 116/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 16.1722\n",
      "Epoch 117/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 17.1880\n",
      "Epoch 118/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 15.6868\n",
      "Epoch 119/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 16.2808\n",
      "Epoch 120/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 15.7172\n",
      "Epoch 121/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 16.5814\n",
      "Epoch 122/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 15.8530\n",
      "Epoch 123/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 16.1629\n",
      "Epoch 124/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 16.5745\n",
      "Epoch 125/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 16.2430\n",
      "Epoch 126/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 16.2778\n",
      "Epoch 127/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 15.7849\n",
      "Epoch 128/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 15.2192\n",
      "Epoch 129/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 16.3625\n",
      "Epoch 130/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 13.7245\n",
      "Epoch 131/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 16.2643\n",
      "Epoch 132/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 14.8666\n",
      "Epoch 133/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 13.7415\n",
      "Epoch 134/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 15.6591\n",
      "Epoch 135/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 14.4860\n",
      "Epoch 136/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 14.0700\n",
      "Epoch 137/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 14.6885\n",
      "Epoch 138/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 14.1439\n",
      "Epoch 139/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 15.8478\n",
      "Epoch 140/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 15.0162\n",
      "Epoch 141/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 14.4978\n",
      "Epoch 142/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 14.7400\n",
      "Epoch 143/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 14.4559\n",
      "Epoch 144/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 14.6119\n",
      "Epoch 145/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 15.3660\n",
      "Epoch 146/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 15.0546\n",
      "Epoch 147/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 14.8781\n",
      "Epoch 148/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 13.9506\n",
      "Epoch 149/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 14.3345\n",
      "Epoch 150/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 13.9727\n",
      "Epoch 151/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 14.3902\n",
      "Epoch 152/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 14.2808\n",
      "Epoch 153/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 14.4558\n",
      "Epoch 154/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 14.1142\n",
      "Epoch 155/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 14.5621\n",
      "Epoch 156/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 13.3243\n",
      "Epoch 157/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 13.7735\n",
      "Epoch 158/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 14.4204\n",
      "Epoch 159/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 14.1999\n",
      "Epoch 160/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 13.3325\n",
      "Epoch 161/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 14.5478\n",
      "Epoch 162/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 14.2797\n",
      "Epoch 163/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 14.4232\n",
      "Epoch 164/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 13.7972\n",
      "Epoch 165/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 12.4098\n",
      "Epoch 166/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 14.4925\n",
      "Epoch 167/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 13.5682\n",
      "Epoch 168/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 14.2602\n",
      "Epoch 169/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 13.6921\n",
      "Epoch 170/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 14.1871\n",
      "Epoch 171/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 13.7779\n",
      "Epoch 172/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 13.8966\n",
      "Epoch 173/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 14.1269\n",
      "Epoch 174/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 14.1735\n",
      "Epoch 175/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 13.8943\n",
      "Epoch 176/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 13.4869\n",
      "Epoch 177/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 13.2388\n",
      "Epoch 178/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 13.5483\n",
      "Epoch 179/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 12.8459\n",
      "Epoch 180/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 13.9133\n",
      "Epoch 181/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.5931\n",
      "Epoch 182/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.4022\n",
      "Epoch 183/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 14.1151\n",
      "Epoch 184/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 13.3650\n",
      "Epoch 185/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 12.7619\n",
      "Epoch 186/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 12.8509\n",
      "Epoch 187/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 13.7814\n",
      "Epoch 188/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.7923\n",
      "Epoch 189/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 13.4620\n",
      "Epoch 190/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 13.6222\n",
      "Epoch 191/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 13.1871\n",
      "Epoch 192/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 13.0380\n",
      "Epoch 193/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 13.2803\n",
      "Epoch 194/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.7234\n",
      "Epoch 195/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 14.2156\n",
      "Epoch 196/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 12.5721\n",
      "Epoch 197/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 13.7160\n",
      "Epoch 198/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 13.9311\n",
      "Epoch 199/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 12.8349\n",
      "Epoch 200/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 12.5451\n",
      "Epoch 201/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 13.1296\n",
      "Epoch 202/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 12.5136\n",
      "Epoch 203/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.4701\n",
      "Epoch 204/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.9414\n",
      "Epoch 205/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 13.1930\n",
      "Epoch 206/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 13.4871\n",
      "Epoch 207/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.6954\n",
      "Epoch 208/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 13.9319\n",
      "Epoch 209/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.2482\n",
      "Epoch 210/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 12.5314\n",
      "Epoch 211/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 12.4672\n",
      "Epoch 212/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.4920\n",
      "Epoch 213/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 12.5743\n",
      "Epoch 214/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 13.3472\n",
      "Epoch 215/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 13.8790\n",
      "Epoch 216/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 12.9416\n",
      "Epoch 217/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 12.1397\n",
      "Epoch 218/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 13.1755\n",
      "Epoch 219/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.9970\n",
      "Epoch 220/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 13.3195\n",
      "Epoch 221/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 14.0117\n",
      "Epoch 222/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.7231\n",
      "Epoch 223/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 12.4121\n",
      "Epoch 224/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 12.1167\n",
      "Epoch 225/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 11.3258\n",
      "Epoch 226/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 12.0676\n",
      "Epoch 227/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.8568\n",
      "Epoch 228/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.0353\n",
      "Epoch 229/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 12.0722\n",
      "Epoch 230/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.2331\n",
      "Epoch 231/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.2462\n",
      "Epoch 232/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.5801\n",
      "Epoch 233/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 12.6950\n",
      "Epoch 234/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.8647\n",
      "Epoch 235/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 13.0081\n",
      "Epoch 236/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.4771\n",
      "Epoch 237/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 12.4755\n",
      "Epoch 238/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.7735\n",
      "Epoch 239/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 12.4349\n",
      "Epoch 240/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 12.3121\n",
      "Epoch 241/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.3503\n",
      "Epoch 242/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.9517\n",
      "Epoch 243/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 14.8343\n",
      "Epoch 244/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.8825\n",
      "Epoch 245/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 12.1034\n",
      "Epoch 246/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.8994\n",
      "Epoch 247/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.6132\n",
      "Epoch 248/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 12.3393\n",
      "Epoch 249/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 13.8048\n",
      "Epoch 250/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.2868\n",
      "Epoch 251/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.3690\n",
      "Epoch 252/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 12.0606\n",
      "Epoch 253/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.2880\n",
      "Epoch 254/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.1530\n",
      "Epoch 255/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.6810\n",
      "Epoch 256/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.5226\n",
      "Epoch 257/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.8127\n",
      "Epoch 258/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 12.3361\n",
      "Epoch 259/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.5081\n",
      "Epoch 260/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.9742\n",
      "Epoch 261/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.0519\n",
      "Epoch 262/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.0204\n",
      "Epoch 263/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.5018\n",
      "Epoch 264/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.4944\n",
      "Epoch 265/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.5599\n",
      "Epoch 266/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.5907\n",
      "Epoch 267/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 12.4292\n",
      "Epoch 268/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.5461\n",
      "Epoch 269/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 12.0064\n",
      "Epoch 270/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.2903\n",
      "Epoch 271/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 12.3779\n",
      "Epoch 272/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.4144\n",
      "Epoch 273/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.1581\n",
      "Epoch 274/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 12.4493\n",
      "Epoch 275/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.4815\n",
      "Epoch 276/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.2464\n",
      "Epoch 277/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.8982\n",
      "Epoch 278/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.7710\n",
      "Epoch 279/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.6807\n",
      "Epoch 280/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 13.0037\n",
      "Epoch 281/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.3123\n",
      "Epoch 282/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 12.0637\n",
      "Epoch 283/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 12.0640\n",
      "Epoch 284/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.1299\n",
      "Epoch 285/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 11.8717\n",
      "Epoch 286/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.2961\n",
      "Epoch 287/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.6715\n",
      "Epoch 288/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.9837\n",
      "Epoch 289/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 12.1608\n",
      "Epoch 290/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.1898\n",
      "Epoch 291/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.8828\n",
      "Epoch 292/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 12.0209\n",
      "Epoch 293/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 12.6942\n",
      "Epoch 294/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.7631\n",
      "Epoch 295/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 12.7128\n",
      "Epoch 296/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.9864\n",
      "Epoch 297/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 12.2306\n",
      "Epoch 298/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.7676\n",
      "Epoch 299/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.6655\n",
      "Epoch 300/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.3572\n",
      "Epoch 301/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.9201\n",
      "Epoch 302/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 12.6798\n",
      "Epoch 303/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.7720\n",
      "Epoch 304/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.8581\n",
      "Epoch 305/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.3005\n",
      "Epoch 306/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.6323\n",
      "Epoch 307/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.3039\n",
      "Epoch 308/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.7660\n",
      "Epoch 309/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.5357\n",
      "Epoch 310/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.3158\n",
      "Epoch 311/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.1674\n",
      "Epoch 312/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.6187\n",
      "Epoch 313/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.3355\n",
      "Epoch 314/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.5425\n",
      "Epoch 315/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.9787\n",
      "Epoch 316/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.7548\n",
      "Epoch 317/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.7023\n",
      "Epoch 318/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.8690\n",
      "Epoch 319/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.0167\n",
      "Epoch 320/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 12.2893\n",
      "Epoch 321/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.5198\n",
      "Epoch 322/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.0613\n",
      "Epoch 323/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.7363\n",
      "Epoch 324/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.5592\n",
      "Epoch 325/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.5889\n",
      "Epoch 326/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.9439\n",
      "Epoch 327/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.0963\n",
      "Epoch 328/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 12.2345\n",
      "Epoch 329/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.4828\n",
      "Epoch 330/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.9475\n",
      "Epoch 331/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.2817\n",
      "Epoch 332/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.5736\n",
      "Epoch 333/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 13.1156\n",
      "Epoch 334/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.8147\n",
      "Epoch 335/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.3375\n",
      "Epoch 336/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.4997\n",
      "Epoch 337/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.5389\n",
      "Epoch 338/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.2048\n",
      "Epoch 339/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.7559\n",
      "Epoch 340/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 11.2181\n",
      "Epoch 341/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 11.8959\n",
      "Epoch 342/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.4179\n",
      "Epoch 343/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 11.5559\n",
      "Epoch 344/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.2252\n",
      "Epoch 345/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 12.1945\n",
      "Epoch 346/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.2168\n",
      "Epoch 347/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 12.6190\n",
      "Epoch 348/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.4585\n",
      "Epoch 349/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 10.3055\n",
      "Epoch 350/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 11.2279\n",
      "Epoch 351/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 11.1268\n",
      "Epoch 352/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 10.8597\n",
      "Epoch 353/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.4456\n",
      "Epoch 354/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 12.1000\n",
      "Epoch 355/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 11.6229\n",
      "Epoch 356/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 10.8381\n",
      "Epoch 357/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 12.5131\n",
      "Epoch 358/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 12.2520\n",
      "Epoch 359/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 11.9261\n",
      "Epoch 360/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.3610\n",
      "Epoch 361/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 10.6597\n",
      "Epoch 362/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.0335\n",
      "Epoch 363/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.1535\n",
      "Epoch 364/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 12.0213\n",
      "Epoch 365/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.2486\n",
      "Epoch 366/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.9509\n",
      "Epoch 367/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.9560\n",
      "Epoch 368/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.3626\n",
      "Epoch 369/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.2547\n",
      "Epoch 370/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.4448\n",
      "Epoch 371/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.7409\n",
      "Epoch 372/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.6133\n",
      "Epoch 373/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.3863\n",
      "Epoch 374/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.1805\n",
      "Epoch 375/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.4604\n",
      "Epoch 376/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.2228\n",
      "Epoch 377/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.1569\n",
      "Epoch 378/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.6764\n",
      "Epoch 379/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.7459\n",
      "Epoch 380/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.4678\n",
      "Epoch 381/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.9018\n",
      "Epoch 382/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.2544\n",
      "Epoch 383/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.1525\n",
      "Epoch 384/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.7389\n",
      "Epoch 385/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.3952\n",
      "Epoch 386/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 13.1278\n",
      "Epoch 387/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.9464\n",
      "Epoch 388/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.7229\n",
      "Epoch 389/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.8193\n",
      "Epoch 390/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.1988\n",
      "Epoch 391/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.7366\n",
      "Epoch 392/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.9839\n",
      "Epoch 393/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.4931\n",
      "Epoch 394/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.5970\n",
      "Epoch 395/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.4999\n",
      "Epoch 396/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.8372\n",
      "Epoch 397/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 12.0421\n",
      "Epoch 398/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.0938\n",
      "Epoch 399/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.5041\n",
      "Epoch 400/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.8353\n",
      "Epoch 401/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.3809\n",
      "Epoch 402/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.0022\n",
      "Epoch 403/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.2410\n",
      "Epoch 404/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.7084\n",
      "Epoch 405/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.9689\n",
      "Epoch 406/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.5379\n",
      "Epoch 407/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.9654\n",
      "Epoch 408/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 13.2493\n",
      "Epoch 409/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.0288\n",
      "Epoch 410/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 12.1854\n",
      "Epoch 411/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.7640\n",
      "Epoch 412/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.0348\n",
      "Epoch 413/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.5645\n",
      "Epoch 414/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 11.9200\n",
      "Epoch 415/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.3634\n",
      "Epoch 416/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.6518\n",
      "Epoch 417/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.2449\n",
      "Epoch 418/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.0451\n",
      "Epoch 419/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.7930\n",
      "Epoch 420/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.9560\n",
      "Epoch 421/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.8704\n",
      "Epoch 422/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 12.1719\n",
      "Epoch 423/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.8954\n",
      "Epoch 424/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.7813\n",
      "Epoch 425/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.3996\n",
      "Epoch 426/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.8250\n",
      "Epoch 427/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.2709\n",
      "Epoch 428/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.1783\n",
      "Epoch 429/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.0309\n",
      "Epoch 430/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.3411\n",
      "Epoch 431/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.3100\n",
      "Epoch 432/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.3336\n",
      "Epoch 433/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.0928\n",
      "Epoch 434/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.5586\n",
      "Epoch 435/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.1366\n",
      "Epoch 436/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.6943\n",
      "Epoch 437/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 12.4952\n",
      "Epoch 438/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.7230\n",
      "Epoch 439/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.2654\n",
      "Epoch 440/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.3542\n",
      "Epoch 441/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.4373\n",
      "Epoch 442/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.7430\n",
      "Epoch 443/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.9854\n",
      "Epoch 444/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.9651\n",
      "Epoch 445/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.8250\n",
      "Epoch 446/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.5897\n",
      "Epoch 447/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.1937\n",
      "Epoch 448/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.9293\n",
      "Epoch 449/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.3212\n",
      "Epoch 450/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.6938\n",
      "Epoch 451/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.8359\n",
      "Epoch 452/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.9759\n",
      "Epoch 453/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.8217\n",
      "Epoch 454/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.4017\n",
      "Epoch 455/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.7911\n",
      "Epoch 456/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.0497\n",
      "Epoch 457/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.3910\n",
      "Epoch 458/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.2678\n",
      "Epoch 459/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.8011\n",
      "Epoch 460/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.8557\n",
      "Epoch 461/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.5541\n",
      "Epoch 462/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.4125\n",
      "Epoch 463/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.7685\n",
      "Epoch 464/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.0147\n",
      "Epoch 465/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.3734\n",
      "Epoch 466/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.4128\n",
      "Epoch 467/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.4527\n",
      "Epoch 468/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.7082\n",
      "Epoch 469/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.2815\n",
      "Epoch 470/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.4448\n",
      "Epoch 471/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.1016\n",
      "Epoch 472/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.0930\n",
      "Epoch 473/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.5278\n",
      "Epoch 474/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.9190\n",
      "Epoch 475/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.2899\n",
      "Epoch 476/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.7982\n",
      "Epoch 477/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.8337\n",
      "Epoch 478/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.6206\n",
      "Epoch 479/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 11.8675\n",
      "Epoch 480/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.4112\n",
      "Epoch 481/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.0129\n",
      "Epoch 482/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 12.5147\n",
      "Epoch 483/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.7205\n",
      "Epoch 484/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.2273\n",
      "Epoch 485/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.9410\n",
      "Epoch 486/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.7198\n",
      "Epoch 487/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.0585\n",
      "Epoch 488/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.3377\n",
      "Epoch 489/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.8285\n",
      "Epoch 490/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.2717\n",
      "Epoch 491/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.6429\n",
      "Epoch 492/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.2887\n",
      "Epoch 493/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.7120\n",
      "Epoch 494/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.6858\n",
      "Epoch 495/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.0671\n",
      "Epoch 496/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.6218\n",
      "Epoch 497/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.3144\n",
      "Epoch 498/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.2835\n",
      "Epoch 499/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.5467\n",
      "Epoch 500/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.2901\n",
      "Epoch 501/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.7836\n",
      "Epoch 502/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.3348\n",
      "Epoch 503/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.3656\n",
      "Epoch 504/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.6125\n",
      "Epoch 505/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.5413\n",
      "Epoch 506/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.6771\n",
      "Epoch 507/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.5765\n",
      "Epoch 508/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.5734\n",
      "Epoch 509/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.2385\n",
      "Epoch 510/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.4391\n",
      "Epoch 511/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.4876\n",
      "Epoch 512/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.1133\n",
      "Epoch 513/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.3567\n",
      "Epoch 514/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.7290\n",
      "Epoch 515/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.1743\n",
      "Epoch 516/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.4134\n",
      "Epoch 517/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.1005\n",
      "Epoch 518/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.8488\n",
      "Epoch 519/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.6460\n",
      "Epoch 520/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.0600\n",
      "Epoch 521/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 12.3725\n",
      "Epoch 522/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 10.7192\n",
      "Epoch 523/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.7087\n",
      "Epoch 524/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.4629\n",
      "Epoch 525/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 11.4980\n",
      "Epoch 526/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.9739\n",
      "Epoch 527/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.9495\n",
      "Epoch 528/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.0127\n",
      "Epoch 529/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.0610\n",
      "Epoch 530/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.4714\n",
      "Epoch 531/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.6037\n",
      "Epoch 532/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.0044\n",
      "Epoch 533/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.0306\n",
      "Epoch 534/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.4813\n",
      "Epoch 535/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.8548\n",
      "Epoch 536/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2572\n",
      "Epoch 537/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.9643\n",
      "Epoch 538/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 12.2448\n",
      "Epoch 539/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.9670\n",
      "Epoch 540/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.6977\n",
      "Epoch 541/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.7509\n",
      "Epoch 542/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.6733\n",
      "Epoch 543/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 11.3134\n",
      "Epoch 544/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.0475\n",
      "Epoch 545/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.2455\n",
      "Epoch 546/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.8253\n",
      "Epoch 547/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.7192\n",
      "Epoch 548/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.7618\n",
      "Epoch 549/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.5299\n",
      "Epoch 550/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.4628\n",
      "Epoch 551/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.1173\n",
      "Epoch 552/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.9196\n",
      "Epoch 553/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2389\n",
      "Epoch 554/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.7261\n",
      "Epoch 555/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.4015\n",
      "Epoch 556/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.6362\n",
      "Epoch 557/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 10.2946\n",
      "Epoch 558/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.1822\n",
      "Epoch 559/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.1776\n",
      "Epoch 560/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 11.2834\n",
      "Epoch 561/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 12.5660\n",
      "Epoch 562/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.2205\n",
      "Epoch 563/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.0398\n",
      "Epoch 564/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.5042\n",
      "Epoch 565/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.5065\n",
      "Epoch 566/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9115\n",
      "Epoch 567/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.6083\n",
      "Epoch 568/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.6727\n",
      "Epoch 569/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.9753\n",
      "Epoch 570/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.1742\n",
      "Epoch 571/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.7547\n",
      "Epoch 572/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.0509\n",
      "Epoch 573/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.2915\n",
      "Epoch 574/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.6467\n",
      "Epoch 575/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.0453\n",
      "Epoch 576/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.6129\n",
      "Epoch 577/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.3346\n",
      "Epoch 578/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.1655\n",
      "Epoch 579/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.5618\n",
      "Epoch 580/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.9396\n",
      "Epoch 581/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.3522\n",
      "Epoch 582/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.4766\n",
      "Epoch 583/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.3469\n",
      "Epoch 584/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.6424\n",
      "Epoch 585/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.2692\n",
      "Epoch 586/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 12.1213\n",
      "Epoch 587/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.8115\n",
      "Epoch 588/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.4601\n",
      "Epoch 589/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.1784\n",
      "Epoch 590/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.7164\n",
      "Epoch 591/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.7615\n",
      "Epoch 592/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 12.2227\n",
      "Epoch 593/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.9899\n",
      "Epoch 594/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.0579\n",
      "Epoch 595/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.4724\n",
      "Epoch 596/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.4189\n",
      "Epoch 597/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.3782\n",
      "Epoch 598/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.8996\n",
      "Epoch 599/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.5186\n",
      "Epoch 600/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.7409\n",
      "Epoch 601/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.0250\n",
      "Epoch 602/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.2059\n",
      "Epoch 603/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.4419\n",
      "Epoch 604/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.2148\n",
      "Epoch 605/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.6297\n",
      "Epoch 606/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.0387\n",
      "Epoch 607/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 11.1914\n",
      "Epoch 608/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.5372\n",
      "Epoch 609/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.7545\n",
      "Epoch 610/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.3280\n",
      "Epoch 611/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.7232\n",
      "Epoch 612/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.2176\n",
      "Epoch 613/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 10.1093\n",
      "Epoch 614/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 11.7937\n",
      "Epoch 615/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.8921\n",
      "Epoch 616/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2947\n",
      "Epoch 617/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.9665\n",
      "Epoch 618/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.2647\n",
      "Epoch 619/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.3101\n",
      "Epoch 620/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 11.8307\n",
      "Epoch 621/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 10.7798\n",
      "Epoch 622/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 10.6493\n",
      "Epoch 623/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 10.2714\n",
      "Epoch 624/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.1263\n",
      "Epoch 625/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.2143\n",
      "Epoch 626/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.7942\n",
      "Epoch 627/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 11.2774\n",
      "Epoch 628/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.9575\n",
      "Epoch 629/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.2958\n",
      "Epoch 630/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.6821\n",
      "Epoch 631/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.6905\n",
      "Epoch 632/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.8920\n",
      "Epoch 633/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.3391\n",
      "Epoch 634/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.5072\n",
      "Epoch 635/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.5283\n",
      "Epoch 636/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.3386\n",
      "Epoch 637/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.8501\n",
      "Epoch 638/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 12.3748\n",
      "Epoch 639/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.6081\n",
      "Epoch 640/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.4424\n",
      "Epoch 641/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.7556\n",
      "Epoch 642/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.5599\n",
      "Epoch 643/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.4651\n",
      "Epoch 644/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.1388\n",
      "Epoch 645/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.2499\n",
      "Epoch 646/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.3523\n",
      "Epoch 647/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.3266\n",
      "Epoch 648/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.6231\n",
      "Epoch 649/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.8156\n",
      "Epoch 650/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.1962\n",
      "Epoch 651/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.6815\n",
      "Epoch 652/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.2246\n",
      "Epoch 653/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.1447\n",
      "Epoch 654/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.4440\n",
      "Epoch 655/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.8613\n",
      "Epoch 656/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.1563\n",
      "Epoch 657/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.8180\n",
      "Epoch 658/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 10.6769\n",
      "Epoch 659/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.1732\n",
      "Epoch 660/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.0231\n",
      "Epoch 661/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.5718\n",
      "Epoch 662/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.5604\n",
      "Epoch 663/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.0334\n",
      "Epoch 664/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.1381\n",
      "Epoch 665/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.7168\n",
      "Epoch 666/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.4072\n",
      "Epoch 667/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.6993\n",
      "Epoch 668/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.2760\n",
      "Epoch 669/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.3678\n",
      "Epoch 670/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.9534\n",
      "Epoch 671/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.2174\n",
      "Epoch 672/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.9675\n",
      "Epoch 673/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.0678\n",
      "Epoch 674/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.2887\n",
      "Epoch 675/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.8272\n",
      "Epoch 676/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.0129\n",
      "Epoch 677/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.4356\n",
      "Epoch 678/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.7709\n",
      "Epoch 679/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.7307\n",
      "Epoch 680/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.3827\n",
      "Epoch 681/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.5429\n",
      "Epoch 682/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 11.1336\n",
      "Epoch 683/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.5424\n",
      "Epoch 684/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 11.0669\n",
      "Epoch 685/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.4882\n",
      "Epoch 686/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.5160\n",
      "Epoch 687/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.4231\n",
      "Epoch 688/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 12.6644\n",
      "Epoch 689/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.6377\n",
      "Epoch 690/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.4244\n",
      "Epoch 691/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.2150\n",
      "Epoch 692/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 11.4201\n",
      "Epoch 693/2000\n",
      "1883/1883 [==============================] - 0s 8us/step - loss: 11.0453\n",
      "Epoch 694/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.8480\n",
      "Epoch 695/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.7717\n",
      "Epoch 696/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.5608\n",
      "Epoch 697/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.9638\n",
      "Epoch 698/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 11.3207\n",
      "Epoch 699/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.7163\n",
      "Epoch 700/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.3209\n",
      "Epoch 701/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.4195\n",
      "Epoch 702/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.6172\n",
      "Epoch 703/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.6009\n",
      "Epoch 704/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.8144\n",
      "Epoch 705/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.2548\n",
      "Epoch 706/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.3588\n",
      "Epoch 707/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.4088\n",
      "Epoch 708/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.7980\n",
      "Epoch 709/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.1841\n",
      "Epoch 710/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.6803\n",
      "Epoch 711/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.4077\n",
      "Epoch 712/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.1502\n",
      "Epoch 713/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 12.1889\n",
      "Epoch 714/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 11.2660\n",
      "Epoch 715/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 11.5612\n",
      "Epoch 716/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.3292\n",
      "Epoch 717/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.2473\n",
      "Epoch 718/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.4985\n",
      "Epoch 719/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.2635\n",
      "Epoch 720/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.0750\n",
      "Epoch 721/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.1006\n",
      "Epoch 722/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.2565\n",
      "Epoch 723/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.7928\n",
      "Epoch 724/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.1475\n",
      "Epoch 725/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2893\n",
      "Epoch 726/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 11.7562\n",
      "Epoch 727/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 11.0205\n",
      "Epoch 728/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.7828\n",
      "Epoch 729/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.5407\n",
      "Epoch 730/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 10.4623\n",
      "Epoch 731/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.8823\n",
      "Epoch 732/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.6011\n",
      "Epoch 733/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.7076\n",
      "Epoch 734/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.4021\n",
      "Epoch 735/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.0709\n",
      "Epoch 736/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.4984\n",
      "Epoch 737/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.2780\n",
      "Epoch 738/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.6465\n",
      "Epoch 739/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.7054\n",
      "Epoch 740/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 10.0700\n",
      "Epoch 741/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 12.2734\n",
      "Epoch 742/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.3923\n",
      "Epoch 743/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.7055\n",
      "Epoch 744/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.7501\n",
      "Epoch 745/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 10.5197\n",
      "Epoch 746/2000\n",
      "1883/1883 [==============================] - 0s 19us/step - loss: 10.3236\n",
      "Epoch 747/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 10.8689\n",
      "Epoch 748/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 10.8339\n",
      "Epoch 749/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 10.5309\n",
      "Epoch 750/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.9736\n",
      "Epoch 751/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.6323\n",
      "Epoch 752/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.0200\n",
      "Epoch 753/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.6469\n",
      "Epoch 754/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.9121\n",
      "Epoch 755/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.4837\n",
      "Epoch 756/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.6214\n",
      "Epoch 757/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.2116\n",
      "Epoch 758/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.4516\n",
      "Epoch 759/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.7334\n",
      "Epoch 760/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2340\n",
      "Epoch 761/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.5209\n",
      "Epoch 762/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 11.0698\n",
      "Epoch 763/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.7902\n",
      "Epoch 764/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.8241\n",
      "Epoch 765/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.5513\n",
      "Epoch 766/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.9765\n",
      "Epoch 767/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.0679\n",
      "Epoch 768/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.1701\n",
      "Epoch 769/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.3122\n",
      "Epoch 770/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.1166\n",
      "Epoch 771/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.9543\n",
      "Epoch 772/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.4987\n",
      "Epoch 773/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 12.1593\n",
      "Epoch 774/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.6308\n",
      "Epoch 775/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.7200\n",
      "Epoch 776/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.4573\n",
      "Epoch 777/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.0750\n",
      "Epoch 778/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.4436\n",
      "Epoch 779/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.2391\n",
      "Epoch 780/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.4252\n",
      "Epoch 781/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.3100\n",
      "Epoch 782/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.0236\n",
      "Epoch 783/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.1695\n",
      "Epoch 784/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9548\n",
      "Epoch 785/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2004\n",
      "Epoch 786/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1069\n",
      "Epoch 787/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.8764\n",
      "Epoch 788/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 11.1253\n",
      "Epoch 789/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.8559\n",
      "Epoch 790/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.1516\n",
      "Epoch 791/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.6931\n",
      "Epoch 792/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.1858\n",
      "Epoch 793/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.8568\n",
      "Epoch 794/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.1753\n",
      "Epoch 795/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.5046\n",
      "Epoch 796/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.1086\n",
      "Epoch 797/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.4965\n",
      "Epoch 798/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.8512\n",
      "Epoch 799/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.6194\n",
      "Epoch 800/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 13.0956\n",
      "Epoch 801/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.7364\n",
      "Epoch 802/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.9956\n",
      "Epoch 803/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.9513\n",
      "Epoch 804/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.2882\n",
      "Epoch 805/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.1334\n",
      "Epoch 806/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.7025\n",
      "Epoch 807/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.3587\n",
      "Epoch 808/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.2692\n",
      "Epoch 809/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.7519\n",
      "Epoch 810/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.3974\n",
      "Epoch 811/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.9440\n",
      "Epoch 812/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.4303\n",
      "Epoch 813/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.4052\n",
      "Epoch 814/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.3600\n",
      "Epoch 815/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.7704\n",
      "Epoch 816/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9300\n",
      "Epoch 817/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.7989\n",
      "Epoch 818/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.6598\n",
      "Epoch 819/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1551\n",
      "Epoch 820/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.8410\n",
      "Epoch 821/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.3040\n",
      "Epoch 822/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.3764\n",
      "Epoch 823/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.9316\n",
      "Epoch 824/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.3108\n",
      "Epoch 825/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.4731\n",
      "Epoch 826/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.7004\n",
      "Epoch 827/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.6063\n",
      "Epoch 828/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.5136\n",
      "Epoch 829/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.6322\n",
      "Epoch 830/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.2018\n",
      "Epoch 831/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.0385\n",
      "Epoch 832/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.1106\n",
      "Epoch 833/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.1307\n",
      "Epoch 834/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.6930\n",
      "Epoch 835/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.9695\n",
      "Epoch 836/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.2673\n",
      "Epoch 837/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.9332\n",
      "Epoch 838/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.7438\n",
      "Epoch 839/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.4586\n",
      "Epoch 840/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.2174\n",
      "Epoch 841/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.7867\n",
      "Epoch 842/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.0836\n",
      "Epoch 843/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.9254\n",
      "Epoch 844/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.0244\n",
      "Epoch 845/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.2865\n",
      "Epoch 846/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.1882\n",
      "Epoch 847/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.4048\n",
      "Epoch 848/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.9243\n",
      "Epoch 849/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.0321\n",
      "Epoch 850/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.9799\n",
      "Epoch 851/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.4170\n",
      "Epoch 852/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.4968\n",
      "Epoch 853/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.5388\n",
      "Epoch 854/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.5253\n",
      "Epoch 855/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.9909\n",
      "Epoch 856/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.6206\n",
      "Epoch 857/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.1670\n",
      "Epoch 858/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.3062\n",
      "Epoch 859/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.2384\n",
      "Epoch 860/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.9398\n",
      "Epoch 861/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.9037\n",
      "Epoch 862/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7976\n",
      "Epoch 863/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.0826\n",
      "Epoch 864/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.5857\n",
      "Epoch 865/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.5914\n",
      "Epoch 866/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1358\n",
      "Epoch 867/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.6556\n",
      "Epoch 868/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.1363\n",
      "Epoch 869/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.0290\n",
      "Epoch 870/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.1612\n",
      "Epoch 871/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 10.0323\n",
      "Epoch 872/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.0171\n",
      "Epoch 873/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.5516\n",
      "Epoch 874/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.3982\n",
      "Epoch 875/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.6972\n",
      "Epoch 876/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.2502\n",
      "Epoch 877/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2264\n",
      "Epoch 878/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 11.0356\n",
      "Epoch 879/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.5573\n",
      "Epoch 880/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.2363\n",
      "Epoch 881/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.9447\n",
      "Epoch 882/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.3467\n",
      "Epoch 883/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.6445\n",
      "Epoch 884/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6925\n",
      "Epoch 885/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.3530\n",
      "Epoch 886/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.5719\n",
      "Epoch 887/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.5669\n",
      "Epoch 888/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.7507\n",
      "Epoch 889/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.6450\n",
      "Epoch 890/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.1994\n",
      "Epoch 891/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.6480\n",
      "Epoch 892/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.9388\n",
      "Epoch 893/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.7083\n",
      "Epoch 894/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.5066\n",
      "Epoch 895/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.2167\n",
      "Epoch 896/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.0170\n",
      "Epoch 897/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.3008\n",
      "Epoch 898/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.6773\n",
      "Epoch 899/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.0801\n",
      "Epoch 900/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.2316\n",
      "Epoch 901/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.3082\n",
      "Epoch 902/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.7168\n",
      "Epoch 903/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.8064\n",
      "Epoch 904/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.1263\n",
      "Epoch 905/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.5371\n",
      "Epoch 906/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.6176\n",
      "Epoch 907/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1766\n",
      "Epoch 908/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4998\n",
      "Epoch 909/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.8531\n",
      "Epoch 910/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 10.9881\n",
      "Epoch 911/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.7958\n",
      "Epoch 912/2000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 10.0084\n",
      "Epoch 913/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 9.8454\n",
      "Epoch 914/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.6758\n",
      "Epoch 915/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.4122\n",
      "Epoch 916/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.4462\n",
      "Epoch 917/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.2554\n",
      "Epoch 918/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.4162\n",
      "Epoch 919/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.1449\n",
      "Epoch 920/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2560\n",
      "Epoch 921/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.9156\n",
      "Epoch 922/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 10.4171\n",
      "Epoch 923/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.1662\n",
      "Epoch 924/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2704\n",
      "Epoch 925/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.2808\n",
      "Epoch 926/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.4677\n",
      "Epoch 927/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.0583\n",
      "Epoch 928/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.8881\n",
      "Epoch 929/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.6787\n",
      "Epoch 930/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.7072\n",
      "Epoch 931/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.2414\n",
      "Epoch 932/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.8621\n",
      "Epoch 933/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.3643\n",
      "Epoch 934/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1406\n",
      "Epoch 935/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.0680\n",
      "Epoch 936/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.4212\n",
      "Epoch 937/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2675\n",
      "Epoch 938/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.3102\n",
      "Epoch 939/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.3254\n",
      "Epoch 940/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.1106\n",
      "Epoch 941/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.5855\n",
      "Epoch 942/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.3093\n",
      "Epoch 943/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.3074\n",
      "Epoch 944/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.2788\n",
      "Epoch 945/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.2323\n",
      "Epoch 946/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.3682\n",
      "Epoch 947/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.8741\n",
      "Epoch 948/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.5185\n",
      "Epoch 949/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.7522\n",
      "Epoch 950/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.7072\n",
      "Epoch 951/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.0335\n",
      "Epoch 952/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5173\n",
      "Epoch 953/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1471\n",
      "Epoch 954/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.2440\n",
      "Epoch 955/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.5556\n",
      "Epoch 956/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3815\n",
      "Epoch 957/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9824\n",
      "Epoch 958/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8684\n",
      "Epoch 959/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7346\n",
      "Epoch 960/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7450\n",
      "Epoch 961/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.2457\n",
      "Epoch 962/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9860\n",
      "Epoch 963/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.8633\n",
      "Epoch 964/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.0187\n",
      "Epoch 965/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.3352\n",
      "Epoch 966/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.5162\n",
      "Epoch 967/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5397\n",
      "Epoch 968/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3421\n",
      "Epoch 969/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.6382\n",
      "Epoch 970/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7986\n",
      "Epoch 971/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.0228\n",
      "Epoch 972/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.4501\n",
      "Epoch 973/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.1835\n",
      "Epoch 974/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2363\n",
      "Epoch 975/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1178\n",
      "Epoch 976/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 10.5943\n",
      "Epoch 977/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.2959\n",
      "Epoch 978/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.8833\n",
      "Epoch 979/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6988\n",
      "Epoch 980/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.0306\n",
      "Epoch 981/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.0580\n",
      "Epoch 982/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.1296\n",
      "Epoch 983/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.3567\n",
      "Epoch 984/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.3010\n",
      "Epoch 985/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.5163\n",
      "Epoch 986/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9367\n",
      "Epoch 987/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.6070\n",
      "Epoch 988/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.3982\n",
      "Epoch 989/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2004\n",
      "Epoch 990/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9781\n",
      "Epoch 991/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5343\n",
      "Epoch 992/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.6797\n",
      "Epoch 993/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.8766\n",
      "Epoch 994/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6230\n",
      "Epoch 995/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2444\n",
      "Epoch 996/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9281\n",
      "Epoch 997/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.7484\n",
      "Epoch 998/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.3235\n",
      "Epoch 999/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.3389\n",
      "Epoch 1000/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 12.0972\n",
      "Epoch 1001/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.8880\n",
      "Epoch 1002/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 11.5081\n",
      "Epoch 1003/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.5679\n",
      "Epoch 1004/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.5487\n",
      "Epoch 1005/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.5787\n",
      "Epoch 1006/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4121\n",
      "Epoch 1007/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2429\n",
      "Epoch 1008/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.1615\n",
      "Epoch 1009/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6448\n",
      "Epoch 1010/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.8813\n",
      "Epoch 1011/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7853\n",
      "Epoch 1012/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.9019\n",
      "Epoch 1013/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.5408\n",
      "Epoch 1014/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2224\n",
      "Epoch 1015/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.7122\n",
      "Epoch 1016/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.1812\n",
      "Epoch 1017/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.5804\n",
      "Epoch 1018/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.1084\n",
      "Epoch 1019/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.7501\n",
      "Epoch 1020/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.6760\n",
      "Epoch 1021/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.5440\n",
      "Epoch 1022/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.3422\n",
      "Epoch 1023/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.7466\n",
      "Epoch 1024/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.7455\n",
      "Epoch 1025/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.8075\n",
      "Epoch 1026/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.8522\n",
      "Epoch 1027/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.8361\n",
      "Epoch 1028/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.7482\n",
      "Epoch 1029/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.5277\n",
      "Epoch 1030/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.2620\n",
      "Epoch 1031/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.3255\n",
      "Epoch 1032/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 10.1692\n",
      "Epoch 1033/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.6223\n",
      "Epoch 1034/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.8372\n",
      "Epoch 1035/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.9450\n",
      "Epoch 1036/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 8.9227\n",
      "Epoch 1037/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.8385\n",
      "Epoch 1038/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.1874\n",
      "Epoch 1039/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3621\n",
      "Epoch 1040/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.6726\n",
      "Epoch 1041/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.7364\n",
      "Epoch 1042/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.1401\n",
      "Epoch 1043/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9883\n",
      "Epoch 1044/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.8038\n",
      "Epoch 1045/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.3674\n",
      "Epoch 1046/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.6086\n",
      "Epoch 1047/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.0187\n",
      "Epoch 1048/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.0734\n",
      "Epoch 1049/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4586\n",
      "Epoch 1050/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.4687\n",
      "Epoch 1051/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.0725\n",
      "Epoch 1052/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.4489\n",
      "Epoch 1053/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9993\n",
      "Epoch 1054/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.3244\n",
      "Epoch 1055/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8270\n",
      "Epoch 1056/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6140\n",
      "Epoch 1057/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.0429\n",
      "Epoch 1058/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.3477\n",
      "Epoch 1059/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9873\n",
      "Epoch 1060/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6558\n",
      "Epoch 1061/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.3239\n",
      "Epoch 1062/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.8176\n",
      "Epoch 1063/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.8537\n",
      "Epoch 1064/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.1672\n",
      "Epoch 1065/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3929\n",
      "Epoch 1066/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.3970\n",
      "Epoch 1067/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.0406\n",
      "Epoch 1068/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8255\n",
      "Epoch 1069/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7025\n",
      "Epoch 1070/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5831\n",
      "Epoch 1071/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.2411\n",
      "Epoch 1072/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8958\n",
      "Epoch 1073/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.5746\n",
      "Epoch 1074/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.9358\n",
      "Epoch 1075/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.0100\n",
      "Epoch 1076/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5608\n",
      "Epoch 1077/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8491\n",
      "Epoch 1078/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.5594\n",
      "Epoch 1079/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.5756\n",
      "Epoch 1080/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3741\n",
      "Epoch 1081/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2451\n",
      "Epoch 1082/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5029\n",
      "Epoch 1083/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5848\n",
      "Epoch 1084/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8750\n",
      "Epoch 1085/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9366\n",
      "Epoch 1086/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.2761\n",
      "Epoch 1087/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8825\n",
      "Epoch 1088/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.3679\n",
      "Epoch 1089/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8059\n",
      "Epoch 1090/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.1344\n",
      "Epoch 1091/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.5200\n",
      "Epoch 1092/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6944\n",
      "Epoch 1093/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9027\n",
      "Epoch 1094/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.3510\n",
      "Epoch 1095/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6294\n",
      "Epoch 1096/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6797\n",
      "Epoch 1097/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6238\n",
      "Epoch 1098/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.1600\n",
      "Epoch 1099/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.1172\n",
      "Epoch 1100/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.4112\n",
      "Epoch 1101/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9240\n",
      "Epoch 1102/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1764\n",
      "Epoch 1103/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.0539\n",
      "Epoch 1104/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4076\n",
      "Epoch 1105/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6761\n",
      "Epoch 1106/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4031\n",
      "Epoch 1107/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.2307\n",
      "Epoch 1108/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2954\n",
      "Epoch 1109/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.5800\n",
      "Epoch 1110/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8572\n",
      "Epoch 1111/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.5459\n",
      "Epoch 1112/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8117\n",
      "Epoch 1113/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.6231\n",
      "Epoch 1114/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.4435\n",
      "Epoch 1115/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0362\n",
      "Epoch 1116/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2466\n",
      "Epoch 1117/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4223\n",
      "Epoch 1118/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9320\n",
      "Epoch 1119/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.8351\n",
      "Epoch 1120/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1036\n",
      "Epoch 1121/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4075\n",
      "Epoch 1122/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7535\n",
      "Epoch 1123/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.8959\n",
      "Epoch 1124/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.7709\n",
      "Epoch 1125/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.2539\n",
      "Epoch 1126/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6240\n",
      "Epoch 1127/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8305\n",
      "Epoch 1128/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.7459\n",
      "Epoch 1129/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.7728\n",
      "Epoch 1130/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9561\n",
      "Epoch 1131/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0306\n",
      "Epoch 1132/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.0216\n",
      "Epoch 1133/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.3426\n",
      "Epoch 1134/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7420\n",
      "Epoch 1135/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6356\n",
      "Epoch 1136/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.2506\n",
      "Epoch 1137/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6378\n",
      "Epoch 1138/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.0419\n",
      "Epoch 1139/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3261\n",
      "Epoch 1140/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.3815\n",
      "Epoch 1141/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3688\n",
      "Epoch 1142/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5048\n",
      "Epoch 1143/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4166\n",
      "Epoch 1144/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.2948\n",
      "Epoch 1145/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1202\n",
      "Epoch 1146/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.7527\n",
      "Epoch 1147/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3323\n",
      "Epoch 1148/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7763\n",
      "Epoch 1149/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.8653\n",
      "Epoch 1150/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6620\n",
      "Epoch 1151/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0557\n",
      "Epoch 1152/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2102\n",
      "Epoch 1153/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.4640\n",
      "Epoch 1154/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.7622\n",
      "Epoch 1155/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.8147\n",
      "Epoch 1156/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.0051\n",
      "Epoch 1157/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1725\n",
      "Epoch 1158/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2619\n",
      "Epoch 1159/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.0116\n",
      "Epoch 1160/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.7194\n",
      "Epoch 1161/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.0469\n",
      "Epoch 1162/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.5614\n",
      "Epoch 1163/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9246\n",
      "Epoch 1164/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1706\n",
      "Epoch 1165/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9303\n",
      "Epoch 1166/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.3444\n",
      "Epoch 1167/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.0079\n",
      "Epoch 1168/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.6201\n",
      "Epoch 1169/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9546\n",
      "Epoch 1170/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6522\n",
      "Epoch 1171/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0599\n",
      "Epoch 1172/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1289\n",
      "Epoch 1173/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1542\n",
      "Epoch 1174/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3432\n",
      "Epoch 1175/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.3524\n",
      "Epoch 1176/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.4037\n",
      "Epoch 1177/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.9731\n",
      "Epoch 1178/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.6112\n",
      "Epoch 1179/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1823\n",
      "Epoch 1180/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.1630\n",
      "Epoch 1181/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.0580\n",
      "Epoch 1182/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.6517\n",
      "Epoch 1183/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.2199\n",
      "Epoch 1184/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0960\n",
      "Epoch 1185/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0407\n",
      "Epoch 1186/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.0825\n",
      "Epoch 1187/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.6233\n",
      "Epoch 1188/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.1535\n",
      "Epoch 1189/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7532\n",
      "Epoch 1190/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.0657\n",
      "Epoch 1191/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.9494\n",
      "Epoch 1192/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.0663\n",
      "Epoch 1193/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.4643\n",
      "Epoch 1194/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.1087\n",
      "Epoch 1195/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.8570\n",
      "Epoch 1196/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.2383\n",
      "Epoch 1197/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3344\n",
      "Epoch 1198/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7291\n",
      "Epoch 1199/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1275\n",
      "Epoch 1200/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.7238\n",
      "Epoch 1201/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9023\n",
      "Epoch 1202/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4412\n",
      "Epoch 1203/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.1182\n",
      "Epoch 1204/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6796\n",
      "Epoch 1205/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.3805\n",
      "Epoch 1206/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.2358\n",
      "Epoch 1207/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1687\n",
      "Epoch 1208/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.9673\n",
      "Epoch 1209/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2016\n",
      "Epoch 1210/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.8080\n",
      "Epoch 1211/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.5305\n",
      "Epoch 1212/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.9920\n",
      "Epoch 1213/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2963\n",
      "Epoch 1214/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1523\n",
      "Epoch 1215/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.6731\n",
      "Epoch 1216/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.0187\n",
      "Epoch 1217/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9001\n",
      "Epoch 1218/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9106\n",
      "Epoch 1219/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.3369\n",
      "Epoch 1220/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.9459\n",
      "Epoch 1221/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1320\n",
      "Epoch 1222/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5079\n",
      "Epoch 1223/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.9921\n",
      "Epoch 1224/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7022\n",
      "Epoch 1225/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.6079\n",
      "Epoch 1226/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7956\n",
      "Epoch 1227/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.3549\n",
      "Epoch 1228/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5676\n",
      "Epoch 1229/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.5963\n",
      "Epoch 1230/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5424\n",
      "Epoch 1231/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9774\n",
      "Epoch 1232/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0584\n",
      "Epoch 1233/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6081\n",
      "Epoch 1234/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.7063\n",
      "Epoch 1235/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8138\n",
      "Epoch 1236/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7383\n",
      "Epoch 1237/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.5813\n",
      "Epoch 1238/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5841\n",
      "Epoch 1239/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4815\n",
      "Epoch 1240/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.0569\n",
      "Epoch 1241/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4990\n",
      "Epoch 1242/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2874\n",
      "Epoch 1243/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.5828\n",
      "Epoch 1244/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2743\n",
      "Epoch 1245/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.0614\n",
      "Epoch 1246/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7078\n",
      "Epoch 1247/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6471\n",
      "Epoch 1248/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.0536\n",
      "Epoch 1249/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6932\n",
      "Epoch 1250/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7773\n",
      "Epoch 1251/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.6336\n",
      "Epoch 1252/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3136\n",
      "Epoch 1253/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.9935\n",
      "Epoch 1254/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1221\n",
      "Epoch 1255/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.1687\n",
      "Epoch 1256/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.8514\n",
      "Epoch 1257/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.5621\n",
      "Epoch 1258/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.4476\n",
      "Epoch 1259/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.7311\n",
      "Epoch 1260/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4565\n",
      "Epoch 1261/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8353\n",
      "Epoch 1262/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.7845\n",
      "Epoch 1263/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5845\n",
      "Epoch 1264/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.9007\n",
      "Epoch 1265/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4367\n",
      "Epoch 1266/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.7265\n",
      "Epoch 1267/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.5643\n",
      "Epoch 1268/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.8216\n",
      "Epoch 1269/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.4617\n",
      "Epoch 1270/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 8.9932\n",
      "Epoch 1271/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0292\n",
      "Epoch 1272/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.5648\n",
      "Epoch 1273/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2034\n",
      "Epoch 1274/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.5382\n",
      "Epoch 1275/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.9898\n",
      "Epoch 1276/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.7936\n",
      "Epoch 1277/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5243\n",
      "Epoch 1278/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9370\n",
      "Epoch 1279/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2606\n",
      "Epoch 1280/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1114\n",
      "Epoch 1281/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.7221\n",
      "Epoch 1282/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1155\n",
      "Epoch 1283/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.8397\n",
      "Epoch 1284/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6096\n",
      "Epoch 1285/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4910\n",
      "Epoch 1286/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8212\n",
      "Epoch 1287/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.9570\n",
      "Epoch 1288/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.3866\n",
      "Epoch 1289/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.4763\n",
      "Epoch 1290/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2643\n",
      "Epoch 1291/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9014\n",
      "Epoch 1292/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1087\n",
      "Epoch 1293/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.3195\n",
      "Epoch 1294/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.6253\n",
      "Epoch 1295/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9539\n",
      "Epoch 1296/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3254\n",
      "Epoch 1297/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.0956\n",
      "Epoch 1298/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1548\n",
      "Epoch 1299/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3406\n",
      "Epoch 1300/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5160\n",
      "Epoch 1301/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2017\n",
      "Epoch 1302/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6984\n",
      "Epoch 1303/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5542\n",
      "Epoch 1304/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.9264\n",
      "Epoch 1305/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.0811\n",
      "Epoch 1306/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.4224\n",
      "Epoch 1307/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.3224\n",
      "Epoch 1308/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6118\n",
      "Epoch 1309/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4509\n",
      "Epoch 1310/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7105\n",
      "Epoch 1311/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2734\n",
      "Epoch 1312/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4361\n",
      "Epoch 1313/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4073\n",
      "Epoch 1314/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7561\n",
      "Epoch 1315/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6435\n",
      "Epoch 1316/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.3470\n",
      "Epoch 1317/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2297\n",
      "Epoch 1318/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1433\n",
      "Epoch 1319/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.3491\n",
      "Epoch 1320/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.7280\n",
      "Epoch 1321/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2990\n",
      "Epoch 1322/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0573\n",
      "Epoch 1323/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.8237\n",
      "Epoch 1324/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.8914\n",
      "Epoch 1325/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.6869\n",
      "Epoch 1326/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5852\n",
      "Epoch 1327/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0783\n",
      "Epoch 1328/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.9218\n",
      "Epoch 1329/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.0978\n",
      "Epoch 1330/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 8.9438\n",
      "Epoch 1331/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0902\n",
      "Epoch 1332/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4626\n",
      "Epoch 1333/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.4620\n",
      "Epoch 1334/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0111\n",
      "Epoch 1335/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6901\n",
      "Epoch 1336/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4647\n",
      "Epoch 1337/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.9074\n",
      "Epoch 1338/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7678\n",
      "Epoch 1339/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.3090\n",
      "Epoch 1340/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.4448\n",
      "Epoch 1341/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.5706\n",
      "Epoch 1342/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.2141\n",
      "Epoch 1343/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.1855\n",
      "Epoch 1344/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.3043\n",
      "Epoch 1345/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.6213\n",
      "Epoch 1346/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.1184\n",
      "Epoch 1347/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.1767\n",
      "Epoch 1348/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6058\n",
      "Epoch 1349/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 8.9574\n",
      "Epoch 1350/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.8724\n",
      "Epoch 1351/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.2295\n",
      "Epoch 1352/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0750\n",
      "Epoch 1353/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 8.7877\n",
      "Epoch 1354/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.2330\n",
      "Epoch 1355/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.3649\n",
      "Epoch 1356/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.7849\n",
      "Epoch 1357/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.7948\n",
      "Epoch 1358/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.5436\n",
      "Epoch 1359/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.8164\n",
      "Epoch 1360/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.5490\n",
      "Epoch 1361/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9642\n",
      "Epoch 1362/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.0073\n",
      "Epoch 1363/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6121\n",
      "Epoch 1364/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.8705\n",
      "Epoch 1365/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.0903\n",
      "Epoch 1366/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1031\n",
      "Epoch 1367/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.1046\n",
      "Epoch 1368/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8680\n",
      "Epoch 1369/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.7140\n",
      "Epoch 1370/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3588\n",
      "Epoch 1371/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1967\n",
      "Epoch 1372/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2212\n",
      "Epoch 1373/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.1413\n",
      "Epoch 1374/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.8241\n",
      "Epoch 1375/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6988\n",
      "Epoch 1376/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3119\n",
      "Epoch 1377/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.8632\n",
      "Epoch 1378/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6433\n",
      "Epoch 1379/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6422\n",
      "Epoch 1380/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4784\n",
      "Epoch 1381/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4884\n",
      "Epoch 1382/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.5573\n",
      "Epoch 1383/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1866\n",
      "Epoch 1384/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.6574\n",
      "Epoch 1385/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.2358\n",
      "Epoch 1386/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 8.9578\n",
      "Epoch 1387/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.1293\n",
      "Epoch 1388/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.3330\n",
      "Epoch 1389/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.7120\n",
      "Epoch 1390/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.0418\n",
      "Epoch 1391/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.6192\n",
      "Epoch 1392/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9730\n",
      "Epoch 1393/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.4496\n",
      "Epoch 1394/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.5181\n",
      "Epoch 1395/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9107\n",
      "Epoch 1396/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.5959\n",
      "Epoch 1397/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3353\n",
      "Epoch 1398/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.8023\n",
      "Epoch 1399/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8102\n",
      "Epoch 1400/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9958\n",
      "Epoch 1401/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0171\n",
      "Epoch 1402/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7327\n",
      "Epoch 1403/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2255\n",
      "Epoch 1404/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.7933\n",
      "Epoch 1405/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.9361\n",
      "Epoch 1406/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.5639\n",
      "Epoch 1407/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2006\n",
      "Epoch 1408/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4121\n",
      "Epoch 1409/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1145\n",
      "Epoch 1410/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8445\n",
      "Epoch 1411/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6707\n",
      "Epoch 1412/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3723\n",
      "Epoch 1413/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2184\n",
      "Epoch 1414/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8476\n",
      "Epoch 1415/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2103\n",
      "Epoch 1416/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9571\n",
      "Epoch 1417/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.9213\n",
      "Epoch 1418/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1348\n",
      "Epoch 1419/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5125\n",
      "Epoch 1420/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 8.7148\n",
      "Epoch 1421/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.5659\n",
      "Epoch 1422/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.4112\n",
      "Epoch 1423/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 10.3348\n",
      "Epoch 1424/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.9087\n",
      "Epoch 1425/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.4710\n",
      "Epoch 1426/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.7738\n",
      "Epoch 1427/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 8.9985\n",
      "Epoch 1428/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 8.8059\n",
      "Epoch 1429/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.6714\n",
      "Epoch 1430/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.7589\n",
      "Epoch 1431/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.0169\n",
      "Epoch 1432/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.5876\n",
      "Epoch 1433/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2619\n",
      "Epoch 1434/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.3217\n",
      "Epoch 1435/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8794\n",
      "Epoch 1436/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3682\n",
      "Epoch 1437/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6462\n",
      "Epoch 1438/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.0809\n",
      "Epoch 1439/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4872\n",
      "Epoch 1440/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9189\n",
      "Epoch 1441/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.6901\n",
      "Epoch 1442/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.6276\n",
      "Epoch 1443/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3862\n",
      "Epoch 1444/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6570\n",
      "Epoch 1445/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.8157\n",
      "Epoch 1446/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 8.9088\n",
      "Epoch 1447/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.5729\n",
      "Epoch 1448/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.9177\n",
      "Epoch 1449/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.6399\n",
      "Epoch 1450/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.6196\n",
      "Epoch 1451/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.2450\n",
      "Epoch 1452/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.7276\n",
      "Epoch 1453/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.7643\n",
      "Epoch 1454/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.9274\n",
      "Epoch 1455/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4196\n",
      "Epoch 1456/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1051\n",
      "Epoch 1457/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5047\n",
      "Epoch 1458/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4315\n",
      "Epoch 1459/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7761\n",
      "Epoch 1460/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4186\n",
      "Epoch 1461/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1885\n",
      "Epoch 1462/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5792\n",
      "Epoch 1463/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6793\n",
      "Epoch 1464/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4528\n",
      "Epoch 1465/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3228\n",
      "Epoch 1466/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.4172\n",
      "Epoch 1467/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2454\n",
      "Epoch 1468/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0376\n",
      "Epoch 1469/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 8.9702\n",
      "Epoch 1470/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2011\n",
      "Epoch 1471/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9324\n",
      "Epoch 1472/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.4611\n",
      "Epoch 1473/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2463\n",
      "Epoch 1474/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1435\n",
      "Epoch 1475/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1592\n",
      "Epoch 1476/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1978\n",
      "Epoch 1477/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6922\n",
      "Epoch 1478/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.8906\n",
      "Epoch 1479/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4244\n",
      "Epoch 1480/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1180\n",
      "Epoch 1481/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1569\n",
      "Epoch 1482/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0378\n",
      "Epoch 1483/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.4636\n",
      "Epoch 1484/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3238\n",
      "Epoch 1485/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4996\n",
      "Epoch 1486/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.0249\n",
      "Epoch 1487/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2679\n",
      "Epoch 1488/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.0344\n",
      "Epoch 1489/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3856\n",
      "Epoch 1490/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6614\n",
      "Epoch 1491/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.0151\n",
      "Epoch 1492/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3081\n",
      "Epoch 1493/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.5980\n",
      "Epoch 1494/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5199\n",
      "Epoch 1495/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.5521\n",
      "Epoch 1496/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 8.9663\n",
      "Epoch 1497/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.9611\n",
      "Epoch 1498/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0453\n",
      "Epoch 1499/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3782\n",
      "Epoch 1500/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3094\n",
      "Epoch 1501/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.8734\n",
      "Epoch 1502/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.8257\n",
      "Epoch 1503/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3457\n",
      "Epoch 1504/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.3056\n",
      "Epoch 1505/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4781\n",
      "Epoch 1506/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3257\n",
      "Epoch 1507/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8162\n",
      "Epoch 1508/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3485\n",
      "Epoch 1509/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7450\n",
      "Epoch 1510/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.8320\n",
      "Epoch 1511/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1736\n",
      "Epoch 1512/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.8493\n",
      "Epoch 1513/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1685\n",
      "Epoch 1514/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6874\n",
      "Epoch 1515/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4260\n",
      "Epoch 1516/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.3164\n",
      "Epoch 1517/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.3835\n",
      "Epoch 1518/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6322\n",
      "Epoch 1519/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.4150\n",
      "Epoch 1520/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.3239\n",
      "Epoch 1521/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.2070\n",
      "Epoch 1522/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2002\n",
      "Epoch 1523/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.6710\n",
      "Epoch 1524/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.3739\n",
      "Epoch 1525/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.9377\n",
      "Epoch 1526/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5728\n",
      "Epoch 1527/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.3924\n",
      "Epoch 1528/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3603\n",
      "Epoch 1529/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.3452\n",
      "Epoch 1530/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8498\n",
      "Epoch 1531/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2365\n",
      "Epoch 1532/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4316\n",
      "Epoch 1533/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.9520\n",
      "Epoch 1534/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.0886\n",
      "Epoch 1535/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1992\n",
      "Epoch 1536/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.5218\n",
      "Epoch 1537/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2751\n",
      "Epoch 1538/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2117\n",
      "Epoch 1539/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4999\n",
      "Epoch 1540/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.0116\n",
      "Epoch 1541/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.0853\n",
      "Epoch 1542/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3635\n",
      "Epoch 1543/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.2068\n",
      "Epoch 1544/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.6414\n",
      "Epoch 1545/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1153\n",
      "Epoch 1546/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0548\n",
      "Epoch 1547/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.8886\n",
      "Epoch 1548/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2315\n",
      "Epoch 1549/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.9412\n",
      "Epoch 1550/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1813\n",
      "Epoch 1551/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8199\n",
      "Epoch 1552/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6201\n",
      "Epoch 1553/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2863\n",
      "Epoch 1554/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.0723\n",
      "Epoch 1555/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3487\n",
      "Epoch 1556/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.7725\n",
      "Epoch 1557/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0206\n",
      "Epoch 1558/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 8.6560\n",
      "Epoch 1559/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.6971\n",
      "Epoch 1560/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0249\n",
      "Epoch 1561/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.3543\n",
      "Epoch 1562/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.4454\n",
      "Epoch 1563/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.4830\n",
      "Epoch 1564/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.6166\n",
      "Epoch 1565/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.7157\n",
      "Epoch 1566/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.0780\n",
      "Epoch 1567/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.5111\n",
      "Epoch 1568/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.7790\n",
      "Epoch 1569/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.0780\n",
      "Epoch 1570/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5460\n",
      "Epoch 1571/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.7140\n",
      "Epoch 1572/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.5088\n",
      "Epoch 1573/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.0211\n",
      "Epoch 1574/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7483\n",
      "Epoch 1575/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4111\n",
      "Epoch 1576/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.5254\n",
      "Epoch 1577/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6819\n",
      "Epoch 1578/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2850\n",
      "Epoch 1579/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1369\n",
      "Epoch 1580/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.4412\n",
      "Epoch 1581/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4765\n",
      "Epoch 1582/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.7749\n",
      "Epoch 1583/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1228\n",
      "Epoch 1584/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.7379\n",
      "Epoch 1585/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5470\n",
      "Epoch 1586/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2752\n",
      "Epoch 1587/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.7288\n",
      "Epoch 1588/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6515\n",
      "Epoch 1589/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1450\n",
      "Epoch 1590/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2808\n",
      "Epoch 1591/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.7018\n",
      "Epoch 1592/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 8.8930\n",
      "Epoch 1593/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.1247\n",
      "Epoch 1594/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.5425\n",
      "Epoch 1595/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2965\n",
      "Epoch 1596/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1931\n",
      "Epoch 1597/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.9087\n",
      "Epoch 1598/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.9497\n",
      "Epoch 1599/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.8243\n",
      "Epoch 1600/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8043\n",
      "Epoch 1601/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.8607\n",
      "Epoch 1602/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.8672\n",
      "Epoch 1603/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2055\n",
      "Epoch 1604/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2651\n",
      "Epoch 1605/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4054\n",
      "Epoch 1606/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.8019\n",
      "Epoch 1607/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7906\n",
      "Epoch 1608/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.2727\n",
      "Epoch 1609/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9462\n",
      "Epoch 1610/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.9085\n",
      "Epoch 1611/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.3069\n",
      "Epoch 1612/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6334\n",
      "Epoch 1613/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.7165\n",
      "Epoch 1614/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.7364\n",
      "Epoch 1615/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 8.8974\n",
      "Epoch 1616/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.5846\n",
      "Epoch 1617/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.0996\n",
      "Epoch 1618/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.7975\n",
      "Epoch 1619/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.7151\n",
      "Epoch 1620/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.3063\n",
      "Epoch 1621/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.4689\n",
      "Epoch 1622/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.0878\n",
      "Epoch 1623/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.1876\n",
      "Epoch 1624/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.3772\n",
      "Epoch 1625/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.3710\n",
      "Epoch 1626/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 8.9542\n",
      "Epoch 1627/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.9923\n",
      "Epoch 1628/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 10.6331\n",
      "Epoch 1629/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 10.3647\n",
      "Epoch 1630/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 8.8215\n",
      "Epoch 1631/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.1994\n",
      "Epoch 1632/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.6842\n",
      "Epoch 1633/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.4983\n",
      "Epoch 1634/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.3348\n",
      "Epoch 1635/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.4804\n",
      "Epoch 1636/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.2067\n",
      "Epoch 1637/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.9962\n",
      "Epoch 1638/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4177\n",
      "Epoch 1639/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6763\n",
      "Epoch 1640/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.1432\n",
      "Epoch 1641/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0268\n",
      "Epoch 1642/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.9162\n",
      "Epoch 1643/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7336\n",
      "Epoch 1644/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.1543\n",
      "Epoch 1645/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.4826\n",
      "Epoch 1646/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9970\n",
      "Epoch 1647/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6383\n",
      "Epoch 1648/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2883\n",
      "Epoch 1649/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6701\n",
      "Epoch 1650/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.1841\n",
      "Epoch 1651/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6870\n",
      "Epoch 1652/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.7333\n",
      "Epoch 1653/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0051\n",
      "Epoch 1654/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1707\n",
      "Epoch 1655/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.2089\n",
      "Epoch 1656/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6604\n",
      "Epoch 1657/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.5465\n",
      "Epoch 1658/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1888\n",
      "Epoch 1659/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.7267\n",
      "Epoch 1660/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.5102\n",
      "Epoch 1661/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.0981\n",
      "Epoch 1662/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.1462\n",
      "Epoch 1663/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0811\n",
      "Epoch 1664/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7782\n",
      "Epoch 1665/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.0439\n",
      "Epoch 1666/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.2651\n",
      "Epoch 1667/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3823\n",
      "Epoch 1668/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.9086\n",
      "Epoch 1669/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.4884\n",
      "Epoch 1670/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.5818\n",
      "Epoch 1671/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.8033\n",
      "Epoch 1672/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.3646\n",
      "Epoch 1673/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.7746\n",
      "Epoch 1674/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.3368\n",
      "Epoch 1675/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7493\n",
      "Epoch 1676/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.6476\n",
      "Epoch 1677/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3170\n",
      "Epoch 1678/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2712\n",
      "Epoch 1679/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.0878\n",
      "Epoch 1680/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1734\n",
      "Epoch 1681/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9653\n",
      "Epoch 1682/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.5438\n",
      "Epoch 1683/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4644\n",
      "Epoch 1684/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.6394\n",
      "Epoch 1685/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.7102\n",
      "Epoch 1686/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2607\n",
      "Epoch 1687/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1189\n",
      "Epoch 1688/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3083\n",
      "Epoch 1689/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9085\n",
      "Epoch 1690/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3956\n",
      "Epoch 1691/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4518\n",
      "Epoch 1692/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7224\n",
      "Epoch 1693/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.5414\n",
      "Epoch 1694/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.8338\n",
      "Epoch 1695/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.5389\n",
      "Epoch 1696/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8264\n",
      "Epoch 1697/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9629\n",
      "Epoch 1698/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3617\n",
      "Epoch 1699/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7157\n",
      "Epoch 1700/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1160\n",
      "Epoch 1701/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.3315\n",
      "Epoch 1702/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3516\n",
      "Epoch 1703/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.6137\n",
      "Epoch 1704/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.2779\n",
      "Epoch 1705/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3708\n",
      "Epoch 1706/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2344\n",
      "Epoch 1707/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1390\n",
      "Epoch 1708/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0127\n",
      "Epoch 1709/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4846\n",
      "Epoch 1710/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8441\n",
      "Epoch 1711/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9190\n",
      "Epoch 1712/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 11.2764\n",
      "Epoch 1713/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.4609\n",
      "Epoch 1714/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.7332\n",
      "Epoch 1715/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4772\n",
      "Epoch 1716/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 8.9017\n",
      "Epoch 1717/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1438\n",
      "Epoch 1718/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.5044\n",
      "Epoch 1719/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4880\n",
      "Epoch 1720/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3405\n",
      "Epoch 1721/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.9790\n",
      "Epoch 1722/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.1404\n",
      "Epoch 1723/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4067\n",
      "Epoch 1724/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1412\n",
      "Epoch 1725/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1250\n",
      "Epoch 1726/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1712\n",
      "Epoch 1727/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.5476\n",
      "Epoch 1728/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4074\n",
      "Epoch 1729/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.1764\n",
      "Epoch 1730/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 9.3058\n",
      "Epoch 1731/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 9.3453\n",
      "Epoch 1732/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.4722\n",
      "Epoch 1733/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.2166\n",
      "Epoch 1734/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.0687\n",
      "Epoch 1735/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.6872\n",
      "Epoch 1736/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3165\n",
      "Epoch 1737/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1107\n",
      "Epoch 1738/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5595\n",
      "Epoch 1739/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.9279\n",
      "Epoch 1740/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.3341\n",
      "Epoch 1741/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1347\n",
      "Epoch 1742/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.9809\n",
      "Epoch 1743/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3952\n",
      "Epoch 1744/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.0742\n",
      "Epoch 1745/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1791\n",
      "Epoch 1746/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7251\n",
      "Epoch 1747/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.2486\n",
      "Epoch 1748/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.4265\n",
      "Epoch 1749/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.0066\n",
      "Epoch 1750/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.7457\n",
      "Epoch 1751/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.9379\n",
      "Epoch 1752/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 8.8648\n",
      "Epoch 1753/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 10.2347\n",
      "Epoch 1754/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.7346\n",
      "Epoch 1755/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 10.6489\n",
      "Epoch 1756/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.2882\n",
      "Epoch 1757/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3344\n",
      "Epoch 1758/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.9452\n",
      "Epoch 1759/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2528\n",
      "Epoch 1760/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3352\n",
      "Epoch 1761/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2656\n",
      "Epoch 1762/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.9138\n",
      "Epoch 1763/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1152\n",
      "Epoch 1764/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.8280\n",
      "Epoch 1765/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.0575\n",
      "Epoch 1766/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2571\n",
      "Epoch 1767/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.0208\n",
      "Epoch 1768/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 8.9564\n",
      "Epoch 1769/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0252\n",
      "Epoch 1770/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3014\n",
      "Epoch 1771/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.6155\n",
      "Epoch 1772/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.9512\n",
      "Epoch 1773/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.0466\n",
      "Epoch 1774/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.7193\n",
      "Epoch 1775/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2702\n",
      "Epoch 1776/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.7248\n",
      "Epoch 1777/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2938\n",
      "Epoch 1778/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 9.0277\n",
      "Epoch 1779/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.3246\n",
      "Epoch 1780/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.7311\n",
      "Epoch 1781/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.3781\n",
      "Epoch 1782/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.8093\n",
      "Epoch 1783/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.3089\n",
      "Epoch 1784/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.8925\n",
      "Epoch 1785/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6458\n",
      "Epoch 1786/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8780\n",
      "Epoch 1787/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4114\n",
      "Epoch 1788/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.9521\n",
      "Epoch 1789/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.6470\n",
      "Epoch 1790/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.6704\n",
      "Epoch 1791/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.9137\n",
      "Epoch 1792/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.5894\n",
      "Epoch 1793/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4244\n",
      "Epoch 1794/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.1225\n",
      "Epoch 1795/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.7526\n",
      "Epoch 1796/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6644\n",
      "Epoch 1797/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3581\n",
      "Epoch 1798/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.7674\n",
      "Epoch 1799/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0993\n",
      "Epoch 1800/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0507\n",
      "Epoch 1801/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.2268\n",
      "Epoch 1802/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.0986\n",
      "Epoch 1803/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.7402\n",
      "Epoch 1804/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.6352\n",
      "Epoch 1805/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.3187\n",
      "Epoch 1806/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 9.4282\n",
      "Epoch 1807/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.3158\n",
      "Epoch 1808/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0397\n",
      "Epoch 1809/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 8.6504\n",
      "Epoch 1810/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 10.3298\n",
      "Epoch 1811/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.2829\n",
      "Epoch 1812/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.5028\n",
      "Epoch 1813/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.0358\n",
      "Epoch 1814/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 8.8398\n",
      "Epoch 1815/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 8.8771\n",
      "Epoch 1816/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.8965\n",
      "Epoch 1817/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.2140\n",
      "Epoch 1818/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.1094\n",
      "Epoch 1819/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.3818\n",
      "Epoch 1820/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3788\n",
      "Epoch 1821/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3043\n",
      "Epoch 1822/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.9871\n",
      "Epoch 1823/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.6038\n",
      "Epoch 1824/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4523\n",
      "Epoch 1825/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 8.7253\n",
      "Epoch 1826/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.8087\n",
      "Epoch 1827/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1193\n",
      "Epoch 1828/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.0445\n",
      "Epoch 1829/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8789\n",
      "Epoch 1830/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0994\n",
      "Epoch 1831/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.1789\n",
      "Epoch 1832/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 8.6501\n",
      "Epoch 1833/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.8507\n",
      "Epoch 1834/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.4465\n",
      "Epoch 1835/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 8.7050\n",
      "Epoch 1836/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0147\n",
      "Epoch 1837/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.2786\n",
      "Epoch 1838/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.4877\n",
      "Epoch 1839/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0977\n",
      "Epoch 1840/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6361\n",
      "Epoch 1841/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.6875\n",
      "Epoch 1842/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.4327\n",
      "Epoch 1843/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.1167\n",
      "Epoch 1844/2000\n",
      "1883/1883 [==============================] - 0s 19us/step - loss: 9.3834\n",
      "Epoch 1845/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 9.3081\n",
      "Epoch 1846/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 8.8590\n",
      "Epoch 1847/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 8.8758\n",
      "Epoch 1848/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 8.9680\n",
      "Epoch 1849/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.4091\n",
      "Epoch 1850/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1882\n",
      "Epoch 1851/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.5859\n",
      "Epoch 1852/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3292\n",
      "Epoch 1853/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6014\n",
      "Epoch 1854/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.3408\n",
      "Epoch 1855/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.3666\n",
      "Epoch 1856/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.6677\n",
      "Epoch 1857/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.4728\n",
      "Epoch 1858/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.2760\n",
      "Epoch 1859/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.0889\n",
      "Epoch 1860/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.0071\n",
      "Epoch 1861/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 8.6480\n",
      "Epoch 1862/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3498\n",
      "Epoch 1863/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.7177\n",
      "Epoch 1864/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1910\n",
      "Epoch 1865/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.9239\n",
      "Epoch 1866/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 8.9860\n",
      "Epoch 1867/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3500\n",
      "Epoch 1868/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.7820\n",
      "Epoch 1869/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.2913\n",
      "Epoch 1870/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.1977\n",
      "Epoch 1871/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1350\n",
      "Epoch 1872/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.9520\n",
      "Epoch 1873/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.7403\n",
      "Epoch 1874/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4670\n",
      "Epoch 1875/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3558\n",
      "Epoch 1876/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.3839\n",
      "Epoch 1877/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.1861\n",
      "Epoch 1878/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.2812\n",
      "Epoch 1879/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.5059\n",
      "Epoch 1880/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6719\n",
      "Epoch 1881/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0031\n",
      "Epoch 1882/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0721\n",
      "Epoch 1883/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.0805\n",
      "Epoch 1884/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9683\n",
      "Epoch 1885/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.4514\n",
      "Epoch 1886/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 8.6959\n",
      "Epoch 1887/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7828\n",
      "Epoch 1888/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.7071\n",
      "Epoch 1889/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 8.9306\n",
      "Epoch 1890/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.8097\n",
      "Epoch 1891/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.0620\n",
      "Epoch 1892/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 9.9150\n",
      "Epoch 1893/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 8.5599\n",
      "Epoch 1894/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 10.9378\n",
      "Epoch 1895/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.8248\n",
      "Epoch 1896/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 8.9712\n",
      "Epoch 1897/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.0639\n",
      "Epoch 1898/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.0094\n",
      "Epoch 1899/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.3608\n",
      "Epoch 1900/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0897\n",
      "Epoch 1901/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.1423\n",
      "Epoch 1902/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.6773\n",
      "Epoch 1903/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.5841\n",
      "Epoch 1904/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3784\n",
      "Epoch 1905/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.4028\n",
      "Epoch 1906/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0942\n",
      "Epoch 1907/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.2910\n",
      "Epoch 1908/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.5739\n",
      "Epoch 1909/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.6136\n",
      "Epoch 1910/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.3352\n",
      "Epoch 1911/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.1531\n",
      "Epoch 1912/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 9.0478\n",
      "Epoch 1913/2000\n",
      "1883/1883 [==============================] - 0s 19us/step - loss: 9.2877\n",
      "Epoch 1914/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 9.6542\n",
      "Epoch 1915/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 9.3466\n",
      "Epoch 1916/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 9.8083\n",
      "Epoch 1917/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 9.5199\n",
      "Epoch 1918/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 9.5053\n",
      "Epoch 1919/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.5499\n",
      "Epoch 1920/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.6445\n",
      "Epoch 1921/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.5618\n",
      "Epoch 1922/2000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 9.3441\n",
      "Epoch 1923/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.0683\n",
      "Epoch 1924/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.1540\n",
      "Epoch 1925/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.4929\n",
      "Epoch 1926/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.1093\n",
      "Epoch 1927/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 8.9719\n",
      "Epoch 1928/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.5868\n",
      "Epoch 1929/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1197\n",
      "Epoch 1930/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.5044\n",
      "Epoch 1931/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.0250\n",
      "Epoch 1932/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 8.8515\n",
      "Epoch 1933/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 9.6351\n",
      "Epoch 1934/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.7723\n",
      "Epoch 1935/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 8.8282\n",
      "Epoch 1936/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.5372\n",
      "Epoch 1937/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.1174\n",
      "Epoch 1938/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.2658\n",
      "Epoch 1939/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 8.9333\n",
      "Epoch 1940/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7276\n",
      "Epoch 1941/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7860\n",
      "Epoch 1942/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.3452\n",
      "Epoch 1943/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 8.9679\n",
      "Epoch 1944/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 8.5024\n",
      "Epoch 1945/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1232\n",
      "Epoch 1946/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5004\n",
      "Epoch 1947/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 8.6711\n",
      "Epoch 1948/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4052\n",
      "Epoch 1949/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.0898\n",
      "Epoch 1950/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.0563\n",
      "Epoch 1951/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.2494\n",
      "Epoch 1952/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.2797\n",
      "Epoch 1953/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.1498\n",
      "Epoch 1954/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.2844\n",
      "Epoch 1955/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.5849\n",
      "Epoch 1956/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.1924\n",
      "Epoch 1957/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.4735\n",
      "Epoch 1958/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.3566\n",
      "Epoch 1959/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0275\n",
      "Epoch 1960/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.6721\n",
      "Epoch 1961/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 8.8515\n",
      "Epoch 1962/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.0081\n",
      "Epoch 1963/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.1387\n",
      "Epoch 1964/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6839\n",
      "Epoch 1965/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4111\n",
      "Epoch 1966/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.9936\n",
      "Epoch 1967/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.8383\n",
      "Epoch 1968/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2103\n",
      "Epoch 1969/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0775\n",
      "Epoch 1970/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4560\n",
      "Epoch 1971/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.8317\n",
      "Epoch 1972/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.3457\n",
      "Epoch 1973/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.0279\n",
      "Epoch 1974/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.7517\n",
      "Epoch 1975/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.6161\n",
      "Epoch 1976/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.2696\n",
      "Epoch 1977/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9087\n",
      "Epoch 1978/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9905\n",
      "Epoch 1979/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.0642\n",
      "Epoch 1980/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3144\n",
      "Epoch 1981/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.4687\n",
      "Epoch 1982/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 9.5586\n",
      "Epoch 1983/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.2065\n",
      "Epoch 1984/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 8.3978\n",
      "Epoch 1985/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.6667\n",
      "Epoch 1986/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3179\n",
      "Epoch 1987/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.0962\n",
      "Epoch 1988/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9537\n",
      "Epoch 1989/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.8112\n",
      "Epoch 1990/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.8620\n",
      "Epoch 1991/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.2588\n",
      "Epoch 1992/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.6898\n",
      "Epoch 1993/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 8.8233\n",
      "Epoch 1994/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.4978\n",
      "Epoch 1995/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.7550\n",
      "Epoch 1996/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0712\n",
      "Epoch 1997/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.0425\n",
      "Epoch 1998/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.9102\n",
      "Epoch 1999/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.5259\n",
      "Epoch 2000/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a21fd02e8>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(X_train), np.array(y_train), epochs=2000,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.5)\n",
    "gbr.fit(X_train,y_train)\n",
    "gbr_predictions = gbr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "925"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = pd.DataFrame(predictions)\n",
    "testing.columns=['NN_predictions']\n",
    "testing['actual'] = y_test.reset_index()['points']\n",
    "testing['GBR_predictions']=gbr_predictions\n",
    "testing['LY_scoring']=X_test['points_ly'].reset_index()['points_ly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN_predictions</th>\n",
       "      <th>actual</th>\n",
       "      <th>GBR_predictions</th>\n",
       "      <th>LY_scoring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15.283444</td>\n",
       "      <td>15.3</td>\n",
       "      <td>14.516847</td>\n",
       "      <td>14.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14.103240</td>\n",
       "      <td>10.5</td>\n",
       "      <td>14.099980</td>\n",
       "      <td>13.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11.281839</td>\n",
       "      <td>13.9</td>\n",
       "      <td>10.685212</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.453426</td>\n",
       "      <td>18.1</td>\n",
       "      <td>16.879166</td>\n",
       "      <td>14.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12.845493</td>\n",
       "      <td>10.4</td>\n",
       "      <td>10.433422</td>\n",
       "      <td>11.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.046763</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.291565</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>14.779439</td>\n",
       "      <td>16.4</td>\n",
       "      <td>14.648856</td>\n",
       "      <td>11.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>11.931538</td>\n",
       "      <td>10.5</td>\n",
       "      <td>12.772061</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13.435926</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.681255</td>\n",
       "      <td>16.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.925048</td>\n",
       "      <td>11.3</td>\n",
       "      <td>7.854545</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8.910604</td>\n",
       "      <td>11.7</td>\n",
       "      <td>9.842944</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>17.523033</td>\n",
       "      <td>14.5</td>\n",
       "      <td>15.890389</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>10.565738</td>\n",
       "      <td>12.7</td>\n",
       "      <td>10.659031</td>\n",
       "      <td>11.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>16.035282</td>\n",
       "      <td>12.4</td>\n",
       "      <td>16.672945</td>\n",
       "      <td>15.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>9.803998</td>\n",
       "      <td>12.7</td>\n",
       "      <td>12.584754</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>25.908287</td>\n",
       "      <td>27.8</td>\n",
       "      <td>23.186448</td>\n",
       "      <td>26.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>22.340355</td>\n",
       "      <td>20.8</td>\n",
       "      <td>24.286563</td>\n",
       "      <td>22.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>17.920033</td>\n",
       "      <td>14.6</td>\n",
       "      <td>16.895189</td>\n",
       "      <td>15.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>10.142896</td>\n",
       "      <td>11.9</td>\n",
       "      <td>13.753258</td>\n",
       "      <td>14.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>13.075540</td>\n",
       "      <td>12.6</td>\n",
       "      <td>11.465363</td>\n",
       "      <td>11.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>11.311777</td>\n",
       "      <td>13.1</td>\n",
       "      <td>12.167192</td>\n",
       "      <td>13.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>15.829757</td>\n",
       "      <td>15.3</td>\n",
       "      <td>17.367826</td>\n",
       "      <td>15.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>16.286255</td>\n",
       "      <td>17.1</td>\n",
       "      <td>15.695024</td>\n",
       "      <td>16.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>7.572212</td>\n",
       "      <td>10.2</td>\n",
       "      <td>6.895618</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>12.045840</td>\n",
       "      <td>12.8</td>\n",
       "      <td>13.036567</td>\n",
       "      <td>12.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>11.553383</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.239090</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>16.152723</td>\n",
       "      <td>13.2</td>\n",
       "      <td>14.517524</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>14.932577</td>\n",
       "      <td>22.3</td>\n",
       "      <td>13.086471</td>\n",
       "      <td>13.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>12.202775</td>\n",
       "      <td>14.9</td>\n",
       "      <td>12.199773</td>\n",
       "      <td>14.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>21.435497</td>\n",
       "      <td>18.7</td>\n",
       "      <td>22.396933</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>28.460144</td>\n",
       "      <td>27.4</td>\n",
       "      <td>23.764332</td>\n",
       "      <td>25.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>20.701866</td>\n",
       "      <td>23.4</td>\n",
       "      <td>21.576183</td>\n",
       "      <td>23.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>33.339657</td>\n",
       "      <td>28.1</td>\n",
       "      <td>25.656534</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>10.005443</td>\n",
       "      <td>11.9</td>\n",
       "      <td>10.782804</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>18.116749</td>\n",
       "      <td>14.6</td>\n",
       "      <td>18.183768</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>3.026304</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.055545</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>8.367245</td>\n",
       "      <td>12.2</td>\n",
       "      <td>8.308007</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>11.824998</td>\n",
       "      <td>12.8</td>\n",
       "      <td>11.105087</td>\n",
       "      <td>13.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>14.050852</td>\n",
       "      <td>12.5</td>\n",
       "      <td>15.478805</td>\n",
       "      <td>15.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>9.036853</td>\n",
       "      <td>12.6</td>\n",
       "      <td>8.383171</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>17.167614</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.563543</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>12.499917</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.822861</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>15.968613</td>\n",
       "      <td>15.2</td>\n",
       "      <td>15.406704</td>\n",
       "      <td>15.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>15.381042</td>\n",
       "      <td>19.2</td>\n",
       "      <td>14.875178</td>\n",
       "      <td>14.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>13.535957</td>\n",
       "      <td>14.5</td>\n",
       "      <td>12.936219</td>\n",
       "      <td>11.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>18.421551</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.147993</td>\n",
       "      <td>19.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>18.703278</td>\n",
       "      <td>19.8</td>\n",
       "      <td>17.775089</td>\n",
       "      <td>16.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>14.546153</td>\n",
       "      <td>15.4</td>\n",
       "      <td>12.709203</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>7.178511</td>\n",
       "      <td>10.3</td>\n",
       "      <td>7.084979</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>9.885945</td>\n",
       "      <td>11.4</td>\n",
       "      <td>8.917404</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>21.451355</td>\n",
       "      <td>24.4</td>\n",
       "      <td>23.864063</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>10.839400</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.730935</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>16.047104</td>\n",
       "      <td>19.1</td>\n",
       "      <td>13.790432</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>10.224899</td>\n",
       "      <td>13.3</td>\n",
       "      <td>10.901404</td>\n",
       "      <td>13.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>9.780862</td>\n",
       "      <td>14.1</td>\n",
       "      <td>11.102448</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>13.691684</td>\n",
       "      <td>12.6</td>\n",
       "      <td>13.541561</td>\n",
       "      <td>13.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>10.779433</td>\n",
       "      <td>13.9</td>\n",
       "      <td>12.380741</td>\n",
       "      <td>14.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>7.683003</td>\n",
       "      <td>11.8</td>\n",
       "      <td>8.215904</td>\n",
       "      <td>13.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>13.076087</td>\n",
       "      <td>12.3</td>\n",
       "      <td>12.636612</td>\n",
       "      <td>12.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>10.323735</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.421279</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>315 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     NN_predictions  actual  GBR_predictions  LY_scoring\n",
       "7         15.283444    15.3        14.516847        14.2\n",
       "11        14.103240    10.5        14.099980        13.3\n",
       "12        11.281839    13.9        10.685212        11.5\n",
       "14        15.453426    18.1        16.879166        14.3\n",
       "15        12.845493    10.4        10.433422        11.3\n",
       "16         6.046763    14.0         7.291565         7.0\n",
       "20        14.779439    16.4        14.648856        11.7\n",
       "21        11.931538    10.5        12.772061        13.5\n",
       "23        13.435926    15.0        17.681255        16.9\n",
       "24         3.925048    11.3         7.854545         2.0\n",
       "28         8.910604    11.7         9.842944         6.2\n",
       "29        17.523033    14.5        15.890389        18.8\n",
       "32        10.565738    12.7        10.659031        11.7\n",
       "33        16.035282    12.4        16.672945        15.3\n",
       "40         9.803998    12.7        12.584754        14.0\n",
       "41        25.908287    27.8        23.186448        26.9\n",
       "44        22.340355    20.8        24.286563        22.5\n",
       "45        17.920033    14.6        16.895189        15.9\n",
       "48        10.142896    11.9        13.753258        14.2\n",
       "50        13.075540    12.6        11.465363        11.3\n",
       "51        11.311777    13.1        12.167192        13.8\n",
       "53        15.829757    15.3        17.367826        15.9\n",
       "54        16.286255    17.1        15.695024        16.7\n",
       "55         7.572212    10.2         6.895618         9.8\n",
       "56        12.045840    12.8        13.036567        12.7\n",
       "57        11.553383    12.0        11.239090         9.7\n",
       "60        16.152723    13.2        14.517524        14.0\n",
       "61        14.932577    22.3        13.086471        13.8\n",
       "64        12.202775    14.9        12.199773        14.3\n",
       "67        21.435497    18.7        22.396933        24.0\n",
       "..              ...     ...              ...         ...\n",
       "729       28.460144    27.4        23.764332        25.4\n",
       "732       20.701866    23.4        21.576183        23.2\n",
       "734       33.339657    28.1        25.656534        28.0\n",
       "735       10.005443    11.9        10.782804         7.9\n",
       "736       18.116749    14.6        18.183768        18.2\n",
       "740        3.026304    13.0         5.055545         2.6\n",
       "745        8.367245    12.2         8.308007         9.7\n",
       "756       11.824998    12.8        11.105087        13.1\n",
       "757       14.050852    12.5        15.478805        15.9\n",
       "758        9.036853    12.6         8.383171         8.8\n",
       "761       17.167614    16.0        17.563543        17.9\n",
       "765       12.499917    12.0        13.822861         8.8\n",
       "768       15.968613    15.2        15.406704        15.2\n",
       "770       15.381042    19.2        14.875178        14.8\n",
       "771       13.535957    14.5        12.936219        11.7\n",
       "772       18.421551    19.8        19.147993        19.6\n",
       "773       18.703278    19.8        17.775089        16.2\n",
       "774       14.546153    15.4        12.709203        13.0\n",
       "776        7.178511    10.3         7.084979         7.8\n",
       "780        9.885945    11.4         8.917404        11.1\n",
       "782       21.451355    24.4        23.864063        20.8\n",
       "784       10.839400    14.0         9.730935         9.1\n",
       "785       16.047104    19.1        13.790432        14.0\n",
       "789       10.224899    13.3        10.901404        13.9\n",
       "791        9.780862    14.1        11.102448        13.5\n",
       "794       13.691684    12.6        13.541561        13.7\n",
       "799       10.779433    13.9        12.380741        14.9\n",
       "802        7.683003    11.8         8.215904        13.7\n",
       "804       13.076087    12.3        12.636612        12.1\n",
       "805       10.323735    12.0        11.421279        11.9\n",
       "\n",
       "[315 rows x 4 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing[testing['actual']>10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1019    17.8\n",
       "3307     2.9\n",
       "3489     7.3\n",
       "3242     3.1\n",
       "1007     9.4\n",
       "2765     4.7\n",
       "2357    18.8\n",
       "3002     5.9\n",
       "2866    11.0\n",
       "2709    14.0\n",
       "3055     6.3\n",
       "1366     7.5\n",
       "3278    12.8\n",
       "3452     5.9\n",
       "1985    12.2\n",
       "2903    12.7\n",
       "715     17.8\n",
       "754      2.2\n",
       "3450     7.2\n",
       "1322    19.5\n",
       "Name: points_ly, dtype: float64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['points_ly'][0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17.844143 ],\n",
       "       [ 4.58346  ],\n",
       "       [10.279707 ],\n",
       "       [ 4.779441 ],\n",
       "       [11.738732 ],\n",
       "       [ 4.8977976],\n",
       "       [20.338715 ],\n",
       "       [ 5.509632 ],\n",
       "       [11.4254465],\n",
       "       [13.024121 ],\n",
       "       [ 4.4234757],\n",
       "       [ 5.667042 ],\n",
       "       [13.13639  ],\n",
       "       [ 3.2999768],\n",
       "       [12.733069 ],\n",
       "       [12.993856 ],\n",
       "       [17.7858   ],\n",
       "       [ 3.7786436],\n",
       "       [ 7.8413477],\n",
       "       [16.594303 ]], dtype=float32)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     17.877944\n",
       "1      3.451549\n",
       "2     10.258897\n",
       "3      5.205964\n",
       "4     11.953578\n",
       "5      4.218924\n",
       "6     18.235270\n",
       "7      5.317524\n",
       "8     10.236510\n",
       "9     13.238273\n",
       "10     5.274126\n",
       "11     6.293032\n",
       "12    11.519619\n",
       "13     4.620900\n",
       "14    14.934067\n",
       "15    13.272919\n",
       "16    16.929187\n",
       "17     4.078159\n",
       "18     8.473781\n",
       "19    17.592289\n",
       "dtype: float64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2017points = players[players['season']==2017].drop(['season','team','player','points'],axis=1)\n",
    "points_2017 = model.predict(pred_2017points)\n",
    "test_2 =pd.DataFrame(points_2017)\n",
    "test_3 = pd.merge(players,pred_2017points,left_index=True,right_index=True).reset_index()\n",
    "test_3['predictions']=test_2[0]\n",
    "test_3[['player','points','points_ly_x','predictions']].sort_values(by='points_ly_x',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09999954, 0.18079444, 0.05630521, 0.068424  , 0.00065053,\n",
       "       0.02123672, 0.02468731, 0.00082807, 0.02697013, 0.02809122,\n",
       "       0.02346993, 0.03004118, 0.04160092, 0.0432922 , 0.0426422 ,\n",
       "       0.02623327, 0.04604534, 0.03923624, 0.02557597, 0.03005844,\n",
       "       0.05530913, 0.0830102 , 0.00549783])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'points_ly', 'change_points_ly', 'starter_change',\n",
       "       'high_usageplayer_added', 'usagemin_opened', 'maxusage_added',\n",
       "       'high_usageplayer_dropped', 'points_opened', 'max_pointsdropped',\n",
       "       'max_pointsadded', 'three_ar_ly', 'change_3ar', 'per_ly', 'change_per',\n",
       "       'usagerank', 'usagerank_ly', 'offensive_winshares',\n",
       "       'offensive_boxplusminus', 'boxplusminus', 'value_overreplacement',\n",
       "       'career_points', 'yearspro'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''next is rebounds'''\n",
    "\n",
    "\n",
    "query= '''\n",
    "        \n",
    "        DROP TABLE IF EXISTS rebounds_pred;\n",
    "        CREATE TABLE rebounds_pred(\n",
    "        season int, --these come from player_stats\n",
    "        player varchar(50),\n",
    "        Age int,\n",
    "        team varchar(50),\n",
    "        rebounds float, -- these come from player_stats\n",
    "        rebounds_ly float,\n",
    "        change_rebounds_ly float,\n",
    "        C_PF int,\n",
    "        PG int,\n",
    "        SG_SF int,\n",
    "        starter_change int, \n",
    "        \n",
    "        -- these come from team_changes\n",
    "        high_usageplayer_added int,\n",
    "        usagemin_opened float,\n",
    "        maxusage_added float,\n",
    "        high_usageplayer_dropped int,\n",
    "        rebounds_opened float,\n",
    "        max_reboundsdropped float,\n",
    "        max_reboundsadded float,\n",
    "        \n",
    "        -- from player_advstats\n",
    "        per_ly float,\n",
    "        change_per float,\n",
    "        usagerank float,\n",
    "        usagerank_ly float,\n",
    "        reb_perc_ly float,\n",
    "        change_reb_perc float,\n",
    "        defensive_winshares float,\n",
    "        defensive_boxplusminus float,\n",
    "        boxplusminus float,\n",
    "        value_overreplacement float,\n",
    "        \n",
    "        career_rebounds float,\n",
    "        yearspro int\n",
    "        );\n",
    "        \n",
    "        INSERT INTO rebounds_pred(season,player,age,team,rebounds,rebounds_ly,change_rebounds_ly,starter_change,C_PF,PG,SG_SF)\n",
    "        SELECT season,player,age,startingteam,rebounds,rebounds_ly,change_reb_ly,starter-starter_ly,\n",
    "        case when pos in ('C','PF') then 1 else 0 end,case when pos='PG' then 1 else 0 end,case when pos in('SG','SF') then 1 else 0 end from player_stats;\n",
    "        \n",
    "        update rebounds_pred rp\n",
    "        set high_usageplayer_added = tc.high_usageplayer_added,usagemin_opened=tc.usagemin_opened,\n",
    "        maxusage_added=tc.max_usageadded,high_usageplayer_dropped=tc.high_usageplayer_dropped,rebounds_opened=tc.rebounds_opened,\n",
    "        max_reboundsdropped=tc.max_reboundsdropped,max_reboundsadded=tc.max_reboundsadded\n",
    "        from team_changes tc\n",
    "        where tc.team = rp.team and rp.season=tc.season;\n",
    "        \n",
    "        update rebounds_pred rp\n",
    "        set per_ly=pa.per_ly,change_per=pa.change_per,usagerank=pa.usagerank,usagerank_ly=pa.usagerank_ly\n",
    "        ,reb_perc_ly = pa.reb_perc_ly,change_reb_perc = pa.change_reb_perc,defensive_winshares=pa.defensive_winshares,\n",
    "        defensive_boxplusminus=pa.defensive_boxplusminus,boxplusminus=pa.boxplusminus,value_overreplacement=pa.value_overreplacement\n",
    "        from player_advstats pa\n",
    "        where rp.player = pa.player and rp.season = pa.season and rp.team = pa.startingteam;\n",
    "        \n",
    "        update rebounds_pred rp\n",
    "        set career_rebounds = pc.career_rebounds, yearspro = pc.yearspro\n",
    "        from player_careerstats pc\n",
    "        where rp.player = pc.player and rp.season = pc.season;\n",
    "        \n",
    "        \n",
    "        select * from rebounds_pred where season>2009\n",
    "        '''\n",
    "\n",
    "\n",
    "cur.execute(query)\n",
    "data = cur.fetchall()\n",
    "rebounds_df = pd.DataFrame(np.array(data))\n",
    "rebounds_df.columns = ['season','player','age','team','rebounds','rebounds_ly','change_rebounds_ly','C_PF','PG','SG_SF','starter_change','high_usageplayer_added','usagemin_opened','maxusage_added','high_usageplayer_dropped','rebounds_opened','max_reboundsdropped',\n",
    "                    'max_reboundsadded','per_ly','change_per','usagerank','usagerank_ly','reb_perc_ly','change_reb_perc','defensive_winshares','defensive_boxplusminus','boxplusminus','value_overreplacement','career_rebounds','yearspro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>player</th>\n",
       "      <th>age</th>\n",
       "      <th>team</th>\n",
       "      <th>rebounds</th>\n",
       "      <th>rebounds_ly</th>\n",
       "      <th>change_rebounds_ly</th>\n",
       "      <th>C_PF</th>\n",
       "      <th>PG</th>\n",
       "      <th>SG_SF</th>\n",
       "      <th>...</th>\n",
       "      <th>usagerank_ly</th>\n",
       "      <th>reb_perc_ly</th>\n",
       "      <th>change_reb_perc</th>\n",
       "      <th>defensive_winshares</th>\n",
       "      <th>defensive_boxplusminus</th>\n",
       "      <th>boxplusminus</th>\n",
       "      <th>value_overreplacement</th>\n",
       "      <th>career_rebounds</th>\n",
       "      <th>yearspro</th>\n",
       "      <th>age_squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>Jalen Jones</td>\n",
       "      <td>24</td>\n",
       "      <td>DAL</td>\n",
       "      <td>2.9</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>Jakob Poeltl</td>\n",
       "      <td>21</td>\n",
       "      <td>TOR</td>\n",
       "      <td>3.1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>Xavier Henry</td>\n",
       "      <td>19</td>\n",
       "      <td>MEM</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>Xavier Silas</td>\n",
       "      <td>24</td>\n",
       "      <td>PHI</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>Zach Collins</td>\n",
       "      <td>20</td>\n",
       "      <td>POR</td>\n",
       "      <td>3.3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  season        player age team rebounds rebounds_ly change_rebounds_ly C_PF  \\\n",
       "0   2017   Jalen Jones  24  DAL      2.9        None               None    0   \n",
       "1   2016  Jakob Poeltl  21  TOR      3.1        None               None    1   \n",
       "2   2010  Xavier Henry  19  MEM        1        None               None    0   \n",
       "3   2011  Xavier Silas  24  PHI        2        None               None    0   \n",
       "4   2017  Zach Collins  20  POR      3.3        None               None    1   \n",
       "\n",
       "  PG SG_SF     ...     usagerank_ly reb_perc_ly change_reb_perc  \\\n",
       "0  0     1     ...                1        None            None   \n",
       "1  0     0     ...                1        None            None   \n",
       "2  0     1     ...                1        None            None   \n",
       "3  0     1     ...                1        None            None   \n",
       "4  0     0     ...                1        None            None   \n",
       "\n",
       "  defensive_winshares defensive_boxplusminus boxplusminus  \\\n",
       "0                None                   None         None   \n",
       "1                None                   None         None   \n",
       "2                None                   None         None   \n",
       "3                None                   None         None   \n",
       "4                None                   None         None   \n",
       "\n",
       "  value_overreplacement career_rebounds yearspro age_squared  \n",
       "0                  None            None     None         576  \n",
       "1                  None            None     None         441  \n",
       "2                  None            None     None         361  \n",
       "3                  None            None     None         576  \n",
       "4                  None            None     None         400  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rebounds_df['age_squared']=rebounds_df['age']*rebounds_df['age']\n",
    "rebounds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "rebounds = rebounds_df[rebounds_df['rebounds_ly'].notna()]\n",
    "for i in rebounds.columns:\n",
    "    if i not in(['player','team']):\n",
    "        rebounds[i]=pd.to_numeric(rebounds[i])\n",
    "rebounds = rebounds.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2157, 28)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rebounds[rebounds['season']!=2017].drop(['player','team','rebounds'],axis=1)\n",
    "y = rebounds[rebounds['season']!=2017]['rebounds']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>age</th>\n",
       "      <th>rebounds_ly</th>\n",
       "      <th>change_rebounds_ly</th>\n",
       "      <th>C_PF</th>\n",
       "      <th>PG</th>\n",
       "      <th>SG_SF</th>\n",
       "      <th>starter_change</th>\n",
       "      <th>high_usageplayer_added</th>\n",
       "      <th>usagemin_opened</th>\n",
       "      <th>...</th>\n",
       "      <th>usagerank_ly</th>\n",
       "      <th>reb_perc_ly</th>\n",
       "      <th>change_reb_perc</th>\n",
       "      <th>defensive_winshares</th>\n",
       "      <th>defensive_boxplusminus</th>\n",
       "      <th>boxplusminus</th>\n",
       "      <th>value_overreplacement</th>\n",
       "      <th>career_rebounds</th>\n",
       "      <th>yearspro</th>\n",
       "      <th>age_squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>2013</td>\n",
       "      <td>30</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1116.111055</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3529</th>\n",
       "      <td>2014</td>\n",
       "      <td>31</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>569.066630</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.383333</td>\n",
       "      <td>6</td>\n",
       "      <td>961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3155</th>\n",
       "      <td>2014</td>\n",
       "      <td>29</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1160.408003</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>6.975000</td>\n",
       "      <td>4</td>\n",
       "      <td>841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>2017</td>\n",
       "      <td>26</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>2016</td>\n",
       "      <td>38</td>\n",
       "      <td>6.5</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1043.974025</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>11.4</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>8</td>\n",
       "      <td>1444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      season  age  rebounds_ly  change_rebounds_ly  C_PF  PG  SG_SF  \\\n",
       "2395    2013   30          3.1                 0.8     0   1      0   \n",
       "3529    2014   31          1.1                 0.8     0   0      1   \n",
       "3155    2014   29          8.7                 0.1     1   0      0   \n",
       "853     2017   26          4.0                 0.0     1   0      0   \n",
       "1992    2016   38          6.5                -0.6     1   0      0   \n",
       "\n",
       "      starter_change  high_usageplayer_added  usagemin_opened     ...       \\\n",
       "2395               0                     0.0     -1116.111055     ...        \n",
       "3529               0                     0.0       569.066630     ...        \n",
       "3155               0                     0.0      1160.408003     ...        \n",
       "853                0                     0.0         0.000000     ...        \n",
       "1992               0                     0.0      1043.974025     ...        \n",
       "\n",
       "      usagerank_ly  reb_perc_ly  change_reb_perc  defensive_winshares  \\\n",
       "2395          10.0          5.7              1.1                  1.8   \n",
       "3529           4.0          6.3             -0.9                  0.5   \n",
       "3155          11.0         15.3              0.6                  1.5   \n",
       "853            6.0         13.3              1.8                  1.9   \n",
       "1992          18.0         11.4             -0.4                  2.6   \n",
       "\n",
       "      defensive_boxplusminus  boxplusminus  value_overreplacement  \\\n",
       "2395                    -1.4          -0.4                    1.0   \n",
       "3529                    -1.7          -0.5                    0.2   \n",
       "3155                    -1.2           0.2                    0.9   \n",
       "853                      1.9           1.4                    1.2   \n",
       "1992                    -0.3           0.9                    1.7   \n",
       "\n",
       "      career_rebounds  yearspro  age_squared  \n",
       "2395         3.000000         5          900  \n",
       "3529         1.383333         6          961  \n",
       "3155         6.975000         4          841  \n",
       "853          3.333333         3          676  \n",
       "1992         6.900000         8         1444  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1883/1883 [==============================] - 1s 492us/step - loss: 21.1961\n",
      "Epoch 2/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 20.1284\n",
      "Epoch 3/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 18.9002\n",
      "Epoch 4/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 17.2254\n",
      "Epoch 5/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 15.2758\n",
      "Epoch 6/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 13.1476\n",
      "Epoch 7/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 10.9907\n",
      "Epoch 8/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 8.9988\n",
      "Epoch 9/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 7.5508\n",
      "Epoch 10/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 6.8509\n",
      "Epoch 11/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.5938\n",
      "Epoch 12/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 6.5308\n",
      "Epoch 13/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.4753\n",
      "Epoch 14/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 6.4449\n",
      "Epoch 15/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 6.4237\n",
      "Epoch 16/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.4043\n",
      "Epoch 17/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.3874\n",
      "Epoch 18/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.3771\n",
      "Epoch 19/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 6.3730\n",
      "Epoch 20/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.3666\n",
      "Epoch 21/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.3530\n",
      "Epoch 22/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.3291\n",
      "Epoch 23/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.3215\n",
      "Epoch 24/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.3165\n",
      "Epoch 25/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.3139\n",
      "Epoch 26/1000\n",
      "1883/1883 [==============================] - 0s 19us/step - loss: 6.3133\n",
      "Epoch 27/1000\n",
      "1883/1883 [==============================] - 0s 19us/step - loss: 6.3106\n",
      "Epoch 28/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 6.3169\n",
      "Epoch 29/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.3124\n",
      "Epoch 30/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 6.3072\n",
      "Epoch 31/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 6.3073\n",
      "Epoch 32/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.3010\n",
      "Epoch 33/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.2942\n",
      "Epoch 34/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.2860\n",
      "Epoch 35/1000\n",
      "1883/1883 [==============================] - 0s 21us/step - loss: 6.2852\n",
      "Epoch 36/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.2799\n",
      "Epoch 37/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 6.2729\n",
      "Epoch 38/1000\n",
      "1883/1883 [==============================] - 0s 19us/step - loss: 6.2656\n",
      "Epoch 39/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 6.2629\n",
      "Epoch 40/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.2615\n",
      "Epoch 41/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.2681\n",
      "Epoch 42/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.2478\n",
      "Epoch 43/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.2734\n",
      "Epoch 44/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.2766\n",
      "Epoch 45/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.2742\n",
      "Epoch 46/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.2719\n",
      "Epoch 47/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 6.2599\n",
      "Epoch 48/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.2587\n",
      "Epoch 49/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.2564\n",
      "Epoch 50/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.2518\n",
      "Epoch 51/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 6.2471\n",
      "Epoch 52/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 6.2525\n",
      "Epoch 53/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 6.2508\n",
      "Epoch 54/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 6.2438\n",
      "Epoch 55/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 6.2384\n",
      "Epoch 56/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 6.2475\n",
      "Epoch 57/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.2404\n",
      "Epoch 58/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 6.2398\n",
      "Epoch 59/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 6.2397\n",
      "Epoch 60/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.2433\n",
      "Epoch 61/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.2463\n",
      "Epoch 62/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.2412\n",
      "Epoch 63/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 6.2344\n",
      "Epoch 64/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.2351\n",
      "Epoch 65/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.2324\n",
      "Epoch 66/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 6.2365\n",
      "Epoch 67/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 6.2297\n",
      "Epoch 68/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.2406\n",
      "Epoch 69/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 6.2494\n",
      "Epoch 70/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.2469\n",
      "Epoch 71/1000\n",
      "1883/1883 [==============================] - 0s 19us/step - loss: 6.2440\n",
      "Epoch 72/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.2449\n",
      "Epoch 73/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.2403\n",
      "Epoch 74/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 6.2450\n",
      "Epoch 75/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 6.2431\n",
      "Epoch 76/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.2236\n",
      "Epoch 77/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 6.2164\n",
      "Epoch 78/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.2252\n",
      "Epoch 79/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 6.2215\n",
      "Epoch 80/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 6.2140\n",
      "Epoch 81/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.2222\n",
      "Epoch 82/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.2037\n",
      "Epoch 83/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 6.2079\n",
      "Epoch 84/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.2060\n",
      "Epoch 85/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.2034\n",
      "Epoch 86/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 6.2070\n",
      "Epoch 87/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 6.1987\n",
      "Epoch 88/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 6.2002\n",
      "Epoch 89/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 6.1957\n",
      "Epoch 90/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 6.1937\n",
      "Epoch 91/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.1954\n",
      "Epoch 92/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 6.2006\n",
      "Epoch 93/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 6.1906\n",
      "Epoch 94/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 6.1956\n",
      "Epoch 95/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.1884\n",
      "Epoch 96/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.1825\n",
      "Epoch 97/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.1798\n",
      "Epoch 98/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.1841\n",
      "Epoch 99/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.1778\n",
      "Epoch 100/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.1790\n",
      "Epoch 101/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 6.1762\n",
      "Epoch 102/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 6.1773\n",
      "Epoch 103/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.1702\n",
      "Epoch 104/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 6.1638\n",
      "Epoch 105/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 6.1636\n",
      "Epoch 106/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.1671\n",
      "Epoch 107/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 6.1617\n",
      "Epoch 108/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 6.1772\n",
      "Epoch 109/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 6.1742\n",
      "Epoch 110/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.1632\n",
      "Epoch 111/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 6.1509\n",
      "Epoch 112/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.1570\n",
      "Epoch 113/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.1598\n",
      "Epoch 114/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.1645\n",
      "Epoch 115/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.1471\n",
      "Epoch 116/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.1483\n",
      "Epoch 117/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.1461\n",
      "Epoch 118/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 6.1351\n",
      "Epoch 119/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 6.1369\n",
      "Epoch 120/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.1344\n",
      "Epoch 121/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 6.1402\n",
      "Epoch 122/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.1345\n",
      "Epoch 123/1000\n",
      "1883/1883 [==============================] - 0s 19us/step - loss: 6.1276\n",
      "Epoch 124/1000\n",
      "1883/1883 [==============================] - 0s 20us/step - loss: 6.1192\n",
      "Epoch 125/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 6.1363\n",
      "Epoch 126/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 6.1214\n",
      "Epoch 127/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.1280\n",
      "Epoch 128/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.1387\n",
      "Epoch 129/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 6.1405\n",
      "Epoch 130/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.1312\n",
      "Epoch 131/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.1383\n",
      "Epoch 132/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 6.1306\n",
      "Epoch 133/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 6.1217\n",
      "Epoch 134/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 6.1317\n",
      "Epoch 135/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.1113\n",
      "Epoch 136/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 6.1141\n",
      "Epoch 137/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 6.1071\n",
      "Epoch 138/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 6.0946\n",
      "Epoch 139/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 6.1218\n",
      "Epoch 140/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.1250\n",
      "Epoch 141/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 6.1025\n",
      "Epoch 142/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.1027\n",
      "Epoch 143/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.1033\n",
      "Epoch 144/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.0912\n",
      "Epoch 145/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.1025\n",
      "Epoch 146/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.1058\n",
      "Epoch 147/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 6.1279\n",
      "Epoch 148/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.1049\n",
      "Epoch 149/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.0951\n",
      "Epoch 150/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 6.0962\n",
      "Epoch 151/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.0923\n",
      "Epoch 152/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.0966\n",
      "Epoch 153/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.0885\n",
      "Epoch 154/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.1042\n",
      "Epoch 155/1000\n",
      "1883/1883 [==============================] - 0s 19us/step - loss: 6.0995\n",
      "Epoch 156/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.1141\n",
      "Epoch 157/1000\n",
      "1883/1883 [==============================] - 0s 19us/step - loss: 6.1033\n",
      "Epoch 158/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.0946\n",
      "Epoch 159/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.0876\n",
      "Epoch 160/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.1005\n",
      "Epoch 161/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.0956\n",
      "Epoch 162/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 6.0960\n",
      "Epoch 163/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.1312\n",
      "Epoch 164/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 6.1567\n",
      "Epoch 165/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 6.1260\n",
      "Epoch 166/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.0997\n",
      "Epoch 167/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 6.1026\n",
      "Epoch 168/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 6.0819\n",
      "Epoch 169/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.0765\n",
      "Epoch 170/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 6.0946\n",
      "Epoch 171/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 6.1004\n",
      "Epoch 172/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.0865\n",
      "Epoch 173/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.0898\n",
      "Epoch 174/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.0815\n",
      "Epoch 175/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.0744\n",
      "Epoch 176/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.0734\n",
      "Epoch 177/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 6.0626\n",
      "Epoch 178/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.0685\n",
      "Epoch 179/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.0689\n",
      "Epoch 180/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 6.0680\n",
      "Epoch 181/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 6.0676\n",
      "Epoch 182/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.0787\n",
      "Epoch 183/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.0683\n",
      "Epoch 184/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 6.0745\n",
      "Epoch 185/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 6.0778\n",
      "Epoch 186/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 6.0558\n",
      "Epoch 187/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.0470\n",
      "Epoch 188/1000\n",
      "1883/1883 [==============================] - 0s 19us/step - loss: 6.0746\n",
      "Epoch 189/1000\n",
      "1883/1883 [==============================] - 0s 21us/step - loss: 6.0640\n",
      "Epoch 190/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 6.0576\n",
      "Epoch 191/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.0598\n",
      "Epoch 192/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 6.0385\n",
      "Epoch 193/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 6.0348\n",
      "Epoch 194/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 6.0332\n",
      "Epoch 195/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 6.0590\n",
      "Epoch 196/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 6.0448\n",
      "Epoch 197/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 6.0555\n",
      "Epoch 198/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 6.0302\n",
      "Epoch 199/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 6.0377\n",
      "Epoch 200/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 6.0064\n",
      "Epoch 201/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 5.9923\n",
      "Epoch 202/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 5.9939\n",
      "Epoch 203/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 5.9915\n",
      "Epoch 204/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 5.9882\n",
      "Epoch 205/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.0080\n",
      "Epoch 206/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 6.0302\n",
      "Epoch 207/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 6.0263\n",
      "Epoch 208/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 6.0306\n",
      "Epoch 209/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 6.0245\n",
      "Epoch 210/1000\n",
      "1883/1883 [==============================] - 0s 19us/step - loss: 6.0191\n",
      "Epoch 211/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.0096\n",
      "Epoch 212/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 6.0223\n",
      "Epoch 213/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.0087\n",
      "Epoch 214/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 6.0046\n",
      "Epoch 215/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 5.9911\n",
      "Epoch 216/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 5.9941\n",
      "Epoch 217/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 5.9898\n",
      "Epoch 218/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 5.9900\n",
      "Epoch 219/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 5.9741\n",
      "Epoch 220/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 6.0039\n",
      "Epoch 221/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 5.9844\n",
      "Epoch 222/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 5.9512\n",
      "Epoch 223/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 5.9433\n",
      "Epoch 224/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 5.9441\n",
      "Epoch 225/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 5.9675\n",
      "Epoch 226/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 5.9960\n",
      "Epoch 227/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 6.0105\n",
      "Epoch 228/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.0052\n",
      "Epoch 229/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.0102\n",
      "Epoch 230/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 5.9794\n",
      "Epoch 231/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 6.0204\n",
      "Epoch 232/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 5.9954\n",
      "Epoch 233/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 5.9623\n",
      "Epoch 234/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 5.9579\n",
      "Epoch 235/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 5.9523\n",
      "Epoch 236/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 5.9579\n",
      "Epoch 237/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 5.9253\n",
      "Epoch 238/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 5.9681\n",
      "Epoch 239/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 5.9456\n",
      "Epoch 240/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 5.9706\n",
      "Epoch 241/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 5.9879\n",
      "Epoch 242/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 5.9776\n",
      "Epoch 243/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 5.9784\n",
      "Epoch 244/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 5.9824\n",
      "Epoch 245/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 5.9877\n",
      "Epoch 246/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 5.9424\n",
      "Epoch 247/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 5.9604\n",
      "Epoch 248/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 5.9328\n",
      "Epoch 249/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 5.9251\n",
      "Epoch 250/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 5.9163\n",
      "Epoch 251/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 5.9144\n",
      "Epoch 252/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 5.9207\n",
      "Epoch 253/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 5.9421\n",
      "Epoch 254/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 5.9220\n",
      "Epoch 255/1000\n",
      "1883/1883 [==============================] - 0s 20us/step - loss: 5.9391\n",
      "Epoch 256/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 5.9347\n",
      "Epoch 257/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 5.9238\n",
      "Epoch 258/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 5.9006\n",
      "Epoch 259/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 5.8980\n",
      "Epoch 260/1000\n",
      "1883/1883 [==============================] - 0s 19us/step - loss: 5.9223\n",
      "Epoch 261/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 5.9022\n",
      "Epoch 262/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 5.8863\n",
      "Epoch 263/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 5.8902\n",
      "Epoch 264/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 5.8960\n",
      "Epoch 265/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 5.8706\n",
      "Epoch 266/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 5.8602\n",
      "Epoch 267/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 5.8636\n",
      "Epoch 268/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 5.8662\n",
      "Epoch 269/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 5.8925\n",
      "Epoch 270/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 5.9014\n",
      "Epoch 271/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 5.8747\n",
      "Epoch 272/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 5.8642\n",
      "Epoch 273/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 5.8515\n",
      "Epoch 274/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 5.8172\n",
      "Epoch 275/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 5.8373\n",
      "Epoch 276/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 5.8188\n",
      "Epoch 277/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 5.8571\n",
      "Epoch 278/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 5.9087\n",
      "Epoch 279/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 5.8725\n",
      "Epoch 280/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 5.8640\n",
      "Epoch 281/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 5.8232\n",
      "Epoch 282/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 5.8089\n",
      "Epoch 283/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 5.7916\n",
      "Epoch 284/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 5.7841\n",
      "Epoch 285/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 5.7613\n",
      "Epoch 286/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 5.7754\n",
      "Epoch 287/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 5.7841\n",
      "Epoch 288/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 5.8199\n",
      "Epoch 289/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 5.7920\n",
      "Epoch 290/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 5.7692\n",
      "Epoch 291/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 5.7091\n",
      "Epoch 292/1000\n",
      "1883/1883 [==============================] - 0s 21us/step - loss: 5.7224\n",
      "Epoch 293/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 5.7600\n",
      "Epoch 294/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 5.8160\n",
      "Epoch 295/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 5.7098\n",
      "Epoch 296/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 5.7438\n",
      "Epoch 297/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 5.7084\n",
      "Epoch 298/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 5.6987\n",
      "Epoch 299/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 5.6237\n",
      "Epoch 300/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 5.5839\n",
      "Epoch 301/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 5.6329\n",
      "Epoch 302/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 5.5765\n",
      "Epoch 303/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 5.5792\n",
      "Epoch 304/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 5.5853\n",
      "Epoch 305/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 5.5992\n",
      "Epoch 306/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 5.5299\n",
      "Epoch 307/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 5.4908\n",
      "Epoch 308/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 5.5244\n",
      "Epoch 309/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 5.5007\n",
      "Epoch 310/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 5.5012\n",
      "Epoch 311/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 5.4926\n",
      "Epoch 312/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 5.4762\n",
      "Epoch 313/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 5.4908\n",
      "Epoch 314/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 5.4664\n",
      "Epoch 315/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 5.4443\n",
      "Epoch 316/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 5.4698\n",
      "Epoch 317/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 5.3914\n",
      "Epoch 318/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 5.4384\n",
      "Epoch 319/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 5.3971\n",
      "Epoch 320/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 5.4614\n",
      "Epoch 321/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 5.3589\n",
      "Epoch 322/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 5.3483\n",
      "Epoch 323/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 5.3054\n",
      "Epoch 324/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 5.2548\n",
      "Epoch 325/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 5.2869\n",
      "Epoch 326/1000\n",
      "1883/1883 [==============================] - 0s 19us/step - loss: 5.2817\n",
      "Epoch 327/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 5.1959\n",
      "Epoch 328/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 5.2406\n",
      "Epoch 329/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 5.2335\n",
      "Epoch 330/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 5.1993\n",
      "Epoch 331/1000\n",
      "1883/1883 [==============================] - 0s 19us/step - loss: 5.1393\n",
      "Epoch 332/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 5.1016\n",
      "Epoch 333/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 5.1005\n",
      "Epoch 334/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 5.0784\n",
      "Epoch 335/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 5.1710\n",
      "Epoch 336/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 5.0620\n",
      "Epoch 337/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 5.0299\n",
      "Epoch 338/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 4.9541\n",
      "Epoch 339/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 4.9118\n",
      "Epoch 340/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 4.9263\n",
      "Epoch 341/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 4.9423\n",
      "Epoch 342/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 4.8756\n",
      "Epoch 343/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 4.9726\n",
      "Epoch 344/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 4.9257\n",
      "Epoch 345/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 4.9760\n",
      "Epoch 346/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 4.8335\n",
      "Epoch 347/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 4.7018\n",
      "Epoch 348/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 4.6695\n",
      "Epoch 349/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 4.6573\n",
      "Epoch 350/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 4.5668\n",
      "Epoch 351/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 4.5471\n",
      "Epoch 352/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 4.5366\n",
      "Epoch 353/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 4.5761\n",
      "Epoch 354/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 4.5264\n",
      "Epoch 355/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 4.5702\n",
      "Epoch 356/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 4.5260\n",
      "Epoch 357/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 4.4821\n",
      "Epoch 358/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 4.3806\n",
      "Epoch 359/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 4.3352\n",
      "Epoch 360/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 4.2199\n",
      "Epoch 361/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 4.2740\n",
      "Epoch 362/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 4.2108\n",
      "Epoch 363/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 4.2208\n",
      "Epoch 364/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 4.4782\n",
      "Epoch 365/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 4.5364\n",
      "Epoch 366/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 4.5754\n",
      "Epoch 367/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 4.4504\n",
      "Epoch 368/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 4.1681\n",
      "Epoch 369/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 4.0769\n",
      "Epoch 370/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.9977\n",
      "Epoch 371/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 4.0310\n",
      "Epoch 372/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 3.9182\n",
      "Epoch 373/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.8842\n",
      "Epoch 374/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.8318\n",
      "Epoch 375/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.8047\n",
      "Epoch 376/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 3.7575\n",
      "Epoch 377/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 3.7449\n",
      "Epoch 378/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.7277\n",
      "Epoch 379/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.6274\n",
      "Epoch 380/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.6633\n",
      "Epoch 381/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 3.7172\n",
      "Epoch 382/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.5393\n",
      "Epoch 383/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.5576\n",
      "Epoch 384/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 3.4739\n",
      "Epoch 385/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.5419\n",
      "Epoch 386/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.4203\n",
      "Epoch 387/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 3.7213\n",
      "Epoch 388/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.7383\n",
      "Epoch 389/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.5747\n",
      "Epoch 390/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.3900\n",
      "Epoch 391/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.3287\n",
      "Epoch 392/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.4601\n",
      "Epoch 393/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.4575\n",
      "Epoch 394/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 3.4344\n",
      "Epoch 395/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.5638\n",
      "Epoch 396/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.4696\n",
      "Epoch 397/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 3.4913\n",
      "Epoch 398/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 3.4998\n",
      "Epoch 399/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.3879\n",
      "Epoch 400/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.5044\n",
      "Epoch 401/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 3.4732\n",
      "Epoch 402/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 3.2989\n",
      "Epoch 403/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 3.6093\n",
      "Epoch 404/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 3.5231\n",
      "Epoch 405/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 3.3944\n",
      "Epoch 406/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.3671\n",
      "Epoch 407/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.2856\n",
      "Epoch 408/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.2919\n",
      "Epoch 409/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 3.3741\n",
      "Epoch 410/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.2962\n",
      "Epoch 411/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 3.4636\n",
      "Epoch 412/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.4523\n",
      "Epoch 413/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.3509\n",
      "Epoch 414/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.3215\n",
      "Epoch 415/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.3542\n",
      "Epoch 416/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 3.3379\n",
      "Epoch 417/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.3232\n",
      "Epoch 418/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.3259\n",
      "Epoch 419/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 3.4291\n",
      "Epoch 420/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.4517\n",
      "Epoch 421/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.2127\n",
      "Epoch 422/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.3295\n",
      "Epoch 423/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.3721\n",
      "Epoch 424/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.3132\n",
      "Epoch 425/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 3.3927\n",
      "Epoch 426/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.3145\n",
      "Epoch 427/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.3500\n",
      "Epoch 428/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.5972\n",
      "Epoch 429/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.5497\n",
      "Epoch 430/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.3469\n",
      "Epoch 431/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 3.3143\n",
      "Epoch 432/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 3.5257\n",
      "Epoch 433/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 3.3418\n",
      "Epoch 434/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 3.2330\n",
      "Epoch 435/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 3.2423\n",
      "Epoch 436/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 3.2402\n",
      "Epoch 437/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.3499\n",
      "Epoch 438/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.2850\n",
      "Epoch 439/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 3.2089\n",
      "Epoch 440/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 3.2505\n",
      "Epoch 441/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 3.3124\n",
      "Epoch 442/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.2424\n",
      "Epoch 443/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 3.2116\n",
      "Epoch 444/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 3.1911\n",
      "Epoch 445/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.2181\n",
      "Epoch 446/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.2813\n",
      "Epoch 447/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 3.2727\n",
      "Epoch 448/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.2616\n",
      "Epoch 449/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 3.2126\n",
      "Epoch 450/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.1713\n",
      "Epoch 451/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.1983\n",
      "Epoch 452/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.1649\n",
      "Epoch 453/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 3.2101\n",
      "Epoch 454/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.1977\n",
      "Epoch 455/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.2045\n",
      "Epoch 456/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 3.2152\n",
      "Epoch 457/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.2250\n",
      "Epoch 458/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.2591\n",
      "Epoch 459/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 3.2111\n",
      "Epoch 460/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.2822\n",
      "Epoch 461/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 3.1921\n",
      "Epoch 462/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 3.1877\n",
      "Epoch 463/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 3.1672\n",
      "Epoch 464/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.2336\n",
      "Epoch 465/1000\n",
      "1883/1883 [==============================] - 0s 20us/step - loss: 3.1637\n",
      "Epoch 466/1000\n",
      "1883/1883 [==============================] - 0s 19us/step - loss: 3.2492\n",
      "Epoch 467/1000\n",
      "1883/1883 [==============================] - 0s 21us/step - loss: 3.3249\n",
      "Epoch 468/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 3.2383\n",
      "Epoch 469/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 3.1392\n",
      "Epoch 470/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.1552\n",
      "Epoch 471/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.2075\n",
      "Epoch 472/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 3.1385\n",
      "Epoch 473/1000\n",
      "1883/1883 [==============================] - 0s 19us/step - loss: 3.2118\n",
      "Epoch 474/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 3.1496\n",
      "Epoch 475/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 3.1264\n",
      "Epoch 476/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 3.1609\n",
      "Epoch 477/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 3.2187\n",
      "Epoch 478/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 3.1496\n",
      "Epoch 479/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 3.1353\n",
      "Epoch 480/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 3.1092\n",
      "Epoch 481/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 3.0835\n",
      "Epoch 482/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.1002\n",
      "Epoch 483/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.1278\n",
      "Epoch 484/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.2283\n",
      "Epoch 485/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.2761\n",
      "Epoch 486/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 3.1899\n",
      "Epoch 487/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.2934\n",
      "Epoch 488/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 3.2422\n",
      "Epoch 489/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 3.2657\n",
      "Epoch 490/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 3.1249\n",
      "Epoch 491/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.1915\n",
      "Epoch 492/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 3.2880\n",
      "Epoch 493/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 3.3809\n",
      "Epoch 494/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.3569\n",
      "Epoch 495/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 3.1577\n",
      "Epoch 496/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.0862\n",
      "Epoch 497/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.0762\n",
      "Epoch 498/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.2873\n",
      "Epoch 499/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 3.3906\n",
      "Epoch 500/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.3446\n",
      "Epoch 501/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.2300\n",
      "Epoch 502/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.0933\n",
      "Epoch 503/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.1060\n",
      "Epoch 504/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.1004\n",
      "Epoch 505/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.4275\n",
      "Epoch 506/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 3.3156\n",
      "Epoch 507/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 3.2231\n",
      "Epoch 508/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 3.1760\n",
      "Epoch 509/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.2353\n",
      "Epoch 510/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.2151\n",
      "Epoch 511/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 3.1237\n",
      "Epoch 512/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.1239\n",
      "Epoch 513/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 3.1566\n",
      "Epoch 514/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.1095\n",
      "Epoch 515/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.1840\n",
      "Epoch 516/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 3.2201\n",
      "Epoch 517/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 3.0932\n",
      "Epoch 518/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 3.1452\n",
      "Epoch 519/1000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 3.0678\n",
      "Epoch 520/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 3.0909\n",
      "Epoch 521/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 3.1668\n",
      "Epoch 522/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.1483\n",
      "Epoch 523/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 3.1547\n",
      "Epoch 524/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 3.0661\n",
      "Epoch 525/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.0247\n",
      "Epoch 526/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.0724\n",
      "Epoch 527/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 3.0525\n",
      "Epoch 528/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 3.0791\n",
      "Epoch 529/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.1566\n",
      "Epoch 530/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.0867\n",
      "Epoch 531/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 3.1031\n",
      "Epoch 532/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.0598\n",
      "Epoch 533/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.0664\n",
      "Epoch 534/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.0503\n",
      "Epoch 535/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.0738\n",
      "Epoch 536/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.0627\n",
      "Epoch 537/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 3.0756\n",
      "Epoch 538/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 3.0597\n",
      "Epoch 539/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.0746\n",
      "Epoch 540/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.0526\n",
      "Epoch 541/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.1001\n",
      "Epoch 542/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 3.0710\n",
      "Epoch 543/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.0894\n",
      "Epoch 544/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 3.0902\n",
      "Epoch 545/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 3.0459\n",
      "Epoch 546/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.0266\n",
      "Epoch 547/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 3.0498\n",
      "Epoch 548/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 3.0370\n",
      "Epoch 549/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.2691\n",
      "Epoch 550/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.1470\n",
      "Epoch 551/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 3.1477\n",
      "Epoch 552/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.0771\n",
      "Epoch 553/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.0332\n",
      "Epoch 554/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.0590\n",
      "Epoch 555/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.0589\n",
      "Epoch 556/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 3.1450\n",
      "Epoch 557/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 3.0081\n",
      "Epoch 558/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.0007\n",
      "Epoch 559/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 3.0049\n",
      "Epoch 560/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 3.0363\n",
      "Epoch 561/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.0412\n",
      "Epoch 562/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.0921\n",
      "Epoch 563/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.0156\n",
      "Epoch 564/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 2.9942\n",
      "Epoch 565/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.0195\n",
      "Epoch 566/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.9998\n",
      "Epoch 567/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 3.0321\n",
      "Epoch 568/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.0250\n",
      "Epoch 569/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.1410\n",
      "Epoch 570/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 3.0578\n",
      "Epoch 571/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 3.0783\n",
      "Epoch 572/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.9789\n",
      "Epoch 573/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 2.9740\n",
      "Epoch 574/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 3.2056\n",
      "Epoch 575/1000\n",
      "1883/1883 [==============================] - 0s 19us/step - loss: 3.1362\n",
      "Epoch 576/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.0432\n",
      "Epoch 577/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.0418\n",
      "Epoch 578/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.0783\n",
      "Epoch 579/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.0455\n",
      "Epoch 580/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 3.0897\n",
      "Epoch 581/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.1180\n",
      "Epoch 582/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 3.0061\n",
      "Epoch 583/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.0519\n",
      "Epoch 584/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.0319\n",
      "Epoch 585/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 3.0321\n",
      "Epoch 586/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 2.9963\n",
      "Epoch 587/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.0258\n",
      "Epoch 588/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 3.0376\n",
      "Epoch 589/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 3.1808\n",
      "Epoch 590/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 3.1003\n",
      "Epoch 591/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 2.9734\n",
      "Epoch 592/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 3.0022\n",
      "Epoch 593/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.9908\n",
      "Epoch 594/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.0394\n",
      "Epoch 595/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.9620\n",
      "Epoch 596/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.9676\n",
      "Epoch 597/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 3.0001\n",
      "Epoch 598/1000\n",
      "1883/1883 [==============================] - 0s 20us/step - loss: 3.0594\n",
      "Epoch 599/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.9945\n",
      "Epoch 600/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.1224\n",
      "Epoch 601/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 3.1539\n",
      "Epoch 602/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 2.9572\n",
      "Epoch 603/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 2.9868\n",
      "Epoch 604/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.9510\n",
      "Epoch 605/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.0478\n",
      "Epoch 606/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 3.0616\n",
      "Epoch 607/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 3.0234\n",
      "Epoch 608/1000\n",
      "1883/1883 [==============================] - 0s 19us/step - loss: 3.0910\n",
      "Epoch 609/1000\n",
      "1883/1883 [==============================] - 0s 20us/step - loss: 3.0178\n",
      "Epoch 610/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 3.1332\n",
      "Epoch 611/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.0459\n",
      "Epoch 612/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.0162\n",
      "Epoch 613/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 3.0008\n",
      "Epoch 614/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 2.9904\n",
      "Epoch 615/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 3.0112\n",
      "Epoch 616/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 3.0107\n",
      "Epoch 617/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.0192\n",
      "Epoch 618/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.9860\n",
      "Epoch 619/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.9977\n",
      "Epoch 620/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.9505\n",
      "Epoch 621/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.9739\n",
      "Epoch 622/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.1521\n",
      "Epoch 623/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.9907\n",
      "Epoch 624/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.9886\n",
      "Epoch 625/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 3.0092\n",
      "Epoch 626/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 3.0213\n",
      "Epoch 627/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.9824\n",
      "Epoch 628/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.9675\n",
      "Epoch 629/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.9482\n",
      "Epoch 630/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.9433\n",
      "Epoch 631/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.8977\n",
      "Epoch 632/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.9874\n",
      "Epoch 633/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.9049\n",
      "Epoch 634/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 3.0067\n",
      "Epoch 635/1000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 3.1212\n",
      "Epoch 636/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.9783\n",
      "Epoch 637/1000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 3.0627\n",
      "Epoch 638/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 3.1979\n",
      "Epoch 639/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.1257\n",
      "Epoch 640/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.9685\n",
      "Epoch 641/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.9761\n",
      "Epoch 642/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.9198\n",
      "Epoch 643/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.9260\n",
      "Epoch 644/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.0189\n",
      "Epoch 645/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.0074\n",
      "Epoch 646/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.9776\n",
      "Epoch 647/1000\n",
      "1883/1883 [==============================] - 0s 20us/step - loss: 2.9642\n",
      "Epoch 648/1000\n",
      "1883/1883 [==============================] - 0s 20us/step - loss: 2.9762\n",
      "Epoch 649/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.0681\n",
      "Epoch 650/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 2.9678\n",
      "Epoch 651/1000\n",
      "1883/1883 [==============================] - 0s 21us/step - loss: 2.9700\n",
      "Epoch 652/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 2.9508\n",
      "Epoch 653/1000\n",
      "1883/1883 [==============================] - 0s 20us/step - loss: 2.9812\n",
      "Epoch 654/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 3.0044\n",
      "Epoch 655/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 3.0434\n",
      "Epoch 656/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 3.0683\n",
      "Epoch 657/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.9147\n",
      "Epoch 658/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.9548\n",
      "Epoch 659/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.9387\n",
      "Epoch 660/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 2.9672\n",
      "Epoch 661/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 2.9583\n",
      "Epoch 662/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.9343\n",
      "Epoch 663/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.9017\n",
      "Epoch 664/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.9358\n",
      "Epoch 665/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.9258\n",
      "Epoch 666/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.9378\n",
      "Epoch 667/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.9041\n",
      "Epoch 668/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 2.9079\n",
      "Epoch 669/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.8836\n",
      "Epoch 670/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.9164\n",
      "Epoch 671/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.9119\n",
      "Epoch 672/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.9185\n",
      "Epoch 673/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.9596\n",
      "Epoch 674/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 2.9256\n",
      "Epoch 675/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.9550\n",
      "Epoch 676/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.9285\n",
      "Epoch 677/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 3.0431\n",
      "Epoch 678/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 2.9573\n",
      "Epoch 679/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.9278\n",
      "Epoch 680/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 2.9430\n",
      "Epoch 681/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 2.9203\n",
      "Epoch 682/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 2.9021\n",
      "Epoch 683/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.9025\n",
      "Epoch 684/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.8952\n",
      "Epoch 685/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.9860\n",
      "Epoch 686/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.9819\n",
      "Epoch 687/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.9179\n",
      "Epoch 688/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.9408\n",
      "Epoch 689/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.9013\n",
      "Epoch 690/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 2.8789\n",
      "Epoch 691/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.8920\n",
      "Epoch 692/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.9040\n",
      "Epoch 693/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.9189\n",
      "Epoch 694/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.9012\n",
      "Epoch 695/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.9392\n",
      "Epoch 696/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.8874\n",
      "Epoch 697/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 2.9008\n",
      "Epoch 698/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.9082\n",
      "Epoch 699/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.9461\n",
      "Epoch 700/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 3.0683\n",
      "Epoch 701/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.1238\n",
      "Epoch 702/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.9557\n",
      "Epoch 703/1000\n",
      "1883/1883 [==============================] - 0s 20us/step - loss: 2.9316\n",
      "Epoch 704/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.9285\n",
      "Epoch 705/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.8948\n",
      "Epoch 706/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.9685\n",
      "Epoch 707/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 3.1269\n",
      "Epoch 708/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 3.0456\n",
      "Epoch 709/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.9375\n",
      "Epoch 710/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.8950\n",
      "Epoch 711/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.9908\n",
      "Epoch 712/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 3.1312\n",
      "Epoch 713/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 3.0121\n",
      "Epoch 714/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.9603\n",
      "Epoch 715/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.8380\n",
      "Epoch 716/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.8677\n",
      "Epoch 717/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.8846\n",
      "Epoch 718/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.8669\n",
      "Epoch 719/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.9588\n",
      "Epoch 720/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 2.9506\n",
      "Epoch 721/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 2.8920\n",
      "Epoch 722/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.8281\n",
      "Epoch 723/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.8616\n",
      "Epoch 724/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.8373\n",
      "Epoch 725/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.8345\n",
      "Epoch 726/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.8207\n",
      "Epoch 727/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.8465\n",
      "Epoch 728/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.7924\n",
      "Epoch 729/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.8108\n",
      "Epoch 730/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.8166\n",
      "Epoch 731/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.8255\n",
      "Epoch 732/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.8030\n",
      "Epoch 733/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.9302\n",
      "Epoch 734/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.8689\n",
      "Epoch 735/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.8834\n",
      "Epoch 736/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.8250\n",
      "Epoch 737/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.7924\n",
      "Epoch 738/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.8737\n",
      "Epoch 739/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.8937\n",
      "Epoch 740/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.8771\n",
      "Epoch 741/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.8531\n",
      "Epoch 742/1000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 2.8377\n",
      "Epoch 743/1000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 2.9104\n",
      "Epoch 744/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.8546\n",
      "Epoch 745/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.8944\n",
      "Epoch 746/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.8949\n",
      "Epoch 747/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.9653\n",
      "Epoch 748/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 3.1034\n",
      "Epoch 749/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.8321\n",
      "Epoch 750/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.8479\n",
      "Epoch 751/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.8113\n",
      "Epoch 752/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.7996\n",
      "Epoch 753/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.7764\n",
      "Epoch 754/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.7911\n",
      "Epoch 755/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.8060\n",
      "Epoch 756/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.7244\n",
      "Epoch 757/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.7271\n",
      "Epoch 758/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.7150\n",
      "Epoch 759/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 2.7277\n",
      "Epoch 760/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 2.7167\n",
      "Epoch 761/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.7141\n",
      "Epoch 762/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.6757\n",
      "Epoch 763/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.7308\n",
      "Epoch 764/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.6779\n",
      "Epoch 765/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.7701\n",
      "Epoch 766/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 2.7477\n",
      "Epoch 767/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.7277\n",
      "Epoch 768/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.7934\n",
      "Epoch 769/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.9086\n",
      "Epoch 770/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.8017\n",
      "Epoch 771/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.8049\n",
      "Epoch 772/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.8388\n",
      "Epoch 773/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.7958\n",
      "Epoch 774/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.7215\n",
      "Epoch 775/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.7146\n",
      "Epoch 776/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.6568\n",
      "Epoch 777/1000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 2.6452\n",
      "Epoch 778/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.6727\n",
      "Epoch 779/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.6606\n",
      "Epoch 780/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.6777\n",
      "Epoch 781/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.7223\n",
      "Epoch 782/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.6573\n",
      "Epoch 783/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.6528\n",
      "Epoch 784/1000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 2.6402\n",
      "Epoch 785/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.6056\n",
      "Epoch 786/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.6213\n",
      "Epoch 787/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.7321\n",
      "Epoch 788/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.7597\n",
      "Epoch 789/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.7300\n",
      "Epoch 790/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.7464\n",
      "Epoch 791/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.6577\n",
      "Epoch 792/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.6845\n",
      "Epoch 793/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.6429\n",
      "Epoch 794/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 2.6354\n",
      "Epoch 795/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.6557\n",
      "Epoch 796/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.6280\n",
      "Epoch 797/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.6575\n",
      "Epoch 798/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.6697\n",
      "Epoch 799/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.6588\n",
      "Epoch 800/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.6808\n",
      "Epoch 801/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 2.7341\n",
      "Epoch 802/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 2.7340\n",
      "Epoch 803/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.7428\n",
      "Epoch 804/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.6182\n",
      "Epoch 805/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.5758\n",
      "Epoch 806/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.6874\n",
      "Epoch 807/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.6056\n",
      "Epoch 808/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 2.6223\n",
      "Epoch 809/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.5971\n",
      "Epoch 810/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.6293\n",
      "Epoch 811/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.5166\n",
      "Epoch 812/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.6601\n",
      "Epoch 813/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.6061\n",
      "Epoch 814/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.5906\n",
      "Epoch 815/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.5631\n",
      "Epoch 816/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.6496\n",
      "Epoch 817/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 2.5394\n",
      "Epoch 818/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.6225\n",
      "Epoch 819/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.6820\n",
      "Epoch 820/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.5810\n",
      "Epoch 821/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.5411\n",
      "Epoch 822/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.6357\n",
      "Epoch 823/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 2.5793\n",
      "Epoch 824/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 2.5320\n",
      "Epoch 825/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.5327\n",
      "Epoch 826/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.5765\n",
      "Epoch 827/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.5497\n",
      "Epoch 828/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 2.6140\n",
      "Epoch 829/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.6491\n",
      "Epoch 830/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 2.6188\n",
      "Epoch 831/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 2.5691\n",
      "Epoch 832/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.5316\n",
      "Epoch 833/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.5290\n",
      "Epoch 834/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.5788\n",
      "Epoch 835/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.5632\n",
      "Epoch 836/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.5796\n",
      "Epoch 837/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.5378\n",
      "Epoch 838/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 2.5778\n",
      "Epoch 839/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 2.4915\n",
      "Epoch 840/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 2.5575\n",
      "Epoch 841/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.5763\n",
      "Epoch 842/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.5853\n",
      "Epoch 843/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.5651\n",
      "Epoch 844/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.6074\n",
      "Epoch 845/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.5141\n",
      "Epoch 846/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.4655\n",
      "Epoch 847/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.4409\n",
      "Epoch 848/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 2.4899\n",
      "Epoch 849/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.4635\n",
      "Epoch 850/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.5607\n",
      "Epoch 851/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.5228\n",
      "Epoch 852/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.4918\n",
      "Epoch 853/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.3673\n",
      "Epoch 854/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.3496\n",
      "Epoch 855/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.4686\n",
      "Epoch 856/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.5211\n",
      "Epoch 857/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.5086\n",
      "Epoch 858/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.3874\n",
      "Epoch 859/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.5008\n",
      "Epoch 860/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.4360\n",
      "Epoch 861/1000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 2.4603\n",
      "Epoch 862/1000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 2.6123\n",
      "Epoch 863/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.4384\n",
      "Epoch 864/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 2.5966\n",
      "Epoch 865/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 2.5315\n",
      "Epoch 866/1000\n",
      "1883/1883 [==============================] - 0s 19us/step - loss: 2.5479\n",
      "Epoch 867/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.6042\n",
      "Epoch 868/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.5052\n",
      "Epoch 869/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.4190\n",
      "Epoch 870/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.4194\n",
      "Epoch 871/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.5065\n",
      "Epoch 872/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.4661\n",
      "Epoch 873/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 2.3979\n",
      "Epoch 874/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 2.4156\n",
      "Epoch 875/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.3856\n",
      "Epoch 876/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.4217\n",
      "Epoch 877/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.3934\n",
      "Epoch 878/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.4073\n",
      "Epoch 879/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.4051\n",
      "Epoch 880/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 2.3977\n",
      "Epoch 881/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 2.3677\n",
      "Epoch 882/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.3417\n",
      "Epoch 883/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.3217\n",
      "Epoch 884/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.3261\n",
      "Epoch 885/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.3404\n",
      "Epoch 886/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.3523\n",
      "Epoch 887/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.2956\n",
      "Epoch 888/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.3192\n",
      "Epoch 889/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.2619\n",
      "Epoch 890/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.2577\n",
      "Epoch 891/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.2548\n",
      "Epoch 892/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.3088\n",
      "Epoch 893/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.2771\n",
      "Epoch 894/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.3815\n",
      "Epoch 895/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.5583\n",
      "Epoch 896/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.3496\n",
      "Epoch 897/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.3765\n",
      "Epoch 898/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.3968\n",
      "Epoch 899/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.2833\n",
      "Epoch 900/1000\n",
      "1883/1883 [==============================] - 0s 19us/step - loss: 2.2347\n",
      "Epoch 901/1000\n",
      "1883/1883 [==============================] - 0s 20us/step - loss: 2.3605\n",
      "Epoch 902/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 2.4154\n",
      "Epoch 903/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.3399\n",
      "Epoch 904/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.2725\n",
      "Epoch 905/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.3506\n",
      "Epoch 906/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.2620\n",
      "Epoch 907/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.2946\n",
      "Epoch 908/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.4682\n",
      "Epoch 909/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.3025\n",
      "Epoch 910/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.2623\n",
      "Epoch 911/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.3843\n",
      "Epoch 912/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.2491\n",
      "Epoch 913/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.2618\n",
      "Epoch 914/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 2.2435\n",
      "Epoch 915/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 2.2279\n",
      "Epoch 916/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.2360\n",
      "Epoch 917/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.2549\n",
      "Epoch 918/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.2429\n",
      "Epoch 919/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.2001\n",
      "Epoch 920/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.3086\n",
      "Epoch 921/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.2864\n",
      "Epoch 922/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.2313\n",
      "Epoch 923/1000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 2.3142\n",
      "Epoch 924/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.3521\n",
      "Epoch 925/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.2100\n",
      "Epoch 926/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.2203\n",
      "Epoch 927/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.2376\n",
      "Epoch 928/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.2055\n",
      "Epoch 929/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.2079\n",
      "Epoch 930/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.2409\n",
      "Epoch 931/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 2.2806\n",
      "Epoch 932/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.2955\n",
      "Epoch 933/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.3909\n",
      "Epoch 934/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.5330\n",
      "Epoch 935/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.4096\n",
      "Epoch 936/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.5299\n",
      "Epoch 937/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 2.3034\n",
      "Epoch 938/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 2.2672\n",
      "Epoch 939/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.3482\n",
      "Epoch 940/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.2564\n",
      "Epoch 941/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.2665\n",
      "Epoch 942/1000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 2.2545\n",
      "Epoch 943/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.4315\n",
      "Epoch 944/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.2681\n",
      "Epoch 945/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.3881\n",
      "Epoch 946/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.3192\n",
      "Epoch 947/1000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 2.2761\n",
      "Epoch 948/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.2194\n",
      "Epoch 949/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.1869\n",
      "Epoch 950/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.2050\n",
      "Epoch 951/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.2042\n",
      "Epoch 952/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.1777\n",
      "Epoch 953/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.2114\n",
      "Epoch 954/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.2474\n",
      "Epoch 955/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.2567\n",
      "Epoch 956/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.2530\n",
      "Epoch 957/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.2833\n",
      "Epoch 958/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.2530\n",
      "Epoch 959/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.2811\n",
      "Epoch 960/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.2365\n",
      "Epoch 961/1000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 2.1735\n",
      "Epoch 962/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.2430\n",
      "Epoch 963/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.2660\n",
      "Epoch 964/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.2135\n",
      "Epoch 965/1000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 2.2042\n",
      "Epoch 966/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.2603\n",
      "Epoch 967/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.2264\n",
      "Epoch 968/1000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 2.2482\n",
      "Epoch 969/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.2494\n",
      "Epoch 970/1000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 2.1789\n",
      "Epoch 971/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.2531\n",
      "Epoch 972/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.2990\n",
      "Epoch 973/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.3234\n",
      "Epoch 974/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.3229\n",
      "Epoch 975/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.2153\n",
      "Epoch 976/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.2111\n",
      "Epoch 977/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.1768\n",
      "Epoch 978/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.2268\n",
      "Epoch 979/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.2144\n",
      "Epoch 980/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.1449\n",
      "Epoch 981/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.2519\n",
      "Epoch 982/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.2231\n",
      "Epoch 983/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.1680\n",
      "Epoch 984/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.2268\n",
      "Epoch 985/1000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 2.2055\n",
      "Epoch 986/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.2848\n",
      "Epoch 987/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.2280\n",
      "Epoch 988/1000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 2.2618\n",
      "Epoch 989/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.2212\n",
      "Epoch 990/1000\n",
      "1883/1883 [==============================] - 0s 19us/step - loss: 2.2025\n",
      "Epoch 991/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.2320\n",
      "Epoch 992/1000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 2.1918\n",
      "Epoch 993/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.1538\n",
      "Epoch 994/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.2319\n",
      "Epoch 995/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.1728\n",
      "Epoch 996/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.1852\n",
      "Epoch 997/1000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 2.2784\n",
      "Epoch 998/1000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 2.2049\n",
      "Epoch 999/1000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 2.2177\n",
      "Epoch 1000/1000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 2.2606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a2e56f908>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model = Sequential()\n",
    "NN_model.add(Dense(units=16,input_dim= 28,activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_model.add(Dense(units=8, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_model.add(Dense(units=4, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_model.add(Dense(units=1,activation='linear'))\n",
    "NN_model.compile(loss='mse', optimizer='adam')\n",
    "NN_model.fit(np.array(X_train), np.array(y_train), epochs=1000,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a2d21eb00>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_predictions = NN_model.predict(X_train)\n",
    "training = pd.DataFrame(training_predictions)\n",
    "training['actual'] = y_train.reset_index()['rebounds']\n",
    "plt.scatter(training_predictions,training[0]-training['actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = NN_model.predict(X_test)\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.5)\n",
    "gbr.fit(X_train,y_train)\n",
    "gbr_predictions = gbr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = pd.DataFrame(predictions)\n",
    "testing.columns=['NN_predictions']\n",
    "testing['actual'] = y_test.reset_index()['rebounds']\n",
    "testing['GBR_predictions']=gbr_predictions\n",
    "testing['LY_rebounding']=X_test['rebounds_ly'].reset_index()['rebounds_ly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a27e27588>]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(figsize=(16,8))\n",
    "plt.plot(testing[0:100].index,testing['actual'][0:100], color = 'r',alpha = 0.5)\n",
    "plt.plot(testing[0:100].index,testing['NN_predictions'][0:100], color = 'g',alpha = 0.2)\n",
    "#plt.scatter(testing[0:100].index,testing['LY_rebounding'][0:100],color = 'b',alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN_predictions</th>\n",
       "      <th>actual</th>\n",
       "      <th>GBR_predictions</th>\n",
       "      <th>LY_rebounding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>13.025216</td>\n",
       "      <td>13.3</td>\n",
       "      <td>13.587882</td>\n",
       "      <td>15.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>14.232085</td>\n",
       "      <td>14.5</td>\n",
       "      <td>13.326632</td>\n",
       "      <td>14.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>12.486938</td>\n",
       "      <td>14.8</td>\n",
       "      <td>13.632003</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>11.869172</td>\n",
       "      <td>12.2</td>\n",
       "      <td>10.617917</td>\n",
       "      <td>12.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>9.429361</td>\n",
       "      <td>10.3</td>\n",
       "      <td>10.179203</td>\n",
       "      <td>12.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>11.677075</td>\n",
       "      <td>14.1</td>\n",
       "      <td>12.324970</td>\n",
       "      <td>11.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>9.816584</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.318094</td>\n",
       "      <td>11.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>10.823475</td>\n",
       "      <td>12.7</td>\n",
       "      <td>11.648633</td>\n",
       "      <td>11.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>8.778246</td>\n",
       "      <td>14.4</td>\n",
       "      <td>10.077553</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>8.869813</td>\n",
       "      <td>4.8</td>\n",
       "      <td>8.173976</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>10.446122</td>\n",
       "      <td>9.6</td>\n",
       "      <td>10.183756</td>\n",
       "      <td>11.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>9.888350</td>\n",
       "      <td>9.3</td>\n",
       "      <td>9.780809</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>8.972180</td>\n",
       "      <td>10.2</td>\n",
       "      <td>9.680278</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>8.064161</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.413389</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10.762438</td>\n",
       "      <td>8.3</td>\n",
       "      <td>10.173094</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>7.302790</td>\n",
       "      <td>3.3</td>\n",
       "      <td>7.484203</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>9.672986</td>\n",
       "      <td>9.9</td>\n",
       "      <td>11.141972</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>9.517533</td>\n",
       "      <td>10.9</td>\n",
       "      <td>10.808484</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>8.648881</td>\n",
       "      <td>9.2</td>\n",
       "      <td>8.996990</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>8.851230</td>\n",
       "      <td>8.9</td>\n",
       "      <td>8.374113</td>\n",
       "      <td>10.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>10.005464</td>\n",
       "      <td>11.1</td>\n",
       "      <td>9.702730</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>8.704498</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8.892764</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>6.670139</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.571295</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>9.306171</td>\n",
       "      <td>8.1</td>\n",
       "      <td>9.287454</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>9.592052</td>\n",
       "      <td>10.2</td>\n",
       "      <td>10.605474</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>8.970805</td>\n",
       "      <td>9.7</td>\n",
       "      <td>8.796535</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>10.025879</td>\n",
       "      <td>11.1</td>\n",
       "      <td>9.967840</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>9.358714</td>\n",
       "      <td>9.6</td>\n",
       "      <td>10.263344</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>7.183867</td>\n",
       "      <td>11.8</td>\n",
       "      <td>8.908180</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>9.593551</td>\n",
       "      <td>9.3</td>\n",
       "      <td>9.993874</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>1.605425</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.373594</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1.057960</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.545782</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>1.887471</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.767893</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1.667595</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.785025</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.085274</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.433830</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.690294</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.263800</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>1.638487</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.398321</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>1.533214</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.698594</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>1.390387</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.497600</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>2.117598</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.403475</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>1.536174</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.539686</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>1.666069</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.501982</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>1.416096</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.458025</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1.041104</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.161718</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>1.624406</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.056231</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>1.051079</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.052744</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>1.906211</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.190601</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>1.211226</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.185630</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>1.280006</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.053580</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>1.582637</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.317846</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>-0.002004</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.997102</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>1.236564</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.079527</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>1.680050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.194250</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>1.473006</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.497510</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>1.143991</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.705051</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>1.616160</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.277439</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>1.285333</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.353663</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>1.161834</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.181460</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1.406418</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.465930</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>2.951489</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.542021</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>807 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     NN_predictions  actual  GBR_predictions  LY_rebounding\n",
       "492       13.025216    13.3        13.587882           15.2\n",
       "776       14.232085    14.5        13.326632           14.1\n",
       "73        12.486938    14.8        13.632003           13.5\n",
       "50        11.869172    12.2        10.617917           12.4\n",
       "608        9.429361    10.3        10.179203           12.1\n",
       "312       11.677075    14.1        12.324970           11.8\n",
       "558        9.816584    11.0         9.318094           11.8\n",
       "225       10.823475    12.7        11.648633           11.7\n",
       "340        8.778246    14.4        10.077553           11.5\n",
       "610        8.869813     4.8         8.173976           11.5\n",
       "431       10.446122     9.6        10.183756           11.3\n",
       "515        9.888350     9.3         9.780809           11.2\n",
       "498        8.972180    10.2         9.680278           11.1\n",
       "683        8.064161     5.0         6.413389           11.1\n",
       "26        10.762438     8.3        10.173094           11.1\n",
       "780        7.302790     3.3         7.484203           11.0\n",
       "433        9.672986     9.9        11.141972           11.0\n",
       "284        9.517533    10.9        10.808484           11.0\n",
       "92         8.648881     9.2         8.996990           10.4\n",
       "455        8.851230     8.9         8.374113           10.3\n",
       "213       10.005464    11.1         9.702730           10.2\n",
       "586        8.704498     8.5         8.892764           10.2\n",
       "395        6.670139     8.6         8.571295           10.2\n",
       "205        9.306171     8.1         9.287454           10.0\n",
       "314        9.592052    10.2        10.605474           10.0\n",
       "172        8.970805     9.7         8.796535            9.9\n",
       "497       10.025879    11.1         9.967840            9.9\n",
       "323        9.358714     9.6        10.263344            9.7\n",
       "404        7.183867    11.8         8.908180            9.7\n",
       "594        9.593551     9.3         9.993874            9.6\n",
       "..              ...     ...              ...            ...\n",
       "692        1.605425     2.0         2.373594            0.9\n",
       "69         1.057960     2.4         1.545782            0.8\n",
       "800        1.887471     0.2         1.767893            0.8\n",
       "115        1.667595     1.5         1.785025            0.8\n",
       "9          1.085274     3.2         1.433830            0.8\n",
       "19         1.690294     0.1         1.263800            0.8\n",
       "554        1.638487     1.2         1.398321            0.8\n",
       "320        1.533214     1.6         1.698594            0.8\n",
       "616        1.390387     0.6         1.497600            0.8\n",
       "695        2.117598     2.5         2.403475            0.7\n",
       "745        1.536174     1.1         1.539686            0.7\n",
       "343        1.666069     2.0         1.501982            0.7\n",
       "760        1.416096     0.8         1.458025            0.6\n",
       "198        1.041104     1.0         1.161718            0.6\n",
       "715        1.624406     1.2         1.056231            0.6\n",
       "237        1.051079     0.6         1.052744            0.6\n",
       "451        1.906211     1.5         2.190601            0.6\n",
       "216        1.211226     0.5         1.185630            0.6\n",
       "632        1.280006     2.4         2.053580            0.5\n",
       "688        1.582637     3.9         2.317846            0.5\n",
       "111       -0.002004     0.5         1.997102            0.5\n",
       "570        1.236564     0.6         1.079527            0.5\n",
       "202        1.680050     1.0         1.194250            0.5\n",
       "762        1.473006     0.5         1.497510            0.5\n",
       "286        1.143991     1.2         2.705051            0.5\n",
       "333        1.616160     0.7         1.277439            0.5\n",
       "804        1.285333     0.9         1.353663            0.4\n",
       "721        1.161834     1.4         1.181460            0.4\n",
       "68         1.406418     0.8         1.465930            0.2\n",
       "792        2.951489     2.0         1.542021            0.0\n",
       "\n",
       "[807 rows x 4 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing.sort_values(by='LY_rebounding',ascending=False)#[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>rebounds</th>\n",
       "      <th>rebounds_ly_x</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Greg Monroe</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7.884368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Dewayne Dedmon</td>\n",
       "      <td>7.9</td>\n",
       "      <td>6.5</td>\n",
       "      <td>7.666414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>Wilson Chandler</td>\n",
       "      <td>5.4</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.858196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Cody Zeller</td>\n",
       "      <td>5.4</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.124624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Dirk Nowitzki</td>\n",
       "      <td>5.7</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.054944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Markieff Morris</td>\n",
       "      <td>5.6</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.462826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>Robert Covington</td>\n",
       "      <td>5.4</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.797342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Otto Porter</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.4</td>\n",
       "      <td>5.853045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>Robin Lopez</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.4</td>\n",
       "      <td>4.360392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Rudy Gay</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4.024020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Dario Saric</td>\n",
       "      <td>6.7</td>\n",
       "      <td>6.3</td>\n",
       "      <td>7.160113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>Marc Gasol</td>\n",
       "      <td>8.1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.365949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Jabari Parker</td>\n",
       "      <td>4.9</td>\n",
       "      <td>6.2</td>\n",
       "      <td>5.005250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Jimmy Butler</td>\n",
       "      <td>5.3</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.080626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Alan Williams</td>\n",
       "      <td>4.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>7.090030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>Nicolas Batum</td>\n",
       "      <td>4.8</td>\n",
       "      <td>6.2</td>\n",
       "      <td>5.090033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Avery Bradley</td>\n",
       "      <td>2.4</td>\n",
       "      <td>6.1</td>\n",
       "      <td>4.311031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Derrick Favors</td>\n",
       "      <td>7.2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>6.661953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>Thaddeus Young</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.1</td>\n",
       "      <td>6.150802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>P.J. Tucker</td>\n",
       "      <td>5.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.841570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>Ersan Ilyasova</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5.644901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>Larry Nance</td>\n",
       "      <td>6.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5.480356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Carmelo Anthony</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5.008596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>Zaza Pachulia</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5.745903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>Patrick Beverley</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5.9</td>\n",
       "      <td>4.581831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Jusuf Nurkic</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.803559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>Rondae Hollis-Jefferson</td>\n",
       "      <td>6.8</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.811908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Kawhi Leonard</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.8</td>\n",
       "      <td>7.082719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Jae Crowder</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4.087142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>Kosta Koufos</td>\n",
       "      <td>6.6</td>\n",
       "      <td>5.7</td>\n",
       "      <td>3.637576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>Trevor Ariza</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4.907066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>Kyle O'Quinn</td>\n",
       "      <td>6.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5.928813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>Richaun Holmes</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.601238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>Nikola Mirotic</td>\n",
       "      <td>8.2</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.887185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>Tony Allen</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.843081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Gordon Hayward</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5.410412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>Jon Leuer</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>4.824810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Brook Lopez</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5.773311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ed Davis</td>\n",
       "      <td>7.4</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.586911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>Luol Deng</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>4.116254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>Omer Asik</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3.991714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>DeMar DeRozan</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5.2</td>\n",
       "      <td>4.727559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Danilo Gallinari</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5.2</td>\n",
       "      <td>4.542082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Noah Vonleh</td>\n",
       "      <td>5.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.029571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Justise Winslow</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.604992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>Tarik Black</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>5.291780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Andre Roberson</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>4.800034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Aaron Gordon</td>\n",
       "      <td>7.9</td>\n",
       "      <td>5.1</td>\n",
       "      <td>5.272527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>John Henson</td>\n",
       "      <td>6.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>5.636615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>Rajon Rondo</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>4.202285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      player  rebounds  rebounds_ly_x  predictions\n",
       "179              Greg Monroe       6.3            6.6     7.884368\n",
       "150           Dewayne Dedmon       7.9            6.5     7.666414\n",
       "388          Wilson Chandler       5.4            6.5     5.858196\n",
       "118              Cody Zeller       5.4            6.5     5.124624\n",
       "14             Dirk Nowitzki       5.7            6.5     5.054944\n",
       "43           Markieff Morris       5.6            6.5     5.462826\n",
       "329         Robert Covington       5.4            6.5     5.797342\n",
       "50               Otto Porter       6.4            6.4     5.853045\n",
       "330              Robin Lopez       4.5            6.4     4.360392\n",
       "56                  Rudy Gay       5.1            6.3     4.024020\n",
       "131              Dario Saric       6.7            6.3     7.160113\n",
       "274               Marc Gasol       8.1            6.3     6.365949\n",
       "193            Jabari Parker       4.9            6.2     5.005250\n",
       "217             Jimmy Butler       5.3            6.2     6.080626\n",
       "73             Alan Williams       4.4            6.2     7.090030\n",
       "300            Nicolas Batum       4.8            6.2     5.090033\n",
       "92             Avery Bradley       2.4            6.1     4.311031\n",
       "146           Derrick Favors       7.2            6.1     6.661953\n",
       "357           Thaddeus Young       6.3            6.1     6.150802\n",
       "309              P.J. Tucker       5.6            6.0     4.841570\n",
       "164           Ersan Ilyasova       5.5            5.9     5.644901\n",
       "263              Larry Nance       6.8            5.9     5.480356\n",
       "111          Carmelo Anthony       5.8            5.9     5.008596\n",
       "391            Zaza Pachulia       4.7            5.9     5.745903\n",
       "311         Patrick Beverley       4.1            5.9     4.581831\n",
       "35              Jusuf Nurkic       9.0            5.8     5.803559\n",
       "333  Rondae Hollis-Jefferson       6.8            5.8     5.811908\n",
       "36             Kawhi Leonard       4.7            5.8     7.082719\n",
       "194              Jae Crowder       3.3            5.8     4.087142\n",
       "252             Kosta Koufos       6.6            5.7     3.637576\n",
       "367             Trevor Ariza       4.4            5.7     4.907066\n",
       "257             Kyle O'Quinn       6.1            5.6     5.928813\n",
       "327           Richaun Holmes       4.4            5.5     5.601238\n",
       "304           Nikola Mirotic       8.2            5.5     4.887185\n",
       "364               Tony Allen       2.1            5.5     2.843081\n",
       "177           Gordon Hayward       1.0            5.4     5.410412\n",
       "227                Jon Leuer       4.0            5.4     4.824810\n",
       "105              Brook Lopez       4.0            5.4     5.773311\n",
       "17                  Ed Davis       7.4            5.3     5.586911\n",
       "269                Luol Deng       0.0            5.3     4.116254\n",
       "307                Omer Asik       2.6            5.3     3.991714\n",
       "139            DeMar DeRozan       3.9            5.2     4.727559\n",
       "127         Danilo Gallinari       4.8            5.2     4.542082\n",
       "48               Noah Vonleh       5.1            5.2     5.029571\n",
       "34           Justise Winslow       5.4            5.2     3.604992\n",
       "352              Tarik Black       3.2            5.1     5.291780\n",
       "82            Andre Roberson       4.7            5.1     4.800034\n",
       "69              Aaron Gordon       7.9            5.1     5.272527\n",
       "225              John Henson       6.8            5.1     5.636615\n",
       "320              Rajon Rondo       4.0            5.1     4.202285"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_2017rebounds = rebounds[rebounds['season']==2017].drop(['team','player','rebounds'],axis=1)\n",
    "rebounds_2017 = NN_model.predict(pred_2017rebounds)\n",
    "test_2 =pd.DataFrame(rebounds_2017)\n",
    "test_3 = pd.merge(rebounds,pred_2017rebounds,left_index=True,right_index=True).reset_index()\n",
    "test_3['predictions']=test_2[0]\n",
    "test_3[['player','rebounds','rebounds_ly_x','predictions']].sort_values(by='rebounds_ly_x',ascending=False)[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8111346 , 0.75668588, 0.78079755, 0.72744262, 0.75121757])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.5),X_train,y_train,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(LinearRegression(),X_train,y_train,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''next is assists'''\n",
    "\n",
    "\n",
    "query= '''\n",
    "        \n",
    "        DROP TABLE IF EXISTS assists_pred;\n",
    "        CREATE TABLE assists_pred(\n",
    "        season int, --these come from player_stats\n",
    "        player varchar(50),\n",
    "        Age int,\n",
    "        team varchar(50),\n",
    "        ast float, -- these come from player_stats\n",
    "        ast_ly float,\n",
    "        change_ast_ly float,\n",
    "        Games float,\n",
    "        C_PF int,\n",
    "        PG int,\n",
    "        SG_SF int,\n",
    "        starter_change int, \n",
    "        \n",
    "        -- these come from team_changes\n",
    "        high_usageplayer_added int,\n",
    "        usagemin_opened float,\n",
    "        maxusage_added float,\n",
    "        high_usageplayer_dropped int,\n",
    "        assists_opened float,\n",
    "        max_assistsdropped float,\n",
    "        max_assistsadded float,\n",
    "        points_opened float,\n",
    "        threes_opened float,\n",
    "        \n",
    "        -- from player_advstats\n",
    "        per_ly float,\n",
    "        change_per float,\n",
    "        usagerank float,\n",
    "        usagerank_ly float,\n",
    "        ast_perc_ly float,\n",
    "        change_assist_perc float,\n",
    "        offensive_winshares float,\n",
    "        offensive_boxplusminus float,\n",
    "        boxplusminus float,\n",
    "        value_overreplacement float,\n",
    "        \n",
    "        career_ast float,\n",
    "        yearspro int\n",
    "        );\n",
    "        \n",
    "        INSERT INTO assists_pred(season,player,age,team,ast,ast_ly,change_ast_ly,starter_change,Games,C_PF,PG,SG_SF)\n",
    "        SELECT season,player,age,startingteam,ast,ast_ly,change_ast_ly,starter-starter_ly,Games,\n",
    "        case when pos in ('C','PF') then 1 else 0 end,case when pos='PG' then 1 else 0 end,case when pos in('SG','SF') then 1 else 0 end from player_stats;\n",
    "        \n",
    "        update assists_pred ap\n",
    "        set high_usageplayer_added = tc.high_usageplayer_added,usagemin_opened=tc.usagemin_opened,\n",
    "        maxusage_added=tc.max_usageadded,high_usageplayer_dropped=tc.high_usageplayer_dropped,assists_opened=tc.ast_opened,\n",
    "        max_assistsdropped=tc.max_astdropped,max_assistsadded=tc.max_astadded,points_opened = tc.points_opened,threes_opened = tc.threes_opened\n",
    "        from team_changes tc\n",
    "        where tc.team = ap.team and ap.season=tc.season;\n",
    "        \n",
    "        update assists_pred ap\n",
    "        set per_ly=pa.per_ly,change_per=pa.change_per,usagerank=pa.usagerank,usagerank_ly=pa.usagerank_ly\n",
    "        ,ast_perc_ly = pa.ast_perc_ly,change_assist_perc = pa.change_assist_perc,offensive_winshares=pa.offensive_winshares,\n",
    "        offensive_boxplusminus=pa.offensive_boxplusminus,boxplusminus=pa.boxplusminus,value_overreplacement=pa.value_overreplacement\n",
    "        from player_advstats pa\n",
    "        where ap.player = pa.player and ap.season = pa.season and ap.team = pa.startingteam;\n",
    "        \n",
    "        update assists_pred ap\n",
    "        set career_ast = pc.career_ast, yearspro = pc.yearspro\n",
    "        from player_careerstats pc\n",
    "        where ap.player = pc.player and ap.season = pc.season;\n",
    "        \n",
    "        \n",
    "        select * from assists_pred where season>2009\n",
    "        '''\n",
    "\n",
    "\n",
    "cur.execute(query)\n",
    "data = cur.fetchall()\n",
    "assists_df = pd.DataFrame(np.array(data))\n",
    "assists_df.columns = ['season','player','age','team','assists','assists_ly','change_assists_ly','Games','C_PF','PG','SG_SF','starter_change','high_usageplayer_added','usagemin_opened','maxusage_added','high_usageplayer_dropped','assists_opened','max_assistsdropped',\n",
    "                    'max_assistsadded','points_opened','threes_opened','per_ly','change_per','usagerank','usagerank_ly','reb_perc_ly','change_reb_perc','offensive_winshares','offensive_boxplusminus','boxplusminus','value_overreplacement','career_assists','yearspro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "assists_df['age_squared']=assists_df['age']*assists_df['age']\n",
    "assists = assists_df[assists_df['assists_ly'].notna()]\n",
    "for i in assists.columns:\n",
    "    if i not in(['player','team']):\n",
    "        assists[i]=pd.to_numeric(assists[i])\n",
    "assists = assists.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = assists[(assists['season']!=2017) & (assists['Games']>30)].drop(['player','team','assists','Games'],axis=1)\n",
    "y = assists[(assists['season']!=2017) & (assists['Games']>30)]['assists']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1564, 30)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1564/1564 [==============================] - 1s 772us/step - loss: 131254.6657\n",
      "Epoch 2/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 24586.5684\n",
      "Epoch 3/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 4115.9435\n",
      "Epoch 4/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 3024.0218\n",
      "Epoch 5/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 2167.8593\n",
      "Epoch 6/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1472.6947\n",
      "Epoch 7/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1154.9273\n",
      "Epoch 8/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 928.6030\n",
      "Epoch 9/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 762.5785\n",
      "Epoch 10/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 634.2765\n",
      "Epoch 11/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 538.1103\n",
      "Epoch 12/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 465.5421\n",
      "Epoch 13/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 406.7261\n",
      "Epoch 14/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 361.4217\n",
      "Epoch 15/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 324.6061\n",
      "Epoch 16/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 295.7190\n",
      "Epoch 17/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 272.5225\n",
      "Epoch 18/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 253.6571\n",
      "Epoch 19/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 237.0942\n",
      "Epoch 20/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 223.2226\n",
      "Epoch 21/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 211.4131\n",
      "Epoch 22/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 201.4474\n",
      "Epoch 23/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 192.6126\n",
      "Epoch 24/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 185.1880\n",
      "Epoch 25/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 178.5112\n",
      "Epoch 26/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 172.1205\n",
      "Epoch 27/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 165.9590\n",
      "Epoch 28/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 160.1788\n",
      "Epoch 29/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 155.2781\n",
      "Epoch 30/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 150.0755\n",
      "Epoch 31/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 144.6414\n",
      "Epoch 32/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 138.4125\n",
      "Epoch 33/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 133.0434\n",
      "Epoch 34/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 127.5811\n",
      "Epoch 35/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 122.5410\n",
      "Epoch 36/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 118.2007\n",
      "Epoch 37/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 113.9798\n",
      "Epoch 38/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 110.3906\n",
      "Epoch 39/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 106.8985\n",
      "Epoch 40/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 103.7949\n",
      "Epoch 41/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 101.1430\n",
      "Epoch 42/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 98.7997\n",
      "Epoch 43/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 96.7920\n",
      "Epoch 44/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 94.5643\n",
      "Epoch 45/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 92.7494\n",
      "Epoch 46/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 91.0800\n",
      "Epoch 47/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 89.2252\n",
      "Epoch 48/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 87.6690\n",
      "Epoch 49/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 86.0784\n",
      "Epoch 50/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 84.6616\n",
      "Epoch 51/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 83.2765\n",
      "Epoch 52/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 81.8721\n",
      "Epoch 53/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 80.5291\n",
      "Epoch 54/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 79.2994\n",
      "Epoch 55/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 78.0524\n",
      "Epoch 56/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 76.7215\n",
      "Epoch 57/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 75.3710\n",
      "Epoch 58/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 74.3878\n",
      "Epoch 59/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 73.0802\n",
      "Epoch 60/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 71.7311\n",
      "Epoch 61/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 70.5583\n",
      "Epoch 62/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 69.5845\n",
      "Epoch 63/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 68.5059\n",
      "Epoch 64/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 67.1858\n",
      "Epoch 65/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 66.1376\n",
      "Epoch 66/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 65.0689\n",
      "Epoch 67/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 64.0343\n",
      "Epoch 68/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 62.9370\n",
      "Epoch 69/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 61.8700\n",
      "Epoch 70/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 60.7926\n",
      "Epoch 71/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 59.8917\n",
      "Epoch 72/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 58.9584\n",
      "Epoch 73/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 58.0026\n",
      "Epoch 74/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 57.1955\n",
      "Epoch 75/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 56.1506\n",
      "Epoch 76/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 55.0956\n",
      "Epoch 77/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 54.5436\n",
      "Epoch 78/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 53.6407\n",
      "Epoch 79/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 52.7805\n",
      "Epoch 80/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 51.9547\n",
      "Epoch 81/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 51.0507\n",
      "Epoch 82/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 50.1772\n",
      "Epoch 83/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 49.3918\n",
      "Epoch 84/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 48.6359\n",
      "Epoch 85/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 47.9314\n",
      "Epoch 86/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 47.1563\n",
      "Epoch 87/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 46.4539\n",
      "Epoch 88/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 45.8074\n",
      "Epoch 89/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 45.1230\n",
      "Epoch 90/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 44.4601\n",
      "Epoch 91/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 43.7282\n",
      "Epoch 92/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 43.1367\n",
      "Epoch 93/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 42.4799\n",
      "Epoch 94/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 41.9957\n",
      "Epoch 95/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 41.3285\n",
      "Epoch 96/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 40.7120\n",
      "Epoch 97/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 40.1670\n",
      "Epoch 98/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 39.6665\n",
      "Epoch 99/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 39.1622\n",
      "Epoch 100/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 38.5820\n",
      "Epoch 101/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 38.0538\n",
      "Epoch 102/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 37.5960\n",
      "Epoch 103/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 37.0708\n",
      "Epoch 104/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 36.6270\n",
      "Epoch 105/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 36.2362\n",
      "Epoch 106/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 35.7238\n",
      "Epoch 107/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 35.2887\n",
      "Epoch 108/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 34.8744\n",
      "Epoch 109/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 34.4818\n",
      "Epoch 110/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 33.9699\n",
      "Epoch 111/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 33.6109\n",
      "Epoch 112/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 33.1689\n",
      "Epoch 113/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 32.7557\n",
      "Epoch 114/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 32.3828\n",
      "Epoch 115/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 31.9409\n",
      "Epoch 116/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 31.6012\n",
      "Epoch 117/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 31.2584\n",
      "Epoch 118/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 30.8760\n",
      "Epoch 119/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 30.4728\n",
      "Epoch 120/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 30.1103\n",
      "Epoch 121/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 29.7116\n",
      "Epoch 122/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 29.3496\n",
      "Epoch 123/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 29.0545\n",
      "Epoch 124/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 28.6863\n",
      "Epoch 125/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 28.3221\n",
      "Epoch 126/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 28.0894\n",
      "Epoch 127/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 27.6837\n",
      "Epoch 128/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 27.5466\n",
      "Epoch 129/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 27.0996\n",
      "Epoch 130/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 26.7382\n",
      "Epoch 131/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 26.4859\n",
      "Epoch 132/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 26.1631\n",
      "Epoch 133/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 25.8539\n",
      "Epoch 134/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 25.5437\n",
      "Epoch 135/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 25.2720\n",
      "Epoch 136/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 24.9497\n",
      "Epoch 137/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 24.6803\n",
      "Epoch 138/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 24.4186\n",
      "Epoch 139/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 24.1699\n",
      "Epoch 140/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 23.8818\n",
      "Epoch 141/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 23.7395\n",
      "Epoch 142/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 23.5803\n",
      "Epoch 143/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 23.3142\n",
      "Epoch 144/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 23.1149\n",
      "Epoch 145/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 22.6439\n",
      "Epoch 146/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 22.4195\n",
      "Epoch 147/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 22.1506\n",
      "Epoch 148/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 21.9529\n",
      "Epoch 149/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 21.7798\n",
      "Epoch 150/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 21.4880\n",
      "Epoch 151/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 21.3113\n",
      "Epoch 152/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 21.0603\n",
      "Epoch 153/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 20.8529\n",
      "Epoch 154/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 20.6772\n",
      "Epoch 155/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 20.5296\n",
      "Epoch 156/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 20.3165\n",
      "Epoch 157/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 20.1186\n",
      "Epoch 158/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 19.8433\n",
      "Epoch 159/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 19.6695\n",
      "Epoch 160/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 19.4958\n",
      "Epoch 161/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 19.2891\n",
      "Epoch 162/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 19.2140\n",
      "Epoch 163/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 18.9377\n",
      "Epoch 164/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 18.7634\n",
      "Epoch 165/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 18.6133\n",
      "Epoch 166/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 18.4625\n",
      "Epoch 167/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 18.2661\n",
      "Epoch 168/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 18.1142\n",
      "Epoch 169/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 18.0053\n",
      "Epoch 170/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 18.0556\n",
      "Epoch 171/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 17.7140\n",
      "Epoch 172/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 17.4465\n",
      "Epoch 173/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 17.3023\n",
      "Epoch 174/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 17.1516\n",
      "Epoch 175/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 17.0221\n",
      "Epoch 176/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 16.9055\n",
      "Epoch 177/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 16.6927\n",
      "Epoch 178/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 16.5136\n",
      "Epoch 179/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 16.3922\n",
      "Epoch 180/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 16.2569\n",
      "Epoch 181/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 16.0680\n",
      "Epoch 182/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 15.8936\n",
      "Epoch 183/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 15.7927\n",
      "Epoch 184/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 15.6510\n",
      "Epoch 185/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 15.5119\n",
      "Epoch 186/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 15.3493\n",
      "Epoch 187/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 15.2113\n",
      "Epoch 188/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 15.0784\n",
      "Epoch 189/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 15.0268\n",
      "Epoch 190/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 14.8881\n",
      "Epoch 191/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 14.7428\n",
      "Epoch 192/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 14.6973\n",
      "Epoch 193/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 14.5638\n",
      "Epoch 194/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 14.3714\n",
      "Epoch 195/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 14.3502\n",
      "Epoch 196/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 14.1984\n",
      "Epoch 197/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 14.0278\n",
      "Epoch 198/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 13.9034\n",
      "Epoch 199/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 13.7922\n",
      "Epoch 200/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 13.7265\n",
      "Epoch 201/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 13.6012\n",
      "Epoch 202/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 13.5206\n",
      "Epoch 203/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 13.3685\n",
      "Epoch 204/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 13.2472\n",
      "Epoch 205/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 13.1902\n",
      "Epoch 206/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 13.1143\n",
      "Epoch 207/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 13.0261\n",
      "Epoch 208/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 12.8221\n",
      "Epoch 209/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 12.7330\n",
      "Epoch 210/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 12.5950\n",
      "Epoch 211/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 12.4710\n",
      "Epoch 212/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 12.3444\n",
      "Epoch 213/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 12.3368\n",
      "Epoch 214/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 12.2364\n",
      "Epoch 215/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 12.0687\n",
      "Epoch 216/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 12.1568\n",
      "Epoch 217/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 11.8436\n",
      "Epoch 218/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 11.7786\n",
      "Epoch 219/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 11.5829\n",
      "Epoch 220/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 11.4648\n",
      "Epoch 221/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 11.3755\n",
      "Epoch 222/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 11.2680\n",
      "Epoch 223/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 11.1670\n",
      "Epoch 224/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 11.0625\n",
      "Epoch 225/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 10.9331\n",
      "Epoch 226/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 10.8321\n",
      "Epoch 227/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 10.7675\n",
      "Epoch 228/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 10.7082\n",
      "Epoch 229/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 10.5384\n",
      "Epoch 230/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 10.4653\n",
      "Epoch 231/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 10.4123\n",
      "Epoch 232/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 10.3332\n",
      "Epoch 233/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 10.2209\n",
      "Epoch 234/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 10.1212\n",
      "Epoch 235/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 10.0229\n",
      "Epoch 236/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 9.9550\n",
      "Epoch 237/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 9.9058\n",
      "Epoch 238/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 9.7812\n",
      "Epoch 239/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 9.7208\n",
      "Epoch 240/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 9.5651\n",
      "Epoch 241/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 9.4690\n",
      "Epoch 242/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 9.3744\n",
      "Epoch 243/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 9.2813\n",
      "Epoch 244/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 9.2101\n",
      "Epoch 245/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 9.1105\n",
      "Epoch 246/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 9.0216\n",
      "Epoch 247/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 8.9758\n",
      "Epoch 248/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 8.8715\n",
      "Epoch 249/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 8.7833\n",
      "Epoch 250/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 8.7295\n",
      "Epoch 251/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 8.6797\n",
      "Epoch 252/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 8.6854\n",
      "Epoch 253/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 8.6283\n",
      "Epoch 254/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 8.4765\n",
      "Epoch 255/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 8.3755\n",
      "Epoch 256/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 8.2999\n",
      "Epoch 257/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 8.2300\n",
      "Epoch 258/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 8.1709\n",
      "Epoch 259/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 8.1172\n",
      "Epoch 260/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 8.0686\n",
      "Epoch 261/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 7.9955\n",
      "Epoch 262/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 7.9164\n",
      "Epoch 263/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 7.8936\n",
      "Epoch 264/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 7.8638\n",
      "Epoch 265/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 7.8111\n",
      "Epoch 266/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 7.7103\n",
      "Epoch 267/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 7.6786\n",
      "Epoch 268/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 7.6054\n",
      "Epoch 269/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 7.5610\n",
      "Epoch 270/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 7.4707\n",
      "Epoch 271/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 7.4215\n",
      "Epoch 272/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 7.3633\n",
      "Epoch 273/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 7.3235\n",
      "Epoch 274/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 7.2502\n",
      "Epoch 275/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 7.2527\n",
      "Epoch 276/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 7.2339\n",
      "Epoch 277/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 7.1607\n",
      "Epoch 278/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 7.1311\n",
      "Epoch 279/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 7.0081\n",
      "Epoch 280/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 6.9785\n",
      "Epoch 281/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 6.9090\n",
      "Epoch 282/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 6.8524\n",
      "Epoch 283/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 6.8104\n",
      "Epoch 284/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 6.7573\n",
      "Epoch 285/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 6.6997\n",
      "Epoch 286/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 6.6330\n",
      "Epoch 287/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 6.6049\n",
      "Epoch 288/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 6.5731\n",
      "Epoch 289/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 6.6112\n",
      "Epoch 290/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 6.4710\n",
      "Epoch 291/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 6.4321\n",
      "Epoch 292/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 6.3719\n",
      "Epoch 293/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 6.3539\n",
      "Epoch 294/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 6.3430\n",
      "Epoch 295/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 6.2245\n",
      "Epoch 296/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 6.2175\n",
      "Epoch 297/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 6.1336\n",
      "Epoch 298/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 6.0995\n",
      "Epoch 299/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 6.0425\n",
      "Epoch 300/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 6.0021\n",
      "Epoch 301/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 5.9759\n",
      "Epoch 302/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 5.9321\n",
      "Epoch 303/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 5.8735\n",
      "Epoch 304/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 5.8645\n",
      "Epoch 305/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 5.8117\n",
      "Epoch 306/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 5.7808\n",
      "Epoch 307/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 5.7265\n",
      "Epoch 308/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 5.7179\n",
      "Epoch 309/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 5.7015\n",
      "Epoch 310/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 5.6599\n",
      "Epoch 311/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 5.6637\n",
      "Epoch 312/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 5.5666\n",
      "Epoch 313/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 5.5296\n",
      "Epoch 314/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 5.5006\n",
      "Epoch 315/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 5.5565\n",
      "Epoch 316/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 5.4598\n",
      "Epoch 317/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 5.3869\n",
      "Epoch 318/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 5.3323\n",
      "Epoch 319/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 5.3802\n",
      "Epoch 320/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 5.3020\n",
      "Epoch 321/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 5.2364\n",
      "Epoch 322/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 5.1995\n",
      "Epoch 323/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 5.1600\n",
      "Epoch 324/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 5.1250\n",
      "Epoch 325/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 5.1168\n",
      "Epoch 326/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 5.0746\n",
      "Epoch 327/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 5.0712\n",
      "Epoch 328/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 5.0486\n",
      "Epoch 329/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 4.9807\n",
      "Epoch 330/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 4.9577\n",
      "Epoch 331/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 4.9200\n",
      "Epoch 332/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 4.8794\n",
      "Epoch 333/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 4.8571\n",
      "Epoch 334/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 4.8461\n",
      "Epoch 335/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 4.8007\n",
      "Epoch 336/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 4.9254\n",
      "Epoch 337/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 5.2398\n",
      "Epoch 338/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 4.7419\n",
      "Epoch 339/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 4.7428\n",
      "Epoch 340/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 4.6482\n",
      "Epoch 341/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 4.6228\n",
      "Epoch 342/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 4.5885\n",
      "Epoch 343/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 4.5665\n",
      "Epoch 344/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 4.5497\n",
      "Epoch 345/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 4.5204\n",
      "Epoch 346/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 4.5189\n",
      "Epoch 347/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 4.4574\n",
      "Epoch 348/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 4.4564\n",
      "Epoch 349/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 4.4456\n",
      "Epoch 350/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 4.3814\n",
      "Epoch 351/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 4.3723\n",
      "Epoch 352/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 4.3287\n",
      "Epoch 353/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 4.3361\n",
      "Epoch 354/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 4.2834\n",
      "Epoch 355/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 4.2299\n",
      "Epoch 356/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 4.2393\n",
      "Epoch 357/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 4.1727\n",
      "Epoch 358/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 4.1682\n",
      "Epoch 359/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 4.1332\n",
      "Epoch 360/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 4.1216\n",
      "Epoch 361/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 4.1262\n",
      "Epoch 362/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 4.0655\n",
      "Epoch 363/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 4.0380\n",
      "Epoch 364/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 4.0236\n",
      "Epoch 365/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 3.9944\n",
      "Epoch 366/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 3.9995\n",
      "Epoch 367/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 3.9901\n",
      "Epoch 368/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 3.9654\n",
      "Epoch 369/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 3.9139\n",
      "Epoch 370/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 3.8637\n",
      "Epoch 371/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 3.8386\n",
      "Epoch 372/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 3.8505\n",
      "Epoch 373/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 3.8320\n",
      "Epoch 374/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 3.8019\n",
      "Epoch 375/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 3.7621\n",
      "Epoch 376/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 3.7394\n",
      "Epoch 377/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 3.6831\n",
      "Epoch 378/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 3.7022\n",
      "Epoch 379/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 3.7249\n",
      "Epoch 380/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 3.6423\n",
      "Epoch 381/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 3.6171\n",
      "Epoch 382/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 3.6387\n",
      "Epoch 383/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 3.5604\n",
      "Epoch 384/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 3.5848\n",
      "Epoch 385/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 3.5280\n",
      "Epoch 386/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 3.5623\n",
      "Epoch 387/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 3.6262\n",
      "Epoch 388/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 3.5571\n",
      "Epoch 389/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 3.4094\n",
      "Epoch 390/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 3.4104\n",
      "Epoch 391/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 3.4068\n",
      "Epoch 392/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 3.3831\n",
      "Epoch 393/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 3.4267\n",
      "Epoch 394/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 3.3916\n",
      "Epoch 395/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 3.3247\n",
      "Epoch 396/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 3.3745\n",
      "Epoch 397/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 3.3763\n",
      "Epoch 398/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 3.2893\n",
      "Epoch 399/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 3.2323\n",
      "Epoch 400/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 3.1879\n",
      "Epoch 401/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 3.2579\n",
      "Epoch 402/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 3.2359\n",
      "Epoch 403/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 3.2528\n",
      "Epoch 404/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 3.1438\n",
      "Epoch 405/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 3.1404\n",
      "Epoch 406/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 3.0779\n",
      "Epoch 407/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 3.0620\n",
      "Epoch 408/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 3.0503\n",
      "Epoch 409/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 3.0577\n",
      "Epoch 410/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 2.9890\n",
      "Epoch 411/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 3.0133\n",
      "Epoch 412/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 3.0306\n",
      "Epoch 413/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 3.0316\n",
      "Epoch 414/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 2.9578\n",
      "Epoch 415/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 2.9807\n",
      "Epoch 416/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 2.8793\n",
      "Epoch 417/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 2.8838\n",
      "Epoch 418/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 2.8496\n",
      "Epoch 419/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 2.8295\n",
      "Epoch 420/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 2.8323\n",
      "Epoch 421/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 2.8153\n",
      "Epoch 422/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 2.7925\n",
      "Epoch 423/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 2.7892\n",
      "Epoch 424/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 2.7422\n",
      "Epoch 425/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 2.7585\n",
      "Epoch 426/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 2.7320\n",
      "Epoch 427/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 2.7038\n",
      "Epoch 428/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 2.6943\n",
      "Epoch 429/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 2.6983\n",
      "Epoch 430/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 2.6477\n",
      "Epoch 431/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 2.6341\n",
      "Epoch 432/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 2.6258\n",
      "Epoch 433/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 2.6333\n",
      "Epoch 434/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 2.6553\n",
      "Epoch 435/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 2.6048\n",
      "Epoch 436/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 2.5815\n",
      "Epoch 437/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 2.5428\n",
      "Epoch 438/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 2.5309\n",
      "Epoch 439/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 2.5145\n",
      "Epoch 440/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 2.4938\n",
      "Epoch 441/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 2.5036\n",
      "Epoch 442/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 2.5080\n",
      "Epoch 443/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 2.4378\n",
      "Epoch 444/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 2.4655\n",
      "Epoch 445/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 2.4137\n",
      "Epoch 446/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 2.4096\n",
      "Epoch 447/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 2.4331\n",
      "Epoch 448/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 2.3816\n",
      "Epoch 449/1000\n",
      "1564/1564 [==============================] - 0s 12us/step - loss: 2.3640\n",
      "Epoch 450/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 2.3294\n",
      "Epoch 451/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 2.3522\n",
      "Epoch 452/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 2.3355\n",
      "Epoch 453/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 2.2950\n",
      "Epoch 454/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 2.2958\n",
      "Epoch 455/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 2.2987\n",
      "Epoch 456/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 2.2894\n",
      "Epoch 457/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 2.2896\n",
      "Epoch 458/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 2.3304\n",
      "Epoch 459/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 2.2258\n",
      "Epoch 460/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 2.2979\n",
      "Epoch 461/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 2.2741\n",
      "Epoch 462/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 2.3225\n",
      "Epoch 463/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 2.2065\n",
      "Epoch 464/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 2.1515\n",
      "Epoch 465/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 2.1499\n",
      "Epoch 466/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 2.1420\n",
      "Epoch 467/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 2.1494\n",
      "Epoch 468/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 2.2184\n",
      "Epoch 469/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 2.1047\n",
      "Epoch 470/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 2.0819\n",
      "Epoch 471/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 2.0550\n",
      "Epoch 472/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 2.0620\n",
      "Epoch 473/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 2.0459\n",
      "Epoch 474/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 2.0179\n",
      "Epoch 475/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 2.0334\n",
      "Epoch 476/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 2.0371\n",
      "Epoch 477/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 2.0168\n",
      "Epoch 478/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 2.0092\n",
      "Epoch 479/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.9382\n",
      "Epoch 480/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 2.0137\n",
      "Epoch 481/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.9958\n",
      "Epoch 482/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.9417\n",
      "Epoch 483/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.9419\n",
      "Epoch 484/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.9450\n",
      "Epoch 485/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.9603\n",
      "Epoch 486/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.8718\n",
      "Epoch 487/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 1.8759\n",
      "Epoch 488/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.8905\n",
      "Epoch 489/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.9176\n",
      "Epoch 490/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.8510\n",
      "Epoch 491/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.8367\n",
      "Epoch 492/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 1.7923\n",
      "Epoch 493/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 1.8950\n",
      "Epoch 494/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.7982\n",
      "Epoch 495/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.7771\n",
      "Epoch 496/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.7521\n",
      "Epoch 497/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 1.7964\n",
      "Epoch 498/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.7392\n",
      "Epoch 499/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.7257\n",
      "Epoch 500/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.7121\n",
      "Epoch 501/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.7030\n",
      "Epoch 502/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.7024\n",
      "Epoch 503/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.7080\n",
      "Epoch 504/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.6613\n",
      "Epoch 505/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 1.6658\n",
      "Epoch 506/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.6713\n",
      "Epoch 507/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.6258\n",
      "Epoch 508/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.6618\n",
      "Epoch 509/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.6795\n",
      "Epoch 510/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.6614\n",
      "Epoch 511/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.6070\n",
      "Epoch 512/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.5946\n",
      "Epoch 513/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.5667\n",
      "Epoch 514/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.5695\n",
      "Epoch 515/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.6324\n",
      "Epoch 516/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 1.5806\n",
      "Epoch 517/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.5439\n",
      "Epoch 518/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.5317\n",
      "Epoch 519/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.5231\n",
      "Epoch 520/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.5272\n",
      "Epoch 521/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.5256\n",
      "Epoch 522/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.5376\n",
      "Epoch 523/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.5217\n",
      "Epoch 524/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.4976\n",
      "Epoch 525/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.4705\n",
      "Epoch 526/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.4560\n",
      "Epoch 527/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.4477\n",
      "Epoch 528/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.4696\n",
      "Epoch 529/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.4934\n",
      "Epoch 530/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.4358\n",
      "Epoch 531/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.4364\n",
      "Epoch 532/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.4614\n",
      "Epoch 533/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.5145\n",
      "Epoch 534/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.4605\n",
      "Epoch 535/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.5023\n",
      "Epoch 536/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.5379\n",
      "Epoch 537/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 1.4789\n",
      "Epoch 538/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.3793\n",
      "Epoch 539/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.3510\n",
      "Epoch 540/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.3523\n",
      "Epoch 541/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.4380\n",
      "Epoch 542/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.3429\n",
      "Epoch 543/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.3536\n",
      "Epoch 544/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.3244\n",
      "Epoch 545/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 1.3011\n",
      "Epoch 546/1000\n",
      "1564/1564 [==============================] - 0s 12us/step - loss: 1.3187\n",
      "Epoch 547/1000\n",
      "1564/1564 [==============================] - 0s 12us/step - loss: 1.3588\n",
      "Epoch 548/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.2902\n",
      "Epoch 549/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.2840\n",
      "Epoch 550/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.3805\n",
      "Epoch 551/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.2881\n",
      "Epoch 552/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 1.2909\n",
      "Epoch 553/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.2974\n",
      "Epoch 554/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.3216\n",
      "Epoch 555/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.3879\n",
      "Epoch 556/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2798\n",
      "Epoch 557/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.2767\n",
      "Epoch 558/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 1.2425\n",
      "Epoch 559/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.2098\n",
      "Epoch 560/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.2255\n",
      "Epoch 561/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.2073\n",
      "Epoch 562/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2033\n",
      "Epoch 563/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.1769\n",
      "Epoch 564/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 1.1827\n",
      "Epoch 565/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1725\n",
      "Epoch 566/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1910\n",
      "Epoch 567/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.2244\n",
      "Epoch 568/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1875\n",
      "Epoch 569/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.2026\n",
      "Epoch 570/1000\n",
      "1564/1564 [==============================] - 0s 12us/step - loss: 1.2003\n",
      "Epoch 571/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 1.2182\n",
      "Epoch 572/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 1.2610\n",
      "Epoch 573/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 1.1992\n",
      "Epoch 574/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.2461\n",
      "Epoch 575/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 1.1901\n",
      "Epoch 576/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1427\n",
      "Epoch 577/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1486\n",
      "Epoch 578/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.2380\n",
      "Epoch 579/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1257\n",
      "Epoch 580/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1438\n",
      "Epoch 581/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.0987\n",
      "Epoch 582/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.1142\n",
      "Epoch 583/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 1.0970\n",
      "Epoch 584/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1110\n",
      "Epoch 585/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.0939\n",
      "Epoch 586/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.1117\n",
      "Epoch 587/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.0990\n",
      "Epoch 588/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.0749\n",
      "Epoch 589/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.0413\n",
      "Epoch 590/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 1.0880\n",
      "Epoch 591/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 1.1929\n",
      "Epoch 592/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.0991\n",
      "Epoch 593/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.0698\n",
      "Epoch 594/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.2861\n",
      "Epoch 595/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.0554\n",
      "Epoch 596/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.0279\n",
      "Epoch 597/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 1.0189\n",
      "Epoch 598/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 1.0006\n",
      "Epoch 599/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.0029\n",
      "Epoch 600/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.9955\n",
      "Epoch 601/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.0281\n",
      "Epoch 602/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 1.0078\n",
      "Epoch 603/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 1.0065\n",
      "Epoch 604/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.0027\n",
      "Epoch 605/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.9781\n",
      "Epoch 606/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.0109\n",
      "Epoch 607/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.9756\n",
      "Epoch 608/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.9887\n",
      "Epoch 609/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.9635\n",
      "Epoch 610/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.9836\n",
      "Epoch 611/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.0039\n",
      "Epoch 612/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.9810\n",
      "Epoch 613/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.9491\n",
      "Epoch 614/1000\n",
      "1564/1564 [==============================] - 0s 11us/step - loss: 0.9700\n",
      "Epoch 615/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.9437\n",
      "Epoch 616/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.9824\n",
      "Epoch 617/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.0088\n",
      "Epoch 618/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.0605\n",
      "Epoch 619/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.1334\n",
      "Epoch 620/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 1.0007\n",
      "Epoch 621/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 0.9502\n",
      "Epoch 622/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.9204\n",
      "Epoch 623/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.9541\n",
      "Epoch 624/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.0390\n",
      "Epoch 625/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.9499\n",
      "Epoch 626/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.9976\n",
      "Epoch 627/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 1.0185\n",
      "Epoch 628/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 1.0083\n",
      "Epoch 629/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 0.9150\n",
      "Epoch 630/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.9086\n",
      "Epoch 631/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.9636\n",
      "Epoch 632/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.8801\n",
      "Epoch 633/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.9704\n",
      "Epoch 634/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.9951\n",
      "Epoch 635/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.9625\n",
      "Epoch 636/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.9421\n",
      "Epoch 637/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.9179\n",
      "Epoch 638/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.9036\n",
      "Epoch 639/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.9564\n",
      "Epoch 640/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.9832\n",
      "Epoch 641/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.9155\n",
      "Epoch 642/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.8890\n",
      "Epoch 643/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.9122\n",
      "Epoch 644/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 0.9168\n",
      "Epoch 645/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 0.8830\n",
      "Epoch 646/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.8891\n",
      "Epoch 647/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.8629\n",
      "Epoch 648/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.9483\n",
      "Epoch 649/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.9180\n",
      "Epoch 650/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 0.8585\n",
      "Epoch 651/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.8552\n",
      "Epoch 652/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.8609\n",
      "Epoch 653/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.9653\n",
      "Epoch 654/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.8529\n",
      "Epoch 655/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.8968\n",
      "Epoch 656/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.8667\n",
      "Epoch 657/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 0.8742\n",
      "Epoch 658/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 0.8442\n",
      "Epoch 659/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.0113\n",
      "Epoch 660/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.8611\n",
      "Epoch 661/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.8660\n",
      "Epoch 662/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 0.8691\n",
      "Epoch 663/1000\n",
      "1564/1564 [==============================] - 0s 12us/step - loss: 0.8579\n",
      "Epoch 664/1000\n",
      "1564/1564 [==============================] - 0s 12us/step - loss: 0.8354\n",
      "Epoch 665/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.8089\n",
      "Epoch 666/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.9090\n",
      "Epoch 667/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.8127\n",
      "Epoch 668/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.8192\n",
      "Epoch 669/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 0.8803\n",
      "Epoch 670/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 0.8499\n",
      "Epoch 671/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 0.8944\n",
      "Epoch 672/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.8155\n",
      "Epoch 673/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.8077\n",
      "Epoch 674/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.8452\n",
      "Epoch 675/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 0.9574\n",
      "Epoch 676/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 0.9233\n",
      "Epoch 677/1000\n",
      "1564/1564 [==============================] - 0s 12us/step - loss: 1.0006\n",
      "Epoch 678/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.9042\n",
      "Epoch 679/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.8243\n",
      "Epoch 680/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.8548\n",
      "Epoch 681/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.8498\n",
      "Epoch 682/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.8149\n",
      "Epoch 683/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.8014\n",
      "Epoch 684/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.7828\n",
      "Epoch 685/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.7795\n",
      "Epoch 686/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.7846\n",
      "Epoch 687/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.7823\n",
      "Epoch 688/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.8767\n",
      "Epoch 689/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 1.0367\n",
      "Epoch 690/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.9702\n",
      "Epoch 691/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.8050\n",
      "Epoch 692/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.8312\n",
      "Epoch 693/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.7651\n",
      "Epoch 694/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.8184\n",
      "Epoch 695/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.7689\n",
      "Epoch 696/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.7836\n",
      "Epoch 697/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.7588\n",
      "Epoch 698/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.8158\n",
      "Epoch 699/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.9061\n",
      "Epoch 700/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.0935\n",
      "Epoch 701/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.6100\n",
      "Epoch 702/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 0.9404\n",
      "Epoch 703/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.9276\n",
      "Epoch 704/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.0945\n",
      "Epoch 705/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.9030\n",
      "Epoch 706/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.9005\n",
      "Epoch 707/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.8469\n",
      "Epoch 708/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.8325\n",
      "Epoch 709/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 0.8583\n",
      "Epoch 710/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 1.1090\n",
      "Epoch 711/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 0.8180\n",
      "Epoch 712/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.8473\n",
      "Epoch 713/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.8601\n",
      "Epoch 714/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.9168\n",
      "Epoch 715/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.8737\n",
      "Epoch 716/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 0.9245\n",
      "Epoch 717/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 0.8772\n",
      "Epoch 718/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 1.1198\n",
      "Epoch 719/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 0.9140\n",
      "Epoch 720/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 0.8735\n",
      "Epoch 721/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 0.9336\n",
      "Epoch 722/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.9605\n",
      "Epoch 723/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.7965\n",
      "Epoch 724/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.7998\n",
      "Epoch 725/1000\n",
      "1564/1564 [==============================] - 0s 12us/step - loss: 0.9893\n",
      "Epoch 726/1000\n",
      "1564/1564 [==============================] - 0s 12us/step - loss: 0.7383\n",
      "Epoch 727/1000\n",
      "1564/1564 [==============================] - 0s 12us/step - loss: 0.8519\n",
      "Epoch 728/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.7719\n",
      "Epoch 729/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 0.7515\n",
      "Epoch 730/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.8570\n",
      "Epoch 731/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.2029\n",
      "Epoch 732/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.9084\n",
      "Epoch 733/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 0.7891\n",
      "Epoch 734/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 0.7397\n",
      "Epoch 735/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.7439\n",
      "Epoch 736/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.7398\n",
      "Epoch 737/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.8375\n",
      "Epoch 738/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.7890\n",
      "Epoch 739/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.7549\n",
      "Epoch 740/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.7832\n",
      "Epoch 741/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.7134\n",
      "Epoch 742/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 0.8071\n",
      "Epoch 743/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.7200\n",
      "Epoch 744/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 0.7496\n",
      "Epoch 745/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.9175\n",
      "Epoch 746/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.7528\n",
      "Epoch 747/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.8846\n",
      "Epoch 748/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.0347\n",
      "Epoch 749/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.8877\n",
      "Epoch 750/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.8548\n",
      "Epoch 751/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 0.7343\n",
      "Epoch 752/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.7355\n",
      "Epoch 753/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.7219\n",
      "Epoch 754/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.7131\n",
      "Epoch 755/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.7987\n",
      "Epoch 756/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 0.7639\n",
      "Epoch 757/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.7349\n",
      "Epoch 758/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.7448\n",
      "Epoch 759/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.8214\n",
      "Epoch 760/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.8610\n",
      "Epoch 761/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.7822\n",
      "Epoch 762/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.7347\n",
      "Epoch 763/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.7976\n",
      "Epoch 764/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.8847\n",
      "Epoch 765/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.8330\n",
      "Epoch 766/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.6950\n",
      "Epoch 767/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.7857\n",
      "Epoch 768/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.0210\n",
      "Epoch 769/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.7835\n",
      "Epoch 770/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.7343\n",
      "Epoch 771/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.7433\n",
      "Epoch 772/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.8199\n",
      "Epoch 773/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 0.7881\n",
      "Epoch 774/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.7264\n",
      "Epoch 775/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.8530\n",
      "Epoch 776/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.7684\n",
      "Epoch 777/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.8924\n",
      "Epoch 778/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.7417\n",
      "Epoch 779/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 0.7375\n",
      "Epoch 780/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.7392\n",
      "Epoch 781/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.8855\n",
      "Epoch 782/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.8558\n",
      "Epoch 783/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.8466\n",
      "Epoch 784/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.8848\n",
      "Epoch 785/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.8282\n",
      "Epoch 786/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.7245\n",
      "Epoch 787/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.7130\n",
      "Epoch 788/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.7050\n",
      "Epoch 789/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.8167\n",
      "Epoch 790/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.7514\n",
      "Epoch 791/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 0.7327\n",
      "Epoch 792/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 0.9276\n",
      "Epoch 793/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 0.9076\n",
      "Epoch 794/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 0.8146\n",
      "Epoch 795/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.7400\n",
      "Epoch 796/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.8741\n",
      "Epoch 797/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.7178\n",
      "Epoch 798/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.7718\n",
      "Epoch 799/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.6837\n",
      "Epoch 800/1000\n",
      "1564/1564 [==============================] - 0s 12us/step - loss: 0.7281\n",
      "Epoch 801/1000\n",
      "1564/1564 [==============================] - 0s 11us/step - loss: 0.7156\n",
      "Epoch 802/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.7318\n",
      "Epoch 803/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.8733\n",
      "Epoch 804/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 0.6811\n",
      "Epoch 805/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.7178\n",
      "Epoch 806/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.8822\n",
      "Epoch 807/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.6991\n",
      "Epoch 808/1000\n",
      "1564/1564 [==============================] - 0s 12us/step - loss: 0.8340\n",
      "Epoch 809/1000\n",
      "1564/1564 [==============================] - 0s 11us/step - loss: 0.7511\n",
      "Epoch 810/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.7272\n",
      "Epoch 811/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.9438\n",
      "Epoch 812/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.7333\n",
      "Epoch 813/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.7164\n",
      "Epoch 814/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.6974\n",
      "Epoch 815/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.7270\n",
      "Epoch 816/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.9720\n",
      "Epoch 817/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 0.7633\n",
      "Epoch 818/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.1596\n",
      "Epoch 819/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1978\n",
      "Epoch 820/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.7384\n",
      "Epoch 821/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.8813\n",
      "Epoch 822/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.7854\n",
      "Epoch 823/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 0.7518\n",
      "Epoch 824/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.8505\n",
      "Epoch 825/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 0.8387\n",
      "Epoch 826/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.8249\n",
      "Epoch 827/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.8811\n",
      "Epoch 828/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.9076\n",
      "Epoch 829/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.7840\n",
      "Epoch 830/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.7678\n",
      "Epoch 831/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.9662\n",
      "Epoch 832/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.8421\n",
      "Epoch 833/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.6960\n",
      "Epoch 834/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.8018\n",
      "Epoch 835/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.6908\n",
      "Epoch 836/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.8132\n",
      "Epoch 837/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.7516\n",
      "Epoch 838/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.7929\n",
      "Epoch 839/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.7458\n",
      "Epoch 840/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 1.0077\n",
      "Epoch 841/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 0.8706\n",
      "Epoch 842/1000\n",
      "1564/1564 [==============================] - 0s 12us/step - loss: 0.8907\n",
      "Epoch 843/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 0.7023\n",
      "Epoch 844/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.8173\n",
      "Epoch 845/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.1082\n",
      "Epoch 846/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.3845\n",
      "Epoch 847/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.0257\n",
      "Epoch 848/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.8976\n",
      "Epoch 849/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.7164\n",
      "Epoch 850/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.7965\n",
      "Epoch 851/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.6947\n",
      "Epoch 852/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.6990\n",
      "Epoch 853/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.8974\n",
      "Epoch 854/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.7749\n",
      "Epoch 855/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.6606\n",
      "Epoch 856/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.7825\n",
      "Epoch 857/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.6769\n",
      "Epoch 858/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.6821\n",
      "Epoch 859/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.6521\n",
      "Epoch 860/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.7052\n",
      "Epoch 861/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.7710\n",
      "Epoch 862/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.8133\n",
      "Epoch 863/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.6938\n",
      "Epoch 864/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 0.7735\n",
      "Epoch 865/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.7801\n",
      "Epoch 866/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.7082\n",
      "Epoch 867/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.6505\n",
      "Epoch 868/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.7206\n",
      "Epoch 869/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.8474\n",
      "Epoch 870/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.7508\n",
      "Epoch 871/1000\n",
      "1564/1564 [==============================] - 0s 12us/step - loss: 0.7643\n",
      "Epoch 872/1000\n",
      "1564/1564 [==============================] - 0s 12us/step - loss: 0.7060\n",
      "Epoch 873/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.6587\n",
      "Epoch 874/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 0.7621\n",
      "Epoch 875/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 0.9595\n",
      "Epoch 876/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.1890\n",
      "Epoch 877/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.9922\n",
      "Epoch 878/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.9073\n",
      "Epoch 879/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 0.8059\n",
      "Epoch 880/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.7207\n",
      "Epoch 881/1000\n",
      "1564/1564 [==============================] - 0s 12us/step - loss: 0.7295\n",
      "Epoch 882/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.7151\n",
      "Epoch 883/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 0.7643\n",
      "Epoch 884/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 0.7085\n",
      "Epoch 885/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.6603\n",
      "Epoch 886/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.6930\n",
      "Epoch 887/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.6873\n",
      "Epoch 888/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.7033\n",
      "Epoch 889/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 1.2196\n",
      "Epoch 890/1000\n",
      "1564/1564 [==============================] - 0s 12us/step - loss: 0.9589\n",
      "Epoch 891/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.9636\n",
      "Epoch 892/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 0.7542\n",
      "Epoch 893/1000\n",
      "1564/1564 [==============================] - 0s 12us/step - loss: 1.0091\n",
      "Epoch 894/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.9133\n",
      "Epoch 895/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 1.0060\n",
      "Epoch 896/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.9354\n",
      "Epoch 897/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.7555\n",
      "Epoch 898/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.6875\n",
      "Epoch 899/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 0.7078\n",
      "Epoch 900/1000\n",
      "1564/1564 [==============================] - 0s 12us/step - loss: 0.8608\n",
      "Epoch 901/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 0.7367\n",
      "Epoch 902/1000\n",
      "1564/1564 [==============================] - 0s 12us/step - loss: 0.7162\n",
      "Epoch 903/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 0.7517\n",
      "Epoch 904/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.6986\n",
      "Epoch 905/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 0.7153\n",
      "Epoch 906/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.6867\n",
      "Epoch 907/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 0.6417\n",
      "Epoch 908/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.6746\n",
      "Epoch 909/1000\n",
      "1564/1564 [==============================] - 0s 12us/step - loss: 0.7391\n",
      "Epoch 910/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 0.8011\n",
      "Epoch 911/1000\n",
      "1564/1564 [==============================] - 0s 11us/step - loss: 0.9482\n",
      "Epoch 912/1000\n",
      "1564/1564 [==============================] - 0s 11us/step - loss: 0.8916\n",
      "Epoch 913/1000\n",
      "1564/1564 [==============================] - 0s 12us/step - loss: 0.8359\n",
      "Epoch 914/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.8565\n",
      "Epoch 915/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.8893\n",
      "Epoch 916/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.7270\n",
      "Epoch 917/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 0.7485\n",
      "Epoch 918/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.6694\n",
      "Epoch 919/1000\n",
      "1564/1564 [==============================] - 0s 12us/step - loss: 0.6933\n",
      "Epoch 920/1000\n",
      "1564/1564 [==============================] - 0s 11us/step - loss: 0.8886\n",
      "Epoch 921/1000\n",
      "1564/1564 [==============================] - 0s 12us/step - loss: 0.9926\n",
      "Epoch 922/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 1.2870\n",
      "Epoch 923/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.7261\n",
      "Epoch 924/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.7793\n",
      "Epoch 925/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.1048\n",
      "Epoch 926/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 1.0711\n",
      "Epoch 927/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.9612\n",
      "Epoch 928/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.6926\n",
      "Epoch 929/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 0.7994\n",
      "Epoch 930/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 0.9406\n",
      "Epoch 931/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.8527\n",
      "Epoch 932/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.6732\n",
      "Epoch 933/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.7828\n",
      "Epoch 934/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.7916\n",
      "Epoch 935/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.0585\n",
      "Epoch 936/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.8803\n",
      "Epoch 937/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.8455\n",
      "Epoch 938/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.7472\n",
      "Epoch 939/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 0.7307\n",
      "Epoch 940/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.6877\n",
      "Epoch 941/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.7249\n",
      "Epoch 942/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.6441\n",
      "Epoch 943/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.6837\n",
      "Epoch 944/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.6946\n",
      "Epoch 945/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 0.9686\n",
      "Epoch 946/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 0.9858\n",
      "Epoch 947/1000\n",
      "1564/1564 [==============================] - 0s 12us/step - loss: 1.3789\n",
      "Epoch 948/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 1.2081\n",
      "Epoch 949/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.7245\n",
      "Epoch 950/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.8069\n",
      "Epoch 951/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.8073\n",
      "Epoch 952/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.7082\n",
      "Epoch 953/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.7394\n",
      "Epoch 954/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.6671\n",
      "Epoch 955/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.7465\n",
      "Epoch 956/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.6627\n",
      "Epoch 957/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.6892\n",
      "Epoch 958/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 0.7811\n",
      "Epoch 959/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.8038\n",
      "Epoch 960/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.6591\n",
      "Epoch 961/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.6925\n",
      "Epoch 962/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.7204\n",
      "Epoch 963/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.6714\n",
      "Epoch 964/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.7103\n",
      "Epoch 965/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.6671\n",
      "Epoch 966/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.6624\n",
      "Epoch 967/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.6553\n",
      "Epoch 968/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 0.6816\n",
      "Epoch 969/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.8986\n",
      "Epoch 970/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.2849\n",
      "Epoch 971/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.3375\n",
      "Epoch 972/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1102\n",
      "Epoch 973/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.6993\n",
      "Epoch 974/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.6454\n",
      "Epoch 975/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 0.6535\n",
      "Epoch 976/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.6385\n",
      "Epoch 977/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.6396\n",
      "Epoch 978/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.6753\n",
      "Epoch 979/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.7155\n",
      "Epoch 980/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 0.6771\n",
      "Epoch 981/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.8140\n",
      "Epoch 982/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.0095\n",
      "Epoch 983/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 1.0143\n",
      "Epoch 984/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.7245\n",
      "Epoch 985/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 0.8014\n",
      "Epoch 986/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.7143\n",
      "Epoch 987/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 0.6284\n",
      "Epoch 988/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 0.6263\n",
      "Epoch 989/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.6678\n",
      "Epoch 990/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.8560\n",
      "Epoch 991/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.7165\n",
      "Epoch 992/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.7827\n",
      "Epoch 993/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.8295\n",
      "Epoch 994/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 0.7439\n",
      "Epoch 995/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.7400\n",
      "Epoch 996/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 0.6597\n",
      "Epoch 997/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 0.6822\n",
      "Epoch 998/1000\n",
      "1564/1564 [==============================] - 0s 12us/step - loss: 0.6583\n",
      "Epoch 999/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 0.6337\n",
      "Epoch 1000/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.7156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a30cf8cf8>"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_ast = Sequential()\n",
    "NN_ast.add(Dense(units=16,input_dim=30,activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_ast.add(Dense(units=8, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_ast.add(Dense(units=4, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_ast.add(Dense(units=1,activation='linear'))\n",
    "NN_ast.compile(loss='mse', optimizer='adam')\n",
    "NN_ast.fit(np.array(X_train), np.array(y_train), epochs=1000,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = NN_ast.predict(X_test)\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.5)\n",
    "gbr.fit(X_train,y_train)\n",
    "gbr_predictions = gbr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN_predictions</th>\n",
       "      <th>actual</th>\n",
       "      <th>GBR_predictions</th>\n",
       "      <th>LY_assists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>7.480161</td>\n",
       "      <td>6.7</td>\n",
       "      <td>7.464630</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>9.288541</td>\n",
       "      <td>10.2</td>\n",
       "      <td>9.828933</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>8.040952</td>\n",
       "      <td>11.2</td>\n",
       "      <td>9.193121</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>8.732419</td>\n",
       "      <td>10.7</td>\n",
       "      <td>9.066563</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>8.246427</td>\n",
       "      <td>8.7</td>\n",
       "      <td>9.074802</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.959043</td>\n",
       "      <td>6.5</td>\n",
       "      <td>7.853089</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>6.566098</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.494963</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>7.579740</td>\n",
       "      <td>7.7</td>\n",
       "      <td>9.181120</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>8.691312</td>\n",
       "      <td>10.4</td>\n",
       "      <td>8.291187</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>6.665311</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.263340</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>6.885755</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.402471</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>6.565671</td>\n",
       "      <td>5.5</td>\n",
       "      <td>7.809252</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>6.523618</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.349211</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>6.045835</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.564291</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>6.588010</td>\n",
       "      <td>6.1</td>\n",
       "      <td>7.696118</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.311490</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.567171</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.432340</td>\n",
       "      <td>5.7</td>\n",
       "      <td>7.667141</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>6.125638</td>\n",
       "      <td>4.7</td>\n",
       "      <td>6.413258</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>5.918759</td>\n",
       "      <td>5.9</td>\n",
       "      <td>6.585436</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>6.184796</td>\n",
       "      <td>1.2</td>\n",
       "      <td>6.804440</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>5.517072</td>\n",
       "      <td>6.7</td>\n",
       "      <td>6.306192</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>5.741239</td>\n",
       "      <td>5.9</td>\n",
       "      <td>7.071796</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>4.650144</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.570334</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>6.108289</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.641306</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>4.045499</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.930496</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>6.158536</td>\n",
       "      <td>8.5</td>\n",
       "      <td>7.303016</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.983548</td>\n",
       "      <td>5.9</td>\n",
       "      <td>7.105940</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>7.304807</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6.833794</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>5.139157</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5.706879</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>6.116513</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6.677352</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>-0.659579</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.392531</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>-0.086932</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.531416</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>-0.158420</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.471734</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>0.042142</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.535693</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>-0.146121</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.485913</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>0.062039</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.826489</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.064740</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.592716</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>0.256970</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.956251</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>0.053983</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.431681</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>-0.406528</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.482454</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-0.396243</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.635838</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>-0.719943</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.402762</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.038968</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.713300</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>-0.228519</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.621086</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>0.551801</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.984880</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>-0.064502</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.495301</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>-0.246417</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.554398</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>-0.089130</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.734039</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>-0.332675</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.619870</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>-0.279391</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.533672</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>-0.257754</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.672385</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>-0.144977</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.545874</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>-0.322238</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.480192</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.758060</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.270716</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>-0.073642</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.766106</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>-0.417895</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.535827</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>-0.279315</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.904761</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-0.927508</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.529774</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>-0.493640</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.719527</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>-0.650287</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.571717</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>671 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     NN_predictions  actual  GBR_predictions  LY_assists\n",
       "34         7.480161     6.7         7.464630        10.7\n",
       "20         9.288541    10.2         9.828933        10.7\n",
       "444        8.040952    11.2         9.193121         9.8\n",
       "226        8.732419    10.7         9.066563         9.7\n",
       "581        8.246427     8.7         9.074802         9.7\n",
       "23         5.959043     6.5         7.853089         9.0\n",
       "101        6.566098     7.4         7.494963         8.8\n",
       "418        7.579740     7.7         9.181120         8.7\n",
       "649        8.691312    10.4         8.291187         8.6\n",
       "66         6.665311     8.0         7.263340         8.3\n",
       "523        6.885755     7.3         7.402471         8.2\n",
       "663        6.565671     5.5         7.809252         8.2\n",
       "323        6.523618     7.0         8.349211         8.0\n",
       "493        6.045835     7.6         7.564291         7.7\n",
       "434        6.588010     6.1         7.696118         7.7\n",
       "6          5.311490     5.0         6.567171         7.6\n",
       "13         6.432340     5.7         7.667141         7.6\n",
       "346        6.125638     4.7         6.413258         7.4\n",
       "43         5.918759     5.9         6.585436         7.4\n",
       "563        6.184796     1.2         6.804440         7.2\n",
       "476        5.517072     6.7         6.306192         7.2\n",
       "535        5.741239     5.9         7.071796         7.0\n",
       "50         4.650144     3.7         4.570334         7.0\n",
       "70         6.108289     7.5         6.641306         7.0\n",
       "605        4.045499     5.2         2.930496         7.0\n",
       "546        6.158536     8.5         7.303016         6.9\n",
       "99         5.983548     5.9         7.105940         6.8\n",
       "532        7.304807     6.6         6.833794         6.7\n",
       "575        5.139157     5.9         5.706879         6.7\n",
       "341        6.116513     5.8         6.677352         6.6\n",
       "..              ...     ...              ...         ...\n",
       "422       -0.659579     0.2         0.392531         0.2\n",
       "357       -0.086932     1.3         0.531416         0.2\n",
       "171       -0.158420     0.4         0.471734         0.2\n",
       "472        0.042142     0.3         0.535693         0.2\n",
       "384       -0.146121     0.2         0.485913         0.2\n",
       "465        0.062039     1.2         0.826489         0.2\n",
       "182        0.064740     0.5         0.592716         0.2\n",
       "359        0.256970     0.8         0.956251         0.2\n",
       "229        0.053983     0.4         0.431681         0.2\n",
       "461       -0.406528     0.4         0.482454         0.2\n",
       "39        -0.396243     0.9         0.635838         0.2\n",
       "224       -0.719943     0.3         0.402762         0.2\n",
       "125        0.038968     0.4         0.713300         0.2\n",
       "554       -0.228519     0.8         0.621086         0.2\n",
       "314        0.551801     1.0         0.984880         0.2\n",
       "577       -0.064502     0.1         0.495301         0.2\n",
       "304       -0.246417     0.3         0.554398         0.2\n",
       "190       -0.089130     0.6         0.734039         0.2\n",
       "351       -0.332675     0.1         0.619870         0.1\n",
       "281       -0.279391     0.2         0.533672         0.1\n",
       "65        -0.257754     0.4         0.672385         0.1\n",
       "643       -0.144977     0.3         0.545874         0.1\n",
       "659       -0.322238     0.2         0.480192         0.1\n",
       "1         -0.758060     0.2         0.270716         0.1\n",
       "140       -0.073642     0.6         0.766106         0.1\n",
       "343       -0.417895     0.2         0.535827         0.1\n",
       "382       -0.279315     1.8         0.904761         0.0\n",
       "36        -0.927508     0.3         0.529774         0.0\n",
       "376       -0.493640     0.9         0.719527         0.0\n",
       "360       -0.650287     1.8         0.571717         0.0\n",
       "\n",
       "[671 rows x 4 columns]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing = pd.DataFrame(predictions)\n",
    "testing.columns=['NN_predictions']\n",
    "testing['actual'] = y_test.reset_index()['assists']\n",
    "testing['GBR_predictions']=gbr_predictions\n",
    "testing['LY_assists']=X_test['assists_ly'].reset_index()['assists_ly']\n",
    "testing.sort_values(by='LY_assists',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>assists</th>\n",
       "      <th>predictions</th>\n",
       "      <th>assists_ly_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>James Harden</td>\n",
       "      <td>8.8</td>\n",
       "      <td>8.751309</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>John Wall</td>\n",
       "      <td>9.6</td>\n",
       "      <td>8.472669</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>Russell Westbrook</td>\n",
       "      <td>10.3</td>\n",
       "      <td>10.363492</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Chris Paul</td>\n",
       "      <td>7.9</td>\n",
       "      <td>8.602536</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>Ricky Rubio</td>\n",
       "      <td>5.3</td>\n",
       "      <td>7.056455</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>LeBron James</td>\n",
       "      <td>9.1</td>\n",
       "      <td>7.620450</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>Jeff Teague</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.642941</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Jrue Holiday</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.235166</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>Kyle Lowry</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.189878</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Draymond Green</td>\n",
       "      <td>7.3</td>\n",
       "      <td>5.111875</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>Rajon Rondo</td>\n",
       "      <td>8.2</td>\n",
       "      <td>4.627744</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>T.J. McConnell</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.980649</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>Stephen Curry</td>\n",
       "      <td>6.1</td>\n",
       "      <td>6.681119</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Elfrid Payton</td>\n",
       "      <td>6.3</td>\n",
       "      <td>5.870633</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Dennis Schroder</td>\n",
       "      <td>6.2</td>\n",
       "      <td>5.507077</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>Mike Conley</td>\n",
       "      <td>4.1</td>\n",
       "      <td>6.208508</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Eric Bledsoe</td>\n",
       "      <td>5.1</td>\n",
       "      <td>5.172452</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Isaiah Thomas</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.471768</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>Nicolas Batum</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.009671</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Damian Lillard</td>\n",
       "      <td>6.6</td>\n",
       "      <td>5.388913</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Goran Dragic</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.565366</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>Kyrie Irving</td>\n",
       "      <td>5.1</td>\n",
       "      <td>5.269162</td>\n",
       "      <td>5.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>J.J. Barea</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4.676785</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Jimmy Butler</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.143125</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Kemba Walker</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5.212674</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Giannis Antetokounmpo</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.931149</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Tim Frazier</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.233258</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>Reggie Jackson</td>\n",
       "      <td>5.3</td>\n",
       "      <td>4.449368</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Ish Smith</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.370481</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>Jeremy Lin</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.498899</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Jameer Nelson</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.842404</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Al Horford</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.590726</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Blake Griffin</td>\n",
       "      <td>5.4</td>\n",
       "      <td>4.710477</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Brandon Jennings</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.403440</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>Nikola Jokic</td>\n",
       "      <td>6.1</td>\n",
       "      <td>4.603726</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Kevin Durant</td>\n",
       "      <td>5.4</td>\n",
       "      <td>4.548368</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>D'Angelo Russell</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.996640</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>DeMarcus Cousins</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1.966550</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>Lance Stephenson</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.039639</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Matthew Dellavedova</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.610166</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Darren Collison</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3.906064</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>Marc Gasol</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3.817685</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>Marcus Smart</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.010861</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Tony Parker</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.477597</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Derrick Rose</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.341214</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Yogi Ferrell</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.725537</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Jerryd Bayless</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.938870</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dion Waiters</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.814725</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>Malcolm Brogdon</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.625485</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>Patrick Beverley</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.522611</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    player  assists  predictions  assists_ly_x\n",
       "202           James Harden      8.8     8.751309          11.2\n",
       "30               John Wall      9.6     8.472669          10.7\n",
       "335      Russell Westbrook     10.3    10.363492          10.4\n",
       "116             Chris Paul      7.9     8.602536           9.2\n",
       "329            Ricky Rubio      5.3     7.056455           9.1\n",
       "265           LeBron James      9.1     7.620450           8.7\n",
       "212            Jeff Teague      7.0     5.642941           7.8\n",
       "237           Jrue Holiday      6.0     3.235166           7.3\n",
       "257             Kyle Lowry      6.9     6.189878           7.0\n",
       "156         Draymond Green      7.3     5.111875           7.0\n",
       "321            Rajon Rondo      8.2     4.627744           6.7\n",
       "349         T.J. McConnell      4.0     4.980649           6.6\n",
       "347          Stephen Curry      6.1     6.681119           6.6\n",
       "160          Elfrid Payton      6.3     5.870633           6.5\n",
       "144        Dennis Schroder      6.2     5.507077           6.3\n",
       "290            Mike Conley      4.1     6.208508           6.3\n",
       "163           Eric Bledsoe      5.1     5.172452           6.3\n",
       "186          Isaiah Thomas      5.0     5.471768           5.9\n",
       "301          Nicolas Batum      5.5     4.009671           5.9\n",
       "6           Damian Lillard      6.6     5.388913           5.9\n",
       "19            Goran Dragic      4.8     4.565366           5.8\n",
       "260           Kyrie Irving      5.1     5.269162           5.8\n",
       "23              J.J. Barea      6.3     4.676785           5.5\n",
       "218           Jimmy Butler      4.9     4.143125           5.5\n",
       "244           Kemba Walker      5.6     5.212674           5.5\n",
       "176  Giannis Antetokounmpo      4.8     4.931149           5.4\n",
       "59             Tim Frazier      3.3     4.233258           5.2\n",
       "326         Reggie Jackson      5.3     4.449368           5.2\n",
       "188              Ish Smith      4.4     4.370481           5.2\n",
       "215             Jeremy Lin      4.0     4.498899           5.1\n",
       "200          Jameer Nelson      3.6     2.842404           5.1\n",
       "71              Al Horford      4.7     3.590726           5.0\n",
       "95           Blake Griffin      5.4     4.710477           4.9\n",
       "102       Brandon Jennings      3.1     4.403440           4.9\n",
       "304           Nikola Jokic      6.1     4.603726           4.9\n",
       "248           Kevin Durant      5.4     4.548368           4.8\n",
       "124       D'Angelo Russell      5.2     3.996640           4.8\n",
       "140       DeMarcus Cousins      5.4     1.966550           4.8\n",
       "261       Lance Stephenson      2.9     3.039639           4.8\n",
       "286    Matthew Dellavedova      3.8     2.610166           4.7\n",
       "133        Darren Collison      5.3     3.906064           4.6\n",
       "275             Marc Gasol      4.2     3.817685           4.6\n",
       "279           Marcus Smart      4.8     3.010861           4.6\n",
       "61             Tony Parker      3.5     3.477597           4.5\n",
       "147           Derrick Rose      1.6     3.341214           4.4\n",
       "67            Yogi Ferrell      2.5     2.725537           4.3\n",
       "217         Jerryd Bayless      1.4     2.938870           4.3\n",
       "13            Dion Waiters      3.8     2.814725           4.3\n",
       "272        Malcolm Brogdon      3.2     3.625485           4.2\n",
       "312       Patrick Beverley      2.9     3.522611           4.2"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_2017assists = assists[assists['season']==2017].drop(['team','player','assists','Games'],axis=1)\n",
    "assists_2017 = NN_ast.predict(pred_2017assists)\n",
    "test_2 =pd.DataFrame(assists_2017)\n",
    "test_3 = pd.merge(assists,pred_2017assists,left_index=True,right_index=True).reset_index()\n",
    "test_3['predictions']=test_2[0]\n",
    "test_3[['player','assists','predictions','assists_ly_x']].sort_values(by='assists_ly_x',ascending=False)[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>player</th>\n",
       "      <th>age</th>\n",
       "      <th>team</th>\n",
       "      <th>assists</th>\n",
       "      <th>assists_ly</th>\n",
       "      <th>change_assists_ly</th>\n",
       "      <th>Games</th>\n",
       "      <th>C_PF</th>\n",
       "      <th>PG</th>\n",
       "      <th>...</th>\n",
       "      <th>usagerank_ly</th>\n",
       "      <th>reb_perc_ly</th>\n",
       "      <th>change_reb_perc</th>\n",
       "      <th>offensive_winshares</th>\n",
       "      <th>offensive_boxplusminus</th>\n",
       "      <th>boxplusminus</th>\n",
       "      <th>value_overreplacement</th>\n",
       "      <th>career_assists</th>\n",
       "      <th>yearspro</th>\n",
       "      <th>age_squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>2015</td>\n",
       "      <td>Aaron Brooks</td>\n",
       "      <td>31</td>\n",
       "      <td>CHI</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>24.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.25</td>\n",
       "      <td>6</td>\n",
       "      <td>961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>2015</td>\n",
       "      <td>Aaron Gordon</td>\n",
       "      <td>20</td>\n",
       "      <td>ORL</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>2017</td>\n",
       "      <td>Aaron Harrison</td>\n",
       "      <td>23</td>\n",
       "      <td>DAL</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.6</td>\n",
       "      <td>-19.6</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-9.6</td>\n",
       "      <td>-11.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>2</td>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>2015</td>\n",
       "      <td>Adreian Payne</td>\n",
       "      <td>24</td>\n",
       "      <td>MIN</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>2016</td>\n",
       "      <td>Adreian Payne</td>\n",
       "      <td>25</td>\n",
       "      <td>MIN</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>-6.1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2</td>\n",
       "      <td>625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     season          player  age team  assists  assists_ly  change_assists_ly  \\\n",
       "673    2015    Aaron Brooks   31  CHI      2.6         3.2               -1.3   \n",
       "674    2015    Aaron Gordon   20  ORL      1.6         0.7                0.0   \n",
       "675    2017  Aaron Harrison   23  DAL      1.2         0.6               -0.5   \n",
       "676    2015   Adreian Payne   24  MIN      0.6         1.0                0.0   \n",
       "677    2016   Adreian Payne   25  MIN      0.4         0.6                0.4   \n",
       "\n",
       "     Games  C_PF  PG     ...       usagerank_ly  reb_perc_ly  change_reb_perc  \\\n",
       "673   69.0     0   1     ...               13.0         24.2              3.5   \n",
       "674   78.0     1   0     ...                9.0          6.3              0.0   \n",
       "675    9.0     0   0     ...                3.0         22.6            -19.6   \n",
       "676   52.0     1   0     ...               22.0          6.4              0.0   \n",
       "677   18.0     1   0     ...                5.0          8.9             -2.5   \n",
       "\n",
       "     offensive_winshares  offensive_boxplusminus  boxplusminus  \\\n",
       "673                  1.7                     1.0          -1.4   \n",
       "674                  0.3                    -2.8          -2.8   \n",
       "675                 -0.1                    -9.6         -11.6   \n",
       "676                 -0.7                    -4.6          -5.9   \n",
       "677                 -0.9                    -5.9          -6.1   \n",
       "\n",
       "     value_overreplacement  career_assists  yearspro  age_squared  \n",
       "673                    0.3            3.25         6          961  \n",
       "674                   -0.2            0.70         1          400  \n",
       "675                    0.0            0.35         2          529  \n",
       "676                   -0.7            1.00         1          576  \n",
       "677                   -0.5            0.80         2          625  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
