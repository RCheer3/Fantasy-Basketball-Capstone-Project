{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "import psycopg2 as pg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from Player_rank import Player_ranker\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential, Model, Input\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "import tensorflow as tf\n",
    "import scipy.stats as scs\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nHere we're loading in all of the traditional Fantasy basketball stats into SQL, using window function to get a ranking by minutes\\n\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Here we're loading in all of the traditional Fantasy basketball stats into SQL, using window function to get a ranking by minutes\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"IF you have open connections run the following in the psql command prompt:\\n\\nSELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname = 'nba_capstone';\\n\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''IF you have open connections run the following in the psql command prompt:\n",
    "\n",
    "SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname = 'nba_capstone';\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pg2.connect(dbname = 'postgres',host='localhost')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.autocommit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Note for some reason you can not access the database if it is not all lowercase'''\n",
    "\n",
    "cur.execute('DROP DATABASE IF EXISTS nba_capstone;')  # Makes sure there is not already a class_example database and removes is if there is\n",
    "cur.execute('CREATE DATABASE nba_capstone;')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pg2.connect(dbname = 'nba_capstone',host='localhost')\n",
    "conn.autocommit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "        CREATE TABLE NBA_stats (\n",
    "            Season integer, \n",
    "            Player varchar(50), \n",
    "            Pos varchar(10),\n",
    "            Age int,\n",
    "            Tm varchar(15),\n",
    "            G int,\n",
    "            GS int,\n",
    "            MP float,\n",
    "            FG float,\n",
    "            FGA float,\n",
    "            FG_Percentage float,\n",
    "            Threes_Made float,\n",
    "            Threes_Attempted float,\n",
    "            Three_Percentage float,\n",
    "            Twos_Made float,\n",
    "            Twos_Attempted float,\n",
    "            Twos_Percentage float,\n",
    "            eff_FG_Percentage float,\n",
    "            FTM float,\n",
    "            FTA float,\n",
    "            FT_Percentage float,\n",
    "            ORB float,\n",
    "            DRB float,\n",
    "            Rebounds float,\n",
    "            AST float,\n",
    "            STL float,\n",
    "            BLK float,\n",
    "            TOV float,\n",
    "            Fouls float,\n",
    "            Points float\n",
    "        );\n",
    "        '''\n",
    "\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# current_directory_path = os.getcwd()\n",
    "# current_directory_path\n",
    "\n",
    "query = '''\n",
    "        COPY NBA_stats \n",
    "        FROM '/Users/rcheer/Desktop/Galvanize/Capstone/Fantasy-Basketball-Capstone-Project/NBA stats.csv' \n",
    "        DELIMITER ',' \n",
    "        CSV HEADER;\n",
    "        '''\n",
    "\n",
    "\n",
    "\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "        CREATE TABLE nba_advanced (\n",
    "            Season integer, \n",
    "            Player varchar(50), \n",
    "            Pos varchar(10),\n",
    "            Age int,\n",
    "            Tm varchar(15),\n",
    "            G int,\n",
    "            total_MP float,\n",
    "            PER float,\n",
    "            True_Shooting float,\n",
    "            Three_Attempt_Rate float,\n",
    "            FT_rate float,\n",
    "            ORB_Percentage float,\n",
    "            DRB_Percentage float,\n",
    "            Rebound_Percentage float,\n",
    "            Assist_Percentage float,\n",
    "            Steal_Percentage float,\n",
    "            Block_Percentage float,\n",
    "            Turnover_Percentage float,\n",
    "            Usage_Percentage float,\n",
    "            Offensive_WinShares float,\n",
    "            Defensive_WinShares float,\n",
    "            WinShares float,\n",
    "            WinShares_Per48 float,\n",
    "            Offensive_BoxPlusMinus float,\n",
    "            Defensive_BoxPlusMinus float,\n",
    "            BoxPlusMinus float,\n",
    "            Value_overReplacement float\n",
    "        );\n",
    "        '''\n",
    "\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "        COPY nba_advanced \n",
    "        FROM '/Users/rcheer/Desktop/Galvanize/Capstone/Fantasy-Basketball-Capstone-Project/NBA Advanced.csv' \n",
    "        DELIMITER ',' \n",
    "        CSV HEADER;\n",
    "        '''\n",
    "\n",
    "\n",
    "\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "save for later\n",
    "d.points,d.rebounds,d.ast,d.stl,d.blk,d.tov,d.fg_percentage,d.FT_percentage\n",
    "'''\n",
    "\n",
    "\n",
    "query1 = '''\n",
    "            update nba_stats set Tm = 'NOP' where Tm = 'NOH';\n",
    "            update nba_advanced set Tm = 'NOP' where Tm = 'NOH';\n",
    "            update nba_stats set Tm = 'CHA' where Tm = 'CHO';\n",
    "            update nba_advanced set Tm = 'CHA' where Tm = 'CHO';\n",
    "            \n",
    "            DROP TABLE IF EXISTS players;\n",
    "            CREATE TABLE players AS\n",
    "            select season,player,max(G) as Games from NBA_stats where Tm!='TOT' group by season,player;\n",
    "            \n",
    "            DROP TABLE IF EXISTS y_predictions;\n",
    "            CREATE TABLE y_predictions AS\n",
    "            select d.season,d.player,d.pos,d.age,MAX(case when p.player is not null then d.Tm else NULL end) as StartingTeam,SUM(G) as Games,SUM(GS) as GS,\n",
    "            max(MP) as minutes\n",
    "            from NBA_stats d\n",
    "            left join players p\n",
    "                on d.season = p.season\n",
    "                and d.player = p.player\n",
    "                and d.G = p.Games\n",
    "            where d.Tm!='TOT'\n",
    "            group by d.season,d.player,d.pos,d.age;\n",
    "            \n",
    "            update y_predictions set StartingTeam = 'NOP' where startingTeam = 'NOH';\n",
    "            update y_predictions set StartingTeam = 'CHA' where startingTeam = 'CHO';\n",
    "            \n",
    "            DROP TABLE IF EXISTS rank_by_minutes;\n",
    "            CREATE TABLE rank_by_minutes AS\n",
    "            select y.*,n.points,n.rebounds,n.ast,n.stl,n.blk,n.tov,n.threes_made,n.fg,n.fga,n.ftm,n.fta,\n",
    "            case when cast(y.GS as float)/y.Games >0.6 then 1 else 0 end as starter,\n",
    "            row_number() over(partition by n.season order by MP*G desc) as min_rank from NBA_stats n\n",
    "            inner join y_predictions y\n",
    "                ON n.player = y.player\n",
    "                and n.season = y.season\n",
    "                and n.Tm=y.startingTeam;\n",
    "            \n",
    "            DROP TABLE IF EXISTS adv_withminrank;\n",
    "            CREATE TABLE adv_withminrank AS\n",
    "            select y.*,n.per,n.true_shooting,n.three_attempt_rate,n.ft_rate,n.rebound_percentage,n.assist_percentage\n",
    "            ,n.steal_percentage,n.block_percentage,n.turnover_percentage,n.usage_percentage,n.offensive_winshares,\n",
    "            n.defensive_winshares,winshares,winshares_per48,offensive_boxplusminus,defensive_boxplusminus,boxplusminus,value_overreplacement,\n",
    "            case when cast(y.GS as float)/y.Games >0.6 then 1 else 0 end as starter,\n",
    "            row_number() over(partition by n.season order by total_mp desc) as min_rank from NBA_advanced n\n",
    "            inner join y_predictions y\n",
    "                ON n.player = y.player\n",
    "                and n.season = y.season\n",
    "                and n.Tm=y.startingTeam;\n",
    "            \n",
    "            \n",
    "            select * from rank_by_minutes        \n",
    "                \n",
    "        '''\n",
    "cur.execute(query1)\n",
    "data = cur.fetchall()\n",
    "df = pd.DataFrame(np.array(data))\n",
    "df.columns = ['season','player','position','age','team','gamesPlayed','gamesStarted','minutes'\n",
    "              ,'points','rebounds','assists','steals','blocks','turnovers','threes_made','FGM','FGA','FTM','FTA','starter','min_rank']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['min_rank']=pd.to_numeric(df['min_rank'])\n",
    "df['points']=pd.to_numeric(df['points'])\n",
    "df['rebounds']=pd.to_numeric(df['rebounds'])\n",
    "df['assists']=pd.to_numeric(df['assists'])\n",
    "df['steals']=pd.to_numeric(df['steals'])\n",
    "df['blocks']=pd.to_numeric(df['blocks'])\n",
    "df['turnovers']=pd.to_numeric(df['turnovers'])\n",
    "df['threes_made']=pd.to_numeric(df['threes_made'])\n",
    "df['FGM']=pd.to_numeric(df['FGM'])\n",
    "df['FGA']=pd.to_numeric(df['FGA'])\n",
    "df['FTM']=pd.to_numeric(df['FTM'])\n",
    "df['FTA']=pd.to_numeric(df['FTA'])\n",
    "df['gamesPlayed']=pd.to_numeric(df['gamesPlayed'])\n",
    "df['gamesStarted']=pd.to_numeric(df['gamesStarted'])\n",
    "df['minutes']=pd.to_numeric(df['minutes'])\n",
    "df['age']=pd.to_numeric(df['age'])\n",
    "df['season']=pd.to_numeric(df['season'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>mean_points</th>\n",
       "      <th>mean_rebounds</th>\n",
       "      <th>mean_assists</th>\n",
       "      <th>mean_steals</th>\n",
       "      <th>mean_blocks</th>\n",
       "      <th>mean_turnovers</th>\n",
       "      <th>mean_threes_made</th>\n",
       "      <th>mean_fgm</th>\n",
       "      <th>mean_fga</th>\n",
       "      <th>mean_ftm</th>\n",
       "      <th>mean_fta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>13.3005</td>\n",
       "      <td>5.1235</td>\n",
       "      <td>2.7870</td>\n",
       "      <td>0.9150</td>\n",
       "      <td>0.5690</td>\n",
       "      <td>1.7035</td>\n",
       "      <td>0.8780</td>\n",
       "      <td>4.9095</td>\n",
       "      <td>10.5850</td>\n",
       "      <td>2.5990</td>\n",
       "      <td>3.3115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>12.9850</td>\n",
       "      <td>5.1080</td>\n",
       "      <td>2.8490</td>\n",
       "      <td>0.9120</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>1.6965</td>\n",
       "      <td>0.8265</td>\n",
       "      <td>4.8530</td>\n",
       "      <td>10.4370</td>\n",
       "      <td>2.4600</td>\n",
       "      <td>3.1825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>12.9225</td>\n",
       "      <td>5.0185</td>\n",
       "      <td>2.8135</td>\n",
       "      <td>0.9085</td>\n",
       "      <td>0.5685</td>\n",
       "      <td>1.6790</td>\n",
       "      <td>0.8380</td>\n",
       "      <td>4.7955</td>\n",
       "      <td>10.3525</td>\n",
       "      <td>2.4955</td>\n",
       "      <td>3.2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>12.1830</td>\n",
       "      <td>4.8915</td>\n",
       "      <td>2.6840</td>\n",
       "      <td>0.9225</td>\n",
       "      <td>0.5725</td>\n",
       "      <td>1.6805</td>\n",
       "      <td>0.8030</td>\n",
       "      <td>4.5925</td>\n",
       "      <td>10.1180</td>\n",
       "      <td>2.1955</td>\n",
       "      <td>2.8590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012</td>\n",
       "      <td>12.5550</td>\n",
       "      <td>5.0520</td>\n",
       "      <td>2.8840</td>\n",
       "      <td>0.9585</td>\n",
       "      <td>0.6125</td>\n",
       "      <td>1.7410</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>4.7285</td>\n",
       "      <td>10.3275</td>\n",
       "      <td>2.2150</td>\n",
       "      <td>2.8920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013</td>\n",
       "      <td>13.0510</td>\n",
       "      <td>5.1265</td>\n",
       "      <td>2.8310</td>\n",
       "      <td>0.9505</td>\n",
       "      <td>0.5420</td>\n",
       "      <td>1.7375</td>\n",
       "      <td>0.9715</td>\n",
       "      <td>4.8545</td>\n",
       "      <td>10.5425</td>\n",
       "      <td>2.3790</td>\n",
       "      <td>3.1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014</td>\n",
       "      <td>12.3805</td>\n",
       "      <td>4.9890</td>\n",
       "      <td>2.7145</td>\n",
       "      <td>0.9230</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>1.6315</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>4.6260</td>\n",
       "      <td>10.1940</td>\n",
       "      <td>2.1725</td>\n",
       "      <td>2.8505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015</td>\n",
       "      <td>12.8715</td>\n",
       "      <td>5.1935</td>\n",
       "      <td>2.7720</td>\n",
       "      <td>0.9530</td>\n",
       "      <td>0.5900</td>\n",
       "      <td>1.6785</td>\n",
       "      <td>1.0530</td>\n",
       "      <td>4.7645</td>\n",
       "      <td>10.4595</td>\n",
       "      <td>2.2840</td>\n",
       "      <td>2.9900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>13.3550</td>\n",
       "      <td>5.0420</td>\n",
       "      <td>2.8950</td>\n",
       "      <td>0.9230</td>\n",
       "      <td>0.5340</td>\n",
       "      <td>1.6195</td>\n",
       "      <td>1.2170</td>\n",
       "      <td>4.8980</td>\n",
       "      <td>10.6355</td>\n",
       "      <td>2.3385</td>\n",
       "      <td>2.9850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>13.2915</td>\n",
       "      <td>5.0950</td>\n",
       "      <td>2.9355</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.5585</td>\n",
       "      <td>1.6825</td>\n",
       "      <td>1.3200</td>\n",
       "      <td>4.9175</td>\n",
       "      <td>10.6135</td>\n",
       "      <td>2.1395</td>\n",
       "      <td>2.7465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  mean_points  mean_rebounds  mean_assists  mean_steals  mean_blocks  \\\n",
       "0    2008      13.3005         5.1235        2.7870       0.9150       0.5690   \n",
       "1    2009      12.9850         5.1080        2.8490       0.9120       0.5600   \n",
       "2    2010      12.9225         5.0185        2.8135       0.9085       0.5685   \n",
       "3    2011      12.1830         4.8915        2.6840       0.9225       0.5725   \n",
       "4    2012      12.5550         5.0520        2.8840       0.9585       0.6125   \n",
       "5    2013      13.0510         5.1265        2.8310       0.9505       0.5420   \n",
       "6    2014      12.3805         4.9890        2.7145       0.9230       0.5390   \n",
       "7    2015      12.8715         5.1935        2.7720       0.9530       0.5900   \n",
       "8    2016      13.3550         5.0420        2.8950       0.9230       0.5340   \n",
       "9    2017      13.2915         5.0950        2.9355       0.9240       0.5585   \n",
       "\n",
       "   mean_turnovers  mean_threes_made  mean_fgm  mean_fga  mean_ftm  mean_fta  \n",
       "0          1.7035            0.8780    4.9095   10.5850    2.5990    3.3115  \n",
       "1          1.6965            0.8265    4.8530   10.4370    2.4600    3.1825  \n",
       "2          1.6790            0.8380    4.7955   10.3525    2.4955    3.2005  \n",
       "3          1.6805            0.8030    4.5925   10.1180    2.1955    2.8590  \n",
       "4          1.7410            0.8800    4.7285   10.3275    2.2150    2.8920  \n",
       "5          1.7375            0.9715    4.8545   10.5425    2.3790    3.1020  \n",
       "6          1.6315            0.9600    4.6260   10.1940    2.1725    2.8505  \n",
       "7          1.6785            1.0530    4.7645   10.4595    2.2840    2.9900  \n",
       "8          1.6195            1.2170    4.8980   10.6355    2.3385    2.9850  \n",
       "9          1.6825            1.3200    4.9175   10.6135    2.1395    2.7465  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = Player_ranker(df)\n",
    "test.get_category_dist()\n",
    "test.cat_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.assign_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_copy = test.value.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>player</th>\n",
       "      <th>value_tot</th>\n",
       "      <th>value_points</th>\n",
       "      <th>value_rebounds</th>\n",
       "      <th>value_assists</th>\n",
       "      <th>value_blocks</th>\n",
       "      <th>value_steals</th>\n",
       "      <th>value_turnovers</th>\n",
       "      <th>value_threes</th>\n",
       "      <th>value_fg</th>\n",
       "      <th>value_ft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>Andre Iguodala</td>\n",
       "      <td>1.569149</td>\n",
       "      <td>1.022902</td>\n",
       "      <td>0.233549</td>\n",
       "      <td>1.209232</td>\n",
       "      <td>-0.313073</td>\n",
       "      <td>1.720216</td>\n",
       "      <td>-1.392654</td>\n",
       "      <td>0.164932</td>\n",
       "      <td>0.201353</td>\n",
       "      <td>-1.277308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>Joe Johnson</td>\n",
       "      <td>2.248938</td>\n",
       "      <td>1.506499</td>\n",
       "      <td>-0.293101</td>\n",
       "      <td>1.449827</td>\n",
       "      <td>-0.683573</td>\n",
       "      <td>0.464584</td>\n",
       "      <td>-1.113145</td>\n",
       "      <td>1.381647</td>\n",
       "      <td>-1.036752</td>\n",
       "      <td>0.572951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>O.J. Mayo</td>\n",
       "      <td>0.491912</td>\n",
       "      <td>0.967102</td>\n",
       "      <td>-0.536170</td>\n",
       "      <td>0.198732</td>\n",
       "      <td>-0.683573</td>\n",
       "      <td>0.464584</td>\n",
       "      <td>-1.532409</td>\n",
       "      <td>1.246456</td>\n",
       "      <td>-0.633993</td>\n",
       "      <td>1.001183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008</td>\n",
       "      <td>Antawn Jamison</td>\n",
       "      <td>3.459954</td>\n",
       "      <td>1.655298</td>\n",
       "      <td>1.529918</td>\n",
       "      <td>-0.426816</td>\n",
       "      <td>-0.498323</td>\n",
       "      <td>0.715710</td>\n",
       "      <td>0.284401</td>\n",
       "      <td>0.705694</td>\n",
       "      <td>0.083254</td>\n",
       "      <td>-0.589183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>Raymond Felton</td>\n",
       "      <td>-0.135656</td>\n",
       "      <td>0.167306</td>\n",
       "      <td>-0.536170</td>\n",
       "      <td>1.882899</td>\n",
       "      <td>-0.313073</td>\n",
       "      <td>1.469090</td>\n",
       "      <td>-1.532409</td>\n",
       "      <td>-0.240639</td>\n",
       "      <td>-1.364914</td>\n",
       "      <td>0.332253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season          player  value_tot  value_points  value_rebounds  \\\n",
       "0    2008  Andre Iguodala   1.569149      1.022902        0.233549   \n",
       "1    2008     Joe Johnson   2.248938      1.506499       -0.293101   \n",
       "2    2008       O.J. Mayo   0.491912      0.967102       -0.536170   \n",
       "3    2008  Antawn Jamison   3.459954      1.655298        1.529918   \n",
       "4    2008  Raymond Felton  -0.135656      0.167306       -0.536170   \n",
       "\n",
       "   value_assists  value_blocks  value_steals  value_turnovers  value_threes  \\\n",
       "0       1.209232     -0.313073      1.720216        -1.392654      0.164932   \n",
       "1       1.449827     -0.683573      0.464584        -1.113145      1.381647   \n",
       "2       0.198732     -0.683573      0.464584        -1.532409      1.246456   \n",
       "3      -0.426816     -0.498323      0.715710         0.284401      0.705694   \n",
       "4       1.882899     -0.313073      1.469090        -1.532409     -0.240639   \n",
       "\n",
       "   value_fg  value_ft  \n",
       "0  0.201353 -1.277308  \n",
       "1 -1.036752  0.572951  \n",
       "2 -0.633993  1.001183  \n",
       "3  0.083254 -0.589183  \n",
       "4 -1.364914  0.332253  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy value data back into SQL\n",
    "engine = create_engine(\"postgresql://@localhost/nba_capstone\")\n",
    "\n",
    "value_copy.to_sql(name='value', con=engine, if_exists = 'replace', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "        DROP TABLE IF EXISTS player_value;\n",
    "        CREATE TABLE player_value AS\n",
    "        select ROW_NUMBER() OVER(PARTITION BY season ORDER BY value_tot DESC),* from value;\n",
    "        \n",
    "        DROP TABLE IF EXISTS value;\n",
    "        \n",
    "        select * from player_value;\n",
    "        \n",
    "        '''\n",
    "\n",
    "\n",
    "cur.execute(query)\n",
    "ranking_data = cur.fetchall()\n",
    "df_2 = pd.DataFrame(np.array(ranking_data))\n",
    "cols_value = ['playerrank']\n",
    "for item in (list(value_copy.columns)):\n",
    "    cols_value.append(item)\n",
    "cols_value\n",
    "df_2.columns=cols_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_2.columns:\n",
    "    if i!='player':\n",
    "        df_2[i]=pd.to_numeric(df_2[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_2.columns:\n",
    "    if i!='player':\n",
    "        df_2[i]=pd.to_numeric(df_2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playerrank</th>\n",
       "      <th>season</th>\n",
       "      <th>player</th>\n",
       "      <th>value_tot</th>\n",
       "      <th>value_points</th>\n",
       "      <th>value_rebounds</th>\n",
       "      <th>value_assists</th>\n",
       "      <th>value_blocks</th>\n",
       "      <th>value_steals</th>\n",
       "      <th>value_turnovers</th>\n",
       "      <th>value_threes</th>\n",
       "      <th>value_fg</th>\n",
       "      <th>value_ft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>Chris Paul</td>\n",
       "      <td>10.649584</td>\n",
       "      <td>1.766898</td>\n",
       "      <td>0.152526</td>\n",
       "      <td>3.952019</td>\n",
       "      <td>-0.868823</td>\n",
       "      <td>4.733733</td>\n",
       "      <td>-1.811918</td>\n",
       "      <td>-0.105449</td>\n",
       "      <td>1.195183</td>\n",
       "      <td>1.635414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>LeBron James</td>\n",
       "      <td>8.708530</td>\n",
       "      <td>2.808492</td>\n",
       "      <td>1.003268</td>\n",
       "      <td>2.123494</td>\n",
       "      <td>0.983678</td>\n",
       "      <td>1.971343</td>\n",
       "      <td>-1.811918</td>\n",
       "      <td>0.976075</td>\n",
       "      <td>0.888138</td>\n",
       "      <td>-0.234041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2008</td>\n",
       "      <td>Dwyane Wade</td>\n",
       "      <td>8.419529</td>\n",
       "      <td>3.143291</td>\n",
       "      <td>-0.050032</td>\n",
       "      <td>2.267852</td>\n",
       "      <td>1.354178</td>\n",
       "      <td>3.226975</td>\n",
       "      <td>-2.370936</td>\n",
       "      <td>0.300123</td>\n",
       "      <td>1.126183</td>\n",
       "      <td>-0.578103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "      <td>Danny Granger</td>\n",
       "      <td>6.463654</td>\n",
       "      <td>2.324895</td>\n",
       "      <td>-0.009520</td>\n",
       "      <td>-0.041864</td>\n",
       "      <td>1.539428</td>\n",
       "      <td>0.213457</td>\n",
       "      <td>-1.113145</td>\n",
       "      <td>2.463170</td>\n",
       "      <td>-0.678128</td>\n",
       "      <td>1.765360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2008</td>\n",
       "      <td>Dirk Nowitzki</td>\n",
       "      <td>6.094625</td>\n",
       "      <td>2.343495</td>\n",
       "      <td>1.327360</td>\n",
       "      <td>-0.186221</td>\n",
       "      <td>0.427928</td>\n",
       "      <td>-0.288795</td>\n",
       "      <td>-0.274618</td>\n",
       "      <td>-0.105449</td>\n",
       "      <td>0.611555</td>\n",
       "      <td>2.239370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   playerrank  season         player  value_tot  value_points  value_rebounds  \\\n",
       "0           1    2008     Chris Paul  10.649584      1.766898        0.152526   \n",
       "1           2    2008   LeBron James   8.708530      2.808492        1.003268   \n",
       "2           3    2008    Dwyane Wade   8.419529      3.143291       -0.050032   \n",
       "3           4    2008  Danny Granger   6.463654      2.324895       -0.009520   \n",
       "4           5    2008  Dirk Nowitzki   6.094625      2.343495        1.327360   \n",
       "\n",
       "   value_assists  value_blocks  value_steals  value_turnovers  value_threes  \\\n",
       "0       3.952019     -0.868823      4.733733        -1.811918     -0.105449   \n",
       "1       2.123494      0.983678      1.971343        -1.811918      0.976075   \n",
       "2       2.267852      1.354178      3.226975        -2.370936      0.300123   \n",
       "3      -0.041864      1.539428      0.213457        -1.113145      2.463170   \n",
       "4      -0.186221      0.427928     -0.288795        -0.274618     -0.105449   \n",
       "\n",
       "   value_fg  value_ft  \n",
       "0  1.195183  1.635414  \n",
       "1  0.888138 -0.234041  \n",
       "2  1.126183 -0.578103  \n",
       "3 -0.678128  1.765360  \n",
       "4  0.611555  2.239370  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playerrank</th>\n",
       "      <th>season</th>\n",
       "      <th>player</th>\n",
       "      <th>value_tot</th>\n",
       "      <th>value_points</th>\n",
       "      <th>value_rebounds</th>\n",
       "      <th>value_assists</th>\n",
       "      <th>value_blocks</th>\n",
       "      <th>value_steals</th>\n",
       "      <th>value_turnovers</th>\n",
       "      <th>value_threes</th>\n",
       "      <th>value_fg</th>\n",
       "      <th>value_ft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4219</th>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>Anthony Davis</td>\n",
       "      <td>13.069292</td>\n",
       "      <td>2.728406</td>\n",
       "      <td>2.327843</td>\n",
       "      <td>-0.323373</td>\n",
       "      <td>4.382346</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>-0.642579</td>\n",
       "      <td>-0.719758</td>\n",
       "      <td>2.572502</td>\n",
       "      <td>1.340136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4220</th>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>Stephen Curry</td>\n",
       "      <td>10.977767</td>\n",
       "      <td>2.415188</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>1.610250</td>\n",
       "      <td>-0.769567</td>\n",
       "      <td>1.647478</td>\n",
       "      <td>-1.635937</td>\n",
       "      <td>3.343394</td>\n",
       "      <td>1.073741</td>\n",
       "      <td>3.291282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4221</th>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>Kevin Durant</td>\n",
       "      <td>10.555627</td>\n",
       "      <td>2.415188</td>\n",
       "      <td>0.660945</td>\n",
       "      <td>1.254056</td>\n",
       "      <td>2.665042</td>\n",
       "      <td>-0.545910</td>\n",
       "      <td>-1.635937</td>\n",
       "      <td>1.369863</td>\n",
       "      <td>1.809299</td>\n",
       "      <td>2.563082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4222</th>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>James Harden</td>\n",
       "      <td>10.522310</td>\n",
       "      <td>3.152171</td>\n",
       "      <td>0.118234</td>\n",
       "      <td>2.984140</td>\n",
       "      <td>0.303748</td>\n",
       "      <td>2.134898</td>\n",
       "      <td>-3.374314</td>\n",
       "      <td>2.762944</td>\n",
       "      <td>-0.589500</td>\n",
       "      <td>3.029989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4223</th>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "      <td>Karl-Anthony Towns</td>\n",
       "      <td>9.046572</td>\n",
       "      <td>1.475533</td>\n",
       "      <td>2.793024</td>\n",
       "      <td>-0.272488</td>\n",
       "      <td>1.806390</td>\n",
       "      <td>-0.302200</td>\n",
       "      <td>-0.270069</td>\n",
       "      <td>0.208962</td>\n",
       "      <td>2.213129</td>\n",
       "      <td>1.394291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4224</th>\n",
       "      <td>6</td>\n",
       "      <td>2017</td>\n",
       "      <td>LeBron James</td>\n",
       "      <td>8.050018</td>\n",
       "      <td>2.617858</td>\n",
       "      <td>1.358716</td>\n",
       "      <td>3.136795</td>\n",
       "      <td>0.733074</td>\n",
       "      <td>1.160059</td>\n",
       "      <td>-3.125975</td>\n",
       "      <td>0.557232</td>\n",
       "      <td>2.935558</td>\n",
       "      <td>-1.323300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4225</th>\n",
       "      <td>7</td>\n",
       "      <td>2017</td>\n",
       "      <td>Giannis Antetokounmpo</td>\n",
       "      <td>7.982516</td>\n",
       "      <td>2.507311</td>\n",
       "      <td>1.901427</td>\n",
       "      <td>0.948747</td>\n",
       "      <td>1.806390</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>-1.635937</td>\n",
       "      <td>-0.835849</td>\n",
       "      <td>2.328774</td>\n",
       "      <td>-0.442116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4226</th>\n",
       "      <td>8</td>\n",
       "      <td>2017</td>\n",
       "      <td>Damian Lillard</td>\n",
       "      <td>7.758411</td>\n",
       "      <td>2.507311</td>\n",
       "      <td>-0.230652</td>\n",
       "      <td>1.864674</td>\n",
       "      <td>-0.340241</td>\n",
       "      <td>0.428929</td>\n",
       "      <td>-1.387598</td>\n",
       "      <td>2.066403</td>\n",
       "      <td>-0.920536</td>\n",
       "      <td>3.770119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4227</th>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "      <td>Chris Paul</td>\n",
       "      <td>7.259998</td>\n",
       "      <td>0.978069</td>\n",
       "      <td>0.118234</td>\n",
       "      <td>2.526177</td>\n",
       "      <td>-0.769567</td>\n",
       "      <td>1.891188</td>\n",
       "      <td>-0.642579</td>\n",
       "      <td>1.369863</td>\n",
       "      <td>-0.176916</td>\n",
       "      <td>1.965529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4228</th>\n",
       "      <td>10</td>\n",
       "      <td>2017</td>\n",
       "      <td>Jimmy Butler</td>\n",
       "      <td>7.194467</td>\n",
       "      <td>1.641355</td>\n",
       "      <td>0.079468</td>\n",
       "      <td>0.999632</td>\n",
       "      <td>-0.340241</td>\n",
       "      <td>2.622318</td>\n",
       "      <td>-0.145900</td>\n",
       "      <td>-0.139308</td>\n",
       "      <td>0.324360</td>\n",
       "      <td>2.152782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4229</th>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>Victor Oladipo</td>\n",
       "      <td>6.742591</td>\n",
       "      <td>1.807176</td>\n",
       "      <td>0.040703</td>\n",
       "      <td>0.694323</td>\n",
       "      <td>0.518411</td>\n",
       "      <td>3.597157</td>\n",
       "      <td>-1.511767</td>\n",
       "      <td>0.905503</td>\n",
       "      <td>0.389094</td>\n",
       "      <td>0.301991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4230</th>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>DeMarcus Cousins</td>\n",
       "      <td>6.513379</td>\n",
       "      <td>2.194092</td>\n",
       "      <td>3.025615</td>\n",
       "      <td>1.254056</td>\n",
       "      <td>2.235716</td>\n",
       "      <td>1.647478</td>\n",
       "      <td>-4.119333</td>\n",
       "      <td>1.021593</td>\n",
       "      <td>0.301785</td>\n",
       "      <td>-1.047624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4231</th>\n",
       "      <td>13</td>\n",
       "      <td>2017</td>\n",
       "      <td>Nikola Jokic</td>\n",
       "      <td>6.424866</td>\n",
       "      <td>0.959645</td>\n",
       "      <td>2.172783</td>\n",
       "      <td>1.610250</td>\n",
       "      <td>0.518411</td>\n",
       "      <td>0.672639</td>\n",
       "      <td>-1.387598</td>\n",
       "      <td>0.208962</td>\n",
       "      <td>0.838766</td>\n",
       "      <td>0.831007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4232</th>\n",
       "      <td>14</td>\n",
       "      <td>2017</td>\n",
       "      <td>Kyrie Irving</td>\n",
       "      <td>6.159878</td>\n",
       "      <td>2.046696</td>\n",
       "      <td>-0.502008</td>\n",
       "      <td>1.101402</td>\n",
       "      <td>-0.554904</td>\n",
       "      <td>0.428929</td>\n",
       "      <td>-0.766749</td>\n",
       "      <td>1.718133</td>\n",
       "      <td>0.968233</td>\n",
       "      <td>1.720144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4233</th>\n",
       "      <td>15</td>\n",
       "      <td>2017</td>\n",
       "      <td>Andre Ingram</td>\n",
       "      <td>5.581832</td>\n",
       "      <td>-0.237954</td>\n",
       "      <td>-0.812129</td>\n",
       "      <td>0.287245</td>\n",
       "      <td>2.021053</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>0.226610</td>\n",
       "      <td>1.369863</td>\n",
       "      <td>0.116338</td>\n",
       "      <td>1.207037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234</th>\n",
       "      <td>16</td>\n",
       "      <td>2017</td>\n",
       "      <td>LaMarcus Aldridge</td>\n",
       "      <td>5.370052</td>\n",
       "      <td>1.807176</td>\n",
       "      <td>1.319951</td>\n",
       "      <td>-0.476027</td>\n",
       "      <td>1.377064</td>\n",
       "      <td>-0.789620</td>\n",
       "      <td>0.226610</td>\n",
       "      <td>-1.068029</td>\n",
       "      <td>1.620860</td>\n",
       "      <td>1.352068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4235</th>\n",
       "      <td>17</td>\n",
       "      <td>2017</td>\n",
       "      <td>MarShon Brooks</td>\n",
       "      <td>5.131062</td>\n",
       "      <td>1.254438</td>\n",
       "      <td>-0.812129</td>\n",
       "      <td>0.338130</td>\n",
       "      <td>-0.340241</td>\n",
       "      <td>1.647478</td>\n",
       "      <td>-0.766749</td>\n",
       "      <td>1.602043</td>\n",
       "      <td>1.009007</td>\n",
       "      <td>1.199083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4236</th>\n",
       "      <td>18</td>\n",
       "      <td>2017</td>\n",
       "      <td>Paul George</td>\n",
       "      <td>5.126899</td>\n",
       "      <td>1.586081</td>\n",
       "      <td>0.234529</td>\n",
       "      <td>0.185475</td>\n",
       "      <td>-0.125578</td>\n",
       "      <td>2.622318</td>\n",
       "      <td>-1.263428</td>\n",
       "      <td>2.066403</td>\n",
       "      <td>-1.086400</td>\n",
       "      <td>0.907499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4237</th>\n",
       "      <td>19</td>\n",
       "      <td>2017</td>\n",
       "      <td>Kristaps Porzingis</td>\n",
       "      <td>4.816889</td>\n",
       "      <td>1.733478</td>\n",
       "      <td>0.583415</td>\n",
       "      <td>-0.883106</td>\n",
       "      <td>3.953020</td>\n",
       "      <td>-0.302200</td>\n",
       "      <td>-0.270069</td>\n",
       "      <td>0.673322</td>\n",
       "      <td>-0.888515</td>\n",
       "      <td>0.217545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4238</th>\n",
       "      <td>20</td>\n",
       "      <td>2017</td>\n",
       "      <td>Jrue Holiday</td>\n",
       "      <td>4.397228</td>\n",
       "      <td>1.051768</td>\n",
       "      <td>-0.230652</td>\n",
       "      <td>1.559365</td>\n",
       "      <td>0.518411</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>-1.139258</td>\n",
       "      <td>0.208962</td>\n",
       "      <td>0.875856</td>\n",
       "      <td>0.149007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4239</th>\n",
       "      <td>21</td>\n",
       "      <td>2017</td>\n",
       "      <td>Khris Middleton</td>\n",
       "      <td>4.231094</td>\n",
       "      <td>1.254438</td>\n",
       "      <td>0.040703</td>\n",
       "      <td>0.541669</td>\n",
       "      <td>-0.554904</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>-0.766749</td>\n",
       "      <td>0.557232</td>\n",
       "      <td>0.034790</td>\n",
       "      <td>1.720144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4240</th>\n",
       "      <td>22</td>\n",
       "      <td>2017</td>\n",
       "      <td>Nikola Vucevic</td>\n",
       "      <td>4.156660</td>\n",
       "      <td>0.591153</td>\n",
       "      <td>1.591307</td>\n",
       "      <td>0.236360</td>\n",
       "      <td>1.162400</td>\n",
       "      <td>0.185219</td>\n",
       "      <td>-0.270069</td>\n",
       "      <td>-0.255398</td>\n",
       "      <td>0.356381</td>\n",
       "      <td>0.559307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4241</th>\n",
       "      <td>23</td>\n",
       "      <td>2017</td>\n",
       "      <td>Kyle Lowry</td>\n",
       "      <td>4.141570</td>\n",
       "      <td>0.535879</td>\n",
       "      <td>0.195764</td>\n",
       "      <td>2.017329</td>\n",
       "      <td>-0.769567</td>\n",
       "      <td>0.428929</td>\n",
       "      <td>-0.766749</td>\n",
       "      <td>2.066403</td>\n",
       "      <td>-0.765502</td>\n",
       "      <td>1.199083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4242</th>\n",
       "      <td>24</td>\n",
       "      <td>2017</td>\n",
       "      <td>Otto Porter</td>\n",
       "      <td>4.136911</td>\n",
       "      <td>0.259510</td>\n",
       "      <td>0.505884</td>\n",
       "      <td>-0.476027</td>\n",
       "      <td>-0.125578</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>0.847459</td>\n",
       "      <td>0.557232</td>\n",
       "      <td>0.888985</td>\n",
       "      <td>0.275676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4243</th>\n",
       "      <td>25</td>\n",
       "      <td>2017</td>\n",
       "      <td>Kawhi Leonard</td>\n",
       "      <td>4.001655</td>\n",
       "      <td>0.535879</td>\n",
       "      <td>-0.153122</td>\n",
       "      <td>-0.323373</td>\n",
       "      <td>0.947737</td>\n",
       "      <td>2.622318</td>\n",
       "      <td>-0.145900</td>\n",
       "      <td>-0.139308</td>\n",
       "      <td>0.190517</td>\n",
       "      <td>0.466907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4244</th>\n",
       "      <td>26</td>\n",
       "      <td>2017</td>\n",
       "      <td>Kevin Love</td>\n",
       "      <td>3.988737</td>\n",
       "      <td>0.793824</td>\n",
       "      <td>1.630072</td>\n",
       "      <td>-0.628682</td>\n",
       "      <td>-0.340241</td>\n",
       "      <td>-0.545910</td>\n",
       "      <td>0.226610</td>\n",
       "      <td>1.137683</td>\n",
       "      <td>-0.085231</td>\n",
       "      <td>1.800614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4245</th>\n",
       "      <td>27</td>\n",
       "      <td>2017</td>\n",
       "      <td>Andre Drummond</td>\n",
       "      <td>3.805188</td>\n",
       "      <td>0.314784</td>\n",
       "      <td>4.227332</td>\n",
       "      <td>0.032821</td>\n",
       "      <td>2.235716</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>-1.139258</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>1.440481</td>\n",
       "      <td>-3.178068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4246</th>\n",
       "      <td>28</td>\n",
       "      <td>2017</td>\n",
       "      <td>Russell Westbrook</td>\n",
       "      <td>3.763264</td>\n",
       "      <td>2.230942</td>\n",
       "      <td>1.940192</td>\n",
       "      <td>3.747412</td>\n",
       "      <td>-0.554904</td>\n",
       "      <td>2.134898</td>\n",
       "      <td>-3.870994</td>\n",
       "      <td>-0.139308</td>\n",
       "      <td>-0.520390</td>\n",
       "      <td>-1.204585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4247</th>\n",
       "      <td>29</td>\n",
       "      <td>2017</td>\n",
       "      <td>Kemba Walker</td>\n",
       "      <td>3.725170</td>\n",
       "      <td>1.622930</td>\n",
       "      <td>-0.773363</td>\n",
       "      <td>1.355826</td>\n",
       "      <td>-0.554904</td>\n",
       "      <td>0.428929</td>\n",
       "      <td>-0.642579</td>\n",
       "      <td>1.834223</td>\n",
       "      <td>-0.897960</td>\n",
       "      <td>1.352068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4248</th>\n",
       "      <td>30</td>\n",
       "      <td>2017</td>\n",
       "      <td>Eric Bledsoe</td>\n",
       "      <td>3.653643</td>\n",
       "      <td>0.830673</td>\n",
       "      <td>-0.463243</td>\n",
       "      <td>1.101402</td>\n",
       "      <td>0.089085</td>\n",
       "      <td>2.622318</td>\n",
       "      <td>-1.511767</td>\n",
       "      <td>0.441142</td>\n",
       "      <td>0.360757</td>\n",
       "      <td>0.183276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4729</th>\n",
       "      <td>511</td>\n",
       "      <td>2017</td>\n",
       "      <td>Darrun Hilliard</td>\n",
       "      <td>-8.567256</td>\n",
       "      <td>-2.246234</td>\n",
       "      <td>-1.781256</td>\n",
       "      <td>-1.086645</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.008169</td>\n",
       "      <td>1.716648</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.468564</td>\n",
       "      <td>0.038246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4730</th>\n",
       "      <td>512</td>\n",
       "      <td>2017</td>\n",
       "      <td>Tim Quarterman</td>\n",
       "      <td>-8.645561</td>\n",
       "      <td>-2.209385</td>\n",
       "      <td>-1.587430</td>\n",
       "      <td>-1.341069</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>1.219968</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.307768</td>\n",
       "      <td>0.563284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4731</th>\n",
       "      <td>513</td>\n",
       "      <td>2017</td>\n",
       "      <td>Demetrius Jackson</td>\n",
       "      <td>-8.660268</td>\n",
       "      <td>-2.319932</td>\n",
       "      <td>-1.626195</td>\n",
       "      <td>-1.290185</td>\n",
       "      <td>-0.984230</td>\n",
       "      <td>-1.520749</td>\n",
       "      <td>1.095798</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.482386</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4732</th>\n",
       "      <td>514</td>\n",
       "      <td>2017</td>\n",
       "      <td>Markel Brown</td>\n",
       "      <td>-8.715761</td>\n",
       "      <td>-2.209385</td>\n",
       "      <td>-1.471135</td>\n",
       "      <td>-1.239300</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>1.468308</td>\n",
       "      <td>-1.184119</td>\n",
       "      <td>-0.629359</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4733</th>\n",
       "      <td>515</td>\n",
       "      <td>2017</td>\n",
       "      <td>Josh Smith</td>\n",
       "      <td>-8.748490</td>\n",
       "      <td>-2.319932</td>\n",
       "      <td>-1.471135</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.569694</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4734</th>\n",
       "      <td>516</td>\n",
       "      <td>2017</td>\n",
       "      <td>Erik McCree</td>\n",
       "      <td>-8.773341</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.858786</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-1.520749</td>\n",
       "      <td>1.716648</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.436543</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4735</th>\n",
       "      <td>517</td>\n",
       "      <td>2017</td>\n",
       "      <td>Xavier Munford</td>\n",
       "      <td>-8.789856</td>\n",
       "      <td>-2.356782</td>\n",
       "      <td>-1.897551</td>\n",
       "      <td>-1.137530</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-1.764459</td>\n",
       "      <td>1.716648</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.496208</td>\n",
       "      <td>-0.122692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4736</th>\n",
       "      <td>518</td>\n",
       "      <td>2017</td>\n",
       "      <td>Tyler Lydon</td>\n",
       "      <td>-8.811713</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.975081</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4737</th>\n",
       "      <td>519</td>\n",
       "      <td>2017</td>\n",
       "      <td>Trey McKinney-Jones</td>\n",
       "      <td>-8.811713</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.975081</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4738</th>\n",
       "      <td>520</td>\n",
       "      <td>2017</td>\n",
       "      <td>Xavier Rathan-Mayes</td>\n",
       "      <td>-8.814577</td>\n",
       "      <td>-1.380278</td>\n",
       "      <td>-1.587430</td>\n",
       "      <td>0.338130</td>\n",
       "      <td>0.089085</td>\n",
       "      <td>0.672639</td>\n",
       "      <td>-0.642579</td>\n",
       "      <td>-1.300209</td>\n",
       "      <td>-2.811382</td>\n",
       "      <td>-2.192553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4739</th>\n",
       "      <td>521</td>\n",
       "      <td>2017</td>\n",
       "      <td>Matt Williams</td>\n",
       "      <td>-8.833537</td>\n",
       "      <td>-2.135687</td>\n",
       "      <td>-1.858786</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>1.716648</td>\n",
       "      <td>-1.184119</td>\n",
       "      <td>-0.427098</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4740</th>\n",
       "      <td>522</td>\n",
       "      <td>2017</td>\n",
       "      <td>Cole Aldrich</td>\n",
       "      <td>-8.856290</td>\n",
       "      <td>-2.338357</td>\n",
       "      <td>-1.703725</td>\n",
       "      <td>-1.442839</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.008169</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.234282</td>\n",
       "      <td>-0.486792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4741</th>\n",
       "      <td>523</td>\n",
       "      <td>2017</td>\n",
       "      <td>Nicolas Brussino</td>\n",
       "      <td>-8.938136</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.664960</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.436543</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4742</th>\n",
       "      <td>524</td>\n",
       "      <td>2017</td>\n",
       "      <td>PJ Dozier</td>\n",
       "      <td>-8.985381</td>\n",
       "      <td>-2.264659</td>\n",
       "      <td>-1.781256</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>1.468308</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>0.069110</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4743</th>\n",
       "      <td>525</td>\n",
       "      <td>2017</td>\n",
       "      <td>Omer Asik</td>\n",
       "      <td>-9.030298</td>\n",
       "      <td>-2.209385</td>\n",
       "      <td>-0.967189</td>\n",
       "      <td>-1.442839</td>\n",
       "      <td>-0.984230</td>\n",
       "      <td>-2.008169</td>\n",
       "      <td>1.592478</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.018199</td>\n",
       "      <td>-1.460376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4744</th>\n",
       "      <td>526</td>\n",
       "      <td>2017</td>\n",
       "      <td>London Perrantes</td>\n",
       "      <td>-9.069214</td>\n",
       "      <td>-2.356782</td>\n",
       "      <td>-1.858786</td>\n",
       "      <td>-1.290185</td>\n",
       "      <td>-0.984230</td>\n",
       "      <td>-2.008169</td>\n",
       "      <td>1.964987</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.597338</td>\n",
       "      <td>-0.406323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4745</th>\n",
       "      <td>527</td>\n",
       "      <td>2017</td>\n",
       "      <td>Jacob Pullen</td>\n",
       "      <td>-9.101093</td>\n",
       "      <td>-2.319932</td>\n",
       "      <td>-1.975081</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>1.716648</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.045843</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4746</th>\n",
       "      <td>528</td>\n",
       "      <td>2017</td>\n",
       "      <td>Charles Cooke</td>\n",
       "      <td>-9.142223</td>\n",
       "      <td>-2.356782</td>\n",
       "      <td>-1.897551</td>\n",
       "      <td>-1.442839</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.008169</td>\n",
       "      <td>1.964987</td>\n",
       "      <td>-1.416299</td>\n",
       "      <td>-0.583516</td>\n",
       "      <td>-0.203161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4747</th>\n",
       "      <td>529</td>\n",
       "      <td>2017</td>\n",
       "      <td>Nate Wolters</td>\n",
       "      <td>-9.152010</td>\n",
       "      <td>-2.375206</td>\n",
       "      <td>-1.820021</td>\n",
       "      <td>-1.391954</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.670825</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4748</th>\n",
       "      <td>530</td>\n",
       "      <td>2017</td>\n",
       "      <td>Derrick Williams</td>\n",
       "      <td>-9.237618</td>\n",
       "      <td>-2.264659</td>\n",
       "      <td>-1.781256</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.803976</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4749</th>\n",
       "      <td>531</td>\n",
       "      <td>2017</td>\n",
       "      <td>Josh McRoberts</td>\n",
       "      <td>-9.248257</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.975081</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.436543</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4750</th>\n",
       "      <td>532</td>\n",
       "      <td>2017</td>\n",
       "      <td>Nick Collison</td>\n",
       "      <td>-9.288480</td>\n",
       "      <td>-2.061988</td>\n",
       "      <td>-1.471135</td>\n",
       "      <td>-1.341069</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>1.468308</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>0.560941</td>\n",
       "      <td>-1.460376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4751</th>\n",
       "      <td>533</td>\n",
       "      <td>2017</td>\n",
       "      <td>Chris Boucher</td>\n",
       "      <td>-9.297149</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.587430</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.873086</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4752</th>\n",
       "      <td>534</td>\n",
       "      <td>2017</td>\n",
       "      <td>Kyle Singler</td>\n",
       "      <td>-9.322633</td>\n",
       "      <td>-2.098837</td>\n",
       "      <td>-1.664960</td>\n",
       "      <td>-1.391954</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.008169</td>\n",
       "      <td>1.716648</td>\n",
       "      <td>-1.300209</td>\n",
       "      <td>-0.440920</td>\n",
       "      <td>-0.935338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4753</th>\n",
       "      <td>535</td>\n",
       "      <td>2017</td>\n",
       "      <td>Vander Blue</td>\n",
       "      <td>-9.478457</td>\n",
       "      <td>-2.338357</td>\n",
       "      <td>-1.897551</td>\n",
       "      <td>-1.188415</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-1.764459</td>\n",
       "      <td>1.344138</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.496208</td>\n",
       "      <td>-0.406323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4754</th>\n",
       "      <td>536</td>\n",
       "      <td>2017</td>\n",
       "      <td>Aaron Jackson</td>\n",
       "      <td>-9.982955</td>\n",
       "      <td>-0.974937</td>\n",
       "      <td>-0.812129</td>\n",
       "      <td>-0.984876</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>0.847459</td>\n",
       "      <td>-0.371488</td>\n",
       "      <td>-2.204598</td>\n",
       "      <td>-2.031614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4755</th>\n",
       "      <td>537</td>\n",
       "      <td>2017</td>\n",
       "      <td>Luis Montero</td>\n",
       "      <td>-10.102304</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.587430</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>0.847459</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.436543</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4756</th>\n",
       "      <td>538</td>\n",
       "      <td>2017</td>\n",
       "      <td>Chinanu Onuaku</td>\n",
       "      <td>-10.337018</td>\n",
       "      <td>-1.711921</td>\n",
       "      <td>-0.424478</td>\n",
       "      <td>-0.984876</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>-1.635937</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.596646</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4757</th>\n",
       "      <td>539</td>\n",
       "      <td>2017</td>\n",
       "      <td>Mindaugas Kuzminskas</td>\n",
       "      <td>-10.557886</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.975081</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-1.746172</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4758</th>\n",
       "      <td>540</td>\n",
       "      <td>2017</td>\n",
       "      <td>Scotty Hopson</td>\n",
       "      <td>-12.265018</td>\n",
       "      <td>-2.264659</td>\n",
       "      <td>-1.975081</td>\n",
       "      <td>-0.984876</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>0.847459</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.873086</td>\n",
       "      <td>-2.031614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      playerrank  season                 player  value_tot  value_points  \\\n",
       "4219           1    2017          Anthony Davis  13.069292      2.728406   \n",
       "4220           2    2017          Stephen Curry  10.977767      2.415188   \n",
       "4221           3    2017           Kevin Durant  10.555627      2.415188   \n",
       "4222           4    2017           James Harden  10.522310      3.152171   \n",
       "4223           5    2017     Karl-Anthony Towns   9.046572      1.475533   \n",
       "4224           6    2017           LeBron James   8.050018      2.617858   \n",
       "4225           7    2017  Giannis Antetokounmpo   7.982516      2.507311   \n",
       "4226           8    2017         Damian Lillard   7.758411      2.507311   \n",
       "4227           9    2017             Chris Paul   7.259998      0.978069   \n",
       "4228          10    2017           Jimmy Butler   7.194467      1.641355   \n",
       "4229          11    2017         Victor Oladipo   6.742591      1.807176   \n",
       "4230          12    2017       DeMarcus Cousins   6.513379      2.194092   \n",
       "4231          13    2017           Nikola Jokic   6.424866      0.959645   \n",
       "4232          14    2017           Kyrie Irving   6.159878      2.046696   \n",
       "4233          15    2017           Andre Ingram   5.581832     -0.237954   \n",
       "4234          16    2017      LaMarcus Aldridge   5.370052      1.807176   \n",
       "4235          17    2017         MarShon Brooks   5.131062      1.254438   \n",
       "4236          18    2017            Paul George   5.126899      1.586081   \n",
       "4237          19    2017     Kristaps Porzingis   4.816889      1.733478   \n",
       "4238          20    2017           Jrue Holiday   4.397228      1.051768   \n",
       "4239          21    2017        Khris Middleton   4.231094      1.254438   \n",
       "4240          22    2017         Nikola Vucevic   4.156660      0.591153   \n",
       "4241          23    2017             Kyle Lowry   4.141570      0.535879   \n",
       "4242          24    2017            Otto Porter   4.136911      0.259510   \n",
       "4243          25    2017          Kawhi Leonard   4.001655      0.535879   \n",
       "4244          26    2017             Kevin Love   3.988737      0.793824   \n",
       "4245          27    2017         Andre Drummond   3.805188      0.314784   \n",
       "4246          28    2017      Russell Westbrook   3.763264      2.230942   \n",
       "4247          29    2017           Kemba Walker   3.725170      1.622930   \n",
       "4248          30    2017           Eric Bledsoe   3.653643      0.830673   \n",
       "...          ...     ...                    ...        ...           ...   \n",
       "4729         511    2017        Darrun Hilliard  -8.567256     -2.246234   \n",
       "4730         512    2017         Tim Quarterman  -8.645561     -2.209385   \n",
       "4731         513    2017      Demetrius Jackson  -8.660268     -2.319932   \n",
       "4732         514    2017           Markel Brown  -8.715761     -2.209385   \n",
       "4733         515    2017             Josh Smith  -8.748490     -2.319932   \n",
       "4734         516    2017            Erik McCree  -8.773341     -2.448905   \n",
       "4735         517    2017         Xavier Munford  -8.789856     -2.356782   \n",
       "4736         518    2017            Tyler Lydon  -8.811713     -2.448905   \n",
       "4737         519    2017    Trey McKinney-Jones  -8.811713     -2.448905   \n",
       "4738         520    2017    Xavier Rathan-Mayes  -8.814577     -1.380278   \n",
       "4739         521    2017          Matt Williams  -8.833537     -2.135687   \n",
       "4740         522    2017           Cole Aldrich  -8.856290     -2.338357   \n",
       "4741         523    2017       Nicolas Brussino  -8.938136     -2.448905   \n",
       "4742         524    2017              PJ Dozier  -8.985381     -2.264659   \n",
       "4743         525    2017              Omer Asik  -9.030298     -2.209385   \n",
       "4744         526    2017       London Perrantes  -9.069214     -2.356782   \n",
       "4745         527    2017           Jacob Pullen  -9.101093     -2.319932   \n",
       "4746         528    2017          Charles Cooke  -9.142223     -2.356782   \n",
       "4747         529    2017           Nate Wolters  -9.152010     -2.375206   \n",
       "4748         530    2017       Derrick Williams  -9.237618     -2.264659   \n",
       "4749         531    2017         Josh McRoberts  -9.248257     -2.448905   \n",
       "4750         532    2017          Nick Collison  -9.288480     -2.061988   \n",
       "4751         533    2017          Chris Boucher  -9.297149     -2.448905   \n",
       "4752         534    2017           Kyle Singler  -9.322633     -2.098837   \n",
       "4753         535    2017            Vander Blue  -9.478457     -2.338357   \n",
       "4754         536    2017          Aaron Jackson  -9.982955     -0.974937   \n",
       "4755         537    2017           Luis Montero -10.102304     -2.448905   \n",
       "4756         538    2017         Chinanu Onuaku -10.337018     -1.711921   \n",
       "4757         539    2017   Mindaugas Kuzminskas -10.557886     -2.448905   \n",
       "4758         540    2017          Scotty Hopson -12.265018     -2.264659   \n",
       "\n",
       "      value_rebounds  value_assists  value_blocks  value_steals  \\\n",
       "4219        2.327843      -0.323373      4.382346      1.403769   \n",
       "4220        0.001938       1.610250     -0.769567      1.647478   \n",
       "4221        0.660945       1.254056      2.665042     -0.545910   \n",
       "4222        0.118234       2.984140      0.303748      2.134898   \n",
       "4223        2.793024      -0.272488      1.806390     -0.302200   \n",
       "4224        1.358716       3.136795      0.733074      1.160059   \n",
       "4225        1.901427       0.948747      1.806390      1.403769   \n",
       "4226       -0.230652       1.864674     -0.340241      0.428929   \n",
       "4227        0.118234       2.526177     -0.769567      1.891188   \n",
       "4228        0.079468       0.999632     -0.340241      2.622318   \n",
       "4229        0.040703       0.694323      0.518411      3.597157   \n",
       "4230        3.025615       1.254056      2.235716      1.647478   \n",
       "4231        2.172783       1.610250      0.518411      0.672639   \n",
       "4232       -0.502008       1.101402     -0.554904      0.428929   \n",
       "4233       -0.812129       0.287245      2.021053      1.403769   \n",
       "4234        1.319951      -0.476027      1.377064     -0.789620   \n",
       "4235       -0.812129       0.338130     -0.340241      1.647478   \n",
       "4236        0.234529       0.185475     -0.125578      2.622318   \n",
       "4237        0.583415      -0.883106      3.953020     -0.302200   \n",
       "4238       -0.230652       1.559365      0.518411      1.403769   \n",
       "4239        0.040703       0.541669     -0.554904      1.403769   \n",
       "4240        1.591307       0.236360      1.162400      0.185219   \n",
       "4241        0.195764       2.017329     -0.769567      0.428929   \n",
       "4242        0.505884      -0.476027     -0.125578      1.403769   \n",
       "4243       -0.153122      -0.323373      0.947737      2.622318   \n",
       "4244        1.630072      -0.628682     -0.340241     -0.545910   \n",
       "4245        4.227332       0.032821      2.235716      1.403769   \n",
       "4246        1.940192       3.747412     -0.554904      2.134898   \n",
       "4247       -0.773363       1.355826     -0.554904      0.428929   \n",
       "4248       -0.463243       1.101402      0.089085      2.622318   \n",
       "...              ...            ...           ...           ...   \n",
       "4729       -1.781256      -1.086645     -1.198893     -2.008169   \n",
       "4730       -1.587430      -1.341069     -1.198893     -2.251879   \n",
       "4731       -1.626195      -1.290185     -0.984230     -1.520749   \n",
       "4732       -1.471135      -1.239300     -1.198893     -2.251879   \n",
       "4733       -1.471135      -1.493724     -1.198893     -2.251879   \n",
       "4734       -1.858786      -1.493724     -1.198893     -1.520749   \n",
       "4735       -1.897551      -1.137530     -1.198893     -1.764459   \n",
       "4736       -1.975081      -1.493724     -1.198893     -2.251879   \n",
       "4737       -1.975081      -1.493724     -1.198893     -2.251879   \n",
       "4738       -1.587430       0.338130      0.089085      0.672639   \n",
       "4739       -1.858786      -1.493724     -1.198893     -2.251879   \n",
       "4740       -1.703725      -1.442839     -1.198893     -2.008169   \n",
       "4741       -1.664960      -1.493724     -1.198893     -2.251879   \n",
       "4742       -1.781256      -1.493724     -1.198893     -2.251879   \n",
       "4743       -0.967189      -1.442839     -0.984230     -2.008169   \n",
       "4744       -1.858786      -1.290185     -0.984230     -2.008169   \n",
       "4745       -1.975081      -1.493724     -1.198893     -2.251879   \n",
       "4746       -1.897551      -1.442839     -1.198893     -2.008169   \n",
       "4747       -1.820021      -1.391954     -1.198893     -2.251879   \n",
       "4748       -1.781256      -1.493724     -1.198893     -2.251879   \n",
       "4749       -1.975081      -1.493724     -1.198893     -2.251879   \n",
       "4750       -1.471135      -1.341069     -1.198893     -2.251879   \n",
       "4751       -1.587430      -1.493724     -1.198893     -2.251879   \n",
       "4752       -1.664960      -1.391954     -1.198893     -2.008169   \n",
       "4753       -1.897551      -1.188415     -1.198893     -1.764459   \n",
       "4754       -0.812129      -0.984876     -1.198893     -2.251879   \n",
       "4755       -1.587430      -1.493724     -1.198893     -2.251879   \n",
       "4756       -0.424478      -0.984876     -1.198893     -2.251879   \n",
       "4757       -1.975081      -1.493724     -1.198893     -2.251879   \n",
       "4758       -1.975081      -0.984876     -1.198893     -2.251879   \n",
       "\n",
       "      value_turnovers  value_threes  value_fg  value_ft  \n",
       "4219        -0.642579     -0.719758  2.572502  1.340136  \n",
       "4220        -1.635937      3.343394  1.073741  3.291282  \n",
       "4221        -1.635937      1.369863  1.809299  2.563082  \n",
       "4222        -3.374314      2.762944 -0.589500  3.029989  \n",
       "4223        -0.270069      0.208962  2.213129  1.394291  \n",
       "4224        -3.125975      0.557232  2.935558 -1.323300  \n",
       "4225        -1.635937     -0.835849  2.328774 -0.442116  \n",
       "4226        -1.387598      2.066403 -0.920536  3.770119  \n",
       "4227        -0.642579      1.369863 -0.176916  1.965529  \n",
       "4228        -0.145900     -0.139308  0.324360  2.152782  \n",
       "4229        -1.511767      0.905503  0.389094  0.301991  \n",
       "4230        -4.119333      1.021593  0.301785 -1.047624  \n",
       "4231        -1.387598      0.208962  0.838766  0.831007  \n",
       "4232        -0.766749      1.718133  0.968233  1.720144  \n",
       "4233         0.226610      1.369863  0.116338  1.207037  \n",
       "4234         0.226610     -1.068029  1.620860  1.352068  \n",
       "4235        -0.766749      1.602043  1.009007  1.199083  \n",
       "4236        -1.263428      2.066403 -1.086400  0.907499  \n",
       "4237        -0.270069      0.673322 -0.888515  0.217545  \n",
       "4238        -1.139258      0.208962  0.875856  0.149007  \n",
       "4239        -0.766749      0.557232  0.034790  1.720144  \n",
       "4240        -0.270069     -0.255398  0.356381  0.559307  \n",
       "4241        -0.766749      2.066403 -0.765502  1.199083  \n",
       "4242         0.847459      0.557232  0.888985  0.275676  \n",
       "4243        -0.145900     -0.139308  0.190517  0.466907  \n",
       "4244         0.226610      1.137683 -0.085231  1.800614  \n",
       "4245        -1.139258     -1.532389  1.440481 -3.178068  \n",
       "4246        -3.870994     -0.139308 -0.520390 -1.204585  \n",
       "4247        -0.642579      1.834223 -0.897960  1.352068  \n",
       "4248        -1.511767      0.441142  0.360757  0.183276  \n",
       "...               ...           ...       ...       ...  \n",
       "4729         1.716648     -1.532389 -0.468564  0.038246  \n",
       "4730         1.219968     -1.532389 -0.307768  0.563284  \n",
       "4731         1.095798     -1.532389 -0.482386  0.000000  \n",
       "4732         1.468308     -1.184119 -0.629359  0.000000  \n",
       "4733         2.089157     -1.532389 -0.569694  0.000000  \n",
       "4734         1.716648     -1.532389 -0.436543  0.000000  \n",
       "4735         1.716648     -1.532389 -0.496208 -0.122692  \n",
       "4736         2.089157     -1.532389  0.000000  0.000000  \n",
       "4737         2.089157     -1.532389  0.000000  0.000000  \n",
       "4738        -0.642579     -1.300209 -2.811382 -2.192553  \n",
       "4739         1.716648     -1.184119 -0.427098  0.000000  \n",
       "4740         2.089157     -1.532389 -0.234282 -0.486792  \n",
       "4741         2.089157     -1.532389 -0.436543  0.000000  \n",
       "4742         1.468308     -1.532389  0.069110  0.000000  \n",
       "4743         1.592478     -1.532389 -0.018199 -1.460376  \n",
       "4744         1.964987     -1.532389 -0.597338 -0.406323  \n",
       "4745         1.716648     -1.532389 -0.045843  0.000000  \n",
       "4746         1.964987     -1.416299 -0.583516 -0.203161  \n",
       "4747         2.089157     -1.532389 -0.670825  0.000000  \n",
       "4748         2.089157     -1.532389 -0.803976  0.000000  \n",
       "4749         2.089157     -1.532389 -0.436543  0.000000  \n",
       "4750         1.468308     -1.532389  0.560941 -1.460376  \n",
       "4751         2.089157     -1.532389 -0.873086  0.000000  \n",
       "4752         1.716648     -1.300209 -0.440920 -0.935338  \n",
       "4753         1.344138     -1.532389 -0.496208 -0.406323  \n",
       "4754         0.847459     -0.371488 -2.204598 -2.031614  \n",
       "4755         0.847459     -1.532389 -0.436543  0.000000  \n",
       "4756        -1.635937     -1.532389 -0.596646  0.000000  \n",
       "4757         2.089157     -1.532389 -1.746172  0.000000  \n",
       "4758         0.847459     -1.532389 -0.873086 -2.031614  \n",
       "\n",
       "[540 rows x 13 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2[df_2['season']==2017].sort_values(by='playerrank', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Creating all teammate based changes\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "query = '''\n",
    "        DROP TABLE IF EXISTS adv_top10min;\n",
    "        CREATE TABLE adv_top10min as \n",
    "        select a.*,usage_percentage*total_MP/G as usage_withMins,row_number() over(partition by a.season,tm order by usage_percentage*total_MP/G desc) as usage_rank\n",
    "        from(select *,row_number() over(partition by season,tm order by total_MP desc) as min_rank from nba_advanced) a\n",
    "        inner join y_predictions y\n",
    "                ON a.player = y.player\n",
    "                and a.season = y.season\n",
    "                and a.Tm=y.startingTeam\n",
    "        where min_rank<=10;\n",
    "        \n",
    "        DROP TABLE IF EXISTS Change_Teams;\n",
    "        CREATE TABLE Change_Teams AS\n",
    "        select na.tm as old_team,na2.tm as new_team,na2.player,na2.pos,p.season,na.usage_withMins,\n",
    "        n.points,n.rebounds,n.ast,n.threes_made,na.usage_rank \n",
    "        from player_value p\n",
    "        inner join adv_top10min na\n",
    "            on p.player = na.player\n",
    "            and p.season = na.season+1\n",
    "        inner join adv_top10min na2\n",
    "            on na2.player = na.player\n",
    "            and na2.season = p.season\n",
    "            and na2.tm != na.tm\n",
    "        inner join rank_by_minutes n\n",
    "            ON N.player = na.player\n",
    "            and n.season = na.season;\n",
    "        \n",
    "        \n",
    "        \n",
    "        DROP TABLE IF EXISTS incoming_by_team;\n",
    "        CREATE TABLE incoming_by_team AS\n",
    "        select new_team,season,SUM(case when usage_withmins >1000 then 1 else 0 end) as high_usageplayer_added,\n",
    "        SUM(usage_withmins) as usagemin_added, MAX(usage_withmins) as max_usageadded,\n",
    "        SUM(points) as points_added, MAX(points) as max_pointsadded,SUM(rebounds) as rebounds_added,\n",
    "        MAX(rebounds) as max_reboundsadded, SUM(ast) as ast_added, MAX(ast) as max_astadded,\n",
    "        SUM(threes_made) as threes_added, MAX(threes_made) as max_threesadded \n",
    "        from change_teams\n",
    "        group by new_team,season;\n",
    "        \n",
    "        DROP TABLE IF EXISTS outgoing_by_team;\n",
    "        CREATE TABLE outgoing_by_team AS\n",
    "        select old_team,season,SUM(case when usage_withmins >1000 then 1 else 0 end) as high_usageplayer_dropped,\n",
    "        SUM(usage_withmins) as usagemin_dropped, MAX(usage_withmins) as max_usagedropped,\n",
    "        SUM(points) as points_dropped, MAX(points) as max_pointsdropped,SUM(rebounds) as rebounds_dropped,\n",
    "        MAX(rebounds) as max_reboundsdropped, SUM(ast) as ast_dropped, MAX(ast) as max_astdropped,\n",
    "        SUM(threes_made) as threes_dropped, MAX(threes_made) as max_threesdropped\n",
    "        from change_teams\n",
    "        group by old_team,season;\n",
    "        \n",
    "        DROP TABLE IF EXISTS Team_Changes;\n",
    "        CREATE TABLE Team_Changes AS\n",
    "        select c.new_team as team, c.season,c.high_usageplayer_added,o.usagemin_dropped-c.usagemin_added as usagemin_opened,\n",
    "        c.max_usageadded,o.high_usageplayer_dropped,o.max_usagedropped,\n",
    "        o.points_dropped-c.points_added as points_opened,max_pointsdropped,max_pointsadded,\n",
    "        o.rebounds_dropped-c.rebounds_added as rebounds_opened,max_reboundsdropped,max_reboundsadded,\n",
    "        o.ast_dropped-c.ast_added as ast_opened,max_astdropped,max_astadded,\n",
    "        o.threes_dropped-c.threes_added as threes_opened,max_threesdropped,max_threesadded\n",
    "        from incoming_by_team c\n",
    "        inner join outgoing_by_team o\n",
    "            ON o.old_team = c.new_team\n",
    "            and o.season = c.season;\n",
    "            \n",
    "        DROP TABLE IF EXISTS Teammate_maxes;\n",
    "        CREATE TABLE Teammate_maxes AS\n",
    "        select R.season,R.startingTeam,R.player,MAX(R2.points) as max_teammatepts, max(r2.rebounds) as max_teammatereb, max(r2.ast) as max_teammateast,\n",
    "        MAX(R2.Tov) as max_teammateTO,MAX(r2.FGA) as max_teammateshot_attempts, cast(NULL as float) as max_teammate_usage \n",
    "        from rank_by_minutes R\n",
    "        inner join rank_by_minutes R2\n",
    "            ON R2.startingTeam = R.startingTeam\n",
    "            and R2.season+1 = R.season\n",
    "            and R2.player != R.player\n",
    "        group by R.season,R.startingTeam, R.player;\n",
    "        \n",
    "        \n",
    "        --would like to change this to max teammate and usage usagewithmins rather than usage\n",
    "        update Teammate_maxes T\n",
    "        set max_teammate_usage = usagemins\n",
    "        from\n",
    "        (select T.season,T.startingTeam,T.player,MAX(a2.usage_withMins) as usagemins from Teammate_maxes T\n",
    "        inner join adv_top10min a\n",
    "            ON A.season = T.season\n",
    "            and A.tm = T.startingteam\n",
    "            and A.player != T.player\n",
    "        inner join adv_top10min a2\n",
    "            ON a2.season+1 = a.season\n",
    "            and a2.player=a.player\n",
    "        group by T.season,T.startingTeam,T.player) A\n",
    "        WHERE A.season = T.season and  A.startingTeam = T.startingTeam and A.player = T.player;\n",
    "        \n",
    "        \n",
    "        \n",
    "        '''\n",
    "\n",
    "\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Get player based data\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "query = '''\n",
    "        DROP TABLE IF EXISTS player_stats;\n",
    "        CREATE TABLE player_stats AS\n",
    "        select r.*,r2.starter as starter_ly,r2.points-r3.points as change_points_ly,r2.points as points_ly\n",
    "        ,r2.rebounds-r3.rebounds as change_reb_ly, r2.rebounds as rebounds_ly,\n",
    "        r2.ast-r3.ast as change_ast_ly, r2.ast as ast_ly,r2.stl-r3.stl as change_stl_ly,r2.stl as stl_ly,\n",
    "        r2.blk-r3.blk as change_blk_ly, r2.blk as blk_ly,r2.tov-r3.tov as change_tov_ly,r2.tov as tov_ly,\n",
    "        r2.threes_made as threes_ly,r2.threes_made-r3.threes_made as change_threes,r2.fg as fg_ly, r2.fga as fga_ly,\n",
    "        r2.ftm as ftm_ly,r2.fta as fta_ly\n",
    "        from rank_by_minutes r\n",
    "        left join rank_by_minutes r2\n",
    "            on r.player = r2.player\n",
    "            and r.season = r2.season+1\n",
    "        left join rank_by_minutes r3\n",
    "            ON r3.player = r2.player\n",
    "            and r3.season+1 = r2.season;\n",
    "        \n",
    "        DROP TABLE IF EXISTS player_advstats;\n",
    "        CREATE TABLE player_advstats AS\n",
    "        select y.player,y.season,y.startingteam,a.per as per_ly, a.per-a2.per as change_per,a.three_attempt_rate as threeAR_ly,\n",
    "        a.three_attempt_rate-a2.three_attempt_rate as change_3AR, a.rebound_percentage as reb_perc_ly, a.rebound_percentage-a2.rebound_percentage as change_reb_perc\n",
    "        ,a.assist_percentage as ast_perc_ly, a.assist_percentage-a2.assist_percentage as change_assist_perc\n",
    "        ,a.steal_percentage as stl_perc_ly, a.steal_percentage-a2.steal_percentage as change_stl_perc_ly\n",
    "        ,a.block_percentage as blk_perc_ly, a.block_percentage-a2.block_percentage as change_blk_perc_ly\n",
    "        ,a.turnover_percentage as TO_perc_ly, a.turnover_percentage-a2.turnover_percentage as change_turnover_perc_ly,\n",
    "        rank() over(partition by y.season,y.startingTeam order by cast(CONCAT(a.usage_percentage*a.minutes,0) as float) DESC) as usagerank,\n",
    "        rank() over(partition by y.season,a.startingTeam order by a.usage_percentage DESC) as usagerank_ly,\n",
    "        a.offensive_winshares,\n",
    "        a.defensive_winshares,a.winshares,a.winshares_per48,a.offensive_boxplusminus,a.defensive_boxplusminus,\n",
    "        a.boxplusminus,a.value_overreplacement        \n",
    "        from y_predictions y\n",
    "        left join adv_withminrank a\n",
    "            ON a.player = y.player\n",
    "            and a.season+1 = y.season\n",
    "        left join adv_withminrank a2\n",
    "            ON a2.player = a.player\n",
    "            and a2.season+1 = a.season;\n",
    "    \n",
    "        \n",
    "        DROP TABLE IF EXISTS player_careerstats;\n",
    "        CREATE TABLE player_careerstats AS\n",
    "        select r.player,r.season,SUM(case when r2.player is not null then 1 else 0 end) as YearsPro, SUM(r2.points*r2.games)/SUM(r2.games) as career_points\n",
    "        ,SUM(r2.games*r2.rebounds)/SUM(r2.games) as career_rebounds,SUM(r2.games*r2.ast)/SUM(r2.games) as career_ast, SUM(r2.stl*r2.games)/SUM(r2.games) as career_stl\n",
    "        ,SUM(r2.blk*r2.games)/SUM(r2.games) as career_blk,SUM(r2.tov*r2.games)/SUM(r2.games) as career_TO, SUM(r2.threes_made*r2.games)/SUM(r2.games) as career_threesmade\n",
    "        ,avg(r2.ftm) as career_ftm,avg(r2.fta) as career_fta,avg(r2.fga) as career_fga, avg(r2.fg) as career_fgm\n",
    "        from rank_by_minutes r\n",
    "        inner join rank_by_minutes r2\n",
    "            ON r.player = r2.player\n",
    "            and r.season > r2.season\n",
    "        group by r.player,r.season;\n",
    "       \n",
    "        '''\n",
    "\n",
    "\n",
    "cur.execute(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>player</th>\n",
       "      <th>position</th>\n",
       "      <th>age</th>\n",
       "      <th>team</th>\n",
       "      <th>gamesPlayed</th>\n",
       "      <th>gamesStarted</th>\n",
       "      <th>minutes</th>\n",
       "      <th>points</th>\n",
       "      <th>rebounds</th>\n",
       "      <th>...</th>\n",
       "      <th>steals</th>\n",
       "      <th>blocks</th>\n",
       "      <th>turnovers</th>\n",
       "      <th>threes_made</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>starter</th>\n",
       "      <th>min_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>LeBron James</td>\n",
       "      <td>PF</td>\n",
       "      <td>33</td>\n",
       "      <td>CLE</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>36.9</td>\n",
       "      <td>27.5</td>\n",
       "      <td>8.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>10.5</td>\n",
       "      <td>19.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>Khris Middleton</td>\n",
       "      <td>SF</td>\n",
       "      <td>26</td>\n",
       "      <td>MIL</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>36.4</td>\n",
       "      <td>20.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>7.2</td>\n",
       "      <td>15.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>Bradley Beal</td>\n",
       "      <td>SG</td>\n",
       "      <td>24</td>\n",
       "      <td>WAS</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>36.3</td>\n",
       "      <td>22.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>8.3</td>\n",
       "      <td>18.1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>Andrew Wiggins</td>\n",
       "      <td>SF</td>\n",
       "      <td>22</td>\n",
       "      <td>MIN</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>36.3</td>\n",
       "      <td>17.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>6.9</td>\n",
       "      <td>15.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>CJ McCollum</td>\n",
       "      <td>SG</td>\n",
       "      <td>26</td>\n",
       "      <td>POR</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>36.1</td>\n",
       "      <td>21.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>8.2</td>\n",
       "      <td>18.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   season           player position  age team  gamesPlayed  gamesStarted  \\\n",
       "0    2017     LeBron James       PF   33  CLE           82            82   \n",
       "1    2017  Khris Middleton       SF   26  MIL           82            82   \n",
       "2    2017     Bradley Beal       SG   24  WAS           82            82   \n",
       "3    2017   Andrew Wiggins       SF   22  MIN           82            82   \n",
       "4    2017      CJ McCollum       SG   26  POR           81            81   \n",
       "\n",
       "   minutes  points  rebounds    ...     steals  blocks  turnovers  \\\n",
       "0     36.9    27.5       8.6    ...        1.4     0.9        4.2   \n",
       "1     36.4    20.1       5.2    ...        1.5     0.3        2.3   \n",
       "2     36.3    22.6       4.4    ...        1.2     0.4        2.6   \n",
       "3     36.3    17.7       4.4    ...        1.1     0.6        1.7   \n",
       "4     36.1    21.4       4.0    ...        1.0     0.4        1.9   \n",
       "\n",
       "   threes_made   FGM   FGA  FTM  FTA  starter  min_rank  \n",
       "0          1.8  10.5  19.3  4.7  6.5        1         1  \n",
       "1          1.8   7.2  15.5  3.9  4.4        1         2  \n",
       "2          2.4   8.3  18.1  3.6  4.5        1         3  \n",
       "3          1.4   6.9  15.9  2.5  3.8        1         4  \n",
       "4          2.3   8.2  18.6  2.6  3.1        1         5  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 1075,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''testing leaving out 2017 and inputting predicted stats (Will later do this on 2018, but validating on 2017 first)'''\n",
    "query = '''\n",
    "        select * from rank_by_minutes where season = 2017;    \n",
    "                \n",
    "        '''\n",
    "cur.execute(query)\n",
    "data = cur.fetchall()\n",
    "df_2017 = pd.DataFrame(np.array(data))\n",
    "df_2017.columns = ['season','player','position','age','team','gamesPlayed','gamesStarted','minutes'\n",
    "              ,'points','rebounds','assists','steals','blocks','turnovers','threes_made','FGM','FGA','FTM','FTA','starter','min_rank']\n",
    "\n",
    "for i in df_2017.columns:\n",
    "    if i not in(['player','position','team']):\n",
    "        df_2017[i]=pd.to_numeric(df_2017[i])\n",
    "\n",
    "rank_2017 = Player_ranker(df_2017)\n",
    "rank_2017.get_category_dist()\n",
    "rank_2017.assign_values()\n",
    "rank_2017.value.head()\n",
    "df_2017.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "metadata": {},
   "outputs": [],
   "source": [
    " query= '''\n",
    "        \n",
    "        DROP TABLE IF EXISTS points_pred;\n",
    "        CREATE TABLE points_pred(\n",
    "        season int, --these come from player_stats\n",
    "        player varchar(50),\n",
    "        Age int,\n",
    "        team varchar(50),\n",
    "        points float, -- these come from player_stats\n",
    "        points_ly float,\n",
    "        change_points_ly float,\n",
    "        starter_change int,\n",
    "        Games int,\n",
    "        C_PF int,\n",
    "        PG int,\n",
    "        SG_SF int,\n",
    "        \n",
    "         -- these come from team_changes\n",
    "        high_usageplayer_added int,\n",
    "        usagemin_opened float,\n",
    "        maxusage_added float,\n",
    "        high_usageplayer_dropped int,\n",
    "        points_opened float,\n",
    "        max_pointsdropped float,\n",
    "        max_pointsadded float,\n",
    "        \n",
    "        three_ar_ly float, -- from player_advstats\n",
    "        change_3ar float,\n",
    "        per_ly float,\n",
    "        change_per float,\n",
    "        usagerank float,\n",
    "        usagerank_ly float,\n",
    "        offensive_winshares float,\n",
    "        offensive_boxplusminus float,\n",
    "        boxplusminus float,\n",
    "        value_overreplacement float,\n",
    "        \n",
    "        max_teammatepts float,\n",
    "        max_teammate_usage float,\n",
    "        max_teammateto float,\n",
    "        max_teammateshot_attempts float,\n",
    "        \n",
    "        career_points float,\n",
    "        yearspro int\n",
    "        );\n",
    "        \n",
    "        INSERT INTO points_pred(season,player,age,team,points,points_ly,change_points_ly,starter_change,Games,C_PF,PG,SG_SF)\n",
    "        SELECT season,player,age,startingteam,points,points_ly,change_points_ly,starter-starter_ly,Games,\n",
    "        case when pos in ('C','PF') then 1 else 0 end,case when pos='PG' then 1 else 0 end,case when pos in('SG','SF') then 1 else 0 end from player_stats;\n",
    "        \n",
    "        update points_pred pp\n",
    "        set high_usageplayer_added = tc.high_usageplayer_added,usagemin_opened=tc.usagemin_opened,\n",
    "        maxusage_added=tc.max_usageadded,high_usageplayer_dropped=tc.high_usageplayer_dropped,points_opened=tc.points_opened,\n",
    "        max_pointsdropped=tc.max_pointsdropped,max_pointsadded=tc.max_pointsadded\n",
    "        from team_changes tc\n",
    "        where tc.team = pp.team and pp.season=tc.season;\n",
    "        \n",
    "        update points_pred pp\n",
    "        set three_ar_ly = pa.threear_ly,change_3ar=pa.change_3ar,per_ly=pa.per_ly,change_per=pa.change_per,\n",
    "        usagerank=pa.usagerank,usagerank_ly=pa.usagerank_ly,offensive_winshares=pa.offensive_winshares,\n",
    "        offensive_boxplusminus=pa.offensive_boxplusminus,boxplusminus=pa.boxplusminus,value_overreplacement=pa.value_overreplacement\n",
    "        from player_advstats pa\n",
    "        where pp.player = pa.player and pp.season = pa.season and pp.team = pa.startingteam;\n",
    "        \n",
    "        update points_pred pp\n",
    "        set max_teammatepts = tm.max_teammatepts,max_teammate_usage=tm.max_teammate_usage,max_teammateto=tm.max_teammateto,\n",
    "        max_teammateshot_attempts=tm.max_teammateshot_attempts\n",
    "        from teammate_maxes tm\n",
    "        where tm.season = pp.season and tm.player = pp.player;\n",
    "        \n",
    "        update points_pred pp\n",
    "        set career_points = pc.career_points, yearspro = pc.yearspro\n",
    "        from player_careerstats pc\n",
    "        where pp.player = pc.player and pp.season = pc.season;\n",
    "        \n",
    "        \n",
    "        select * from points_pred where season>2009\n",
    "        '''\n",
    "\n",
    "\n",
    "cur.execute(query)\n",
    "data = cur.fetchall()\n",
    "points_df = pd.DataFrame(np.array(data))\n",
    "points_df.columns = ['season','player','age','team','points','points_ly','change_points_ly','starter_change','Games','C_PF','PG','SG_SF','high_usageplayer_added','usagemin_opened','maxusage_added','high_usageplayer_dropped','points_opened','max_pointsdropped',\n",
    "                    'max_pointsadded','three_ar_ly','change_3ar','per_ly','change_per','usagerank','usagerank_ly','offensive_winshares','offensive_boxplusminus','boxplusminus','value_overreplacement',\n",
    "                     'max_teammatepts','max_teammateusage','max_teammateto','max_teammateshot_attempts','career_points','yearspro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rookies = points_df[points_df['points_ly'].isna()]\n",
    "rookies.sort_values(by='points',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "points['age_squared']=points['age']*points['age']\n",
    "points = points_df[points_df['points_ly'].notna()]\n",
    "for i in points.columns:\n",
    "    if i not in(['player','team']):\n",
    "        points[i]=pd.to_numeric(points[i])\n",
    "points = points.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = points[(points['season']!=2017) & (points['Games']>30)]['points']\n",
    "X = points[(points['season']!=2017) & (points['Games']>30)].drop(['points','player','season','team','Games'],axis=1)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression r2: 0.7746187096528391\n",
      "GradientBoost r2: 0.7715932876985157\n",
      "RandomForest r2: 0.6962466937101812\n"
     ]
    }
   ],
   "source": [
    "r2_lr = np.mean(cross_val_score(LinearRegression(),X_train,y_train,cv=10,n_jobs=-1))\n",
    "print('Linear Regression r2: {}'.format(r2_lr))\n",
    "\n",
    "r2_gb = np.mean(cross_val_score(GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.5),X_train,y_train,cv=5,n_jobs=-1))\n",
    "print('GradientBoost r2: {}'.format(r2_gb))\n",
    "\n",
    "r2_rf = np.mean(cross_val_score(RandomForestRegressor(n_estimators=1000,max_depth = 3,max_features=0.5),X_train,y_train,cv=5,n_jobs=-1))\n",
    "print('RandomForest r2: {}'.format(r2_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7495924120019375, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7476594944544669, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7943399658158287, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7190431458804185, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7222216933630867, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7627053638805009, total=   0.6s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7502206778411044, total=   0.6s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000, score=0.8045909017875303, total=   0.6s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7293798119305249, total=   0.6s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7300588658432952, total=   0.6s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7724619977012069, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7526974885743176, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000, score=0.810172956048633, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7464345262995764, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7359319991432365, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000, score=0.7714118315177116, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000, score=0.7484088434769929, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000, score=0.809351530051144, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000, score=0.7396221339062757, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000, score=0.7360800496568037, total=   1.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7782412972206614, total=   0.7s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7534142959553877, total=   0.7s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000, score=0.8076397951828361, total=   0.7s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7526210846094401, total=   0.8s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000, score=0.739283943797602, total=   0.8s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000, score=0.7718861303857902, total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000, score=0.7502934336936846, total=   1.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000, score=0.8069350259476348, total=   1.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000, score=0.7376255382516397, total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000, score=0.737654204563374, total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7626771339183323, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7465049831143591, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000, score=0.8018587343434184, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7303094382099727, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7286900382983863, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7601056582996399, total=   1.0s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7428013575185071, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000, score=0.8003830497626752, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7290513105397022, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7293391964796927, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7770393060223986, total=   1.0s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7515317599698752, total=   1.0s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000, score=0.8057791616339796, total=   1.2s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7403035333377772, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7380020790437171, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7661440685290489, total=   1.7s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7396205227844399, total=   1.7s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000, score=0.802302081648347, total=   1.7s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7295044347022633, total=   1.8s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7316890912641884, total=   1.8s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7715801807194493, total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7457471806092637, total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000, score=0.8033399817639613, total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000, score=0.744422152544153, total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7393631477275849, total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7603685317760063, total=   2.7s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7374521750249801, total=   2.7s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7991477867900119, total=   2.8s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7310660946972016, total=   2.7s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000, score=0.73103055543112, total=   2.7s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7562111426304283, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7480430230577373, total=   0.8s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7967011623928267, total=   0.8s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7257278038368107, total=   0.8s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7256501733403956, total=   0.8s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7461836284262331, total=   1.5s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7426505957356664, total=   1.5s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7943318467730048, total=   1.5s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7163064966131981, total=   1.5s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7268958591275507, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7642667464108575, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7472279720786172, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000, score=0.8051508686829824, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000, score=0.730024428630686, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7321632082347167, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7570609920410137, total=   3.2s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7422406018737014, total=   3.1s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000, score=0.8025975188997343, total=   3.1s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7321555092651384, total=   3.1s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7271797914893012, total=   3.1s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7624550271802718, total=   2.8s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7422698693042158, total=   2.8s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000, score=0.80269818476494, total=   2.6s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7366475381642718, total=   2.7s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7304025880552752, total=   2.6s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7579714310310804, total=   5.0s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7381936611530922, total=   5.0s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7997123433740743, total=   4.9s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000, score=0.729932346775635, total=   4.9s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000, score=0.721586215979279, total=   4.9s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000, score=0.737095505582872, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7391002109576411, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7821762588610093, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7153281788280829, total=   1.8s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7123294115378661, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7394600909167903, total=   3.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7397868483744654, total=   3.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7868843929850418, total=   3.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7230768853387237, total=   3.1s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7163275204374132, total=   3.1s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7546220342493819, total=   3.9s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7452179324783312, total=   3.9s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7971776444927601, total=   3.9s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7299268435231488, total=   3.9s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000, score=0.721997645297602, total=   3.8s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7537602466103849, total=   6.7s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7453613935960759, total=   6.9s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7963422967116403, total=   7.3s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000, score=0.731775920024456, total=   7.0s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7192168588867147, total=   7.3s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7521194216181062, total=   6.8s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000, score=0.73591294700449, total=   6.6s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000, score=0.8000873197537989, total=   6.5s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7281733634094683, total=   6.7s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7275044178926261, total=   6.4s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7545468244722808, total=  11.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7373252340416532, total=  11.3s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000, score=0.8003975458072936, total=  11.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7251717171625662, total=  11.6s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7249564186650879, total=  11.5s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000, score=0.752286846835078, total=   0.3s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7344522867350258, total=   0.3s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000, score=0.8002626878951357, total=   0.3s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000, score=0.703864233587904, total=   0.3s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7235337227035721, total=   0.3s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7393922487573352, total=   0.6s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7125520140158332, total=   0.6s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000, score=0.79302259406663, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7073971620006783, total=   0.6s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7119012948136328, total=   0.6s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7559099138338337, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7319007998160488, total=   0.4s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7992056979535583, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7203937644737937, total=   0.4s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000, score=0.721137441584053, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000, score=0.7385908644620797, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000, score=0.7092442173441982, total=   0.9s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000, score=0.7851112072120722, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000, score=0.6894879510843741, total=   0.9s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000, score=0.7074554670306207, total=   0.9s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7466439072911673, total=   0.7s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7257824680827822, total=   0.7s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000, score=0.8005423190440591, total=   0.7s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7147742701837227, total=   0.7s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7219265556585865, total=   0.7s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000, score=0.729322513231452, total=   1.4s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000, score=0.7082251376147489, total=   1.4s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000, score=0.786368296727049, total=   1.4s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000, score=0.6927225064421316, total=   1.4s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000, score=0.7021674528402333, total=   1.4s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000, score=0.735987099698128, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7163199673523517, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7837932451898368, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7048473971269863, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7286024372293955, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7434888704202895, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7199128185929571, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7876007854609404, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000, score=0.6945420460139555, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7055204482159698, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7510237368472615, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7303682814183251, total=   0.9s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7875888975676699, total=   0.9s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7086265574189083, total=   0.9s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7244035036909662, total=   0.9s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7393223717485395, total=   1.8s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7229888788680818, total=   1.8s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7914514342873987, total=   1.9s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7119477121686841, total=   1.8s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7131420118957748, total=   1.8s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7483604041973191, total=   1.4s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000, score=0.722014021511503, total=   1.4s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7873754260611263, total=   1.5s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7146158970835647, total=   1.4s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7223065561849062, total=   1.4s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7445193304153469, total=   2.9s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7268449941649757, total=   2.9s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7910472172522893, total=   2.8s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7076979390667831, total=   2.9s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7155123783998669, total=   3.1s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7508683171448276, total=   0.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7369347684284189, total=   0.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7868665407329936, total=   0.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7051506815535404, total=   0.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7168202672140183, total=   0.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7403865965978269, total=   1.5s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7394960864825679, total=   1.5s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7866143604997458, total=   1.5s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000, score=0.70787989008121, total=   1.5s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000, score=0.708104263057199, total=   1.5s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7527646705276453, total=   1.6s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7306964803031681, total=   1.6s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7968111012770279, total=   1.6s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7207640091874379, total=   1.6s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7215776096779543, total=   1.6s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7532871973495969, total=   2.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7300993993125191, total=   2.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7962722790974893, total=   2.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7249697944914697, total=   2.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7245997112925274, total=   2.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7450880758859164, total=   2.4s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7219047273998561, total=   2.4s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7968425632753985, total=   2.5s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7228328199892681, total=   2.5s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7210661583696008, total=   2.5s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7490806201728469, total=   4.3s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7251426220404611, total=   4.4s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7987682411300973, total=   4.4s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7209759908921514, total=   4.6s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7279667359080849, total=   4.7s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7177709865279249, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7284447966563368, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7781155952166244, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7134790895649794, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7022702697577334, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7278511082439557, total=   1.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7282186855102353, total=   1.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000, score=0.771979995001921, total=   1.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7168075035305853, total=   1.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7107626870256414, total=   1.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7485030109277822, total=   2.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7434980023515272, total=   2.0s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7896427314684267, total=   2.0s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7194799449885727, total=   2.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7233966325426893, total=   2.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7397012993381731, total=   2.2s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7369431862597071, total=   2.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7890744709242321, total=   2.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7174973044650194, total=   2.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7198864632305905, total=   2.2s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7494867760789095, total=   3.3s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7325835434169372, total=   3.4s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7991469983980578, total=   3.3s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7226740586690906, total=   3.4s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7216717811919983, total=   3.4s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7487770435984751, total=   3.5s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7330375830969063, total=   3.5s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7975796905296982, total=   3.4s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7222503677852579, total=   3.4s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7095453234854497, total=   3.5s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7400927184551788, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7051763260749899, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7863782256378044, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000, score=0.6903610883360561, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000, score=0.709880163506944, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7238648057886273, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7015505815972904, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000, score=0.771189774211563, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000, score=0.6774645909887353, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000, score=0.6983061932376536, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7346831372833165, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000, score=0.6977042165981303, total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7876122507583366, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000, score=0.690826704359533, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7044378218776257, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000, score=0.7191456328307622, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000, score=0.6950523653128976, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000, score=0.770112856119971, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000, score=0.6671644457002963, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000, score=0.6967486575476491, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7239935260934496, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000, score=0.6968332954089733, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7912071424581322, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000, score=0.6787669355629476, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7036425895595, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000, score=0.7107280285375973, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000, score=0.6906934320836046, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000, score=0.7684853436032557, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000, score=0.6733068186415727, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000, score=0.6881659954174325, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000, score=0.73062496919834, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7112315806878475, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7889885476586568, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000, score=0.6938845522487078, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7078837587072513, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7355003080703729, total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7127437181038732, total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7818553463982422, total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000, score=0.6858339349017537, total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7021546186806401, total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7417695496650021, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7099484489978046, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7923173090695046, total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000, score=0.6985217244130694, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7017796878802254, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7366849469695127, total=   1.8s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000, score=0.710631893814357, total=   1.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7701324326286275, total=   1.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000, score=0.6971844661677287, total=   1.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000, score=0.710067350050307, total=   1.8s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7378688585097068, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000, score=0.723908544033475, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7861375811253967, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7083898379004534, total=   1.5s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7020346355186942, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7436745379932068, total=   3.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000, score=0.721390374669193, total=   3.1s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7899364619877614, total=   2.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7023376993387401, total=   2.8s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7078778010172415, total=   2.9s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7332085221187111, total=   0.8s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7260121075747383, total=   0.8s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7757299189069455, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7071261929320487, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7061625505249256, total=   0.8s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7394025958553498, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7376728682711406, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7813160199839769, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000, score=0.699058564582554, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7095696708273942, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7501109680043165, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7320737587546198, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7871169906244867, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7234201757710497, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7194652481909605, total=   1.5s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7418655595748486, total=   1.5s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7244626202046608, total=   1.5s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7834005945928676, total=   1.5s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7241832829411852, total=   1.5s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7227272210830801, total=   1.5s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7453695426305416, total=   2.2s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7308966989776801, total=   2.3s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7894149280812881, total=   2.2s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7252913188700597, total=   2.2s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7107156873553534, total=   2.3s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7499877423621176, total=   2.3s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7295974357531997, total=   2.4s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000, score=0.8033482037577244, total=   2.4s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000, score=0.708724944503413, total=   2.4s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7096245120460201, total=   2.3s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7245899828276123, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7213787716744793, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000, score=0.771114043249621, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000, score=0.6951395793983591, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000, score=0.6866123757502176, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7083380746262937, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7218458017159783, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7729539221198265, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000, score=0.6786220787087511, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000, score=0.6924059206715347, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7461429399331911, total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7335854835740997, total=   1.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7882061664132022, total=   1.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000, score=0.715496985489933, total=   1.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7125187406617058, total=   1.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7351299096149566, total=   1.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7332982267329171, total=   1.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7847242825214382, total=   1.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7182262515857962, total=   1.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7061579918019316, total=   1.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7342673085994973, total=   1.8s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7324242118013593, total=   1.8s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7848016999949579, total=   1.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7116218347626846, total=   1.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7100725360014587, total=   1.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7420754701332148, total=   1.8s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7149834059138893, total=   1.8s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7906294839563833, total=   1.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7086771799125724, total=   1.8s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7012909195205025, total=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed: 11.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'learning_rate': [0.01, 0.05, 0.1], 'n_estimators': [1000, 2000], 'max_depth': [3, 5, 7, 10], 'max_features': [0.1, 0.3, 0.5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'learning_rate':[0.01,0.05,0.1], 'n_estimators':[1000,2000],'max_depth':[3,5,7,10],'max_features':[0.1,0.3,0.5]}\n",
    "\n",
    "clf = GridSearchCV(GradientBoostingRegressor(), parameters, cv=5,verbose=3)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.01, loss='ls', max_depth=3, max_features=0.5,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=1000, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>points_ly</th>\n",
       "      <th>change_points_ly</th>\n",
       "      <th>starter_change</th>\n",
       "      <th>C_PF</th>\n",
       "      <th>PG</th>\n",
       "      <th>SG_SF</th>\n",
       "      <th>high_usageplayer_added</th>\n",
       "      <th>usagemin_opened</th>\n",
       "      <th>maxusage_added</th>\n",
       "      <th>...</th>\n",
       "      <th>per_ly</th>\n",
       "      <th>change_per</th>\n",
       "      <th>usagerank</th>\n",
       "      <th>usagerank_ly</th>\n",
       "      <th>offensive_winshares</th>\n",
       "      <th>offensive_boxplusminus</th>\n",
       "      <th>boxplusminus</th>\n",
       "      <th>value_overreplacement</th>\n",
       "      <th>career_points</th>\n",
       "      <th>yearspro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>24</td>\n",
       "      <td>16.4</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>868.379858</td>\n",
       "      <td>673.950617</td>\n",
       "      <td>...</td>\n",
       "      <td>14.6</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>15.366667</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>26</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-152.301781</td>\n",
       "      <td>993.128302</td>\n",
       "      <td>...</td>\n",
       "      <td>17.8</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.333333</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>22</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-98.010991</td>\n",
       "      <td>428.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>16.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>25</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-6.7</td>\n",
       "      <td>-7.7</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3157</th>\n",
       "      <td>35</td>\n",
       "      <td>3.7</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-290.057346</td>\n",
       "      <td>1068.484507</td>\n",
       "      <td>...</td>\n",
       "      <td>10.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.742857</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  points_ly  change_points_ly  starter_change  C_PF  PG  SG_SF  \\\n",
       "1879   24       16.4              -1.1               0     0   0      1   \n",
       "1626   26       10.0              -1.9               1     1   0      0   \n",
       "1705   22        6.3               0.0               0     1   0      0   \n",
       "1194   25        0.6               0.0               0     1   0      0   \n",
       "3157   35        3.7              -0.5               0     1   0      0   \n",
       "\n",
       "      high_usageplayer_added  usagemin_opened  maxusage_added    ...     \\\n",
       "1879                     0.0       868.379858      673.950617    ...      \n",
       "1626                     0.0      -152.301781      993.128302    ...      \n",
       "1705                     0.0       -98.010991      428.000000    ...      \n",
       "1194                     0.0         0.000000        0.000000    ...      \n",
       "3157                     1.0      -290.057346     1068.484507    ...      \n",
       "\n",
       "      per_ly  change_per  usagerank  usagerank_ly  offensive_winshares  \\\n",
       "1879    14.6        -0.9       18.0          51.0                  2.1   \n",
       "1626    17.8        -2.7       13.0           6.0                  2.7   \n",
       "1705    16.7         0.0        1.0          10.0                  1.7   \n",
       "1194     2.1         0.0        2.0           3.0                 -0.1   \n",
       "3157    10.1         1.1        1.0           1.0                  1.3   \n",
       "\n",
       "      offensive_boxplusminus  boxplusminus  value_overreplacement  \\\n",
       "1879                    -0.1          -0.5                    0.9   \n",
       "1626                    -1.5           0.0                    1.0   \n",
       "1705                     0.0           0.5                    0.5   \n",
       "1194                    -6.7          -7.7                   -0.1   \n",
       "3157                    -0.2          -0.9                    0.3   \n",
       "\n",
       "      career_points  yearspro  \n",
       "1879      15.366667         3  \n",
       "1626       7.333333         3  \n",
       "1705       6.300000         1  \n",
       "1194       0.600000         1  \n",
       "3157       5.742857         7  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1564/1564 [==============================] - 4s 3ms/step - loss: 2559.6664\n",
      "Epoch 2/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 684.8111\n",
      "Epoch 3/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 250.3355\n",
      "Epoch 4/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 138.5952\n",
      "Epoch 5/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 92.8092\n",
      "Epoch 6/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 73.9737\n",
      "Epoch 7/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 63.3565\n",
      "Epoch 8/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 58.7542\n",
      "Epoch 9/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 55.6189\n",
      "Epoch 10/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 52.7347\n",
      "Epoch 11/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 50.4796\n",
      "Epoch 12/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 48.3650\n",
      "Epoch 13/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 45.8848\n",
      "Epoch 14/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 44.2027\n",
      "Epoch 15/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 42.3113\n",
      "Epoch 16/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 40.7865\n",
      "Epoch 17/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 39.4311\n",
      "Epoch 18/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 38.2998\n",
      "Epoch 19/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 37.3143\n",
      "Epoch 20/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 36.0316\n",
      "Epoch 21/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 34.8391\n",
      "Epoch 22/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 33.6242\n",
      "Epoch 23/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 32.4294\n",
      "Epoch 24/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 31.0633\n",
      "Epoch 25/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 30.1015\n",
      "Epoch 26/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 29.1176\n",
      "Epoch 27/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 28.2327\n",
      "Epoch 28/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 27.7620\n",
      "Epoch 29/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 26.9992\n",
      "Epoch 30/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 26.4935\n",
      "Epoch 31/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 26.0301\n",
      "Epoch 32/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 25.5234\n",
      "Epoch 33/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 25.0617\n",
      "Epoch 34/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 24.7025\n",
      "Epoch 35/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 24.2245\n",
      "Epoch 36/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 23.8920\n",
      "Epoch 37/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 23.4843\n",
      "Epoch 38/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 23.1686\n",
      "Epoch 39/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 22.9395\n",
      "Epoch 40/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 22.5037\n",
      "Epoch 41/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 22.2840\n",
      "Epoch 42/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 21.8486\n",
      "Epoch 43/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 21.6446\n",
      "Epoch 44/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 21.4716\n",
      "Epoch 45/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 21.2008\n",
      "Epoch 46/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 21.0389\n",
      "Epoch 47/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 20.6456\n",
      "Epoch 48/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 20.3357\n",
      "Epoch 49/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 20.2618\n",
      "Epoch 50/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 20.0440\n",
      "Epoch 51/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 19.8892\n",
      "Epoch 52/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 19.4320\n",
      "Epoch 53/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 19.2503\n",
      "Epoch 54/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 19.0597\n",
      "Epoch 55/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 18.8636\n",
      "Epoch 56/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 18.4904\n",
      "Epoch 57/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 17.6848\n",
      "Epoch 58/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 16.7175\n",
      "Epoch 59/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 15.5902\n",
      "Epoch 60/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 14.5363\n",
      "Epoch 61/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 14.0603\n",
      "Epoch 62/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 13.6305\n",
      "Epoch 63/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 13.3437\n",
      "Epoch 64/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 13.0273\n",
      "Epoch 65/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 12.8522\n",
      "Epoch 66/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 12.7256\n",
      "Epoch 67/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 12.5023\n",
      "Epoch 68/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 12.4268\n",
      "Epoch 69/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 12.3664\n",
      "Epoch 70/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 12.2050\n",
      "Epoch 71/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 12.1975\n",
      "Epoch 72/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 11.9342\n",
      "Epoch 73/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 11.8921\n",
      "Epoch 74/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 11.7785\n",
      "Epoch 75/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 11.6379\n",
      "Epoch 76/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 11.8061\n",
      "Epoch 77/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 11.8132\n",
      "Epoch 78/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 11.5451\n",
      "Epoch 79/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 11.3852\n",
      "Epoch 80/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 11.3735\n",
      "Epoch 81/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 11.2236\n",
      "Epoch 82/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 11.2013\n",
      "Epoch 83/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 11.0496\n",
      "Epoch 84/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 11.0619\n",
      "Epoch 85/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 11.0468\n",
      "Epoch 86/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 11.2043\n",
      "Epoch 87/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 10.8819\n",
      "Epoch 88/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 10.9796\n",
      "Epoch 89/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 11.1609\n",
      "Epoch 90/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 10.7930\n",
      "Epoch 91/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 10.7846\n",
      "Epoch 92/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 10.5687\n",
      "Epoch 93/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 10.8001\n",
      "Epoch 94/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 10.5310\n",
      "Epoch 95/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 10.5081\n",
      "Epoch 96/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 10.5517\n",
      "Epoch 97/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 10.4216\n",
      "Epoch 98/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 10.3056\n",
      "Epoch 99/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 10.2957\n",
      "Epoch 100/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 10.2202\n",
      "Epoch 101/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 10.3165\n",
      "Epoch 102/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 10.5117\n",
      "Epoch 103/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 10.3604\n",
      "Epoch 104/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 10.3806\n",
      "Epoch 105/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 10.3487\n",
      "Epoch 106/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 9.9973\n",
      "Epoch 107/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 10.1103\n",
      "Epoch 108/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 10.0691\n",
      "Epoch 109/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 9.9896\n",
      "Epoch 110/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 9.9073\n",
      "Epoch 111/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 10.0205\n",
      "Epoch 112/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 9.8633\n",
      "Epoch 113/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 9.7811\n",
      "Epoch 114/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 9.8931\n",
      "Epoch 115/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 9.9155\n",
      "Epoch 116/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 9.6788\n",
      "Epoch 117/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 9.7028\n",
      "Epoch 118/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 9.7159\n",
      "Epoch 119/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 9.6875\n",
      "Epoch 120/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 9.6710\n",
      "Epoch 121/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 9.5117\n",
      "Epoch 122/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 9.5687\n",
      "Epoch 123/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 9.4092\n",
      "Epoch 124/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 9.3256\n",
      "Epoch 125/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 9.3098\n",
      "Epoch 126/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 9.3429\n",
      "Epoch 127/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 9.3610\n",
      "Epoch 128/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 9.3101\n",
      "Epoch 129/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 9.4091\n",
      "Epoch 130/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 9.3462\n",
      "Epoch 131/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 9.4373\n",
      "Epoch 132/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 9.1214\n",
      "Epoch 133/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 9.1222\n",
      "Epoch 134/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 9.0632\n",
      "Epoch 135/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 9.1303\n",
      "Epoch 136/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 9.0145\n",
      "Epoch 137/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 9.0639\n",
      "Epoch 138/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 9.2496\n",
      "Epoch 139/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 9.1130\n",
      "Epoch 140/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 9.1018\n",
      "Epoch 141/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 9.2035\n",
      "Epoch 142/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 9.0543\n",
      "Epoch 143/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 8.9911\n",
      "Epoch 144/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 8.9613\n",
      "Epoch 145/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 8.8719\n",
      "Epoch 146/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 8.7657\n",
      "Epoch 147/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 8.9895\n",
      "Epoch 148/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 8.8818\n",
      "Epoch 149/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 8.8544\n",
      "Epoch 150/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 8.7053\n",
      "Epoch 151/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 8.7841\n",
      "Epoch 152/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.8078\n",
      "Epoch 153/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 8.6949\n",
      "Epoch 154/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 9.0959\n",
      "Epoch 155/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 9.8717\n",
      "Epoch 156/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 9.1640\n",
      "Epoch 157/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 8.8878\n",
      "Epoch 158/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 8.7096\n",
      "Epoch 159/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 8.6474\n",
      "Epoch 160/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 9.0197\n",
      "Epoch 161/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 8.4850\n",
      "Epoch 162/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 8.5912\n",
      "Epoch 163/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 8.4521\n",
      "Epoch 164/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 8.3459\n",
      "Epoch 165/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 8.3887\n",
      "Epoch 166/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 8.3374\n",
      "Epoch 167/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 8.3324\n",
      "Epoch 168/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 8.3076\n",
      "Epoch 169/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 8.3211\n",
      "Epoch 170/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 8.5371\n",
      "Epoch 171/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 8.5413\n",
      "Epoch 172/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 8.7257\n",
      "Epoch 173/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 8.4569\n",
      "Epoch 174/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 8.1851\n",
      "Epoch 175/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 8.1729\n",
      "Epoch 176/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 8.4033\n",
      "Epoch 177/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 8.9064\n",
      "Epoch 178/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 8.4427\n",
      "Epoch 179/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 8.1072\n",
      "Epoch 180/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 8.6176\n",
      "Epoch 181/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 8.2061\n",
      "Epoch 182/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 8.4956\n",
      "Epoch 183/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 8.2020\n",
      "Epoch 184/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 8.2496\n",
      "Epoch 185/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 8.2653\n",
      "Epoch 186/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 8.4319\n",
      "Epoch 187/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 8.2155\n",
      "Epoch 188/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.9516\n",
      "Epoch 189/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 8.0109\n",
      "Epoch 190/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 8.0114\n",
      "Epoch 191/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 8.0879\n",
      "Epoch 192/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.9344\n",
      "Epoch 193/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 8.2126\n",
      "Epoch 194/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 8.0031\n",
      "Epoch 195/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 8.0989\n",
      "Epoch 196/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 7.9800\n",
      "Epoch 197/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.0503\n",
      "Epoch 198/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 8.2893\n",
      "Epoch 199/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 8.2812\n",
      "Epoch 200/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 8.2693\n",
      "Epoch 201/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 8.1951\n",
      "Epoch 202/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 8.1496\n",
      "Epoch 203/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.9485\n",
      "Epoch 204/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.7382\n",
      "Epoch 205/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 8.0156\n",
      "Epoch 206/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 8.1739\n",
      "Epoch 207/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 8.0254\n",
      "Epoch 208/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.9769\n",
      "Epoch 209/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.8060\n",
      "Epoch 210/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 7.8586\n",
      "Epoch 211/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.6477\n",
      "Epoch 212/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.9730\n",
      "Epoch 213/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 7.8473\n",
      "Epoch 214/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 8.1471\n",
      "Epoch 215/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 8.0762\n",
      "Epoch 216/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 7.8035\n",
      "Epoch 217/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.7215\n",
      "Epoch 218/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 8.0793\n",
      "Epoch 219/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 8.0500\n",
      "Epoch 220/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 7.9725\n",
      "Epoch 221/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 8.0060\n",
      "Epoch 222/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 7.8432\n",
      "Epoch 223/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.8895\n",
      "Epoch 224/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.5874\n",
      "Epoch 225/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 7.5382\n",
      "Epoch 226/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.9953\n",
      "Epoch 227/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 8.1062\n",
      "Epoch 228/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 8.1261\n",
      "Epoch 229/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.6640\n",
      "Epoch 230/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.5769\n",
      "Epoch 231/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.6277\n",
      "Epoch 232/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 7.7601\n",
      "Epoch 233/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 8.1126\n",
      "Epoch 234/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 7.8583\n",
      "Epoch 235/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 7.7013\n",
      "Epoch 236/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.4934\n",
      "Epoch 237/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.3639\n",
      "Epoch 238/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 7.4112\n",
      "Epoch 239/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 7.3217\n",
      "Epoch 240/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.5937\n",
      "Epoch 241/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 7.4658\n",
      "Epoch 242/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.3998\n",
      "Epoch 243/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.6674\n",
      "Epoch 244/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 7.4126\n",
      "Epoch 245/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.4016\n",
      "Epoch 246/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.4051\n",
      "Epoch 247/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 7.4270\n",
      "Epoch 248/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 8.4809\n",
      "Epoch 249/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.8127\n",
      "Epoch 250/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.5003\n",
      "Epoch 251/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.5532\n",
      "Epoch 252/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.5374\n",
      "Epoch 253/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 7.3672\n",
      "Epoch 254/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 7.5069\n",
      "Epoch 255/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.5661\n",
      "Epoch 256/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.5451\n",
      "Epoch 257/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.3073\n",
      "Epoch 258/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.3842\n",
      "Epoch 259/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.6316\n",
      "Epoch 260/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.4128\n",
      "Epoch 261/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 7.5108\n",
      "Epoch 262/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 7.6941\n",
      "Epoch 263/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 7.5436\n",
      "Epoch 264/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 7.6617\n",
      "Epoch 265/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 8.7764\n",
      "Epoch 266/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 8.2130\n",
      "Epoch 267/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 7.5237\n",
      "Epoch 268/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.6067\n",
      "Epoch 269/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.3223\n",
      "Epoch 270/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.0852\n",
      "Epoch 271/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 7.3260\n",
      "Epoch 272/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.1208\n",
      "Epoch 273/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.2470\n",
      "Epoch 274/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.2496\n",
      "Epoch 275/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 7.3498\n",
      "Epoch 276/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 7.2738\n",
      "Epoch 277/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.6970\n",
      "Epoch 278/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 7.5155\n",
      "Epoch 279/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.3427\n",
      "Epoch 280/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.4281\n",
      "Epoch 281/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.1731\n",
      "Epoch 282/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.4200\n",
      "Epoch 283/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.4270\n",
      "Epoch 284/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.2668\n",
      "Epoch 285/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 7.1855\n",
      "Epoch 286/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 7.3385\n",
      "Epoch 287/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.1294\n",
      "Epoch 288/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 7.0773\n",
      "Epoch 289/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 7.5599\n",
      "Epoch 290/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.5003\n",
      "Epoch 291/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 7.2939\n",
      "Epoch 292/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 7.0736\n",
      "Epoch 293/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.0672\n",
      "Epoch 294/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.2582\n",
      "Epoch 295/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.1998\n",
      "Epoch 296/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 7.3823\n",
      "Epoch 297/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.6666\n",
      "Epoch 298/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.1696\n",
      "Epoch 299/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.0156\n",
      "Epoch 300/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.0720\n",
      "Epoch 301/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.0317\n",
      "Epoch 302/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 7.2105\n",
      "Epoch 303/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.2211\n",
      "Epoch 304/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.2429\n",
      "Epoch 305/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.3859\n",
      "Epoch 306/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 7.2646\n",
      "Epoch 307/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 7.1573\n",
      "Epoch 308/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 7.3328\n",
      "Epoch 309/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.0900\n",
      "Epoch 310/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 7.1158\n",
      "Epoch 311/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 7.5840\n",
      "Epoch 312/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.0634\n",
      "Epoch 313/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.2113\n",
      "Epoch 314/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 6.9697\n",
      "Epoch 315/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 7.0468\n",
      "Epoch 316/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.9180\n",
      "Epoch 317/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 7.0184\n",
      "Epoch 318/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.2885\n",
      "Epoch 319/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.9833\n",
      "Epoch 320/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 6.8840\n",
      "Epoch 321/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.1533\n",
      "Epoch 322/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.0200\n",
      "Epoch 323/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 7.0250\n",
      "Epoch 324/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.0109\n",
      "Epoch 325/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.1585\n",
      "Epoch 326/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.1617\n",
      "Epoch 327/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.0923\n",
      "Epoch 328/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 7.4245\n",
      "Epoch 329/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.5132\n",
      "Epoch 330/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.3573\n",
      "Epoch 331/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.4910\n",
      "Epoch 332/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.2595\n",
      "Epoch 333/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.6177\n",
      "Epoch 334/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.1211\n",
      "Epoch 335/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.3187\n",
      "Epoch 336/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 7.1414\n",
      "Epoch 337/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.4065\n",
      "Epoch 338/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.0530\n",
      "Epoch 339/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.1316\n",
      "Epoch 340/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.3593\n",
      "Epoch 341/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.3310\n",
      "Epoch 342/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.1860\n",
      "Epoch 343/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.3690\n",
      "Epoch 344/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.1402\n",
      "Epoch 345/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.3430\n",
      "Epoch 346/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.3640\n",
      "Epoch 347/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.3330\n",
      "Epoch 348/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.0154\n",
      "Epoch 349/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.9194\n",
      "Epoch 350/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.8226\n",
      "Epoch 351/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.8284\n",
      "Epoch 352/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.9380\n",
      "Epoch 353/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.9609\n",
      "Epoch 354/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.0907\n",
      "Epoch 355/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.9805\n",
      "Epoch 356/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 6.9402\n",
      "Epoch 357/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.8627\n",
      "Epoch 358/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.0681\n",
      "Epoch 359/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.9671\n",
      "Epoch 360/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.1339\n",
      "Epoch 361/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.9045\n",
      "Epoch 362/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.1272\n",
      "Epoch 363/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 7.0699\n",
      "Epoch 364/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.2552\n",
      "Epoch 365/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.1545\n",
      "Epoch 366/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.5878\n",
      "Epoch 367/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.9925\n",
      "Epoch 368/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.1783\n",
      "Epoch 369/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.0719\n",
      "Epoch 370/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.4069\n",
      "Epoch 371/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.0113\n",
      "Epoch 372/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.8737\n",
      "Epoch 373/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.1798\n",
      "Epoch 374/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 7.0693\n",
      "Epoch 375/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.9595\n",
      "Epoch 376/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.9960\n",
      "Epoch 377/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.7591\n",
      "Epoch 378/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.8183\n",
      "Epoch 379/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.9008\n",
      "Epoch 380/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 6.8260\n",
      "Epoch 381/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.9305\n",
      "Epoch 382/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.1194\n",
      "Epoch 383/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.7821\n",
      "Epoch 384/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.9946\n",
      "Epoch 385/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.4295\n",
      "Epoch 386/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 7.2697\n",
      "Epoch 387/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.4740\n",
      "Epoch 388/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.9877\n",
      "Epoch 389/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.2553\n",
      "Epoch 390/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 7.2099\n",
      "Epoch 391/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.7634\n",
      "Epoch 392/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.7927\n",
      "Epoch 393/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.8454\n",
      "Epoch 394/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.1982\n",
      "Epoch 395/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 7.5854\n",
      "Epoch 396/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.9832\n",
      "Epoch 397/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.1101\n",
      "Epoch 398/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.9249\n",
      "Epoch 399/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.8646\n",
      "Epoch 400/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.7662\n",
      "Epoch 401/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.8234\n",
      "Epoch 402/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.8772\n",
      "Epoch 403/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.7257\n",
      "Epoch 404/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.0410\n",
      "Epoch 405/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.8637\n",
      "Epoch 406/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.1112\n",
      "Epoch 407/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.0513\n",
      "Epoch 408/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.3589\n",
      "Epoch 409/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.0728\n",
      "Epoch 410/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.6755\n",
      "Epoch 411/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.3731\n",
      "Epoch 412/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.1862\n",
      "Epoch 413/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 7.0985\n",
      "Epoch 414/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.1497\n",
      "Epoch 415/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 7.1641\n",
      "Epoch 416/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.7980\n",
      "Epoch 417/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.7830\n",
      "Epoch 418/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.2165\n",
      "Epoch 419/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.9397\n",
      "Epoch 420/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.9263\n",
      "Epoch 421/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.7806\n",
      "Epoch 422/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.8408\n",
      "Epoch 423/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.8536\n",
      "Epoch 424/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.7655\n",
      "Epoch 425/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.8037\n",
      "Epoch 426/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.6679\n",
      "Epoch 427/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.8634\n",
      "Epoch 428/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 6.8291\n",
      "Epoch 429/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.7913\n",
      "Epoch 430/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 7.0143\n",
      "Epoch 431/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.8344\n",
      "Epoch 432/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.6913\n",
      "Epoch 433/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.7723\n",
      "Epoch 434/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.8876\n",
      "Epoch 435/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.8880\n",
      "Epoch 436/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.7611\n",
      "Epoch 437/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.7601\n",
      "Epoch 438/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.6439\n",
      "Epoch 439/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.0198\n",
      "Epoch 440/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.8258\n",
      "Epoch 441/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.2106\n",
      "Epoch 442/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 7.6943\n",
      "Epoch 443/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 6.9242\n",
      "Epoch 444/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.6397\n",
      "Epoch 445/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.7915\n",
      "Epoch 446/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.8446\n",
      "Epoch 447/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.2527\n",
      "Epoch 448/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.0415\n",
      "Epoch 449/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.2237\n",
      "Epoch 450/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.1152\n",
      "Epoch 451/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.6351\n",
      "Epoch 452/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.7051\n",
      "Epoch 453/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.7521\n",
      "Epoch 454/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.0631\n",
      "Epoch 455/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.2694\n",
      "Epoch 456/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.0106\n",
      "Epoch 457/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.9197\n",
      "Epoch 458/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 6.6696\n",
      "Epoch 459/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.6838\n",
      "Epoch 460/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 6.9091\n",
      "Epoch 461/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.7219\n",
      "Epoch 462/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.7911\n",
      "Epoch 463/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.8806\n",
      "Epoch 464/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.1668\n",
      "Epoch 465/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.9338\n",
      "Epoch 466/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.3691\n",
      "Epoch 467/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.7157\n",
      "Epoch 468/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.0989\n",
      "Epoch 469/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.6753\n",
      "Epoch 470/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.8136\n",
      "Epoch 471/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.9253\n",
      "Epoch 472/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.7171\n",
      "Epoch 473/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.7968\n",
      "Epoch 474/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.9713\n",
      "Epoch 475/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.8082\n",
      "Epoch 476/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.6774\n",
      "Epoch 477/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.6604\n",
      "Epoch 478/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.7010\n",
      "Epoch 479/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.8040\n",
      "Epoch 480/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.9252\n",
      "Epoch 481/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.7317\n",
      "Epoch 482/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.6241\n",
      "Epoch 483/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.5973\n",
      "Epoch 484/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.9424\n",
      "Epoch 485/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.6190\n",
      "Epoch 486/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.5619\n",
      "Epoch 487/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.4885\n",
      "Epoch 488/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.6588\n",
      "Epoch 489/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.8970\n",
      "Epoch 490/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.5848\n",
      "Epoch 491/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.2824\n",
      "Epoch 492/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 7.0622\n",
      "Epoch 493/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.7472\n",
      "Epoch 494/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.8806\n",
      "Epoch 495/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.8108\n",
      "Epoch 496/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.8052\n",
      "Epoch 497/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.6180\n",
      "Epoch 498/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.5997\n",
      "Epoch 499/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.8200\n",
      "Epoch 500/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.8332\n",
      "Epoch 501/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.0473\n",
      "Epoch 502/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.0683\n",
      "Epoch 503/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.8336\n",
      "Epoch 504/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.0551\n",
      "Epoch 505/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 7.2154\n",
      "Epoch 506/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.5008\n",
      "Epoch 507/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 7.3825\n",
      "Epoch 508/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.9916\n",
      "Epoch 509/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.8542\n",
      "Epoch 510/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.2454\n",
      "Epoch 511/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.7401\n",
      "Epoch 512/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.0920\n",
      "Epoch 513/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.8297\n",
      "Epoch 514/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.6288\n",
      "Epoch 515/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.7279\n",
      "Epoch 516/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.6917\n",
      "Epoch 517/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.8420\n",
      "Epoch 518/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 7.1254\n",
      "Epoch 519/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.8275\n",
      "Epoch 520/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.5851\n",
      "Epoch 521/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.8180\n",
      "Epoch 522/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.7440\n",
      "Epoch 523/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.1373\n",
      "Epoch 524/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.0447\n",
      "Epoch 525/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.7784\n",
      "Epoch 526/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.9678\n",
      "Epoch 527/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.8004\n",
      "Epoch 528/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.5774\n",
      "Epoch 529/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.0224\n",
      "Epoch 530/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.8125\n",
      "Epoch 531/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.5979\n",
      "Epoch 532/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.1432\n",
      "Epoch 533/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.7685\n",
      "Epoch 534/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.9057\n",
      "Epoch 535/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.7529\n",
      "Epoch 536/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.6958\n",
      "Epoch 537/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.7662\n",
      "Epoch 538/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.2416\n",
      "Epoch 539/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.9685\n",
      "Epoch 540/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.7234\n",
      "Epoch 541/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.6116\n",
      "Epoch 542/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.9043\n",
      "Epoch 543/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.6495\n",
      "Epoch 544/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.7083\n",
      "Epoch 545/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.0314\n",
      "Epoch 546/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.7433\n",
      "Epoch 547/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.5363\n",
      "Epoch 548/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.8343\n",
      "Epoch 549/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 7.2059\n",
      "Epoch 550/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.0629\n",
      "Epoch 551/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.6816\n",
      "Epoch 552/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.2640\n",
      "Epoch 553/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.5549\n",
      "Epoch 554/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.6111\n",
      "Epoch 555/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 6.5993\n",
      "Epoch 556/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.9445\n",
      "Epoch 557/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.0995\n",
      "Epoch 558/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.7909\n",
      "Epoch 559/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.7305\n",
      "Epoch 560/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.7286\n",
      "Epoch 561/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.7012\n",
      "Epoch 562/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.6913\n",
      "Epoch 563/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.8464\n",
      "Epoch 564/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.0708\n",
      "Epoch 565/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.7886\n",
      "Epoch 566/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.5831\n",
      "Epoch 567/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.6572\n",
      "Epoch 568/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.7121\n",
      "Epoch 569/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.6458\n",
      "Epoch 570/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.5558\n",
      "Epoch 571/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.5939\n",
      "Epoch 572/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.9747\n",
      "Epoch 573/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 7.0704\n",
      "Epoch 574/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.8089\n",
      "Epoch 575/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.5588\n",
      "Epoch 576/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.8217\n",
      "Epoch 577/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.8281\n",
      "Epoch 578/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.7292\n",
      "Epoch 579/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.6829\n",
      "Epoch 580/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.2194\n",
      "Epoch 581/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 7.1059\n",
      "Epoch 582/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.8291\n",
      "Epoch 583/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.6880\n",
      "Epoch 584/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.7693\n",
      "Epoch 585/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.7983\n",
      "Epoch 586/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.5114\n",
      "Epoch 587/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.6728\n",
      "Epoch 588/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.7142\n",
      "Epoch 589/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.7658\n",
      "Epoch 590/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.2511\n",
      "Epoch 591/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.7284\n",
      "Epoch 592/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.5400\n",
      "Epoch 593/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.6990\n",
      "Epoch 594/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.5850\n",
      "Epoch 595/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.9036\n",
      "Epoch 596/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.6959\n",
      "Epoch 597/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.9093\n",
      "Epoch 598/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.5815\n",
      "Epoch 599/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.5947\n",
      "Epoch 600/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.8803\n",
      "Epoch 601/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.9787\n",
      "Epoch 602/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.8058\n",
      "Epoch 603/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.6983\n",
      "Epoch 604/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.5508\n",
      "Epoch 605/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.7152\n",
      "Epoch 606/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.5685\n",
      "Epoch 607/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.5376\n",
      "Epoch 608/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.9245\n",
      "Epoch 609/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 6.7633\n",
      "Epoch 610/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 6.7749\n",
      "Epoch 611/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 6.7866\n",
      "Epoch 612/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 6.7680\n",
      "Epoch 613/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 6.5403\n",
      "Epoch 614/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.4592\n",
      "Epoch 615/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.5119\n",
      "Epoch 616/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.5322\n",
      "Epoch 617/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.5337\n",
      "Epoch 618/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 6.7864\n",
      "Epoch 619/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 6.5017\n",
      "Epoch 620/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 6.4304\n",
      "Epoch 621/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 6.7972\n",
      "Epoch 622/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 7.0184\n",
      "Epoch 623/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 6.6484\n",
      "Epoch 624/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 6.7838\n",
      "Epoch 625/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.5291\n",
      "Epoch 626/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.8141\n",
      "Epoch 627/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 6.6788\n",
      "Epoch 628/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.9262\n",
      "Epoch 629/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.7977\n",
      "Epoch 630/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.6377\n",
      "Epoch 631/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.6610\n",
      "Epoch 632/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.3095\n",
      "Epoch 633/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.8442\n",
      "Epoch 634/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.4625\n",
      "Epoch 635/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.4881\n",
      "Epoch 636/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.6462\n",
      "Epoch 637/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.5315\n",
      "Epoch 638/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 6.4206\n",
      "Epoch 639/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 6.5883\n",
      "Epoch 640/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 7.5045\n",
      "Epoch 641/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 7.0523\n",
      "Epoch 642/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 6.8167\n",
      "Epoch 643/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 6.8831\n",
      "Epoch 644/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 6.6944\n",
      "Epoch 645/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 7.0511\n",
      "Epoch 646/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 7.0105\n",
      "Epoch 647/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 6.7096\n",
      "Epoch 648/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 6.5608\n",
      "Epoch 649/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 6.8967\n",
      "Epoch 650/1000\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 6.9535\n",
      "Epoch 651/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.6641\n",
      "Epoch 652/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.8233\n",
      "Epoch 653/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.4508\n",
      "Epoch 654/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.2431\n",
      "Epoch 655/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.8477\n",
      "Epoch 656/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 6.6267\n",
      "Epoch 657/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.5292\n",
      "Epoch 658/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.5711\n",
      "Epoch 659/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.5869\n",
      "Epoch 660/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.5031\n",
      "Epoch 661/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.5709\n",
      "Epoch 662/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.7203\n",
      "Epoch 663/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 6.7304\n",
      "Epoch 664/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 6.9814\n",
      "Epoch 665/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.7089\n",
      "Epoch 666/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.4079\n",
      "Epoch 667/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.2397\n",
      "Epoch 668/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 6.6165\n",
      "Epoch 669/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.5422\n",
      "Epoch 670/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.7096\n",
      "Epoch 671/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.6449\n",
      "Epoch 672/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.4659\n",
      "Epoch 673/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.6606\n",
      "Epoch 674/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.6477\n",
      "Epoch 675/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.5034\n",
      "Epoch 676/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.5548\n",
      "Epoch 677/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 6.4598\n",
      "Epoch 678/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 6.5495\n",
      "Epoch 679/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.4892\n",
      "Epoch 680/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.4895\n",
      "Epoch 681/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 6.9977\n",
      "Epoch 682/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 6.8670\n",
      "Epoch 683/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.6299\n",
      "Epoch 684/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 6.6360\n",
      "Epoch 685/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 6.6101\n",
      "Epoch 686/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.6835\n",
      "Epoch 687/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.6731\n",
      "Epoch 688/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.6834\n",
      "Epoch 689/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.5913\n",
      "Epoch 690/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.6706\n",
      "Epoch 691/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.5469\n",
      "Epoch 692/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 6.4152\n",
      "Epoch 693/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 6.9153\n",
      "Epoch 694/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.8604\n",
      "Epoch 695/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.6302\n",
      "Epoch 696/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.5568\n",
      "Epoch 697/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.7484\n",
      "Epoch 698/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.5164\n",
      "Epoch 699/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.6141\n",
      "Epoch 700/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.7026\n",
      "Epoch 701/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 6.6357\n",
      "Epoch 702/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 7.1317\n",
      "Epoch 703/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.6493\n",
      "Epoch 704/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.9697\n",
      "Epoch 705/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.6057\n",
      "Epoch 706/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.6687\n",
      "Epoch 707/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.4540\n",
      "Epoch 708/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 6.7671\n",
      "Epoch 709/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 6.8890\n",
      "Epoch 710/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.7306\n",
      "Epoch 711/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.6116\n",
      "Epoch 712/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.5891\n",
      "Epoch 713/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.6916\n",
      "Epoch 714/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.6397\n",
      "Epoch 715/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 6.8404\n",
      "Epoch 716/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.8585\n",
      "Epoch 717/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.8902\n",
      "Epoch 718/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.5385\n",
      "Epoch 719/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.6255\n",
      "Epoch 720/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.4186\n",
      "Epoch 721/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.5451\n",
      "Epoch 722/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.4565\n",
      "Epoch 723/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.6774\n",
      "Epoch 724/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.6168\n",
      "Epoch 725/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.7285\n",
      "Epoch 726/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.5472\n",
      "Epoch 727/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.6080\n",
      "Epoch 728/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.6648\n",
      "Epoch 729/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.8619\n",
      "Epoch 730/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.5547\n",
      "Epoch 731/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.5058\n",
      "Epoch 732/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.8317\n",
      "Epoch 733/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 6.5227\n",
      "Epoch 734/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.7226\n",
      "Epoch 735/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.6100\n",
      "Epoch 736/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.8002\n",
      "Epoch 737/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.6571\n",
      "Epoch 738/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 6.6054\n",
      "Epoch 739/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.4740\n",
      "Epoch 740/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.5631\n",
      "Epoch 741/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.5004\n",
      "Epoch 742/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 7.0715\n",
      "Epoch 743/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.0543\n",
      "Epoch 744/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.5793\n",
      "Epoch 745/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.4594\n",
      "Epoch 746/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.5109\n",
      "Epoch 747/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.4275\n",
      "Epoch 748/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.5981\n",
      "Epoch 749/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.4153\n",
      "Epoch 750/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.6546\n",
      "Epoch 751/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.7065\n",
      "Epoch 752/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.5859\n",
      "Epoch 753/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.6775\n",
      "Epoch 754/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.8498\n",
      "Epoch 755/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.8774\n",
      "Epoch 756/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.8526\n",
      "Epoch 757/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.7939\n",
      "Epoch 758/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.2066\n",
      "Epoch 759/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.4988\n",
      "Epoch 760/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.5078\n",
      "Epoch 761/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.6102\n",
      "Epoch 762/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.9376\n",
      "Epoch 763/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.4613\n",
      "Epoch 764/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.5691\n",
      "Epoch 765/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.8713\n",
      "Epoch 766/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.5893\n",
      "Epoch 767/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.0427\n",
      "Epoch 768/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.7982\n",
      "Epoch 769/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 7.2004\n",
      "Epoch 770/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.2501\n",
      "Epoch 771/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 6.6202\n",
      "Epoch 772/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 6.5192\n",
      "Epoch 773/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.7237\n",
      "Epoch 774/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.9207\n",
      "Epoch 775/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.5475\n",
      "Epoch 776/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.6848\n",
      "Epoch 777/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.7209\n",
      "Epoch 778/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.4721\n",
      "Epoch 779/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.5738\n",
      "Epoch 780/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.4062\n",
      "Epoch 781/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.4267\n",
      "Epoch 782/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.7224\n",
      "Epoch 783/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.0102\n",
      "Epoch 784/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.9008\n",
      "Epoch 785/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.5406\n",
      "Epoch 786/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 6.7338\n",
      "Epoch 787/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 6.5773\n",
      "Epoch 788/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.8301\n",
      "Epoch 789/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.6044\n",
      "Epoch 790/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.3020\n",
      "Epoch 791/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.4387\n",
      "Epoch 792/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.3560\n",
      "Epoch 793/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.4184\n",
      "Epoch 794/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.4370\n",
      "Epoch 795/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.3681\n",
      "Epoch 796/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.4372\n",
      "Epoch 797/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.4639\n",
      "Epoch 798/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.7965\n",
      "Epoch 799/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 6.7832\n",
      "Epoch 800/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.5189\n",
      "Epoch 801/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.6101\n",
      "Epoch 802/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.4515\n",
      "Epoch 803/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.8864\n",
      "Epoch 804/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 6.5747\n",
      "Epoch 805/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.5122\n",
      "Epoch 806/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.3614\n",
      "Epoch 807/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.4163\n",
      "Epoch 808/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.5086\n",
      "Epoch 809/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.4525\n",
      "Epoch 810/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.4015\n",
      "Epoch 811/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.2816\n",
      "Epoch 812/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.4492\n",
      "Epoch 813/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.5436\n",
      "Epoch 814/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.3415\n",
      "Epoch 815/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.5159\n",
      "Epoch 816/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.7728\n",
      "Epoch 817/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.6100\n",
      "Epoch 818/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.4463\n",
      "Epoch 819/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.5029\n",
      "Epoch 820/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.5593\n",
      "Epoch 821/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.4144\n",
      "Epoch 822/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.4506\n",
      "Epoch 823/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.7196\n",
      "Epoch 824/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.5312\n",
      "Epoch 825/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.5224\n",
      "Epoch 826/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.3267\n",
      "Epoch 827/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.3206\n",
      "Epoch 828/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.6183\n",
      "Epoch 829/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.7312\n",
      "Epoch 830/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.3764\n",
      "Epoch 831/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.6413\n",
      "Epoch 832/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.5841\n",
      "Epoch 833/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.4732\n",
      "Epoch 834/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.5052\n",
      "Epoch 835/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.4371\n",
      "Epoch 836/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.2625\n",
      "Epoch 837/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.4798\n",
      "Epoch 838/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.2705\n",
      "Epoch 839/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.3244\n",
      "Epoch 840/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.6115\n",
      "Epoch 841/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.3128\n",
      "Epoch 842/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.2849\n",
      "Epoch 843/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.4240\n",
      "Epoch 844/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.6010\n",
      "Epoch 845/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.5293\n",
      "Epoch 846/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.4999\n",
      "Epoch 847/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.7246\n",
      "Epoch 848/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.6699\n",
      "Epoch 849/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.5618\n",
      "Epoch 850/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.3647\n",
      "Epoch 851/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.3744\n",
      "Epoch 852/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.3931\n",
      "Epoch 853/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.4846\n",
      "Epoch 854/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.7612\n",
      "Epoch 855/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.5937\n",
      "Epoch 856/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.7710\n",
      "Epoch 857/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.2818\n",
      "Epoch 858/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.5537\n",
      "Epoch 859/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.4128\n",
      "Epoch 860/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.6098\n",
      "Epoch 861/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 6.4573\n",
      "Epoch 862/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 6.3824\n",
      "Epoch 863/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.6665\n",
      "Epoch 864/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 6.4745\n",
      "Epoch 865/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.0358\n",
      "Epoch 866/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.4741\n",
      "Epoch 867/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.6877\n",
      "Epoch 868/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.5494\n",
      "Epoch 869/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.3543\n",
      "Epoch 870/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.3808\n",
      "Epoch 871/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.4504\n",
      "Epoch 872/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.4500\n",
      "Epoch 873/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.5341\n",
      "Epoch 874/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.4556\n",
      "Epoch 875/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.5813\n",
      "Epoch 876/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.4946\n",
      "Epoch 877/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.4951\n",
      "Epoch 878/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.5279\n",
      "Epoch 879/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.7616\n",
      "Epoch 880/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.6728\n",
      "Epoch 881/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.4141\n",
      "Epoch 882/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.4718\n",
      "Epoch 883/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.3560\n",
      "Epoch 884/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.4013\n",
      "Epoch 885/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.3310\n",
      "Epoch 886/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.2581\n",
      "Epoch 887/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.5105\n",
      "Epoch 888/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.9211\n",
      "Epoch 889/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.3035\n",
      "Epoch 890/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.6682\n",
      "Epoch 891/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.4405\n",
      "Epoch 892/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.6130\n",
      "Epoch 893/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.2989\n",
      "Epoch 894/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.5413\n",
      "Epoch 895/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 6.5013\n",
      "Epoch 896/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.9023\n",
      "Epoch 897/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.4673\n",
      "Epoch 898/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.3379\n",
      "Epoch 899/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.5449\n",
      "Epoch 900/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.8981\n",
      "Epoch 901/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.4744\n",
      "Epoch 902/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.3337\n",
      "Epoch 903/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.8193\n",
      "Epoch 904/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.3469\n",
      "Epoch 905/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.9407\n",
      "Epoch 906/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.6918\n",
      "Epoch 907/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 6.2719\n",
      "Epoch 908/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.8709\n",
      "Epoch 909/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.4237\n",
      "Epoch 910/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.3603\n",
      "Epoch 911/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.2211\n",
      "Epoch 912/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 6.4020\n",
      "Epoch 913/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 6.3655\n",
      "Epoch 914/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.4426\n",
      "Epoch 915/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.5564\n",
      "Epoch 916/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.5318\n",
      "Epoch 917/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.5181\n",
      "Epoch 918/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.3709\n",
      "Epoch 919/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.5232\n",
      "Epoch 920/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.4142\n",
      "Epoch 921/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.6336\n",
      "Epoch 922/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.5027\n",
      "Epoch 923/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.3582\n",
      "Epoch 924/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.6224\n",
      "Epoch 925/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.0876\n",
      "Epoch 926/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.7340\n",
      "Epoch 927/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.5260\n",
      "Epoch 928/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.4152\n",
      "Epoch 929/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.3354\n",
      "Epoch 930/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.4982\n",
      "Epoch 931/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.2746\n",
      "Epoch 932/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.6918\n",
      "Epoch 933/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.8635\n",
      "Epoch 934/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.6068\n",
      "Epoch 935/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.4357\n",
      "Epoch 936/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.4836\n",
      "Epoch 937/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.4693\n",
      "Epoch 938/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.6631\n",
      "Epoch 939/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.6382\n",
      "Epoch 940/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.5545\n",
      "Epoch 941/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.5424\n",
      "Epoch 942/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.4621\n",
      "Epoch 943/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.4728\n",
      "Epoch 944/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.5199\n",
      "Epoch 945/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.3283\n",
      "Epoch 946/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.2021\n",
      "Epoch 947/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.2915\n",
      "Epoch 948/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.3792\n",
      "Epoch 949/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.3409\n",
      "Epoch 950/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.3702\n",
      "Epoch 951/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.2403\n",
      "Epoch 952/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.7655\n",
      "Epoch 953/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.4699\n",
      "Epoch 954/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.3182\n",
      "Epoch 955/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.4753\n",
      "Epoch 956/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 6.5746\n",
      "Epoch 957/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.3798\n",
      "Epoch 958/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.4110\n",
      "Epoch 959/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.2423\n",
      "Epoch 960/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.3460\n",
      "Epoch 961/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.3482\n",
      "Epoch 962/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.5430\n",
      "Epoch 963/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.5918\n",
      "Epoch 964/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 6.5617\n",
      "Epoch 965/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.4540\n",
      "Epoch 966/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.4592\n",
      "Epoch 967/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.2409\n",
      "Epoch 968/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.2431\n",
      "Epoch 969/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.2508\n",
      "Epoch 970/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.6552\n",
      "Epoch 971/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 6.2629\n",
      "Epoch 972/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.5340\n",
      "Epoch 973/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.2062\n",
      "Epoch 974/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.5309\n",
      "Epoch 975/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.3212\n",
      "Epoch 976/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.3508\n",
      "Epoch 977/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.3479\n",
      "Epoch 978/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.5074\n",
      "Epoch 979/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.2477\n",
      "Epoch 980/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.4493\n",
      "Epoch 981/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.3136\n",
      "Epoch 982/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.2259\n",
      "Epoch 983/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.4347\n",
      "Epoch 984/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.3993\n",
      "Epoch 985/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.2956\n",
      "Epoch 986/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.6106\n",
      "Epoch 987/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.2732\n",
      "Epoch 988/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.2638\n",
      "Epoch 989/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.5596\n",
      "Epoch 990/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.2087\n",
      "Epoch 991/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.1477\n",
      "Epoch 992/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.2748\n",
      "Epoch 993/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.4509\n",
      "Epoch 994/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.5031\n",
      "Epoch 995/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.4810\n",
      "Epoch 996/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.2674\n",
      "Epoch 997/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.4609\n",
      "Epoch 998/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.6157\n",
      "Epoch 999/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.1531\n",
      "Epoch 1000/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.3806\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a4d68c5c0>"
      ]
     },
     "execution_count": 1079,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=16,input_dim= X_train.shape[1],activation='relu'))\n",
    "#model.add(Dense(units=8, activation='relu'))\n",
    "#model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(units=8, activation='relu'))\n",
    "#model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(units=4, activation='relu'))\n",
    "#model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(units=1,activation='linear'))\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.fit(np.array(X_train), np.array(y_train), epochs=1000,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.5)\n",
    "gbr.fit(X_train,y_train)\n",
    "gbr_predictions = gbr.predict(X_test)\n",
    "LR = LinearRegression(fit_intercept=True).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN_predictions</th>\n",
       "      <th>actual</th>\n",
       "      <th>GBR_predictions</th>\n",
       "      <th>LY_scoring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.047908</td>\n",
       "      <td>10.1</td>\n",
       "      <td>9.918161</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.606041</td>\n",
       "      <td>17.5</td>\n",
       "      <td>15.898964</td>\n",
       "      <td>16.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.756142</td>\n",
       "      <td>6.7</td>\n",
       "      <td>4.895916</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.496284</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.902894</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.367739</td>\n",
       "      <td>18.9</td>\n",
       "      <td>20.560814</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.317717</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.288318</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.102070</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.591461</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9.474962</td>\n",
       "      <td>7.6</td>\n",
       "      <td>11.229569</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.580517</td>\n",
       "      <td>5.1</td>\n",
       "      <td>7.408105</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.848618</td>\n",
       "      <td>5.6</td>\n",
       "      <td>6.119970</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8.283195</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.969022</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13.983689</td>\n",
       "      <td>18.2</td>\n",
       "      <td>14.945651</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.391405</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.444453</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.213360</td>\n",
       "      <td>4.6</td>\n",
       "      <td>8.533099</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.300426</td>\n",
       "      <td>12.8</td>\n",
       "      <td>5.960202</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15.529226</td>\n",
       "      <td>18.8</td>\n",
       "      <td>16.884859</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15.757663</td>\n",
       "      <td>15.3</td>\n",
       "      <td>14.185932</td>\n",
       "      <td>12.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9.235337</td>\n",
       "      <td>8.6</td>\n",
       "      <td>10.571591</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.548198</td>\n",
       "      <td>7.9</td>\n",
       "      <td>4.714800</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7.923435</td>\n",
       "      <td>9.9</td>\n",
       "      <td>8.413511</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.548150</td>\n",
       "      <td>10.7</td>\n",
       "      <td>7.591786</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>12.240225</td>\n",
       "      <td>6.7</td>\n",
       "      <td>12.057197</td>\n",
       "      <td>13.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8.407709</td>\n",
       "      <td>6.3</td>\n",
       "      <td>8.956161</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.512348</td>\n",
       "      <td>3.6</td>\n",
       "      <td>5.127004</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8.120575</td>\n",
       "      <td>9.6</td>\n",
       "      <td>8.928006</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>14.058949</td>\n",
       "      <td>12.6</td>\n",
       "      <td>12.997861</td>\n",
       "      <td>14.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>9.584270</td>\n",
       "      <td>10.9</td>\n",
       "      <td>9.158974</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4.258907</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.369186</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>12.778444</td>\n",
       "      <td>14.2</td>\n",
       "      <td>12.537855</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.533352</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6.155942</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>4.604390</td>\n",
       "      <td>8.6</td>\n",
       "      <td>5.675732</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>3.116310</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.037261</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>2.596672</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.677603</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>4.255187</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.939301</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>13.820995</td>\n",
       "      <td>15.3</td>\n",
       "      <td>14.432752</td>\n",
       "      <td>13.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>6.902370</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5.946590</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>10.563084</td>\n",
       "      <td>6.8</td>\n",
       "      <td>10.128328</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>5.806253</td>\n",
       "      <td>8.3</td>\n",
       "      <td>6.330910</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>13.355308</td>\n",
       "      <td>12.7</td>\n",
       "      <td>13.422818</td>\n",
       "      <td>18.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>4.759924</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.159577</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>6.838818</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.086210</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>15.038845</td>\n",
       "      <td>16.4</td>\n",
       "      <td>15.630164</td>\n",
       "      <td>17.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>6.437821</td>\n",
       "      <td>5.9</td>\n",
       "      <td>6.607437</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>18.930464</td>\n",
       "      <td>23.5</td>\n",
       "      <td>18.964010</td>\n",
       "      <td>20.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>9.138570</td>\n",
       "      <td>10.2</td>\n",
       "      <td>8.934233</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>9.570580</td>\n",
       "      <td>7.8</td>\n",
       "      <td>10.145493</td>\n",
       "      <td>12.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>4.535789</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.148111</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>9.119448</td>\n",
       "      <td>9.3</td>\n",
       "      <td>5.510096</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>10.867390</td>\n",
       "      <td>10.1</td>\n",
       "      <td>10.446623</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>12.802690</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.038446</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>7.033832</td>\n",
       "      <td>7.6</td>\n",
       "      <td>6.744524</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>5.141224</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.971744</td>\n",
       "      <td>4.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>6.896482</td>\n",
       "      <td>5.4</td>\n",
       "      <td>8.547985</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>11.419913</td>\n",
       "      <td>11.7</td>\n",
       "      <td>10.909029</td>\n",
       "      <td>12.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>9.192696</td>\n",
       "      <td>7.1</td>\n",
       "      <td>9.467279</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>13.417774</td>\n",
       "      <td>15.8</td>\n",
       "      <td>14.297292</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>11.942076</td>\n",
       "      <td>16.5</td>\n",
       "      <td>12.221186</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>11.557228</td>\n",
       "      <td>7.1</td>\n",
       "      <td>13.204112</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669</th>\n",
       "      <td>4.914625</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.777721</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>16.369080</td>\n",
       "      <td>12.5</td>\n",
       "      <td>15.597491</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>671 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     NN_predictions  actual  GBR_predictions  LY_scoring\n",
       "0          8.047908    10.1         9.918161         4.0\n",
       "1         16.606041    17.5        15.898964        16.3\n",
       "2          2.756142     6.7         4.895916         7.5\n",
       "3          4.496284     5.5         3.902894         4.1\n",
       "4         23.367739    18.9        20.560814        21.0\n",
       "5          8.317717    10.0         6.288318         6.6\n",
       "6          6.102070     4.0         6.591461         7.1\n",
       "7          9.474962     7.6        11.229569         7.5\n",
       "8          8.580517     5.1         7.408105         5.2\n",
       "9          4.848618     5.6         6.119970         9.3\n",
       "10         8.283195    13.0         9.969022         9.4\n",
       "11        13.983689    18.2        14.945651        16.5\n",
       "12         7.391405     4.5         6.444453         1.9\n",
       "13         7.213360     4.6         8.533099         6.4\n",
       "14         5.300426    12.8         5.960202         5.0\n",
       "15        15.529226    18.8        16.884859        18.2\n",
       "16        15.757663    15.3        14.185932        12.6\n",
       "17         9.235337     8.6        10.571591         7.0\n",
       "18         3.548198     7.9         4.714800         4.4\n",
       "19         7.923435     9.9         8.413511         4.3\n",
       "20         5.548150    10.7         7.591786         9.6\n",
       "21        12.240225     6.7        12.057197        13.3\n",
       "22         8.407709     6.3         8.956161         8.5\n",
       "23         4.512348     3.6         5.127004         5.9\n",
       "24         8.120575     9.6         8.928006         7.2\n",
       "25        14.058949    12.6        12.997861        14.3\n",
       "26         9.584270    10.9         9.158974         8.1\n",
       "27         4.258907     2.6         5.369186         3.3\n",
       "28        12.778444    14.2        12.537855         9.6\n",
       "29         4.533352     6.6         6.155942         4.8\n",
       "..              ...     ...              ...         ...\n",
       "641        4.604390     8.6         5.675732         2.6\n",
       "642        3.116310     2.8         5.037261         2.9\n",
       "643        2.596672     2.6         3.677603         2.7\n",
       "644        4.255187     4.2         4.939301         4.9\n",
       "645       13.820995    15.3        14.432752        13.8\n",
       "646        6.902370     9.6         5.946590         4.6\n",
       "647       10.563084     6.8        10.128328         7.0\n",
       "648        5.806253     8.3         6.330910         7.7\n",
       "649       13.355308    12.7        13.422818        18.7\n",
       "650        4.759924     7.0         5.159577         4.1\n",
       "651        6.838818     3.1         5.086210         3.9\n",
       "652       15.038845    16.4        15.630164        17.7\n",
       "653        6.437821     5.9         6.607437         7.2\n",
       "654       18.930464    23.5        18.964010        20.1\n",
       "655        9.138570    10.2         8.934233         8.8\n",
       "656        9.570580     7.8        10.145493        12.7\n",
       "657        4.535789     3.0         4.148111         4.3\n",
       "658        9.119448     9.3         5.510096         1.9\n",
       "659       10.867390    10.1        10.446623         6.4\n",
       "660       12.802690    10.1        13.038446         9.5\n",
       "661        7.033832     7.6         6.744524         7.0\n",
       "662        5.141224     4.8         4.971744         4.8\n",
       "663        6.896482     5.4         8.547985         9.5\n",
       "664       11.419913    11.7        10.909029        12.7\n",
       "665        9.192696     7.1         9.467279        10.4\n",
       "666       13.417774    15.8        14.297292         9.8\n",
       "667       11.942076    16.5        12.221186        14.0\n",
       "668       11.557228     7.1        13.204112         9.6\n",
       "669        4.914625     4.1         4.777721         3.7\n",
       "670       16.369080    12.5        15.597491        17.5\n",
       "\n",
       "[671 rows x 4 columns]"
      ]
     },
     "execution_count": 1081,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing = pd.DataFrame(predictions)\n",
    "testing.columns=['NN_predictions']\n",
    "testing['actual'] = y_test.reset_index()['points']\n",
    "testing['GBR_predictions']=gbr_predictions\n",
    "testing['LY_scoring']=X_test['points_ly'].reset_index()['points_ly']\n",
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2017points = points[points['season']==2017].drop(['season','team','player','points','Games'],axis=1)\n",
    "points_2017 = model.predict(pred_2017points)\n",
    "test_2 =pd.DataFrame(points_2017)\n",
    "gbr_pts_2017 = pd.DataFrame(gbr.predict(pred_2017points))\n",
    "LR_pts_2017 = pd.DataFrame(LR.predict(pred_2017points))\n",
    "test_3 = pd.merge(points,pred_2017points,left_index=True,right_index=True).reset_index()\n",
    "test_3['predictions']=test_2[0]\n",
    "test_3['gbr_pred'] = gbr_pts_2017[0]\n",
    "test_3['LR_pred'] = LR_pts_2017[0]\n",
    "test_3['mean_pred'] = (test_3['predictions']+test_3['gbr_pred']+test_3['LR_pred'])/3\n",
    "test_3 = test_3[test_3['Games']>30]\n",
    "test_3[['player','points','points_ly_x','predictions','gbr_pred','LR_pred','mean_pred']].sort_values(by='points_ly_x',ascending=False)\n",
    "\n",
    "points_pred = test_3[['player','LR_pred']]\n",
    "points_pred.columns = ['player','point_prediction1']\n",
    "\n",
    "df_2017 = pd.merge(df_2017,points_pred,how = 'left',left_on = 'player',right_on='player')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 947,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09715074, 0.1687321 , 0.04240801, 0.06339758, 0.00168377,\n",
       "       0.00236543, 0.00078106, 0.        , 0.02688646, 0.0145768 ,\n",
       "       0.0004906 , 0.02614391, 0.02260494, 0.01884231, 0.05531208,\n",
       "       0.04725459, 0.03733018, 0.0706518 , 0.04590708, 0.03301813,\n",
       "       0.06606104, 0.02548585, 0.02077978, 0.04818103, 0.05865998,\n",
       "       0.00529474])"
      ]
     },
     "execution_count": 947,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1089,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.039124951254946"
      ]
     },
     "execution_count": 1089,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean((df_2017['points']-df_2017['point_prediction1'])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''next is rebounds'''\n",
    "\n",
    "\n",
    "query= '''\n",
    "        \n",
    "        DROP TABLE IF EXISTS rebounds_pred;\n",
    "        CREATE TABLE rebounds_pred(\n",
    "        season int, --these come from player_stats\n",
    "        player varchar(50),\n",
    "        Age int,\n",
    "        team varchar(50),\n",
    "        rebounds float, -- these come from player_stats\n",
    "        rebounds_ly float,\n",
    "        change_rebounds_ly float,\n",
    "        Games int,\n",
    "        C_PF int,\n",
    "        PG int,\n",
    "        SG_SF int,\n",
    "        starter_change int, \n",
    "        \n",
    "        -- these come from team_changes\n",
    "        high_usageplayer_added int,\n",
    "        usagemin_opened float,\n",
    "        maxusage_added float,\n",
    "        high_usageplayer_dropped int,\n",
    "        rebounds_opened float,\n",
    "        max_reboundsdropped float,\n",
    "        max_reboundsadded float,\n",
    "        \n",
    "        -- from player_advstats\n",
    "        per_ly float,\n",
    "        change_per float,\n",
    "        usagerank float,\n",
    "        usagerank_ly float,\n",
    "        reb_perc_ly float,\n",
    "        change_reb_perc float,\n",
    "        defensive_winshares float,\n",
    "        defensive_boxplusminus float,\n",
    "        boxplusminus float,\n",
    "        value_overreplacement float,\n",
    "        \n",
    "        max_teammatereb float,\n",
    "        max_teammate_usage float,\n",
    "        max_teammateto float,\n",
    "        max_teammateshot_attempts float,\n",
    "        \n",
    "        career_rebounds float,\n",
    "        yearspro int\n",
    "        );\n",
    "        \n",
    "        INSERT INTO rebounds_pred(season,player,age,team,rebounds,rebounds_ly,change_rebounds_ly,Games,starter_change,C_PF,PG,SG_SF)\n",
    "        SELECT season,player,age,startingteam,rebounds,rebounds_ly,change_reb_ly,Games,starter-starter_ly,\n",
    "        case when pos in ('C','PF') then 1 else 0 end,case when pos='PG' then 1 else 0 end,case when pos in('SG','SF') then 1 else 0 end from player_stats;\n",
    "        \n",
    "        update rebounds_pred rp\n",
    "        set high_usageplayer_added = tc.high_usageplayer_added,usagemin_opened=tc.usagemin_opened,\n",
    "        maxusage_added=tc.max_usageadded,high_usageplayer_dropped=tc.high_usageplayer_dropped,rebounds_opened=tc.rebounds_opened,\n",
    "        max_reboundsdropped=tc.max_reboundsdropped,max_reboundsadded=tc.max_reboundsadded\n",
    "        from team_changes tc\n",
    "        where tc.team = rp.team and rp.season=tc.season;\n",
    "        \n",
    "        update rebounds_pred rp\n",
    "        set per_ly=pa.per_ly,change_per=pa.change_per,usagerank=pa.usagerank,usagerank_ly=pa.usagerank_ly\n",
    "        ,reb_perc_ly = pa.reb_perc_ly,change_reb_perc = pa.change_reb_perc,defensive_winshares=pa.defensive_winshares,\n",
    "        defensive_boxplusminus=pa.defensive_boxplusminus,boxplusminus=pa.boxplusminus,value_overreplacement=pa.value_overreplacement\n",
    "        from player_advstats pa\n",
    "        where rp.player = pa.player and rp.season = pa.season and rp.team = pa.startingteam;\n",
    "        \n",
    "        update rebounds_pred rp\n",
    "        set max_teammatereb = tm.max_teammatereb,max_teammate_usage=tm.max_teammate_usage,max_teammateto=tm.max_teammateto,\n",
    "        max_teammateshot_attempts=tm.max_teammateshot_attempts\n",
    "        from teammate_maxes tm\n",
    "        where tm.season = rp.season and tm.player = rp.player;\n",
    "        \n",
    "        update rebounds_pred rp\n",
    "        set career_rebounds = pc.career_rebounds, yearspro = pc.yearspro\n",
    "        from player_careerstats pc\n",
    "        where rp.player = pc.player and rp.season = pc.season;\n",
    "        \n",
    "        \n",
    "        select * from rebounds_pred where season>2009\n",
    "        '''\n",
    "\n",
    "\n",
    "cur.execute(query)\n",
    "data = cur.fetchall()\n",
    "rebounds_df = pd.DataFrame(np.array(data))\n",
    "rebounds_df.columns = ['season','player','age','team','rebounds','rebounds_ly','change_rebounds_ly','Games','C_PF','PG','SG_SF','starter_change','high_usageplayer_added','usagemin_opened','maxusage_added','high_usageplayer_dropped','rebounds_opened','max_reboundsdropped',\n",
    "                    'max_reboundsadded','per_ly','change_per','usagerank','usagerank_ly','reb_perc_ly','change_reb_perc','defensive_winshares','defensive_boxplusminus','boxplusminus','value_overreplacement'\n",
    "                       ,'max_teammatereb','max_teammate_usage','max_teammateto','max_teammateshot_attempts','career_rebounds','yearspro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>player</th>\n",
       "      <th>age</th>\n",
       "      <th>team</th>\n",
       "      <th>rebounds</th>\n",
       "      <th>rebounds_ly</th>\n",
       "      <th>change_rebounds_ly</th>\n",
       "      <th>Games</th>\n",
       "      <th>C_PF</th>\n",
       "      <th>PG</th>\n",
       "      <th>...</th>\n",
       "      <th>defensive_boxplusminus</th>\n",
       "      <th>boxplusminus</th>\n",
       "      <th>value_overreplacement</th>\n",
       "      <th>max_teammatereb</th>\n",
       "      <th>max_teammate_usage</th>\n",
       "      <th>max_teammateto</th>\n",
       "      <th>max_teammateshot_attempts</th>\n",
       "      <th>career_rebounds</th>\n",
       "      <th>yearspro</th>\n",
       "      <th>age_squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012</td>\n",
       "      <td>Mirza Teletovic</td>\n",
       "      <td>27</td>\n",
       "      <td>BRK</td>\n",
       "      <td>1.8</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012</td>\n",
       "      <td>Tyshawn Taylor</td>\n",
       "      <td>22</td>\n",
       "      <td>BRK</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012</td>\n",
       "      <td>Tornike Shengelia</td>\n",
       "      <td>21</td>\n",
       "      <td>BRK</td>\n",
       "      <td>1.2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>Casper Ware</td>\n",
       "      <td>24</td>\n",
       "      <td>PHI</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>7.5</td>\n",
       "      <td>747.688</td>\n",
       "      <td>3.7</td>\n",
       "      <td>16.5</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>Jalen Jones</td>\n",
       "      <td>24</td>\n",
       "      <td>DAL</td>\n",
       "      <td>2.9</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>8.4</td>\n",
       "      <td>897.67</td>\n",
       "      <td>2.5</td>\n",
       "      <td>16.2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  season             player age team rebounds rebounds_ly change_rebounds_ly  \\\n",
       "0   2012    Mirza Teletovic  27  BRK      1.8        None               None   \n",
       "1   2012     Tyshawn Taylor  22  BRK      0.5        None               None   \n",
       "2   2012  Tornike Shengelia  21  BRK      1.2        None               None   \n",
       "3   2013        Casper Ware  24  PHI        1        None               None   \n",
       "4   2017        Jalen Jones  24  DAL      2.9        None               None   \n",
       "\n",
       "  Games C_PF PG     ...     defensive_boxplusminus boxplusminus  \\\n",
       "0    53    1  0     ...                       None         None   \n",
       "1    38    0  1     ...                       None         None   \n",
       "2    19    0  0     ...                       None         None   \n",
       "3     9    0  1     ...                       None         None   \n",
       "4    16    0  0     ...                       None         None   \n",
       "\n",
       "  value_overreplacement max_teammatereb max_teammate_usage max_teammateto  \\\n",
       "0                  None            None               None           None   \n",
       "1                  None            None               None           None   \n",
       "2                  None            None               None           None   \n",
       "3                  None             7.5            747.688            3.7   \n",
       "4                  None             8.4             897.67            2.5   \n",
       "\n",
       "  max_teammateshot_attempts career_rebounds yearspro age_squared  \n",
       "0                      None            None     None         729  \n",
       "1                      None            None     None         484  \n",
       "2                      None            None     None         441  \n",
       "3                      16.5            None     None         576  \n",
       "4                      16.2            None     None         576  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 1091,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rebounds_df['age_squared']=rebounds_df['age']*rebounds_df['age']\n",
    "rebounds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1092,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "rebounds = rebounds_df[rebounds_df['rebounds_ly'].notna()]\n",
    "for i in rebounds.columns:\n",
    "    if i not in(['player','team']):\n",
    "        rebounds[i]=pd.to_numeric(rebounds[i])\n",
    "rebounds = rebounds.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rebounds[(rebounds['season']!=2017) & (rebounds['Games']>30)].drop(['player','team','rebounds','Games'],axis=1)\n",
    "y = rebounds[(rebounds['season']!=2017) & (rebounds['Games']>30)]['rebounds']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1564/1564 [==============================] - 4s 2ms/step - loss: 172469.6691\n",
      "Epoch 2/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 80006.6425\n",
      "Epoch 3/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 34906.8944\n",
      "Epoch 4/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 12482.4917\n",
      "Epoch 5/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 4344.5975\n",
      "Epoch 6/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1778.3153\n",
      "Epoch 7/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 856.1724\n",
      "Epoch 8/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 481.7394\n",
      "Epoch 9/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 283.7637\n",
      "Epoch 10/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 181.7322\n",
      "Epoch 11/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 114.4832\n",
      "Epoch 12/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 78.6953\n",
      "Epoch 13/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 60.2889\n",
      "Epoch 14/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 50.6458\n",
      "Epoch 15/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 44.7819\n",
      "Epoch 16/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 40.9135\n",
      "Epoch 17/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 38.5237\n",
      "Epoch 18/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 36.2895\n",
      "Epoch 19/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 34.6239\n",
      "Epoch 20/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 32.8535\n",
      "Epoch 21/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 31.9556\n",
      "Epoch 22/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 31.2493\n",
      "Epoch 23/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 30.6505\n",
      "Epoch 24/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 30.0996\n",
      "Epoch 25/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 29.4822\n",
      "Epoch 26/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 28.9619\n",
      "Epoch 27/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 28.3693\n",
      "Epoch 28/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 27.8730\n",
      "Epoch 29/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 27.5022\n",
      "Epoch 30/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 27.1220\n",
      "Epoch 31/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 26.7201\n",
      "Epoch 32/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 26.4267\n",
      "Epoch 33/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 26.1435\n",
      "Epoch 34/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 25.8320\n",
      "Epoch 35/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 25.5839\n",
      "Epoch 36/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 25.4178\n",
      "Epoch 37/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 25.0932\n",
      "Epoch 38/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 24.9214\n",
      "Epoch 39/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 24.7741\n",
      "Epoch 40/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 24.6800\n",
      "Epoch 41/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 24.5940\n",
      "Epoch 42/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 24.5177\n",
      "Epoch 43/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 24.4681\n",
      "Epoch 44/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 24.4175\n",
      "Epoch 45/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 24.3870\n",
      "Epoch 46/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 24.3599\n",
      "Epoch 47/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 24.3288\n",
      "Epoch 48/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 24.2954\n",
      "Epoch 49/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 24.2670\n",
      "Epoch 50/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 24.2329\n",
      "Epoch 51/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 24.2041\n",
      "Epoch 52/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 24.1746\n",
      "Epoch 53/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 24.1378\n",
      "Epoch 54/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 24.0996\n",
      "Epoch 55/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 24.0675\n",
      "Epoch 56/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 24.0317\n",
      "Epoch 57/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 23.9951\n",
      "Epoch 58/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 23.9669\n",
      "Epoch 59/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 23.9276\n",
      "Epoch 60/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 23.8982\n",
      "Epoch 61/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 23.8519\n",
      "Epoch 62/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 23.8050\n",
      "Epoch 63/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 23.7553\n",
      "Epoch 64/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 23.7178\n",
      "Epoch 65/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 23.6837\n",
      "Epoch 66/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 23.6554\n",
      "Epoch 67/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 23.6212\n",
      "Epoch 68/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 23.5882\n",
      "Epoch 69/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 23.5595\n",
      "Epoch 70/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 23.5346\n",
      "Epoch 71/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 23.5013\n",
      "Epoch 72/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 23.4753\n",
      "Epoch 73/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 23.4484\n",
      "Epoch 74/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 23.4228\n",
      "Epoch 75/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 23.3881\n",
      "Epoch 76/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 23.3639\n",
      "Epoch 77/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 23.3414\n",
      "Epoch 78/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 23.3059\n",
      "Epoch 79/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 23.2824\n",
      "Epoch 80/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 23.2535\n",
      "Epoch 81/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 23.2317\n",
      "Epoch 82/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 23.1998\n",
      "Epoch 83/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 23.1753\n",
      "Epoch 84/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 23.1519\n",
      "Epoch 85/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 23.1253\n",
      "Epoch 86/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 23.1012\n",
      "Epoch 87/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 23.0775\n",
      "Epoch 88/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 23.0548\n",
      "Epoch 89/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 23.0308\n",
      "Epoch 90/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 23.0113\n",
      "Epoch 91/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 22.9843\n",
      "Epoch 92/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 22.9641\n",
      "Epoch 93/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 22.9409\n",
      "Epoch 94/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 22.9176\n",
      "Epoch 95/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 22.8980\n",
      "Epoch 96/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 22.8813\n",
      "Epoch 97/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 22.8655\n",
      "Epoch 98/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 22.8494\n",
      "Epoch 99/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 22.8341\n",
      "Epoch 100/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 22.8179\n",
      "Epoch 101/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 22.8016\n",
      "Epoch 102/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 22.7864\n",
      "Epoch 103/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 22.7702\n",
      "Epoch 104/1000\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 22.7538\n",
      "Epoch 105/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 22.7369\n",
      "Epoch 106/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 22.7207\n",
      "Epoch 107/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 22.7048\n",
      "Epoch 108/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 22.6877\n",
      "Epoch 109/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 22.6719\n",
      "Epoch 110/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 22.6556\n",
      "Epoch 111/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 22.6383\n",
      "Epoch 112/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 22.6229\n",
      "Epoch 113/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 22.6060\n",
      "Epoch 114/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 22.5900\n",
      "Epoch 115/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 22.5754\n",
      "Epoch 116/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 22.5605\n",
      "Epoch 117/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 22.5461\n",
      "Epoch 118/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 22.5313\n",
      "Epoch 119/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 22.5165\n",
      "Epoch 120/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 22.5014\n",
      "Epoch 121/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 22.4864\n",
      "Epoch 122/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 22.4709\n",
      "Epoch 123/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 22.4558\n",
      "Epoch 124/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 22.4402\n",
      "Epoch 125/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 22.4244\n",
      "Epoch 126/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 22.4093\n",
      "Epoch 127/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 22.3937\n",
      "Epoch 128/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 22.3776\n",
      "Epoch 129/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 22.3618\n",
      "Epoch 130/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 22.3459\n",
      "Epoch 131/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 22.3297\n",
      "Epoch 132/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 22.3138\n",
      "Epoch 133/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 22.2971\n",
      "Epoch 134/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 22.2809\n",
      "Epoch 135/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 22.2645\n",
      "Epoch 136/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 22.2480\n",
      "Epoch 137/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 22.2315\n",
      "Epoch 138/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 22.2148\n",
      "Epoch 139/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 22.1980\n",
      "Epoch 140/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 22.1811\n",
      "Epoch 141/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 22.1642\n",
      "Epoch 142/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 22.1472\n",
      "Epoch 143/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 22.1301\n",
      "Epoch 144/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 22.1127\n",
      "Epoch 145/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 22.0955\n",
      "Epoch 146/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 22.0783\n",
      "Epoch 147/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 22.0597\n",
      "Epoch 148/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 22.0414\n",
      "Epoch 149/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 22.0226\n",
      "Epoch 150/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 22.0009\n",
      "Epoch 151/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 21.9809\n",
      "Epoch 152/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 21.9590\n",
      "Epoch 153/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 21.9392\n",
      "Epoch 154/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 21.9186\n",
      "Epoch 155/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 21.8989\n",
      "Epoch 156/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 21.8781\n",
      "Epoch 157/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 21.8582\n",
      "Epoch 158/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 21.8381\n",
      "Epoch 159/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 21.8179\n",
      "Epoch 160/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 21.7977\n",
      "Epoch 161/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 21.7779\n",
      "Epoch 162/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 21.7583\n",
      "Epoch 163/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 21.7389\n",
      "Epoch 164/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 21.7194\n",
      "Epoch 165/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 21.6997\n",
      "Epoch 166/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 21.6798\n",
      "Epoch 167/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 21.6598\n",
      "Epoch 168/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 21.6406\n",
      "Epoch 169/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 21.6198\n",
      "Epoch 170/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 21.6002\n",
      "Epoch 171/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 21.5794\n",
      "Epoch 172/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 21.5595\n",
      "Epoch 173/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 21.5388\n",
      "Epoch 174/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 21.5178\n",
      "Epoch 175/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 21.4972\n",
      "Epoch 176/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 21.4766\n",
      "Epoch 177/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 21.4553\n",
      "Epoch 178/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 21.4346\n",
      "Epoch 179/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 21.4127\n",
      "Epoch 180/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 21.3910\n",
      "Epoch 181/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 21.3676\n",
      "Epoch 182/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 21.3451\n",
      "Epoch 183/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 21.3241\n",
      "Epoch 184/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 21.3023\n",
      "Epoch 185/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 21.2805\n",
      "Epoch 186/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 21.2587\n",
      "Epoch 187/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 21.2368\n",
      "Epoch 188/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 21.2150\n",
      "Epoch 189/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 21.1927\n",
      "Epoch 190/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 21.1707\n",
      "Epoch 191/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 21.1483\n",
      "Epoch 192/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 21.1257\n",
      "Epoch 193/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 21.1040\n",
      "Epoch 194/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 21.0804\n",
      "Epoch 195/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 21.0562\n",
      "Epoch 196/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 21.0333\n",
      "Epoch 197/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 21.0090\n",
      "Epoch 198/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 20.9856\n",
      "Epoch 199/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 20.9625\n",
      "Epoch 200/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 20.9391\n",
      "Epoch 201/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 20.9160\n",
      "Epoch 202/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 20.8923\n",
      "Epoch 203/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 20.8690\n",
      "Epoch 204/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 20.8453\n",
      "Epoch 205/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 20.8216\n",
      "Epoch 206/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 20.7978\n",
      "Epoch 207/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 20.7740\n",
      "Epoch 208/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 20.7494\n",
      "Epoch 209/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 20.7256\n",
      "Epoch 210/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 20.7008\n",
      "Epoch 211/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 20.6768\n",
      "Epoch 212/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 20.6522\n",
      "Epoch 213/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 20.6278\n",
      "Epoch 214/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 20.6030\n",
      "Epoch 215/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 20.5783\n",
      "Epoch 216/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 20.5535\n",
      "Epoch 217/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 20.5286\n",
      "Epoch 218/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 20.5035\n",
      "Epoch 219/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 20.4784\n",
      "Epoch 220/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 20.4525\n",
      "Epoch 221/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 20.4268\n",
      "Epoch 222/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 20.4011\n",
      "Epoch 223/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 20.3756\n",
      "Epoch 224/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 20.3496\n",
      "Epoch 225/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 20.3239\n",
      "Epoch 226/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 20.2977\n",
      "Epoch 227/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 20.2720\n",
      "Epoch 228/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 20.2457\n",
      "Epoch 229/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 20.2191\n",
      "Epoch 230/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 20.1927\n",
      "Epoch 231/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 20.1665\n",
      "Epoch 232/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 20.1393\n",
      "Epoch 233/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 20.1126\n",
      "Epoch 234/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 20.0862\n",
      "Epoch 235/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 20.0590\n",
      "Epoch 236/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 20.0320\n",
      "Epoch 237/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 20.0048\n",
      "Epoch 238/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 19.9779\n",
      "Epoch 239/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 19.9501\n",
      "Epoch 240/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 19.9220\n",
      "Epoch 241/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 19.8947\n",
      "Epoch 242/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 19.8668\n",
      "Epoch 243/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 19.8386\n",
      "Epoch 244/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 19.8110\n",
      "Epoch 245/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 19.7831\n",
      "Epoch 246/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 19.7548\n",
      "Epoch 247/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 19.7270\n",
      "Epoch 248/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 19.6988\n",
      "Epoch 249/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 19.6706\n",
      "Epoch 250/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 19.6420\n",
      "Epoch 251/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 19.6135\n",
      "Epoch 252/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 19.5853\n",
      "Epoch 253/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 19.5564\n",
      "Epoch 254/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 19.5277\n",
      "Epoch 255/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 19.4990\n",
      "Epoch 256/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 19.4696\n",
      "Epoch 257/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 19.4406\n",
      "Epoch 258/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 19.4113\n",
      "Epoch 259/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 19.3819\n",
      "Epoch 260/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 19.3527\n",
      "Epoch 261/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 19.3225\n",
      "Epoch 262/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 19.2931\n",
      "Epoch 263/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 19.2628\n",
      "Epoch 264/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 19.2326\n",
      "Epoch 265/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 19.2026\n",
      "Epoch 266/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 19.1727\n",
      "Epoch 267/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 19.1425\n",
      "Epoch 268/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 19.1123\n",
      "Epoch 269/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 19.0827\n",
      "Epoch 270/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 19.0522\n",
      "Epoch 271/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 19.0221\n",
      "Epoch 272/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 18.9917\n",
      "Epoch 273/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 18.9613\n",
      "Epoch 274/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 18.9311\n",
      "Epoch 275/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 18.9008\n",
      "Epoch 276/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 18.8700\n",
      "Epoch 277/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 18.8396\n",
      "Epoch 278/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 18.8086\n",
      "Epoch 279/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 18.7776\n",
      "Epoch 280/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 18.7465\n",
      "Epoch 281/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 18.7153\n",
      "Epoch 282/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 18.6841\n",
      "Epoch 283/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 18.6530\n",
      "Epoch 284/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 18.6214\n",
      "Epoch 285/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 18.5897\n",
      "Epoch 286/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 18.5580\n",
      "Epoch 287/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 18.5259\n",
      "Epoch 288/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 18.4940\n",
      "Epoch 289/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 18.4621\n",
      "Epoch 290/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 18.4302\n",
      "Epoch 291/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 18.3980\n",
      "Epoch 292/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 18.3655\n",
      "Epoch 293/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 18.3332\n",
      "Epoch 294/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 18.3005\n",
      "Epoch 295/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 18.2677\n",
      "Epoch 296/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 18.2348\n",
      "Epoch 297/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 18.2019\n",
      "Epoch 298/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 18.1687\n",
      "Epoch 299/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 18.1356\n",
      "Epoch 300/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 18.1023\n",
      "Epoch 301/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 18.0693\n",
      "Epoch 302/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 18.0355\n",
      "Epoch 303/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 18.0017\n",
      "Epoch 304/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 17.9680\n",
      "Epoch 305/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 17.9343\n",
      "Epoch 306/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 17.9003\n",
      "Epoch 307/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 17.8663\n",
      "Epoch 308/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 17.8318\n",
      "Epoch 309/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 17.7978\n",
      "Epoch 310/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 17.7633\n",
      "Epoch 311/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 17.7286\n",
      "Epoch 312/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 17.6940\n",
      "Epoch 313/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 17.6593\n",
      "Epoch 314/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 17.6248\n",
      "Epoch 315/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 17.5901\n",
      "Epoch 316/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 17.5551\n",
      "Epoch 317/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 17.5197\n",
      "Epoch 318/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 17.4842\n",
      "Epoch 319/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 17.4491\n",
      "Epoch 320/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 17.4144\n",
      "Epoch 321/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 17.3790\n",
      "Epoch 322/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 17.3438\n",
      "Epoch 323/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 17.3087\n",
      "Epoch 324/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 17.2731\n",
      "Epoch 325/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 17.2374\n",
      "Epoch 326/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 17.2019\n",
      "Epoch 327/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 17.1660\n",
      "Epoch 328/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 17.1304\n",
      "Epoch 329/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 17.0944\n",
      "Epoch 330/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 17.0583\n",
      "Epoch 331/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 17.0216\n",
      "Epoch 332/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 16.9851\n",
      "Epoch 333/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 16.9489\n",
      "Epoch 334/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 16.9122\n",
      "Epoch 335/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 16.8758\n",
      "Epoch 336/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 16.8392\n",
      "Epoch 337/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 16.8027\n",
      "Epoch 338/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 16.7661\n",
      "Epoch 339/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 16.7295\n",
      "Epoch 340/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 16.6929\n",
      "Epoch 341/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 16.6559\n",
      "Epoch 342/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 16.6192\n",
      "Epoch 343/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 16.5824\n",
      "Epoch 344/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 16.5454\n",
      "Epoch 345/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 16.5082\n",
      "Epoch 346/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 16.4714\n",
      "Epoch 347/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 16.4340\n",
      "Epoch 348/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 16.3967\n",
      "Epoch 349/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 16.3594\n",
      "Epoch 350/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 16.3218\n",
      "Epoch 351/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 16.2846\n",
      "Epoch 352/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 16.2473\n",
      "Epoch 353/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 16.2100\n",
      "Epoch 354/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 16.1721\n",
      "Epoch 355/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 16.1346\n",
      "Epoch 356/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 16.0968\n",
      "Epoch 357/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 16.0592\n",
      "Epoch 358/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 16.0212\n",
      "Epoch 359/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 15.9839\n",
      "Epoch 360/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 15.9460\n",
      "Epoch 361/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 15.9083\n",
      "Epoch 362/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 15.8711\n",
      "Epoch 363/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 15.8329\n",
      "Epoch 364/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 15.7949\n",
      "Epoch 365/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 15.7566\n",
      "Epoch 366/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 15.7184\n",
      "Epoch 367/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 15.6801\n",
      "Epoch 368/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 15.6416\n",
      "Epoch 369/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 15.6038\n",
      "Epoch 370/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 15.5654\n",
      "Epoch 371/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 15.5265\n",
      "Epoch 372/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 15.4881\n",
      "Epoch 373/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 15.4495\n",
      "Epoch 374/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 15.4109\n",
      "Epoch 375/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 15.3720\n",
      "Epoch 376/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 15.3338\n",
      "Epoch 377/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 15.2948\n",
      "Epoch 378/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 15.2559\n",
      "Epoch 379/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 15.2169\n",
      "Epoch 380/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 15.1785\n",
      "Epoch 381/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 15.1399\n",
      "Epoch 382/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 15.1013\n",
      "Epoch 383/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 15.0626\n",
      "Epoch 384/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 15.0239\n",
      "Epoch 385/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 14.9850\n",
      "Epoch 386/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 14.9457\n",
      "Epoch 387/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 14.9066\n",
      "Epoch 388/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 14.8678\n",
      "Epoch 389/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 14.8288\n",
      "Epoch 390/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 14.7896\n",
      "Epoch 391/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 14.7513\n",
      "Epoch 392/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 14.7115\n",
      "Epoch 393/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 14.6724\n",
      "Epoch 394/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 14.6334\n",
      "Epoch 395/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 14.5942\n",
      "Epoch 396/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 14.5552\n",
      "Epoch 397/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 14.5160\n",
      "Epoch 398/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 14.4767\n",
      "Epoch 399/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 14.4380\n",
      "Epoch 400/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 14.3984\n",
      "Epoch 401/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 14.3587\n",
      "Epoch 402/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 14.3192\n",
      "Epoch 403/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 14.2798\n",
      "Epoch 404/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 14.2409\n",
      "Epoch 405/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 14.2022\n",
      "Epoch 406/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 14.1629\n",
      "Epoch 407/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 14.1233\n",
      "Epoch 408/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 14.0840\n",
      "Epoch 409/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 14.0452\n",
      "Epoch 410/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 14.0056\n",
      "Epoch 411/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 13.9666\n",
      "Epoch 412/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 13.9277\n",
      "Epoch 413/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 13.8881\n",
      "Epoch 414/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 13.8493\n",
      "Epoch 415/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 13.8105\n",
      "Epoch 416/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 13.7713\n",
      "Epoch 417/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 13.7323\n",
      "Epoch 418/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 13.6934\n",
      "Epoch 419/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 13.6539\n",
      "Epoch 420/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 13.6147\n",
      "Epoch 421/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 13.5750\n",
      "Epoch 422/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 13.5366\n",
      "Epoch 423/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 13.4976\n",
      "Epoch 424/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 13.4587\n",
      "Epoch 425/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 13.4196\n",
      "Epoch 426/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 13.3803\n",
      "Epoch 427/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 13.3410\n",
      "Epoch 428/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 13.3018\n",
      "Epoch 429/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 13.2632\n",
      "Epoch 430/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 13.2244\n",
      "Epoch 431/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 13.1860\n",
      "Epoch 432/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 13.1476\n",
      "Epoch 433/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 13.1089\n",
      "Epoch 434/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 13.0708\n",
      "Epoch 435/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 13.0324\n",
      "Epoch 436/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 12.9937\n",
      "Epoch 437/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 12.9554\n",
      "Epoch 438/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 12.9175\n",
      "Epoch 439/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 12.8792\n",
      "Epoch 440/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 12.8404\n",
      "Epoch 441/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 12.8024\n",
      "Epoch 442/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 12.7637\n",
      "Epoch 443/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 12.7260\n",
      "Epoch 444/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 12.6879\n",
      "Epoch 445/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 12.6500\n",
      "Epoch 446/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 12.6117\n",
      "Epoch 447/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 12.5734\n",
      "Epoch 448/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 12.5357\n",
      "Epoch 449/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 12.4978\n",
      "Epoch 450/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 12.4606\n",
      "Epoch 451/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 12.4230\n",
      "Epoch 452/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 12.3853\n",
      "Epoch 453/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 12.3476\n",
      "Epoch 454/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 12.3098\n",
      "Epoch 455/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 12.2723\n",
      "Epoch 456/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 12.2354\n",
      "Epoch 457/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 12.1982\n",
      "Epoch 458/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 12.1601\n",
      "Epoch 459/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 12.1232\n",
      "Epoch 460/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 12.0859\n",
      "Epoch 461/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 12.0485\n",
      "Epoch 462/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 12.0112\n",
      "Epoch 463/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 11.9745\n",
      "Epoch 464/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 11.9372\n",
      "Epoch 465/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 11.9002\n",
      "Epoch 466/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 11.8631\n",
      "Epoch 467/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 11.8265\n",
      "Epoch 468/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 11.7898\n",
      "Epoch 469/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 11.7529\n",
      "Epoch 470/1000\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 11.7164\n",
      "Epoch 471/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 11.6798\n",
      "Epoch 472/1000\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 11.6439\n",
      "Epoch 473/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 11.6073\n",
      "Epoch 474/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 11.5703\n",
      "Epoch 475/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 11.5338\n",
      "Epoch 476/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 11.4973\n",
      "Epoch 477/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 11.4604\n",
      "Epoch 478/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 11.4243\n",
      "Epoch 479/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 11.3882\n",
      "Epoch 480/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 11.3529\n",
      "Epoch 481/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 11.3167\n",
      "Epoch 482/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 11.2812\n",
      "Epoch 483/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 11.2453\n",
      "Epoch 484/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 11.2099\n",
      "Epoch 485/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 11.1744\n",
      "Epoch 486/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 11.1399\n",
      "Epoch 487/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 11.1051\n",
      "Epoch 488/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 11.0713\n",
      "Epoch 489/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 11.0363\n",
      "Epoch 490/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 11.0013\n",
      "Epoch 491/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 10.9667\n",
      "Epoch 492/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 10.9319\n",
      "Epoch 493/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 10.8973\n",
      "Epoch 494/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 10.8634\n",
      "Epoch 495/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 10.8287\n",
      "Epoch 496/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 10.7950\n",
      "Epoch 497/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 10.7618\n",
      "Epoch 498/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 10.7276\n",
      "Epoch 499/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 10.6940\n",
      "Epoch 500/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 10.6604\n",
      "Epoch 501/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 10.6265\n",
      "Epoch 502/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 10.5924\n",
      "Epoch 503/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 10.5590\n",
      "Epoch 504/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 10.5255\n",
      "Epoch 505/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 10.4918\n",
      "Epoch 506/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 10.4586\n",
      "Epoch 507/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 10.4254\n",
      "Epoch 508/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 10.3926\n",
      "Epoch 509/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 10.3598\n",
      "Epoch 510/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 10.3269\n",
      "Epoch 511/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 10.2943\n",
      "Epoch 512/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 10.2610\n",
      "Epoch 513/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 10.2281\n",
      "Epoch 514/1000\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 10.1952\n",
      "Epoch 515/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 10.1630\n",
      "Epoch 516/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 10.1315\n",
      "Epoch 517/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 10.0996\n",
      "Epoch 518/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 10.0681\n",
      "Epoch 519/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 10.0357\n",
      "Epoch 520/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 10.0039\n",
      "Epoch 521/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 9.9719\n",
      "Epoch 522/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 9.9403\n",
      "Epoch 523/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 9.9090\n",
      "Epoch 524/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 9.8781\n",
      "Epoch 525/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 9.8473\n",
      "Epoch 526/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 9.8162\n",
      "Epoch 527/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 9.7861\n",
      "Epoch 528/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 9.7550\n",
      "Epoch 529/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 9.7245\n",
      "Epoch 530/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 9.6939\n",
      "Epoch 531/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 9.6635\n",
      "Epoch 532/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 9.6332\n",
      "Epoch 533/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 9.6025\n",
      "Epoch 534/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 9.5726\n",
      "Epoch 535/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 9.5423\n",
      "Epoch 536/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 9.5123\n",
      "Epoch 537/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 9.4824\n",
      "Epoch 538/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 9.4529\n",
      "Epoch 539/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 9.4232\n",
      "Epoch 540/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 9.3936\n",
      "Epoch 541/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 9.3644\n",
      "Epoch 542/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 9.3349\n",
      "Epoch 543/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 9.3063\n",
      "Epoch 544/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 9.2768\n",
      "Epoch 545/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 9.2484\n",
      "Epoch 546/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 9.2201\n",
      "Epoch 547/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 9.1918\n",
      "Epoch 548/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 9.1636\n",
      "Epoch 549/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 9.1362\n",
      "Epoch 550/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 9.1086\n",
      "Epoch 551/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 9.0806\n",
      "Epoch 552/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 9.0532\n",
      "Epoch 553/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 9.0255\n",
      "Epoch 554/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 8.9979\n",
      "Epoch 555/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 8.9707\n",
      "Epoch 556/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 8.9435\n",
      "Epoch 557/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 8.9166\n",
      "Epoch 558/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 8.8897\n",
      "Epoch 559/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 8.8630\n",
      "Epoch 560/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 8.8361\n",
      "Epoch 561/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 8.8092\n",
      "Epoch 562/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 8.7834\n",
      "Epoch 563/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 8.7572\n",
      "Epoch 564/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 8.7316\n",
      "Epoch 565/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 8.7052\n",
      "Epoch 566/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 8.6794\n",
      "Epoch 567/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 8.6539\n",
      "Epoch 568/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 8.6284\n",
      "Epoch 569/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 8.6029\n",
      "Epoch 570/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 8.5779\n",
      "Epoch 571/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 8.5522\n",
      "Epoch 572/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 8.5270\n",
      "Epoch 573/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 8.5026\n",
      "Epoch 574/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 8.4777\n",
      "Epoch 575/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 8.4531\n",
      "Epoch 576/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 8.4282\n",
      "Epoch 577/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 8.4039\n",
      "Epoch 578/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 8.3798\n",
      "Epoch 579/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 8.3558\n",
      "Epoch 580/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 8.3322\n",
      "Epoch 581/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 8.3086\n",
      "Epoch 582/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 8.2851\n",
      "Epoch 583/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 8.2618\n",
      "Epoch 584/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 8.2381\n",
      "Epoch 585/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 8.2149\n",
      "Epoch 586/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 8.1918\n",
      "Epoch 587/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 8.1694\n",
      "Epoch 588/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 8.1467\n",
      "Epoch 589/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 8.1242\n",
      "Epoch 590/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 8.1019\n",
      "Epoch 591/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 8.0800\n",
      "Epoch 592/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 8.0573\n",
      "Epoch 593/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 8.0360\n",
      "Epoch 594/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 8.0142\n",
      "Epoch 595/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 7.9922\n",
      "Epoch 596/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.9707\n",
      "Epoch 597/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.9491\n",
      "Epoch 598/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.9281\n",
      "Epoch 599/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.9060\n",
      "Epoch 600/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.8856\n",
      "Epoch 601/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.8647\n",
      "Epoch 602/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.8440\n",
      "Epoch 603/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.8238\n",
      "Epoch 604/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 7.8034\n",
      "Epoch 605/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.7831\n",
      "Epoch 606/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.7631\n",
      "Epoch 607/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.7423\n",
      "Epoch 608/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.7225\n",
      "Epoch 609/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.7029\n",
      "Epoch 610/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.6836\n",
      "Epoch 611/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.6644\n",
      "Epoch 612/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 7.6453\n",
      "Epoch 613/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.6266\n",
      "Epoch 614/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.6073\n",
      "Epoch 615/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.5880\n",
      "Epoch 616/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 7.5686\n",
      "Epoch 617/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.5497\n",
      "Epoch 618/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.5314\n",
      "Epoch 619/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.5131\n",
      "Epoch 620/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.4948\n",
      "Epoch 621/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 7.4767\n",
      "Epoch 622/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 7.4588\n",
      "Epoch 623/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.4409\n",
      "Epoch 624/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.4236\n",
      "Epoch 625/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.4058\n",
      "Epoch 626/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.3884\n",
      "Epoch 627/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.3711\n",
      "Epoch 628/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.3539\n",
      "Epoch 629/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.3369\n",
      "Epoch 630/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.3205\n",
      "Epoch 631/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.3041\n",
      "Epoch 632/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.2871\n",
      "Epoch 633/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.2708\n",
      "Epoch 634/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.2541\n",
      "Epoch 635/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 7.2381\n",
      "Epoch 636/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.2212\n",
      "Epoch 637/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.2056\n",
      "Epoch 638/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.1893\n",
      "Epoch 639/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 7.1737\n",
      "Epoch 640/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.1583\n",
      "Epoch 641/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.1431\n",
      "Epoch 642/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.1279\n",
      "Epoch 643/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 7.1125\n",
      "Epoch 644/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.0976\n",
      "Epoch 645/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.0829\n",
      "Epoch 646/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.0680\n",
      "Epoch 647/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 7.0539\n",
      "Epoch 648/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 7.0392\n",
      "Epoch 649/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.0249\n",
      "Epoch 650/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.0107\n",
      "Epoch 651/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.9965\n",
      "Epoch 652/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.9831\n",
      "Epoch 653/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.9694\n",
      "Epoch 654/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.9558\n",
      "Epoch 655/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.9418\n",
      "Epoch 656/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.9283\n",
      "Epoch 657/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.9149\n",
      "Epoch 658/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.9016\n",
      "Epoch 659/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.8882\n",
      "Epoch 660/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.8754\n",
      "Epoch 661/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.8623\n",
      "Epoch 662/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.8495\n",
      "Epoch 663/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.8370\n",
      "Epoch 664/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 6.8243\n",
      "Epoch 665/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.8123\n",
      "Epoch 666/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.8004\n",
      "Epoch 667/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.7882\n",
      "Epoch 668/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.7766\n",
      "Epoch 669/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.7650\n",
      "Epoch 670/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.7527\n",
      "Epoch 671/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.7411\n",
      "Epoch 672/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.7291\n",
      "Epoch 673/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.7177\n",
      "Epoch 674/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.7066\n",
      "Epoch 675/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.6954\n",
      "Epoch 676/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.6842\n",
      "Epoch 677/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.6732\n",
      "Epoch 678/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.6619\n",
      "Epoch 679/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.6513\n",
      "Epoch 680/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 6.6404\n",
      "Epoch 681/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.6299\n",
      "Epoch 682/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.6197\n",
      "Epoch 683/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.6092\n",
      "Epoch 684/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.5995\n",
      "Epoch 685/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.5899\n",
      "Epoch 686/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.5804\n",
      "Epoch 687/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.5708\n",
      "Epoch 688/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.5608\n",
      "Epoch 689/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.5511\n",
      "Epoch 690/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.5418\n",
      "Epoch 691/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.5322\n",
      "Epoch 692/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.5231\n",
      "Epoch 693/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.5133\n",
      "Epoch 694/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.5047\n",
      "Epoch 695/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.4957\n",
      "Epoch 696/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.4868\n",
      "Epoch 697/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.4783\n",
      "Epoch 698/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.4693\n",
      "Epoch 699/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.4604\n",
      "Epoch 700/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.4513\n",
      "Epoch 701/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.4431\n",
      "Epoch 702/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.4345\n",
      "Epoch 703/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.4265\n",
      "Epoch 704/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.4183\n",
      "Epoch 705/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.4100\n",
      "Epoch 706/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.4023\n",
      "Epoch 707/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.3947\n",
      "Epoch 708/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.3873\n",
      "Epoch 709/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.3797\n",
      "Epoch 710/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.3724\n",
      "Epoch 711/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 6.3653\n",
      "Epoch 712/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.3580\n",
      "Epoch 713/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.3511\n",
      "Epoch 714/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.3443\n",
      "Epoch 715/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.3371\n",
      "Epoch 716/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.3307\n",
      "Epoch 717/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 6.3242\n",
      "Epoch 718/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.3176\n",
      "Epoch 719/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.3111\n",
      "Epoch 720/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.3048\n",
      "Epoch 721/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.2983\n",
      "Epoch 722/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.2921\n",
      "Epoch 723/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.2864\n",
      "Epoch 724/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.2805\n",
      "Epoch 725/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.2748\n",
      "Epoch 726/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.2693\n",
      "Epoch 727/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.2632\n",
      "Epoch 728/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.2576\n",
      "Epoch 729/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.2519\n",
      "Epoch 730/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.2463\n",
      "Epoch 731/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 6.2408\n",
      "Epoch 732/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 6.2352\n",
      "Epoch 733/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.2298\n",
      "Epoch 734/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.2242\n",
      "Epoch 735/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.2196\n",
      "Epoch 736/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.2139\n",
      "Epoch 737/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.2090\n",
      "Epoch 738/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.2041\n",
      "Epoch 739/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.1991\n",
      "Epoch 740/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.1939\n",
      "Epoch 741/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.1893\n",
      "Epoch 742/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 6.1845\n",
      "Epoch 743/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.1800\n",
      "Epoch 744/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.1754\n",
      "Epoch 745/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.1709\n",
      "Epoch 746/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.1665\n",
      "Epoch 747/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.1621\n",
      "Epoch 748/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.1580\n",
      "Epoch 749/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.1538\n",
      "Epoch 750/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.1494\n",
      "Epoch 751/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.1456\n",
      "Epoch 752/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.1416\n",
      "Epoch 753/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.1377\n",
      "Epoch 754/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.1336\n",
      "Epoch 755/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.1295\n",
      "Epoch 756/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.1257\n",
      "Epoch 757/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.1222\n",
      "Epoch 758/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.1188\n",
      "Epoch 759/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.1152\n",
      "Epoch 760/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.1118\n",
      "Epoch 761/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.1084\n",
      "Epoch 762/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.1051\n",
      "Epoch 763/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.1018\n",
      "Epoch 764/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.0986\n",
      "Epoch 765/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 6.0956\n",
      "Epoch 766/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.0925\n",
      "Epoch 767/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.0896\n",
      "Epoch 768/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.0866\n",
      "Epoch 769/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.0838\n",
      "Epoch 770/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.0810\n",
      "Epoch 771/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.0787\n",
      "Epoch 772/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.0759\n",
      "Epoch 773/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.0735\n",
      "Epoch 774/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.0711\n",
      "Epoch 775/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.0688\n",
      "Epoch 776/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.0665\n",
      "Epoch 777/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.0643\n",
      "Epoch 778/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.0618\n",
      "Epoch 779/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.0597\n",
      "Epoch 780/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.0575\n",
      "Epoch 781/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.0553\n",
      "Epoch 782/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.0529\n",
      "Epoch 783/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.0512\n",
      "Epoch 784/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.0491\n",
      "Epoch 785/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.0470\n",
      "Epoch 786/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.0451\n",
      "Epoch 787/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 6.0429\n",
      "Epoch 788/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.0409\n",
      "Epoch 789/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 6.0393\n",
      "Epoch 790/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 6.0375\n",
      "Epoch 791/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 6.0357\n",
      "Epoch 792/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.0339\n",
      "Epoch 793/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.0321\n",
      "Epoch 794/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.0304\n",
      "Epoch 795/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.0286\n",
      "Epoch 796/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.0269\n",
      "Epoch 797/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.0253\n",
      "Epoch 798/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.0238\n",
      "Epoch 799/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.0224\n",
      "Epoch 800/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 6.0209\n",
      "Epoch 801/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.0195\n",
      "Epoch 802/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.0183\n",
      "Epoch 803/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.0170\n",
      "Epoch 804/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.0157\n",
      "Epoch 805/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.0144\n",
      "Epoch 806/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.0133\n",
      "Epoch 807/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.0121\n",
      "Epoch 808/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.0111\n",
      "Epoch 809/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.0099\n",
      "Epoch 810/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 6.0090\n",
      "Epoch 811/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.0079\n",
      "Epoch 812/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.0068\n",
      "Epoch 813/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.0057\n",
      "Epoch 814/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.0047\n",
      "Epoch 815/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.0034\n",
      "Epoch 816/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.0022\n",
      "Epoch 817/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 6.0011\n",
      "Epoch 818/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.0001\n",
      "Epoch 819/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.9993\n",
      "Epoch 820/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9982\n",
      "Epoch 821/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9973\n",
      "Epoch 822/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9964\n",
      "Epoch 823/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9956\n",
      "Epoch 824/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.9947\n",
      "Epoch 825/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9938\n",
      "Epoch 826/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9932\n",
      "Epoch 827/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 5.9925\n",
      "Epoch 828/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.9918\n",
      "Epoch 829/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 5.9913\n",
      "Epoch 830/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.9907\n",
      "Epoch 831/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.9901\n",
      "Epoch 832/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9894\n",
      "Epoch 833/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.9887\n",
      "Epoch 834/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 5.9880\n",
      "Epoch 835/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.9875\n",
      "Epoch 836/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9870\n",
      "Epoch 837/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 5.9865\n",
      "Epoch 838/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9860\n",
      "Epoch 839/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 5.9855\n",
      "Epoch 840/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9850\n",
      "Epoch 841/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9847\n",
      "Epoch 842/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 5.9841\n",
      "Epoch 843/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9836\n",
      "Epoch 844/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9832\n",
      "Epoch 845/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 5.9828\n",
      "Epoch 846/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 5.9823\n",
      "Epoch 847/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9820\n",
      "Epoch 848/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.9817\n",
      "Epoch 849/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 5.9813\n",
      "Epoch 850/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 5.9808\n",
      "Epoch 851/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9806\n",
      "Epoch 852/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.9802\n",
      "Epoch 853/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9798\n",
      "Epoch 854/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9794\n",
      "Epoch 855/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9791\n",
      "Epoch 856/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9789\n",
      "Epoch 857/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.9786\n",
      "Epoch 858/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 5.9784\n",
      "Epoch 859/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.9782\n",
      "Epoch 860/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9778\n",
      "Epoch 861/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9776\n",
      "Epoch 862/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9774\n",
      "Epoch 863/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9771\n",
      "Epoch 864/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 5.9770\n",
      "Epoch 865/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 5.9767\n",
      "Epoch 866/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 5.9764\n",
      "Epoch 867/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.9761\n",
      "Epoch 868/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 5.9759\n",
      "Epoch 869/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9757\n",
      "Epoch 870/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9756\n",
      "Epoch 871/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.9755\n",
      "Epoch 872/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 5.9754\n",
      "Epoch 873/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.9752\n",
      "Epoch 874/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 5.9752\n",
      "Epoch 875/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9750\n",
      "Epoch 876/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9749\n",
      "Epoch 877/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9749\n",
      "Epoch 878/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9748\n",
      "Epoch 879/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9747\n",
      "Epoch 880/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9746\n",
      "Epoch 881/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9744\n",
      "Epoch 882/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 5.9743\n",
      "Epoch 883/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 5.9742\n",
      "Epoch 884/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 5.9741\n",
      "Epoch 885/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 5.9740\n",
      "Epoch 886/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.9739\n",
      "Epoch 887/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.9739\n",
      "Epoch 888/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9739\n",
      "Epoch 889/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9738\n",
      "Epoch 890/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 5.9737\n",
      "Epoch 891/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9737\n",
      "Epoch 892/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9736\n",
      "Epoch 893/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 5.9735\n",
      "Epoch 894/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9734\n",
      "Epoch 895/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9733\n",
      "Epoch 896/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9733\n",
      "Epoch 897/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9732\n",
      "Epoch 898/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9731\n",
      "Epoch 899/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9730\n",
      "Epoch 900/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 5.9729\n",
      "Epoch 901/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 5.9729\n",
      "Epoch 902/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.9729\n",
      "Epoch 903/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.9729\n",
      "Epoch 904/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9728\n",
      "Epoch 905/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9728\n",
      "Epoch 906/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9728\n",
      "Epoch 907/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9727\n",
      "Epoch 908/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 5.9727\n",
      "Epoch 909/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 5.9726\n",
      "Epoch 910/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.9726\n",
      "Epoch 911/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9727\n",
      "Epoch 912/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 5.9726\n",
      "Epoch 913/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9726\n",
      "Epoch 914/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 5.9727\n",
      "Epoch 915/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9726\n",
      "Epoch 916/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9726\n",
      "Epoch 917/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9726\n",
      "Epoch 918/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9726\n",
      "Epoch 919/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 5.9726\n",
      "Epoch 920/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 5.9725\n",
      "Epoch 921/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 5.9725\n",
      "Epoch 922/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 5.9724\n",
      "Epoch 923/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 5.9725\n",
      "Epoch 924/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9724\n",
      "Epoch 925/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.9724\n",
      "Epoch 926/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9724\n",
      "Epoch 927/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9724\n",
      "Epoch 928/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9724\n",
      "Epoch 929/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9723\n",
      "Epoch 930/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 5.9724\n",
      "Epoch 931/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9724\n",
      "Epoch 932/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.9724\n",
      "Epoch 933/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.9723\n",
      "Epoch 934/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 5.9723\n",
      "Epoch 935/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 5.9723\n",
      "Epoch 936/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9722\n",
      "Epoch 937/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9722\n",
      "Epoch 938/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 5.9722\n",
      "Epoch 939/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9723\n",
      "Epoch 940/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 5.9722\n",
      "Epoch 941/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9722\n",
      "Epoch 942/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 5.9721\n",
      "Epoch 943/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9722\n",
      "Epoch 944/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.9722\n",
      "Epoch 945/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.9721\n",
      "Epoch 946/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9722\n",
      "Epoch 947/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9721\n",
      "Epoch 948/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9722\n",
      "Epoch 949/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9722\n",
      "Epoch 950/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9721\n",
      "Epoch 951/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9721\n",
      "Epoch 952/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.9721\n",
      "Epoch 953/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 5.9722\n",
      "Epoch 954/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 5.9721\n",
      "Epoch 955/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 5.9721\n",
      "Epoch 956/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 5.9721\n",
      "Epoch 957/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 5.9723\n",
      "Epoch 958/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 5.9722\n",
      "Epoch 959/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.9722\n",
      "Epoch 960/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.9721\n",
      "Epoch 961/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.9722\n",
      "Epoch 962/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9721\n",
      "Epoch 963/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 5.9721\n",
      "Epoch 964/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9722\n",
      "Epoch 965/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 5.9721\n",
      "Epoch 966/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 5.9721\n",
      "Epoch 967/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9721\n",
      "Epoch 968/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9721\n",
      "Epoch 969/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9721\n",
      "Epoch 970/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9721\n",
      "Epoch 971/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9721\n",
      "Epoch 972/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9721\n",
      "Epoch 973/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9721\n",
      "Epoch 974/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 5.9720\n",
      "Epoch 975/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 5.9721\n",
      "Epoch 976/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 5.9721\n",
      "Epoch 977/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.9721\n",
      "Epoch 978/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9721\n",
      "Epoch 979/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.9721\n",
      "Epoch 980/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9721\n",
      "Epoch 981/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9722\n",
      "Epoch 982/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9721\n",
      "Epoch 983/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9721\n",
      "Epoch 984/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9721\n",
      "Epoch 985/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9721\n",
      "Epoch 986/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 5.9720\n",
      "Epoch 987/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9720\n",
      "Epoch 988/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9721\n",
      "Epoch 989/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.9721\n",
      "Epoch 990/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9721\n",
      "Epoch 991/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9721\n",
      "Epoch 992/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9721\n",
      "Epoch 993/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 5.9721\n",
      "Epoch 994/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 5.9721\n",
      "Epoch 995/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 5.9721\n",
      "Epoch 996/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 5.9721\n",
      "Epoch 997/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 5.9721\n",
      "Epoch 998/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9721\n",
      "Epoch 999/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.9721\n",
      "Epoch 1000/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9721\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a4c89f860>"
      ]
     },
     "execution_count": 1094,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model = Sequential()\n",
    "NN_model.add(Dense(units=16,input_dim= X_train.shape[1],activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_model.add(Dense(units=8, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_model.add(Dense(units=4, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_model.add(Dense(units=1,activation='linear'))\n",
    "NN_model.compile(loss='mse', optimizer='adam')\n",
    "NN_model.fit(np.array(X_train), np.array(y_train), epochs=1000,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1095,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a4c810898>"
      ]
     },
     "execution_count": 1095,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_predictions = NN_model.predict(X_train)\n",
    "training = pd.DataFrame(training_predictions)\n",
    "training['actual'] = y_train.reset_index()['rebounds']\n",
    "plt.scatter(training_predictions,training[0]-training['actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1096,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = NN_model.predict(X_test)\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.5)\n",
    "gbr.fit(X_train,y_train)\n",
    "gbr_predictions = gbr.predict(X_test)\n",
    "LR = LinearRegression(fit_intercept=True).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1097,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = pd.DataFrame(predictions)\n",
    "testing.columns=['NN_predictions']\n",
    "testing['actual'] = y_test.reset_index()['rebounds']\n",
    "testing['GBR_predictions']=gbr_predictions\n",
    "testing['LY_rebounding']=X_test['rebounds_ly'].reset_index()['rebounds_ly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a38ecf588>]"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(figsize=(16,8))\n",
    "plt.plot(testing[0:100].index,testing['actual'][0:100], color = 'r',alpha = 0.5)\n",
    "plt.plot(testing[0:100].index,testing['NN_predictions'][0:100], color = 'g',alpha = 0.2)\n",
    "#plt.scatter(testing[0:100].index,testing['LY_rebounding'][0:100],color = 'b',alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1098,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2017rebounds = rebounds[rebounds['season']==2017].drop(['team','player','rebounds','Games'],axis=1)\n",
    "rebounds_2017 = NN_model.predict(pred_2017rebounds)\n",
    "test_2 =pd.DataFrame(rebounds_2017)\n",
    "gbr_reb_2017 = pd.DataFrame(gbr.predict(pred_2017rebounds))\n",
    "LR_reb_2017 = pd.DataFrame(LR.predict(pred_2017rebounds))\n",
    "test_3 = pd.merge(rebounds,pred_2017rebounds,left_index=True,right_index=True).reset_index()\n",
    "test_3['predictions']=test_2[0]\n",
    "test_3['gbr_pred'] = gbr_reb_2017[0]\n",
    "test_3['LR_pred'] = LR_reb_2017[0]\n",
    "test_3['mean_pred'] = (test_3['predictions']+test_3['gbr_pred']+test_3['LR_pred'])/3\n",
    "test_3 = test_3[test_3['Games']>30]\n",
    "test_3[['player','rebounds','rebounds_ly_x','predictions','gbr_pred','LR_pred','mean_pred']].sort_values(by='rebounds_ly_x',ascending=False)[50:100]\n",
    "\n",
    "rebounds_2017 = test_3[['player','LR_pred']]\n",
    "rebounds_2017.columns = ['player','rebound_prediction']\n",
    "df_2017 = pd.merge(df_2017,rebounds_2017, how='left',left_on='player',right_on='player')\n",
    "#df_2017.drop(['rebound_prediction_x','rebound_prediction_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MSE using NN:{}'.format(np.mean((test_3['rebounds']-test_3['predictions'])**2)))\n",
    "print('MSE using mean:{}'.format(np.mean((test_3['rebounds']-np.mean(test_3['rebounds']))**2)))\n",
    "print('MSE using last year stats:{}'.format(np.mean((test_3['rebounds']-test_3['rebounds_ly_x'])**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1099,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE using NN:6.310436734856431\n",
      "MSE using mean:6.292553316074948\n",
      "MSE using last year stats:1.808012820512822\n",
      "MSE using gbr:1.3251446163562919\n",
      "MSE using LR:1.2835836799139877\n",
      "MSE using combo:1.8068446110195755\n"
     ]
    }
   ],
   "source": [
    "print('MSE using NN:{}'.format(np.mean((test_3['rebounds']-test_3['predictions'])**2)))\n",
    "print('MSE using mean:{}'.format(np.mean((test_3['rebounds']-np.mean(test_3['rebounds']))**2)))\n",
    "print('MSE using last year stats:{}'.format(np.mean((test_3['rebounds']-test_3['rebounds_ly_x'])**2)))\n",
    "print('MSE using gbr:{}'.format(np.mean((test_3['rebounds']-test_3['gbr_pred'])**2)))\n",
    "print('MSE using LR:{}'.format(np.mean((test_3['rebounds']-test_3['LR_pred'])**2)))\n",
    "print('MSE using combo:{}'.format(np.mean((test_3['rebounds']-test_3['mean_pred'])**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8111346 , 0.75668588, 0.78079755, 0.72744262, 0.75121757])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.5),X_train,y_train,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81701435, 0.79285298, 0.81098242, 0.80524023, 0.80300007])"
      ]
     },
     "execution_count": 1100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(LinearRegression(),X_train,y_train,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1101,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''next is assists'''\n",
    "\n",
    "\n",
    "query= '''\n",
    "        \n",
    "        DROP TABLE IF EXISTS assists_pred;\n",
    "        CREATE TABLE assists_pred(\n",
    "        season int, --these come from player_stats\n",
    "        player varchar(50),\n",
    "        Age int,\n",
    "        team varchar(50),\n",
    "        ast float, -- these come from player_stats\n",
    "        ast_ly float,\n",
    "        change_ast_ly float,\n",
    "        Games float,\n",
    "        C_PF int,\n",
    "        PG int,\n",
    "        SG_SF int,\n",
    "        starter_change int, \n",
    "        \n",
    "        -- these come from team_changes\n",
    "        high_usageplayer_added int,\n",
    "        usagemin_opened float,\n",
    "        maxusage_added float,\n",
    "        high_usageplayer_dropped int,\n",
    "        assists_opened float,\n",
    "        max_assistsdropped float,\n",
    "        max_assistsadded float,\n",
    "        points_opened float,\n",
    "        threes_opened float,\n",
    "        \n",
    "        -- from player_advstats\n",
    "        per_ly float,\n",
    "        change_per float,\n",
    "        usagerank float,\n",
    "        usagerank_ly float,\n",
    "        ast_perc_ly float,\n",
    "        change_assist_perc float,\n",
    "        offensive_winshares float,\n",
    "        offensive_boxplusminus float,\n",
    "        boxplusminus float,\n",
    "        value_overreplacement float,\n",
    "        \n",
    "        max_teammateast float,\n",
    "        max_teammate_usage float,\n",
    "        max_teammateto float,\n",
    "        max_teammateshot_attempts float,\n",
    "        \n",
    "        career_ast float,\n",
    "        yearspro int\n",
    "        );\n",
    "        \n",
    "        INSERT INTO assists_pred(season,player,age,team,ast,ast_ly,change_ast_ly,starter_change,Games,C_PF,PG,SG_SF)\n",
    "        SELECT season,player,age,startingteam,ast,ast_ly,change_ast_ly,starter-starter_ly,Games,\n",
    "        case when pos in ('C','PF') then 1 else 0 end,case when pos='PG' then 1 else 0 end,case when pos in('SG','SF') then 1 else 0 end from player_stats;\n",
    "        \n",
    "        update assists_pred ap\n",
    "        set high_usageplayer_added = tc.high_usageplayer_added,usagemin_opened=tc.usagemin_opened,\n",
    "        maxusage_added=tc.max_usageadded,high_usageplayer_dropped=tc.high_usageplayer_dropped,assists_opened=tc.ast_opened,\n",
    "        max_assistsdropped=tc.max_astdropped,max_assistsadded=tc.max_astadded,points_opened = tc.points_opened,threes_opened = tc.threes_opened\n",
    "        from team_changes tc\n",
    "        where tc.team = ap.team and ap.season=tc.season;\n",
    "        \n",
    "        update assists_pred ap\n",
    "        set per_ly=pa.per_ly,change_per=pa.change_per,usagerank=pa.usagerank,usagerank_ly=pa.usagerank_ly\n",
    "        ,ast_perc_ly = pa.ast_perc_ly,change_assist_perc = pa.change_assist_perc,offensive_winshares=pa.offensive_winshares,\n",
    "        offensive_boxplusminus=pa.offensive_boxplusminus,boxplusminus=pa.boxplusminus,value_overreplacement=pa.value_overreplacement\n",
    "        from player_advstats pa\n",
    "        where ap.player = pa.player and ap.season = pa.season and ap.team = pa.startingteam;\n",
    "        \n",
    "        update assists_pred ap\n",
    "        set max_teammateast = tm.max_teammateast,max_teammate_usage=tm.max_teammate_usage,max_teammateto=tm.max_teammateto,\n",
    "        max_teammateshot_attempts=tm.max_teammateshot_attempts\n",
    "        from teammate_maxes tm\n",
    "        where tm.season = ap.season and tm.player = ap.player;\n",
    "        \n",
    "        update assists_pred ap\n",
    "        set career_ast = pc.career_ast, yearspro = pc.yearspro\n",
    "        from player_careerstats pc\n",
    "        where ap.player = pc.player and ap.season = pc.season;\n",
    "        \n",
    "        \n",
    "        select * from assists_pred where season>2009\n",
    "        '''\n",
    "\n",
    "\n",
    "cur.execute(query)\n",
    "data = cur.fetchall()\n",
    "assists_df = pd.DataFrame(np.array(data))\n",
    "assists_df.columns = ['season','player','age','team','assists','assists_ly','change_assists_ly','Games','C_PF','PG','SG_SF','starter_change','high_usageplayer_added','usagemin_opened','maxusage_added','high_usageplayer_dropped','assists_opened','max_assistsdropped',\n",
    "                    'max_assistsadded','points_opened','threes_opened','per_ly','change_per','usagerank','usagerank_ly','ast_perc_ly','change_ast_perc','offensive_winshares','offensive_boxplusminus','boxplusminus','value_overreplacement'\n",
    "                      ,'max_teammateast','max_teammate_usage','max_teammateto','max_teammateshot_attempts','career_assists','yearspro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "assists_df['age_squared']=assists_df['age']*assists_df['age']\n",
    "assists = assists_df[assists_df['assists_ly'].notna()]\n",
    "for i in assists.columns:\n",
    "    if i not in(['player','team']):\n",
    "        assists[i]=pd.to_numeric(assists[i])\n",
    "assists = assists.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1103,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = assists[(assists['season']!=2017) & (assists['Games']>30)].drop(['player','team','assists','Games'],axis=1)\n",
    "y = assists[(assists['season']!=2017) & (assists['Games']>30)]['assists']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1564/1564 [==============================] - 4s 3ms/step - loss: 358414.0944\n",
      "Epoch 2/1000\n",
      "1564/1564 [==============================] - 0s 88us/step - loss: 105474.1111\n",
      "Epoch 3/1000\n",
      "1564/1564 [==============================] - 0s 85us/step - loss: 20594.1078\n",
      "Epoch 4/1000\n",
      "1564/1564 [==============================] - 0s 89us/step - loss: 2695.7679\n",
      "Epoch 5/1000\n",
      "1564/1564 [==============================] - 0s 87us/step - loss: 943.8340\n",
      "Epoch 6/1000\n",
      "1564/1564 [==============================] - 0s 85us/step - loss: 633.2143\n",
      "Epoch 7/1000\n",
      "1564/1564 [==============================] - 0s 82us/step - loss: 471.8396\n",
      "Epoch 8/1000\n",
      "1564/1564 [==============================] - 0s 81us/step - loss: 364.3458\n",
      "Epoch 9/1000\n",
      "1564/1564 [==============================] - 0s 93us/step - loss: 279.7499\n",
      "Epoch 10/1000\n",
      "1564/1564 [==============================] - 0s 87us/step - loss: 222.2310\n",
      "Epoch 11/1000\n",
      "1564/1564 [==============================] - 0s 89us/step - loss: 179.3289\n",
      "Epoch 12/1000\n",
      "1564/1564 [==============================] - 0s 84us/step - loss: 149.9508\n",
      "Epoch 13/1000\n",
      "1564/1564 [==============================] - 0s 84us/step - loss: 127.9951\n",
      "Epoch 14/1000\n",
      "1564/1564 [==============================] - 0s 87us/step - loss: 110.9456\n",
      "Epoch 15/1000\n",
      "1564/1564 [==============================] - 0s 84us/step - loss: 96.6345\n",
      "Epoch 16/1000\n",
      "1564/1564 [==============================] - 0s 82us/step - loss: 84.9343\n",
      "Epoch 17/1000\n",
      "1564/1564 [==============================] - 0s 91us/step - loss: 75.7258\n",
      "Epoch 18/1000\n",
      "1564/1564 [==============================] - 0s 79us/step - loss: 68.0063\n",
      "Epoch 19/1000\n",
      "1564/1564 [==============================] - 0s 84us/step - loss: 60.9749\n",
      "Epoch 20/1000\n",
      "1564/1564 [==============================] - 0s 83us/step - loss: 55.4308\n",
      "Epoch 21/1000\n",
      "1564/1564 [==============================] - 0s 81us/step - loss: 50.4682\n",
      "Epoch 22/1000\n",
      "1564/1564 [==============================] - 0s 81us/step - loss: 46.7528\n",
      "Epoch 23/1000\n",
      "1564/1564 [==============================] - 0s 79us/step - loss: 43.2066\n",
      "Epoch 24/1000\n",
      "1564/1564 [==============================] - 0s 81us/step - loss: 40.2765\n",
      "Epoch 25/1000\n",
      "1564/1564 [==============================] - 0s 85us/step - loss: 37.7469\n",
      "Epoch 26/1000\n",
      "1564/1564 [==============================] - 0s 83us/step - loss: 35.2008\n",
      "Epoch 27/1000\n",
      "1564/1564 [==============================] - 0s 87us/step - loss: 33.0131\n",
      "Epoch 28/1000\n",
      "1564/1564 [==============================] - 0s 87us/step - loss: 30.9368\n",
      "Epoch 29/1000\n",
      "1564/1564 [==============================] - 0s 83us/step - loss: 29.0745\n",
      "Epoch 30/1000\n",
      "1564/1564 [==============================] - 0s 81us/step - loss: 27.2663\n",
      "Epoch 31/1000\n",
      "1564/1564 [==============================] - 0s 80us/step - loss: 25.6549\n",
      "Epoch 32/1000\n",
      "1564/1564 [==============================] - 0s 86us/step - loss: 24.2403\n",
      "Epoch 33/1000\n",
      "1564/1564 [==============================] - 0s 83us/step - loss: 22.9249\n",
      "Epoch 34/1000\n",
      "1564/1564 [==============================] - 0s 81us/step - loss: 21.7194\n",
      "Epoch 35/1000\n",
      "1564/1564 [==============================] - 0s 81us/step - loss: 20.5531\n",
      "Epoch 36/1000\n",
      "1564/1564 [==============================] - 0s 82us/step - loss: 19.5590\n",
      "Epoch 37/1000\n",
      "1564/1564 [==============================] - 0s 84us/step - loss: 18.8407\n",
      "Epoch 38/1000\n",
      "1564/1564 [==============================] - 0s 83us/step - loss: 18.2515\n",
      "Epoch 39/1000\n",
      "1564/1564 [==============================] - 0s 82us/step - loss: 17.6107\n",
      "Epoch 40/1000\n",
      "1564/1564 [==============================] - 0s 87us/step - loss: 17.1064\n",
      "Epoch 41/1000\n",
      "1564/1564 [==============================] - 0s 90us/step - loss: 16.6627\n",
      "Epoch 42/1000\n",
      "1564/1564 [==============================] - 0s 84us/step - loss: 16.2307\n",
      "Epoch 43/1000\n",
      "1564/1564 [==============================] - 0s 83us/step - loss: 15.8449\n",
      "Epoch 44/1000\n",
      "1564/1564 [==============================] - 0s 83us/step - loss: 15.4779\n",
      "Epoch 45/1000\n",
      "1564/1564 [==============================] - 0s 83us/step - loss: 15.1288\n",
      "Epoch 46/1000\n",
      "1564/1564 [==============================] - 0s 85us/step - loss: 14.8263\n",
      "Epoch 47/1000\n",
      "1564/1564 [==============================] - 0s 94us/step - loss: 14.4859\n",
      "Epoch 48/1000\n",
      "1564/1564 [==============================] - 0s 81us/step - loss: 14.1690\n",
      "Epoch 49/1000\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 13.6298\n",
      "Epoch 50/1000\n",
      "1564/1564 [==============================] - 0s 81us/step - loss: 13.0841\n",
      "Epoch 51/1000\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 12.5965\n",
      "Epoch 52/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 12.2269\n",
      "Epoch 53/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 11.9546\n",
      "Epoch 54/1000\n",
      "1564/1564 [==============================] - 0s 76us/step - loss: 11.7096\n",
      "Epoch 55/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 11.4947\n",
      "Epoch 56/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 11.2839\n",
      "Epoch 57/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 11.1106\n",
      "Epoch 58/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 10.9309\n",
      "Epoch 59/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 10.7729\n",
      "Epoch 60/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 10.5944\n",
      "Epoch 61/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 10.4499\n",
      "Epoch 62/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 10.3164\n",
      "Epoch 63/1000\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 10.1889\n",
      "Epoch 64/1000\n",
      "1564/1564 [==============================] - 0s 76us/step - loss: 10.0681\n",
      "Epoch 65/1000\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 9.9314\n",
      "Epoch 66/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 9.8267\n",
      "Epoch 67/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 9.7082\n",
      "Epoch 68/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 9.6051\n",
      "Epoch 69/1000\n",
      "1564/1564 [==============================] - 0s 77us/step - loss: 9.4945\n",
      "Epoch 70/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 9.4174\n",
      "Epoch 71/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 9.3084\n",
      "Epoch 72/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 9.2184\n",
      "Epoch 73/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 9.1218\n",
      "Epoch 74/1000\n",
      "1564/1564 [==============================] - 0s 80us/step - loss: 9.0416\n",
      "Epoch 75/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 8.9623\n",
      "Epoch 76/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 8.8834\n",
      "Epoch 77/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 8.8111\n",
      "Epoch 78/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 8.7381\n",
      "Epoch 79/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 8.6725\n",
      "Epoch 80/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 8.6275\n",
      "Epoch 81/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 8.5341\n",
      "Epoch 82/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 8.4831\n",
      "Epoch 83/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 8.4121\n",
      "Epoch 84/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 8.3602\n",
      "Epoch 85/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 8.3018\n",
      "Epoch 86/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 8.2472\n",
      "Epoch 87/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 8.2066\n",
      "Epoch 88/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 8.1499\n",
      "Epoch 89/1000\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 8.1034\n",
      "Epoch 90/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 8.0564\n",
      "Epoch 91/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 8.0081\n",
      "Epoch 92/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 7.9690\n",
      "Epoch 93/1000\n",
      "1564/1564 [==============================] - 0s 76us/step - loss: 7.9297\n",
      "Epoch 94/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 7.8894\n",
      "Epoch 95/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 7.8450\n",
      "Epoch 96/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 7.8146\n",
      "Epoch 97/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 7.7754\n",
      "Epoch 98/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 7.7477\n",
      "Epoch 99/1000\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 7.7153\n",
      "Epoch 100/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 7.6963\n",
      "Epoch 101/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 7.6639\n",
      "Epoch 102/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 7.6134\n",
      "Epoch 103/1000\n",
      "1564/1564 [==============================] - 0s 96us/step - loss: 7.5834\n",
      "Epoch 104/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 7.5510\n",
      "Epoch 105/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 7.5249\n",
      "Epoch 106/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 7.4911\n",
      "Epoch 107/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 7.4771\n",
      "Epoch 108/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 7.4358\n",
      "Epoch 109/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 7.4079\n",
      "Epoch 110/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 7.3901\n",
      "Epoch 111/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 7.3709\n",
      "Epoch 112/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 7.3504\n",
      "Epoch 113/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 7.3257\n",
      "Epoch 114/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 7.3179\n",
      "Epoch 115/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 7.3033\n",
      "Epoch 116/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 7.2579\n",
      "Epoch 117/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 7.2443\n",
      "Epoch 118/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 7.2161\n",
      "Epoch 119/1000\n",
      "1564/1564 [==============================] - 0s 77us/step - loss: 7.1926\n",
      "Epoch 120/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 7.1725\n",
      "Epoch 121/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 7.1665\n",
      "Epoch 122/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 7.1424\n",
      "Epoch 123/1000\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 7.1310\n",
      "Epoch 124/1000\n",
      "1564/1564 [==============================] - 0s 85us/step - loss: 7.0987\n",
      "Epoch 125/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 7.0890\n",
      "Epoch 126/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 7.0714\n",
      "Epoch 127/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 7.0636\n",
      "Epoch 128/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 7.0407\n",
      "Epoch 129/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 7.0451\n",
      "Epoch 130/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 7.0129\n",
      "Epoch 131/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 7.0012\n",
      "Epoch 132/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 7.0002\n",
      "Epoch 133/1000\n",
      "1564/1564 [==============================] - 0s 77us/step - loss: 6.9840\n",
      "Epoch 134/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 6.9741\n",
      "Epoch 135/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 6.9622\n",
      "Epoch 136/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 6.9428\n",
      "Epoch 137/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 6.9249\n",
      "Epoch 138/1000\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 6.9071\n",
      "Epoch 139/1000\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 6.9044\n",
      "Epoch 140/1000\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 6.8959\n",
      "Epoch 141/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 6.8794\n",
      "Epoch 142/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 6.8843\n",
      "Epoch 143/1000\n",
      "1564/1564 [==============================] - 0s 82us/step - loss: 6.8880\n",
      "Epoch 144/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 6.8633\n",
      "Epoch 145/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 6.8473\n",
      "Epoch 146/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 6.8303\n",
      "Epoch 147/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 6.8004\n",
      "Epoch 148/1000\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 6.7918\n",
      "Epoch 149/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 6.7841\n",
      "Epoch 150/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 6.7719\n",
      "Epoch 151/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 6.7601\n",
      "Epoch 152/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 6.7540\n",
      "Epoch 153/1000\n",
      "1564/1564 [==============================] - 0s 77us/step - loss: 6.7523\n",
      "Epoch 154/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 6.7301\n",
      "Epoch 155/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 6.7337\n",
      "Epoch 156/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 6.7268\n",
      "Epoch 157/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 6.6981\n",
      "Epoch 158/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 6.6900\n",
      "Epoch 159/1000\n",
      "1564/1564 [==============================] - 0s 77us/step - loss: 6.6987\n",
      "Epoch 160/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 6.6926\n",
      "Epoch 161/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 6.6614\n",
      "Epoch 162/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 6.6569\n",
      "Epoch 163/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 6.6444\n",
      "Epoch 164/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 6.6281\n",
      "Epoch 165/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 6.6224\n",
      "Epoch 166/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 6.5984\n",
      "Epoch 167/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 6.5869\n",
      "Epoch 168/1000\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 6.5792\n",
      "Epoch 169/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 6.5794\n",
      "Epoch 170/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 6.5673\n",
      "Epoch 171/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 6.5546\n",
      "Epoch 172/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 6.5330\n",
      "Epoch 173/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 6.5380\n",
      "Epoch 174/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 6.5295\n",
      "Epoch 175/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 6.5084\n",
      "Epoch 176/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 6.4851\n",
      "Epoch 177/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 6.4788\n",
      "Epoch 178/1000\n",
      "1564/1564 [==============================] - 0s 81us/step - loss: 6.4712\n",
      "Epoch 179/1000\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 6.4544\n",
      "Epoch 180/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 6.4434\n",
      "Epoch 181/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 6.4366\n",
      "Epoch 182/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 6.4517\n",
      "Epoch 183/1000\n",
      "1564/1564 [==============================] - 0s 77us/step - loss: 6.4761\n",
      "Epoch 184/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 6.4057\n",
      "Epoch 185/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 6.3917\n",
      "Epoch 186/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 6.3693\n",
      "Epoch 187/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 6.3809\n",
      "Epoch 188/1000\n",
      "1564/1564 [==============================] - 0s 81us/step - loss: 6.3520\n",
      "Epoch 189/1000\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 6.3552\n",
      "Epoch 190/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 6.3449\n",
      "Epoch 191/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 6.3058\n",
      "Epoch 192/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 6.2943\n",
      "Epoch 193/1000\n",
      "1564/1564 [==============================] - 0s 77us/step - loss: 6.2852\n",
      "Epoch 194/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 6.2811\n",
      "Epoch 195/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 6.2702\n",
      "Epoch 196/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 6.2577\n",
      "Epoch 197/1000\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 6.2494\n",
      "Epoch 198/1000\n",
      "1564/1564 [==============================] - 0s 80us/step - loss: 6.2206\n",
      "Epoch 199/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 6.2044\n",
      "Epoch 200/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 6.1916\n",
      "Epoch 201/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 6.1938\n",
      "Epoch 202/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 6.1996\n",
      "Epoch 203/1000\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 6.1395\n",
      "Epoch 204/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 6.1254\n",
      "Epoch 205/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 6.1218\n",
      "Epoch 206/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 6.0990\n",
      "Epoch 207/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 6.0850\n",
      "Epoch 208/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 6.0966\n",
      "Epoch 209/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 6.0716\n",
      "Epoch 210/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 6.0754\n",
      "Epoch 211/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 6.0817\n",
      "Epoch 212/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 6.0103\n",
      "Epoch 213/1000\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 6.0247\n",
      "Epoch 214/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 5.9828\n",
      "Epoch 215/1000\n",
      "1564/1564 [==============================] - 0s 76us/step - loss: 5.9717\n",
      "Epoch 216/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 5.9593\n",
      "Epoch 217/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 5.9307\n",
      "Epoch 218/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 5.9399\n",
      "Epoch 219/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 5.9296\n",
      "Epoch 220/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 5.8951\n",
      "Epoch 221/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 5.8735\n",
      "Epoch 222/1000\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 5.8572\n",
      "Epoch 223/1000\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 5.8645\n",
      "Epoch 224/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 5.8387\n",
      "Epoch 225/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 5.8029\n",
      "Epoch 226/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 5.7921\n",
      "Epoch 227/1000\n",
      "1564/1564 [==============================] - 0s 82us/step - loss: 5.8035\n",
      "Epoch 228/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 5.7721\n",
      "Epoch 229/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 5.7626\n",
      "Epoch 230/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 5.7301\n",
      "Epoch 231/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 5.7094\n",
      "Epoch 232/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 5.6920\n",
      "Epoch 233/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 5.7162\n",
      "Epoch 234/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 5.6876\n",
      "Epoch 235/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 5.6770\n",
      "Epoch 236/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 5.6269\n",
      "Epoch 237/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 5.6178\n",
      "Epoch 238/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 5.6007\n",
      "Epoch 239/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 5.6333\n",
      "Epoch 240/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 5.5590\n",
      "Epoch 241/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 5.5463\n",
      "Epoch 242/1000\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 5.5549\n",
      "Epoch 243/1000\n",
      "1564/1564 [==============================] - 0s 77us/step - loss: 5.5306\n",
      "Epoch 244/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 5.6571\n",
      "Epoch 245/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 5.5434\n",
      "Epoch 246/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 5.4577\n",
      "Epoch 247/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 5.4438\n",
      "Epoch 248/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 5.4148\n",
      "Epoch 249/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 5.4029\n",
      "Epoch 250/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 5.3858\n",
      "Epoch 251/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 5.3619\n",
      "Epoch 252/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 5.3515\n",
      "Epoch 253/1000\n",
      "1564/1564 [==============================] - 0s 90us/step - loss: 5.3293\n",
      "Epoch 254/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 5.3190\n",
      "Epoch 255/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 5.2934\n",
      "Epoch 256/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 5.2696\n",
      "Epoch 257/1000\n",
      "1564/1564 [==============================] - 0s 79us/step - loss: 5.2738\n",
      "Epoch 258/1000\n",
      "1564/1564 [==============================] - 0s 82us/step - loss: 5.2371\n",
      "Epoch 259/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 5.2332\n",
      "Epoch 260/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 5.2312\n",
      "Epoch 261/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 5.1789\n",
      "Epoch 262/1000\n",
      "1564/1564 [==============================] - 0s 89us/step - loss: 5.1696\n",
      "Epoch 263/1000\n",
      "1564/1564 [==============================] - 0s 102us/step - loss: 5.1751\n",
      "Epoch 264/1000\n",
      "1564/1564 [==============================] - 0s 97us/step - loss: 5.1225\n",
      "Epoch 265/1000\n",
      "1564/1564 [==============================] - 0s 80us/step - loss: 5.1122\n",
      "Epoch 266/1000\n",
      "1564/1564 [==============================] - 0s 80us/step - loss: 5.0877\n",
      "Epoch 267/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 5.0708\n",
      "Epoch 268/1000\n",
      "1564/1564 [==============================] - 0s 93us/step - loss: 5.0616\n",
      "Epoch 269/1000\n",
      "1564/1564 [==============================] - 0s 107us/step - loss: 5.0388\n",
      "Epoch 270/1000\n",
      "1564/1564 [==============================] - 0s 95us/step - loss: 5.0256\n",
      "Epoch 271/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 5.0387\n",
      "Epoch 272/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 5.0107\n",
      "Epoch 273/1000\n",
      "1564/1564 [==============================] - 0s 77us/step - loss: 5.0015\n",
      "Epoch 274/1000\n",
      "1564/1564 [==============================] - 0s 83us/step - loss: 4.9390\n",
      "Epoch 275/1000\n",
      "1564/1564 [==============================] - 0s 111us/step - loss: 4.9160\n",
      "Epoch 276/1000\n",
      "1564/1564 [==============================] - 0s 91us/step - loss: 4.9296\n",
      "Epoch 277/1000\n",
      "1564/1564 [==============================] - 0s 87us/step - loss: 4.8943\n",
      "Epoch 278/1000\n",
      "1564/1564 [==============================] - 0s 76us/step - loss: 4.8585\n",
      "Epoch 279/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 4.8448\n",
      "Epoch 280/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 4.8277\n",
      "Epoch 281/1000\n",
      "1564/1564 [==============================] - 0s 88us/step - loss: 4.8104\n",
      "Epoch 282/1000\n",
      "1564/1564 [==============================] - 0s 100us/step - loss: 4.7990\n",
      "Epoch 283/1000\n",
      "1564/1564 [==============================] - 0s 87us/step - loss: 4.7758\n",
      "Epoch 284/1000\n",
      "1564/1564 [==============================] - 0s 97us/step - loss: 4.7667\n",
      "Epoch 285/1000\n",
      "1564/1564 [==============================] - 0s 91us/step - loss: 4.7288\n",
      "Epoch 286/1000\n",
      "1564/1564 [==============================] - 0s 88us/step - loss: 4.7474\n",
      "Epoch 287/1000\n",
      "1564/1564 [==============================] - 0s 94us/step - loss: 4.7288\n",
      "Epoch 288/1000\n",
      "1564/1564 [==============================] - 0s 87us/step - loss: 4.6754\n",
      "Epoch 289/1000\n",
      "1564/1564 [==============================] - 0s 89us/step - loss: 4.6975\n",
      "Epoch 290/1000\n",
      "1564/1564 [==============================] - 0s 88us/step - loss: 4.6736\n",
      "Epoch 291/1000\n",
      "1564/1564 [==============================] - 0s 98us/step - loss: 4.6275\n",
      "Epoch 292/1000\n",
      "1564/1564 [==============================] - 0s 95us/step - loss: 4.5998\n",
      "Epoch 293/1000\n",
      "1564/1564 [==============================] - 0s 97us/step - loss: 4.6001\n",
      "Epoch 294/1000\n",
      "1564/1564 [==============================] - 0s 97us/step - loss: 4.5718\n",
      "Epoch 295/1000\n",
      "1564/1564 [==============================] - 0s 109us/step - loss: 4.5482\n",
      "Epoch 296/1000\n",
      "1564/1564 [==============================] - 0s 109us/step - loss: 4.5253\n",
      "Epoch 297/1000\n",
      "1564/1564 [==============================] - 0s 93us/step - loss: 4.5138\n",
      "Epoch 298/1000\n",
      "1564/1564 [==============================] - 0s 89us/step - loss: 4.4960\n",
      "Epoch 299/1000\n",
      "1564/1564 [==============================] - 0s 99us/step - loss: 4.4740\n",
      "Epoch 300/1000\n",
      "1564/1564 [==============================] - 0s 126us/step - loss: 4.5223\n",
      "Epoch 301/1000\n",
      "1564/1564 [==============================] - 0s 109us/step - loss: 4.4487\n",
      "Epoch 302/1000\n",
      "1564/1564 [==============================] - 0s 103us/step - loss: 4.4289\n",
      "Epoch 303/1000\n",
      "1564/1564 [==============================] - 0s 112us/step - loss: 4.4247\n",
      "Epoch 304/1000\n",
      "1564/1564 [==============================] - 0s 108us/step - loss: 4.3906\n",
      "Epoch 305/1000\n",
      "1564/1564 [==============================] - 0s 91us/step - loss: 4.3838\n",
      "Epoch 306/1000\n",
      "1564/1564 [==============================] - 0s 96us/step - loss: 4.3676\n",
      "Epoch 307/1000\n",
      "1564/1564 [==============================] - 0s 87us/step - loss: 4.3631\n",
      "Epoch 308/1000\n",
      "1564/1564 [==============================] - 0s 91us/step - loss: 4.3257\n",
      "Epoch 309/1000\n",
      "1564/1564 [==============================] - 0s 83us/step - loss: 4.2990\n",
      "Epoch 310/1000\n",
      "1564/1564 [==============================] - 0s 86us/step - loss: 4.2808\n",
      "Epoch 311/1000\n",
      "1564/1564 [==============================] - 0s 95us/step - loss: 4.2709\n",
      "Epoch 312/1000\n",
      "1564/1564 [==============================] - 0s 94us/step - loss: 4.3100\n",
      "Epoch 313/1000\n",
      "1564/1564 [==============================] - 0s 89us/step - loss: 4.2596\n",
      "Epoch 314/1000\n",
      "1564/1564 [==============================] - 0s 85us/step - loss: 4.3051\n",
      "Epoch 315/1000\n",
      "1564/1564 [==============================] - 0s 94us/step - loss: 4.2513\n",
      "Epoch 316/1000\n",
      "1564/1564 [==============================] - 0s 86us/step - loss: 4.1888\n",
      "Epoch 317/1000\n",
      "1564/1564 [==============================] - 0s 80us/step - loss: 4.1894\n",
      "Epoch 318/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 4.1957\n",
      "Epoch 319/1000\n",
      "1564/1564 [==============================] - 0s 93us/step - loss: 4.1740\n",
      "Epoch 320/1000\n",
      "1564/1564 [==============================] - 0s 106us/step - loss: 4.1297\n",
      "Epoch 321/1000\n",
      "1564/1564 [==============================] - 0s 96us/step - loss: 4.1090\n",
      "Epoch 322/1000\n",
      "1564/1564 [==============================] - 0s 92us/step - loss: 4.1283\n",
      "Epoch 323/1000\n",
      "1564/1564 [==============================] - 0s 118us/step - loss: 4.0854\n",
      "Epoch 324/1000\n",
      "1564/1564 [==============================] - 0s 128us/step - loss: 4.1189\n",
      "Epoch 325/1000\n",
      "1564/1564 [==============================] - 0s 134us/step - loss: 4.0426\n",
      "Epoch 326/1000\n",
      "1564/1564 [==============================] - 0s 120us/step - loss: 4.0495\n",
      "Epoch 327/1000\n",
      "1564/1564 [==============================] - 0s 117us/step - loss: 4.0313\n",
      "Epoch 328/1000\n",
      "1564/1564 [==============================] - 0s 115us/step - loss: 4.0357\n",
      "Epoch 329/1000\n",
      "1564/1564 [==============================] - 0s 103us/step - loss: 4.0120\n",
      "Epoch 330/1000\n",
      "1564/1564 [==============================] - 0s 87us/step - loss: 3.9934\n",
      "Epoch 331/1000\n",
      "1564/1564 [==============================] - 0s 84us/step - loss: 4.0074\n",
      "Epoch 332/1000\n",
      "1564/1564 [==============================] - 0s 88us/step - loss: 3.9668\n",
      "Epoch 333/1000\n",
      "1564/1564 [==============================] - 0s 98us/step - loss: 3.9439\n",
      "Epoch 334/1000\n",
      "1564/1564 [==============================] - 0s 100us/step - loss: 3.9465\n",
      "Epoch 335/1000\n",
      "1564/1564 [==============================] - 0s 94us/step - loss: 3.9305\n",
      "Epoch 336/1000\n",
      "1564/1564 [==============================] - 0s 119us/step - loss: 3.9072\n",
      "Epoch 337/1000\n",
      "1564/1564 [==============================] - 0s 93us/step - loss: 3.8966\n",
      "Epoch 338/1000\n",
      "1564/1564 [==============================] - 0s 91us/step - loss: 3.8726\n",
      "Epoch 339/1000\n",
      "1564/1564 [==============================] - 0s 104us/step - loss: 3.8703\n",
      "Epoch 340/1000\n",
      "1564/1564 [==============================] - 0s 98us/step - loss: 3.8569\n",
      "Epoch 341/1000\n",
      "1564/1564 [==============================] - 0s 107us/step - loss: 3.8456\n",
      "Epoch 342/1000\n",
      "1564/1564 [==============================] - 0s 107us/step - loss: 3.8399\n",
      "Epoch 343/1000\n",
      "1564/1564 [==============================] - 0s 111us/step - loss: 3.8256\n",
      "Epoch 344/1000\n",
      "1564/1564 [==============================] - 0s 100us/step - loss: 3.9222\n",
      "Epoch 345/1000\n",
      "1564/1564 [==============================] - 0s 97us/step - loss: 3.8198\n",
      "Epoch 346/1000\n",
      "1564/1564 [==============================] - 0s 94us/step - loss: 3.7844\n",
      "Epoch 347/1000\n",
      "1564/1564 [==============================] - 0s 88us/step - loss: 3.7853\n",
      "Epoch 348/1000\n",
      "1564/1564 [==============================] - 0s 101us/step - loss: 3.7679\n",
      "Epoch 349/1000\n",
      "1564/1564 [==============================] - 0s 86us/step - loss: 3.7377\n",
      "Epoch 350/1000\n",
      "1564/1564 [==============================] - 0s 86us/step - loss: 3.7479\n",
      "Epoch 351/1000\n",
      "1564/1564 [==============================] - 0s 85us/step - loss: 3.7349\n",
      "Epoch 352/1000\n",
      "1564/1564 [==============================] - 0s 82us/step - loss: 3.7102\n",
      "Epoch 353/1000\n",
      "1564/1564 [==============================] - 0s 82us/step - loss: 3.6948\n",
      "Epoch 354/1000\n",
      "1564/1564 [==============================] - 0s 81us/step - loss: 3.6901\n",
      "Epoch 355/1000\n",
      "1564/1564 [==============================] - 0s 81us/step - loss: 3.6974\n",
      "Epoch 356/1000\n",
      "1564/1564 [==============================] - 0s 89us/step - loss: 3.6947\n",
      "Epoch 357/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 3.6840\n",
      "Epoch 358/1000\n",
      "1564/1564 [==============================] - 0s 81us/step - loss: 3.6468\n",
      "Epoch 359/1000\n",
      "1564/1564 [==============================] - 0s 83us/step - loss: 3.6671\n",
      "Epoch 360/1000\n",
      "1564/1564 [==============================] - 0s 77us/step - loss: 3.6364\n",
      "Epoch 361/1000\n",
      "1564/1564 [==============================] - 0s 77us/step - loss: 3.6496\n",
      "Epoch 362/1000\n",
      "1564/1564 [==============================] - 0s 80us/step - loss: 3.6284\n",
      "Epoch 363/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 3.6193\n",
      "Epoch 364/1000\n",
      "1564/1564 [==============================] - 0s 81us/step - loss: 3.6181\n",
      "Epoch 365/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 3.5865\n",
      "Epoch 366/1000\n",
      "1564/1564 [==============================] - 0s 79us/step - loss: 3.5777\n",
      "Epoch 367/1000\n",
      "1564/1564 [==============================] - 0s 87us/step - loss: 3.5704\n",
      "Epoch 368/1000\n",
      "1564/1564 [==============================] - 0s 97us/step - loss: 3.5645\n",
      "Epoch 369/1000\n",
      "1564/1564 [==============================] - 0s 102us/step - loss: 3.6067\n",
      "Epoch 370/1000\n",
      "1564/1564 [==============================] - 0s 89us/step - loss: 3.5843\n",
      "Epoch 371/1000\n",
      "1564/1564 [==============================] - 0s 98us/step - loss: 3.6079\n",
      "Epoch 372/1000\n",
      "1564/1564 [==============================] - 0s 87us/step - loss: 3.5639\n",
      "Epoch 373/1000\n",
      "1564/1564 [==============================] - 0s 88us/step - loss: 3.5336\n",
      "Epoch 374/1000\n",
      "1564/1564 [==============================] - 0s 93us/step - loss: 3.5279\n",
      "Epoch 375/1000\n",
      "1564/1564 [==============================] - 0s 87us/step - loss: 3.5252\n",
      "Epoch 376/1000\n",
      "1564/1564 [==============================] - 0s 90us/step - loss: 3.5180\n",
      "Epoch 377/1000\n",
      "1564/1564 [==============================] - 0s 92us/step - loss: 3.5026\n",
      "Epoch 378/1000\n",
      "1564/1564 [==============================] - 0s 101us/step - loss: 3.5047\n",
      "Epoch 379/1000\n",
      "1564/1564 [==============================] - 0s 85us/step - loss: 3.4929\n",
      "Epoch 380/1000\n",
      "1564/1564 [==============================] - 0s 86us/step - loss: 3.4963\n",
      "Epoch 381/1000\n",
      "1564/1564 [==============================] - 0s 85us/step - loss: 3.4883\n",
      "Epoch 382/1000\n",
      "1564/1564 [==============================] - 0s 89us/step - loss: 3.4917\n",
      "Epoch 383/1000\n",
      "1564/1564 [==============================] - 0s 90us/step - loss: 3.4658\n",
      "Epoch 384/1000\n",
      "1564/1564 [==============================] - 0s 90us/step - loss: 3.5452\n",
      "Epoch 385/1000\n",
      "1564/1564 [==============================] - 0s 85us/step - loss: 3.4949\n",
      "Epoch 386/1000\n",
      "1564/1564 [==============================] - 0s 83us/step - loss: 3.4905\n",
      "Epoch 387/1000\n",
      "1564/1564 [==============================] - 0s 84us/step - loss: 3.4926\n",
      "Epoch 388/1000\n",
      "1564/1564 [==============================] - 0s 81us/step - loss: 3.4541\n",
      "Epoch 389/1000\n",
      "1564/1564 [==============================] - 0s 81us/step - loss: 3.5194\n",
      "Epoch 390/1000\n",
      "1564/1564 [==============================] - 0s 80us/step - loss: 3.4635\n",
      "Epoch 391/1000\n",
      "1564/1564 [==============================] - 0s 81us/step - loss: 3.4359\n",
      "Epoch 392/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 3.4203\n",
      "Epoch 393/1000\n",
      "1564/1564 [==============================] - 0s 81us/step - loss: 3.4421\n",
      "Epoch 394/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 3.4323\n",
      "Epoch 395/1000\n",
      "1564/1564 [==============================] - 0s 76us/step - loss: 3.4141\n",
      "Epoch 396/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 3.4839\n",
      "Epoch 397/1000\n",
      "1564/1564 [==============================] - 0s 79us/step - loss: 3.4276\n",
      "Epoch 398/1000\n",
      "1564/1564 [==============================] - 0s 80us/step - loss: 3.4132\n",
      "Epoch 399/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 3.3991\n",
      "Epoch 400/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 3.4855\n",
      "Epoch 401/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 3.4315\n",
      "Epoch 402/1000\n",
      "1564/1564 [==============================] - 0s 84us/step - loss: 3.4311\n",
      "Epoch 403/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 3.3916\n",
      "Epoch 404/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 3.3939\n",
      "Epoch 405/1000\n",
      "1564/1564 [==============================] - 0s 76us/step - loss: 3.3850\n",
      "Epoch 406/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 3.3810\n",
      "Epoch 407/1000\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 3.4076\n",
      "Epoch 408/1000\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 3.4167\n",
      "Epoch 409/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 3.4214\n",
      "Epoch 410/1000\n",
      "1564/1564 [==============================] - 0s 79us/step - loss: 3.4038\n",
      "Epoch 411/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 3.3779\n",
      "Epoch 412/1000\n",
      "1564/1564 [==============================] - 0s 76us/step - loss: 3.3697\n",
      "Epoch 413/1000\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 3.3845\n",
      "Epoch 414/1000\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 3.3836\n",
      "Epoch 415/1000\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 3.3581\n",
      "Epoch 416/1000\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 3.3707\n",
      "Epoch 417/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 3.3626\n",
      "Epoch 418/1000\n",
      "1564/1564 [==============================] - 0s 84us/step - loss: 3.3587\n",
      "Epoch 419/1000\n",
      "1564/1564 [==============================] - 0s 86us/step - loss: 3.3709\n",
      "Epoch 420/1000\n",
      "1564/1564 [==============================] - 0s 87us/step - loss: 3.3769\n",
      "Epoch 421/1000\n",
      "1564/1564 [==============================] - 0s 91us/step - loss: 3.3523\n",
      "Epoch 422/1000\n",
      "1564/1564 [==============================] - 0s 80us/step - loss: 3.3541\n",
      "Epoch 423/1000\n",
      "1564/1564 [==============================] - 0s 87us/step - loss: 3.3636\n",
      "Epoch 424/1000\n",
      "1564/1564 [==============================] - 0s 91us/step - loss: 3.3512\n",
      "Epoch 425/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 3.3749\n",
      "Epoch 426/1000\n",
      "1564/1564 [==============================] - 0s 79us/step - loss: 3.3673\n",
      "Epoch 427/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 3.3607\n",
      "Epoch 428/1000\n",
      "1564/1564 [==============================] - 0s 84us/step - loss: 3.3971\n",
      "Epoch 429/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 3.3534\n",
      "Epoch 430/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 3.3470\n",
      "Epoch 431/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.3422\n",
      "Epoch 432/1000\n",
      "1564/1564 [==============================] - 0s 77us/step - loss: 3.3619\n",
      "Epoch 433/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.4088\n",
      "Epoch 434/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.3464\n",
      "Epoch 435/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 3.3505\n",
      "Epoch 436/1000\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 3.3371\n",
      "Epoch 437/1000\n",
      "1564/1564 [==============================] - 0s 88us/step - loss: 3.3607\n",
      "Epoch 438/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.3513\n",
      "Epoch 439/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.3749\n",
      "Epoch 440/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.3608\n",
      "Epoch 441/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.3690\n",
      "Epoch 442/1000\n",
      "1564/1564 [==============================] - 0s 76us/step - loss: 3.3518\n",
      "Epoch 443/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.3549\n",
      "Epoch 444/1000\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 3.3618\n",
      "Epoch 445/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 3.4192\n",
      "Epoch 446/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 3.3545\n",
      "Epoch 447/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 3.3530\n",
      "Epoch 448/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.3637\n",
      "Epoch 449/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.3927\n",
      "Epoch 450/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.3790\n",
      "Epoch 451/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.3811\n",
      "Epoch 452/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 3.3588\n",
      "Epoch 453/1000\n",
      "1564/1564 [==============================] - 0s 77us/step - loss: 3.3520\n",
      "Epoch 454/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 3.3560\n",
      "Epoch 455/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 3.3358\n",
      "Epoch 456/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 3.3349\n",
      "Epoch 457/1000\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 3.3371\n",
      "Epoch 458/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.3444\n",
      "Epoch 459/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.3685\n",
      "Epoch 460/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.3557\n",
      "Epoch 461/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.3468\n",
      "Epoch 462/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 3.3390\n",
      "Epoch 463/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 3.3421\n",
      "Epoch 464/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 3.3297\n",
      "Epoch 465/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 3.3478\n",
      "Epoch 466/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 3.3773\n",
      "Epoch 467/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 3.3558\n",
      "Epoch 468/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.3460\n",
      "Epoch 469/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 3.3662\n",
      "Epoch 470/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.3541\n",
      "Epoch 471/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 3.3776\n",
      "Epoch 472/1000\n",
      "1564/1564 [==============================] - 0s 79us/step - loss: 3.3522\n",
      "Epoch 473/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 3.3480\n",
      "Epoch 474/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 3.3633\n",
      "Epoch 475/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.3569\n",
      "Epoch 476/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.3563\n",
      "Epoch 477/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 3.3663\n",
      "Epoch 478/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.3566\n",
      "Epoch 479/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 3.3504\n",
      "Epoch 480/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.3588\n",
      "Epoch 481/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.3481\n",
      "Epoch 482/1000\n",
      "1564/1564 [==============================] - 0s 85us/step - loss: 3.3468\n",
      "Epoch 483/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 3.3557\n",
      "Epoch 484/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 3.3562\n",
      "Epoch 485/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 3.3521\n",
      "Epoch 486/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.3748\n",
      "Epoch 487/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 3.3617\n",
      "Epoch 488/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.3577\n",
      "Epoch 489/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.3413\n",
      "Epoch 490/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.3553\n",
      "Epoch 491/1000\n",
      "1564/1564 [==============================] - 0s 88us/step - loss: 3.3453\n",
      "Epoch 492/1000\n",
      "1564/1564 [==============================] - 0s 77us/step - loss: 3.3675\n",
      "Epoch 493/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 3.3611\n",
      "Epoch 494/1000\n",
      "1564/1564 [==============================] - 0s 76us/step - loss: 3.3403\n",
      "Epoch 495/1000\n",
      "1564/1564 [==============================] - 0s 79us/step - loss: 3.3702\n",
      "Epoch 496/1000\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 3.3367\n",
      "Epoch 497/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 3.3840\n",
      "Epoch 498/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.3394\n",
      "Epoch 499/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.3575\n",
      "Epoch 500/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 3.3405\n",
      "Epoch 501/1000\n",
      "1564/1564 [==============================] - 0s 90us/step - loss: 3.3464\n",
      "Epoch 502/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.3599\n",
      "Epoch 503/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.3424\n",
      "Epoch 504/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.3673\n",
      "Epoch 505/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.3977\n",
      "Epoch 506/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 3.3534\n",
      "Epoch 507/1000\n",
      "1564/1564 [==============================] - 0s 80us/step - loss: 3.3489\n",
      "Epoch 508/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.3344\n",
      "Epoch 509/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 3.3341\n",
      "Epoch 510/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 3.3287\n",
      "Epoch 511/1000\n",
      "1564/1564 [==============================] - 0s 80us/step - loss: 3.3281\n",
      "Epoch 512/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.3290\n",
      "Epoch 513/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.3322\n",
      "Epoch 514/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.3683\n",
      "Epoch 515/1000\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 3.3336\n",
      "Epoch 516/1000\n",
      "1564/1564 [==============================] - 0s 76us/step - loss: 3.3254\n",
      "Epoch 517/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.3239\n",
      "Epoch 518/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 3.3365\n",
      "Epoch 519/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 3.3315\n",
      "Epoch 520/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 3.3663\n",
      "Epoch 521/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 3.3325\n",
      "Epoch 522/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.3279\n",
      "Epoch 523/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.3290\n",
      "Epoch 524/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.3345\n",
      "Epoch 525/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 3.3353\n",
      "Epoch 526/1000\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 3.3705\n",
      "Epoch 527/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 3.3405\n",
      "Epoch 528/1000\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 3.3459\n",
      "Epoch 529/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 3.3694\n",
      "Epoch 530/1000\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 3.3278\n",
      "Epoch 531/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 3.3555\n",
      "Epoch 532/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.3586\n",
      "Epoch 533/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.3343\n",
      "Epoch 534/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 3.3320\n",
      "Epoch 535/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 3.3572\n",
      "Epoch 536/1000\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 3.3656\n",
      "Epoch 537/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 3.3329\n",
      "Epoch 538/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 3.3345\n",
      "Epoch 539/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 3.3318\n",
      "Epoch 540/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 3.3387\n",
      "Epoch 541/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 3.3485\n",
      "Epoch 542/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.3372\n",
      "Epoch 543/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.3418\n",
      "Epoch 544/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.3269\n",
      "Epoch 545/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 3.3524\n",
      "Epoch 546/1000\n",
      "1564/1564 [==============================] - 0s 84us/step - loss: 3.3792\n",
      "Epoch 547/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 3.3450\n",
      "Epoch 548/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 3.3314\n",
      "Epoch 549/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.3264\n",
      "Epoch 550/1000\n",
      "1564/1564 [==============================] - 0s 79us/step - loss: 3.3448\n",
      "Epoch 551/1000\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 3.3873\n",
      "Epoch 552/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 3.4316\n",
      "Epoch 553/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.4645\n",
      "Epoch 554/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.3691\n",
      "Epoch 555/1000\n",
      "1564/1564 [==============================] - 0s 77us/step - loss: 3.3434\n",
      "Epoch 556/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 3.3552\n",
      "Epoch 557/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 3.3457\n",
      "Epoch 558/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.3577\n",
      "Epoch 559/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.3454\n",
      "Epoch 560/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 3.3407\n",
      "Epoch 561/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 3.3461\n",
      "Epoch 562/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.3397\n",
      "Epoch 563/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.3555\n",
      "Epoch 564/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 3.3498\n",
      "Epoch 565/1000\n",
      "1564/1564 [==============================] - 0s 81us/step - loss: 3.3643\n",
      "Epoch 566/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 3.3592\n",
      "Epoch 567/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.3775\n",
      "Epoch 568/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.3629\n",
      "Epoch 569/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.3584\n",
      "Epoch 570/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 3.3593\n",
      "Epoch 571/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 3.3473\n",
      "Epoch 572/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.3420\n",
      "Epoch 573/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.3439\n",
      "Epoch 574/1000\n",
      "1564/1564 [==============================] - 0s 90us/step - loss: 3.3390\n",
      "Epoch 575/1000\n",
      "1564/1564 [==============================] - 0s 84us/step - loss: 3.3419\n",
      "Epoch 576/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 3.3490\n",
      "Epoch 577/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 3.3395\n",
      "Epoch 578/1000\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 3.3405\n",
      "Epoch 579/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 3.3907\n",
      "Epoch 580/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 3.3491\n",
      "Epoch 581/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.3383\n",
      "Epoch 582/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 3.3415\n",
      "Epoch 583/1000\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 3.3515\n",
      "Epoch 584/1000\n",
      "1564/1564 [==============================] - 0s 81us/step - loss: 3.3446\n",
      "Epoch 585/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.3382\n",
      "Epoch 586/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.3791\n",
      "Epoch 587/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.3257\n",
      "Epoch 588/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 3.3487\n",
      "Epoch 589/1000\n",
      "1564/1564 [==============================] - 0s 79us/step - loss: 3.3673\n",
      "Epoch 590/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 3.3499\n",
      "Epoch 591/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 3.3890\n",
      "Epoch 592/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 3.3725\n",
      "Epoch 593/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 3.3460\n",
      "Epoch 594/1000\n",
      "1564/1564 [==============================] - 0s 79us/step - loss: 3.3445\n",
      "Epoch 595/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 3.3457\n",
      "Epoch 596/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.3328\n",
      "Epoch 597/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.3604\n",
      "Epoch 598/1000\n",
      "1564/1564 [==============================] - 0s 77us/step - loss: 3.3413\n",
      "Epoch 599/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.3553\n",
      "Epoch 600/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.3376\n",
      "Epoch 601/1000\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 3.3269\n",
      "Epoch 602/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 3.3437\n",
      "Epoch 603/1000\n",
      "1564/1564 [==============================] - 0s 76us/step - loss: 3.3380\n",
      "Epoch 604/1000\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 3.3374\n",
      "Epoch 605/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.3567\n",
      "Epoch 606/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.3495\n",
      "Epoch 607/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 3.3430\n",
      "Epoch 608/1000\n",
      "1564/1564 [==============================] - 0s 77us/step - loss: 3.4051\n",
      "Epoch 609/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.3937\n",
      "Epoch 610/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 3.3818\n",
      "Epoch 611/1000\n",
      "1564/1564 [==============================] - 0s 79us/step - loss: 3.3869\n",
      "Epoch 612/1000\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 3.3916\n",
      "Epoch 613/1000\n",
      "1564/1564 [==============================] - 0s 79us/step - loss: 3.3919\n",
      "Epoch 614/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.3903\n",
      "Epoch 615/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.4021\n",
      "Epoch 616/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 3.4242\n",
      "Epoch 617/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.4078\n",
      "Epoch 618/1000\n",
      "1564/1564 [==============================] - 0s 76us/step - loss: 3.4119\n",
      "Epoch 619/1000\n",
      "1564/1564 [==============================] - 0s 80us/step - loss: 3.3895\n",
      "Epoch 620/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.4146\n",
      "Epoch 621/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 3.3863\n",
      "Epoch 622/1000\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 3.3796\n",
      "Epoch 623/1000\n",
      "1564/1564 [==============================] - 0s 79us/step - loss: 3.3869\n",
      "Epoch 624/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 3.3817\n",
      "Epoch 625/1000\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 3.4063\n",
      "Epoch 626/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 3.3966\n",
      "Epoch 627/1000\n",
      "1564/1564 [==============================] - 0s 77us/step - loss: 3.3918\n",
      "Epoch 628/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 3.3856\n",
      "Epoch 629/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 3.3834\n",
      "Epoch 630/1000\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 3.3965\n",
      "Epoch 631/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.4241\n",
      "Epoch 632/1000\n",
      "1564/1564 [==============================] - 0s 76us/step - loss: 3.3884\n",
      "Epoch 633/1000\n",
      "1564/1564 [==============================] - 0s 79us/step - loss: 3.3807\n",
      "Epoch 634/1000\n",
      "1564/1564 [==============================] - 0s 82us/step - loss: 3.3796\n",
      "Epoch 635/1000\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 3.3897\n",
      "Epoch 636/1000\n",
      "1564/1564 [==============================] - 0s 95us/step - loss: 3.3803\n",
      "Epoch 637/1000\n",
      "1564/1564 [==============================] - 0s 84us/step - loss: 3.3850\n",
      "Epoch 638/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 3.4294\n",
      "Epoch 639/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 3.4093\n",
      "Epoch 640/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 3.3840\n",
      "Epoch 641/1000\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 3.3832\n",
      "Epoch 642/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 3.3908\n",
      "Epoch 643/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.3851\n",
      "Epoch 644/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.4014\n",
      "Epoch 645/1000\n",
      "1564/1564 [==============================] - 0s 76us/step - loss: 3.3917\n",
      "Epoch 646/1000\n",
      "1564/1564 [==============================] - 0s 76us/step - loss: 3.3852\n",
      "Epoch 647/1000\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 3.3877\n",
      "Epoch 648/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 3.3827\n",
      "Epoch 649/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.4024\n",
      "Epoch 650/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 3.3815\n",
      "Epoch 651/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 3.3985\n",
      "Epoch 652/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.4077\n",
      "Epoch 653/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.3991\n",
      "Epoch 654/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.4012\n",
      "Epoch 655/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 3.3839\n",
      "Epoch 656/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 3.3832\n",
      "Epoch 657/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.3833\n",
      "Epoch 658/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.4052\n",
      "Epoch 659/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.3904\n",
      "Epoch 660/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 3.4410\n",
      "Epoch 661/1000\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 3.3972\n",
      "Epoch 662/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 3.3879\n",
      "Epoch 663/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.3951\n",
      "Epoch 664/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 3.3796\n",
      "Epoch 665/1000\n",
      "1564/1564 [==============================] - 0s 77us/step - loss: 3.3933\n",
      "Epoch 666/1000\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 3.3959\n",
      "Epoch 667/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.3841\n",
      "Epoch 668/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.4087\n",
      "Epoch 669/1000\n",
      "1564/1564 [==============================] - 0s 77us/step - loss: 3.4092\n",
      "Epoch 670/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 3.4195\n",
      "Epoch 671/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.4477\n",
      "Epoch 672/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.4130\n",
      "Epoch 673/1000\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 3.4037\n",
      "Epoch 674/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 3.3939\n",
      "Epoch 675/1000\n",
      "1564/1564 [==============================] - 0s 80us/step - loss: 3.3900\n",
      "Epoch 676/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 3.3927\n",
      "Epoch 677/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.3855\n",
      "Epoch 678/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.3872\n",
      "Epoch 679/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 3.3862\n",
      "Epoch 680/1000\n",
      "1564/1564 [==============================] - 0s 77us/step - loss: 3.4243\n",
      "Epoch 681/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.3950\n",
      "Epoch 682/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 3.3845\n",
      "Epoch 683/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 3.3826\n",
      "Epoch 684/1000\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 3.3862\n",
      "Epoch 685/1000\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 3.3838\n",
      "Epoch 686/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 3.3779\n",
      "Epoch 687/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 3.3890\n",
      "Epoch 688/1000\n",
      "1564/1564 [==============================] - 0s 86us/step - loss: 3.4011\n",
      "Epoch 689/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 3.3807\n",
      "Epoch 690/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 3.3748\n",
      "Epoch 691/1000\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 3.3917\n",
      "Epoch 692/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.3786\n",
      "Epoch 693/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 3.3782\n",
      "Epoch 694/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 3.3687\n",
      "Epoch 695/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.4063\n",
      "Epoch 696/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.3892\n",
      "Epoch 697/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 3.3857\n",
      "Epoch 698/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 3.3818\n",
      "Epoch 699/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 3.3774\n",
      "Epoch 700/1000\n",
      "1564/1564 [==============================] - 0s 76us/step - loss: 3.3903\n",
      "Epoch 701/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 3.3741\n",
      "Epoch 702/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 3.3728\n",
      "Epoch 703/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 3.3831\n",
      "Epoch 704/1000\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 3.3690\n",
      "Epoch 705/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 3.3702\n",
      "Epoch 706/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.3875\n",
      "Epoch 707/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 3.3791\n",
      "Epoch 708/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 3.3646\n",
      "Epoch 709/1000\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 3.4393\n",
      "Epoch 710/1000\n",
      "1564/1564 [==============================] - 0s 83us/step - loss: 3.4440\n",
      "Epoch 711/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 3.2596\n",
      "Epoch 712/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 3.0626\n",
      "Epoch 713/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 2.6127\n",
      "Epoch 714/1000\n",
      "1564/1564 [==============================] - 0s 77us/step - loss: 2.2591\n",
      "Epoch 715/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 2.1117\n",
      "Epoch 716/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 1.9890\n",
      "Epoch 717/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 1.6615\n",
      "Epoch 718/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 1.5529\n",
      "Epoch 719/1000\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 1.4512\n",
      "Epoch 720/1000\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 1.3085\n",
      "Epoch 721/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 1.2800\n",
      "Epoch 722/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 1.2491\n",
      "Epoch 723/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 1.1468\n",
      "Epoch 724/1000\n",
      "1564/1564 [==============================] - 0s 77us/step - loss: 1.1403\n",
      "Epoch 725/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 1.0555\n",
      "Epoch 726/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 1.0256\n",
      "Epoch 727/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 1.0295\n",
      "Epoch 728/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 1.0858\n",
      "Epoch 729/1000\n",
      "1564/1564 [==============================] - 0s 77us/step - loss: 1.1941\n",
      "Epoch 730/1000\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 1.0624\n",
      "Epoch 731/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.9728\n",
      "Epoch 732/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.9265\n",
      "Epoch 733/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.9109\n",
      "Epoch 734/1000\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 0.9333\n",
      "Epoch 735/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 0.9511\n",
      "Epoch 736/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.9103\n",
      "Epoch 737/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.8761\n",
      "Epoch 738/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 0.8735\n",
      "Epoch 739/1000\n",
      "1564/1564 [==============================] - 0s 79us/step - loss: 0.8873\n",
      "Epoch 740/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.8506\n",
      "Epoch 741/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.9136\n",
      "Epoch 742/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 0.8494\n",
      "Epoch 743/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 0.8658\n",
      "Epoch 744/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 0.8148\n",
      "Epoch 745/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.8263\n",
      "Epoch 746/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.8109\n",
      "Epoch 747/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 0.8390\n",
      "Epoch 748/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 0.8036\n",
      "Epoch 749/1000\n",
      "1564/1564 [==============================] - 0s 84us/step - loss: 0.8216\n",
      "Epoch 750/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 0.8888\n",
      "Epoch 751/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.8522\n",
      "Epoch 752/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.8538\n",
      "Epoch 753/1000\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 0.8001\n",
      "Epoch 754/1000\n",
      "1564/1564 [==============================] - 0s 85us/step - loss: 0.7964\n",
      "Epoch 755/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 0.7856\n",
      "Epoch 756/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 0.7942\n",
      "Epoch 757/1000\n",
      "1564/1564 [==============================] - 0s 88us/step - loss: 0.7719\n",
      "Epoch 758/1000\n",
      "1564/1564 [==============================] - 0s 82us/step - loss: 0.7778\n",
      "Epoch 759/1000\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 0.8193\n",
      "Epoch 760/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.7790\n",
      "Epoch 761/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.7740\n",
      "Epoch 762/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 0.7841\n",
      "Epoch 763/1000\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 0.8049\n",
      "Epoch 764/1000\n",
      "1564/1564 [==============================] - 0s 86us/step - loss: 0.8024\n",
      "Epoch 765/1000\n",
      "1564/1564 [==============================] - 0s 81us/step - loss: 0.7620\n",
      "Epoch 766/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 0.7525\n",
      "Epoch 767/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 0.8047\n",
      "Epoch 768/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.7694\n",
      "Epoch 769/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.7622\n",
      "Epoch 770/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.7974\n",
      "Epoch 771/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.7596\n",
      "Epoch 772/1000\n",
      "1564/1564 [==============================] - 0s 76us/step - loss: 0.7513\n",
      "Epoch 773/1000\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 0.7745\n",
      "Epoch 774/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 0.7666\n",
      "Epoch 775/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 0.7705\n",
      "Epoch 776/1000\n",
      "1564/1564 [==============================] - 0s 77us/step - loss: 0.7531\n",
      "Epoch 777/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 0.7741\n",
      "Epoch 778/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.7808\n",
      "Epoch 779/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.7565\n",
      "Epoch 780/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.7653\n",
      "Epoch 781/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.7515\n",
      "Epoch 782/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 0.7535\n",
      "Epoch 783/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 0.7464\n",
      "Epoch 784/1000\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 0.7487\n",
      "Epoch 785/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 0.7477\n",
      "Epoch 786/1000\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 0.7281\n",
      "Epoch 787/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 0.7419\n",
      "Epoch 788/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.7476\n",
      "Epoch 789/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 0.7364\n",
      "Epoch 790/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 0.7529\n",
      "Epoch 791/1000\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 0.7367\n",
      "Epoch 792/1000\n",
      "1564/1564 [==============================] - 0s 95us/step - loss: 0.7456\n",
      "Epoch 793/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 0.7919\n",
      "Epoch 794/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.7626\n",
      "Epoch 795/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.7502\n",
      "Epoch 796/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 0.7249\n",
      "Epoch 797/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.7274\n",
      "Epoch 798/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.7416\n",
      "Epoch 799/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.7415\n",
      "Epoch 800/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.8198\n",
      "Epoch 801/1000\n",
      "1564/1564 [==============================] - 0s 82us/step - loss: 0.8556\n",
      "Epoch 802/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.7232\n",
      "Epoch 803/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.7360\n",
      "Epoch 804/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 0.7465\n",
      "Epoch 805/1000\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 0.7401\n",
      "Epoch 806/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.7329\n",
      "Epoch 807/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 0.7447\n",
      "Epoch 808/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.7659\n",
      "Epoch 809/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 0.7244\n",
      "Epoch 810/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 0.7360\n",
      "Epoch 811/1000\n",
      "1564/1564 [==============================] - 0s 81us/step - loss: 0.7213\n",
      "Epoch 812/1000\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 0.7164\n",
      "Epoch 813/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.7220\n",
      "Epoch 814/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.7359\n",
      "Epoch 815/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.8917\n",
      "Epoch 816/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 0.7502\n",
      "Epoch 817/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 0.7355\n",
      "Epoch 818/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.7244\n",
      "Epoch 819/1000\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 0.7233\n",
      "Epoch 820/1000\n",
      "1564/1564 [==============================] - 0s 84us/step - loss: 0.7486\n",
      "Epoch 821/1000\n",
      "1564/1564 [==============================] - 0s 77us/step - loss: 0.7647\n",
      "Epoch 822/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.8083\n",
      "Epoch 823/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.7674\n",
      "Epoch 824/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.7335\n",
      "Epoch 825/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.7379\n",
      "Epoch 826/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 0.7970\n",
      "Epoch 827/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.7298\n",
      "Epoch 828/1000\n",
      "1564/1564 [==============================] - 0s 80us/step - loss: 0.7404\n",
      "Epoch 829/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.7236\n",
      "Epoch 830/1000\n",
      "1564/1564 [==============================] - 0s 80us/step - loss: 0.7620\n",
      "Epoch 831/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.7386\n",
      "Epoch 832/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.7216\n",
      "Epoch 833/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.7113\n",
      "Epoch 834/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.7518\n",
      "Epoch 835/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 0.7368\n",
      "Epoch 836/1000\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 0.7312\n",
      "Epoch 837/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.7349\n",
      "Epoch 838/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 0.7347\n",
      "Epoch 839/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.8037\n",
      "Epoch 840/1000\n",
      "1564/1564 [==============================] - 0s 81us/step - loss: 0.7396\n",
      "Epoch 841/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 0.7112\n",
      "Epoch 842/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 0.7218\n",
      "Epoch 843/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.7352\n",
      "Epoch 844/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 0.7202\n",
      "Epoch 845/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 0.7271\n",
      "Epoch 846/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.7205\n",
      "Epoch 847/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 0.7625\n",
      "Epoch 848/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 0.7094\n",
      "Epoch 849/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 0.7178\n",
      "Epoch 850/1000\n",
      "1564/1564 [==============================] - 0s 77us/step - loss: 0.7151\n",
      "Epoch 851/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.7352\n",
      "Epoch 852/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.7175\n",
      "Epoch 853/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 0.7169\n",
      "Epoch 854/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 0.7142\n",
      "Epoch 855/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 0.7090\n",
      "Epoch 856/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 0.7126\n",
      "Epoch 857/1000\n",
      "1564/1564 [==============================] - 0s 76us/step - loss: 0.7341\n",
      "Epoch 858/1000\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 0.7838\n",
      "Epoch 859/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 0.7061\n",
      "Epoch 860/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 0.7069\n",
      "Epoch 861/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.7724\n",
      "Epoch 862/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 0.7420\n",
      "Epoch 863/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.7307\n",
      "Epoch 864/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 0.7004\n",
      "Epoch 865/1000\n",
      "1564/1564 [==============================] - 0s 81us/step - loss: 0.7185\n",
      "Epoch 866/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 0.7364\n",
      "Epoch 867/1000\n",
      "1564/1564 [==============================] - 0s 76us/step - loss: 0.7949\n",
      "Epoch 868/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 0.7470\n",
      "Epoch 869/1000\n",
      "1564/1564 [==============================] - 0s 76us/step - loss: 0.7300\n",
      "Epoch 870/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 0.7286\n",
      "Epoch 871/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.6951\n",
      "Epoch 872/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.7056\n",
      "Epoch 873/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.7290\n",
      "Epoch 874/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 0.7590\n",
      "Epoch 875/1000\n",
      "1564/1564 [==============================] - 0s 92us/step - loss: 0.7547\n",
      "Epoch 876/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 0.7144\n",
      "Epoch 877/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.7217\n",
      "Epoch 878/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 0.7515\n",
      "Epoch 879/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 0.7255\n",
      "Epoch 880/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.7091\n",
      "Epoch 881/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 0.7265\n",
      "Epoch 882/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.7819\n",
      "Epoch 883/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.7718\n",
      "Epoch 884/1000\n",
      "1564/1564 [==============================] - 0s 83us/step - loss: 0.7149\n",
      "Epoch 885/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.7151\n",
      "Epoch 886/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.7078\n",
      "Epoch 887/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.7228\n",
      "Epoch 888/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.7135\n",
      "Epoch 889/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 0.6978\n",
      "Epoch 890/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.7252\n",
      "Epoch 891/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.7387\n",
      "Epoch 892/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.7207\n",
      "Epoch 893/1000\n",
      "1564/1564 [==============================] - 0s 76us/step - loss: 0.7264\n",
      "Epoch 894/1000\n",
      "1564/1564 [==============================] - 0s 77us/step - loss: 0.7108\n",
      "Epoch 895/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 0.7162\n",
      "Epoch 896/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 0.7453\n",
      "Epoch 897/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.7596\n",
      "Epoch 898/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.7391\n",
      "Epoch 899/1000\n",
      "1564/1564 [==============================] - 0s 77us/step - loss: 0.7026\n",
      "Epoch 900/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.7074\n",
      "Epoch 901/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.7128\n",
      "Epoch 902/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 0.7614\n",
      "Epoch 903/1000\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 0.7563\n",
      "Epoch 904/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 0.7017\n",
      "Epoch 905/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 0.7106\n",
      "Epoch 906/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.7189\n",
      "Epoch 907/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.7156\n",
      "Epoch 908/1000\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 0.7616\n",
      "Epoch 909/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 0.7275\n",
      "Epoch 910/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.7251\n",
      "Epoch 911/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 0.7178\n",
      "Epoch 912/1000\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 0.7017\n",
      "Epoch 913/1000\n",
      "1564/1564 [==============================] - 0s 87us/step - loss: 0.7110\n",
      "Epoch 914/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.7320\n",
      "Epoch 915/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.6998\n",
      "Epoch 916/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.7037\n",
      "Epoch 917/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.7725\n",
      "Epoch 918/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 0.7864\n",
      "Epoch 919/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.7112\n",
      "Epoch 920/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 0.7432\n",
      "Epoch 921/1000\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 0.7564\n",
      "Epoch 922/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 0.8093\n",
      "Epoch 923/1000\n",
      "1564/1564 [==============================] - 0s 79us/step - loss: 0.7376\n",
      "Epoch 924/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 0.6800\n",
      "Epoch 925/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.6937\n",
      "Epoch 926/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.6848\n",
      "Epoch 927/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 0.6804\n",
      "Epoch 928/1000\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 0.6930\n",
      "Epoch 929/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 0.6766\n",
      "Epoch 930/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.7240\n",
      "Epoch 931/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 0.6709\n",
      "Epoch 932/1000\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 0.6706\n",
      "Epoch 933/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 0.7003\n",
      "Epoch 934/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 0.6849\n",
      "Epoch 935/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.6792\n",
      "Epoch 936/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.6588\n",
      "Epoch 937/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 0.6416\n",
      "Epoch 938/1000\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 0.6345\n",
      "Epoch 939/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 0.6385\n",
      "Epoch 940/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.7555\n",
      "Epoch 941/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.6871\n",
      "Epoch 942/1000\n",
      "1564/1564 [==============================] - 0s 76us/step - loss: 0.6864\n",
      "Epoch 943/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.6389\n",
      "Epoch 944/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.6658\n",
      "Epoch 945/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.6522\n",
      "Epoch 946/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.6528\n",
      "Epoch 947/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 0.6431\n",
      "Epoch 948/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 0.6190\n",
      "Epoch 949/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.6318\n",
      "Epoch 950/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 0.6337\n",
      "Epoch 951/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.6227\n",
      "Epoch 952/1000\n",
      "1564/1564 [==============================] - 0s 76us/step - loss: 0.6386\n",
      "Epoch 953/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.6623\n",
      "Epoch 954/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.6139\n",
      "Epoch 955/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.6103\n",
      "Epoch 956/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.5956\n",
      "Epoch 957/1000\n",
      "1564/1564 [==============================] - 0s 94us/step - loss: 0.5888\n",
      "Epoch 958/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 0.5811\n",
      "Epoch 959/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 0.5867\n",
      "Epoch 960/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.6066\n",
      "Epoch 961/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.5925\n",
      "Epoch 962/1000\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 0.6022\n",
      "Epoch 963/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.5916\n",
      "Epoch 964/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.5961\n",
      "Epoch 965/1000\n",
      "1564/1564 [==============================] - 0s 79us/step - loss: 0.5845\n",
      "Epoch 966/1000\n",
      "1564/1564 [==============================] - 0s 84us/step - loss: 0.5964\n",
      "Epoch 967/1000\n",
      "1564/1564 [==============================] - 0s 74us/step - loss: 0.6457\n",
      "Epoch 968/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.5846\n",
      "Epoch 969/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 0.6052\n",
      "Epoch 970/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.6572\n",
      "Epoch 971/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 0.5903\n",
      "Epoch 972/1000\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 0.6351\n",
      "Epoch 973/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 0.5733\n",
      "Epoch 974/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.5810\n",
      "Epoch 975/1000\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 0.6001\n",
      "Epoch 976/1000\n",
      "1564/1564 [==============================] - 0s 80us/step - loss: 0.5844\n",
      "Epoch 977/1000\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 0.6215\n",
      "Epoch 978/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.6086\n",
      "Epoch 979/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.6090\n",
      "Epoch 980/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 0.6220\n",
      "Epoch 981/1000\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 0.6210\n",
      "Epoch 982/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.6077\n",
      "Epoch 983/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.6141\n",
      "Epoch 984/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 0.5818\n",
      "Epoch 985/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 0.6092\n",
      "Epoch 986/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 0.5811\n",
      "Epoch 987/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.6047\n",
      "Epoch 988/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.5805\n",
      "Epoch 989/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.5871\n",
      "Epoch 990/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.6085\n",
      "Epoch 991/1000\n",
      "1564/1564 [==============================] - 0s 80us/step - loss: 0.6212\n",
      "Epoch 992/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.5858\n",
      "Epoch 993/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.5780\n",
      "Epoch 994/1000\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 0.5762\n",
      "Epoch 995/1000\n",
      "1564/1564 [==============================] - 0s 71us/step - loss: 0.5778\n",
      "Epoch 996/1000\n",
      "1564/1564 [==============================] - 0s 79us/step - loss: 0.6054\n",
      "Epoch 997/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.5775\n",
      "Epoch 998/1000\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.6044\n",
      "Epoch 999/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.5805\n",
      "Epoch 1000/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 0.5792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a4c860e48>"
      ]
     },
     "execution_count": 1106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_ast = Sequential()\n",
    "NN_ast.add(Dense(units=16,input_dim=X_train.shape[1],activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_ast.add(Dense(units=8, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_ast.add(Dense(units=4, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_ast.add(Dense(units=1,activation='linear'))\n",
    "NN_ast.compile(loss='mse', optimizer='adam')\n",
    "NN_ast.fit(np.array(X_train), np.array(y_train), epochs=1000,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1107,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = NN_ast.predict(X_test)\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.5)\n",
    "gbr.fit(X_train,y_train)\n",
    "gbr_predictions = gbr.predict(X_test)\n",
    "LR = LinearRegression(fit_intercept=True).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN_predictions</th>\n",
       "      <th>actual</th>\n",
       "      <th>GBR_predictions</th>\n",
       "      <th>LY_assists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>9.242417</td>\n",
       "      <td>10.7</td>\n",
       "      <td>9.917714</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>9.272506</td>\n",
       "      <td>9.1</td>\n",
       "      <td>8.959229</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>7.282634</td>\n",
       "      <td>8.2</td>\n",
       "      <td>7.756411</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>9.095310</td>\n",
       "      <td>9.7</td>\n",
       "      <td>9.223970</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>6.950994</td>\n",
       "      <td>9.6</td>\n",
       "      <td>7.516531</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>7.130557</td>\n",
       "      <td>7.4</td>\n",
       "      <td>6.941857</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>8.558582</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.314799</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>7.589120</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.409781</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>6.382652</td>\n",
       "      <td>7.9</td>\n",
       "      <td>6.455342</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>7.231490</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.523014</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>6.499709</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.392088</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>6.741487</td>\n",
       "      <td>1.2</td>\n",
       "      <td>7.480083</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>4.790092</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.329515</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>7.632704</td>\n",
       "      <td>6.2</td>\n",
       "      <td>7.116505</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>4.723433</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.423371</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>5.482561</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.073050</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>7.310552</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7.081617</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.038743</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5.796425</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5.231649</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.483345</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>5.880826</td>\n",
       "      <td>5.6</td>\n",
       "      <td>6.225080</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>6.094776</td>\n",
       "      <td>11.7</td>\n",
       "      <td>5.519309</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>6.529718</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.691739</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>4.668577</td>\n",
       "      <td>2.4</td>\n",
       "      <td>5.209458</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>4.527278</td>\n",
       "      <td>5.6</td>\n",
       "      <td>4.503635</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>5.963240</td>\n",
       "      <td>6.1</td>\n",
       "      <td>6.043865</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>5.684110</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.284630</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.477052</td>\n",
       "      <td>5.2</td>\n",
       "      <td>6.240832</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>6.435950</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6.854628</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>5.689817</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.267376</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>5.873816</td>\n",
       "      <td>7.7</td>\n",
       "      <td>6.579900</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0.727196</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.650927</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>0.727196</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.580728</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>0.727196</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.459442</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>0.727196</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.869909</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>0.727196</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.592618</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>0.727196</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.513454</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.727196</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.621592</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>0.727196</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.701089</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>0.727196</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.636563</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>0.727196</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.809391</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>0.727196</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.344926</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>0.727196</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.722700</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.727196</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.497658</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>0.727196</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.465638</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>0.727196</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.538703</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.727196</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.425580</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.727196</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.644180</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>0.727196</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.446538</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.727196</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.563520</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>0.727196</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.687243</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>0.727196</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.307763</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.727196</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.613441</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>0.727196</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.496365</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>0.727196</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.608814</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>0.727196</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.752417</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>0.727196</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.763914</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>0.727196</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.566658</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>0.727196</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.613299</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>0.727196</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.661815</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0.727196</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.997804</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>671 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     NN_predictions  actual  GBR_predictions  LY_assists\n",
       "53         9.242417    10.7         9.917714        10.2\n",
       "586        9.272506     9.1         8.959229         9.8\n",
       "359        7.282634     8.2         7.756411         9.1\n",
       "466        9.095310     9.7         9.223970         9.1\n",
       "149        6.950994     9.6         7.516531         8.8\n",
       "218        7.130557     7.4         6.941857         8.8\n",
       "263        8.558582    10.0         8.314799         8.8\n",
       "617        7.589120     7.0         6.409781         8.6\n",
       "259        6.382652     7.9         6.455342         8.0\n",
       "439        7.231490     7.6         7.523014         8.0\n",
       "136        6.499709     5.0         6.392088         7.6\n",
       "403        6.741487     1.2         7.480083         7.2\n",
       "416        4.790092     3.1         3.329515         7.1\n",
       "93         7.632704     6.2         7.116505         7.0\n",
       "335        4.723433     3.7         4.423371         7.0\n",
       "453        5.482561     6.0         5.073050         6.9\n",
       "605        7.310552     6.6         7.081617         6.7\n",
       "26         5.038743     5.9         5.796425         6.7\n",
       "98         5.231649     4.0         4.483345         6.6\n",
       "43         5.880826     5.6         6.225080         6.5\n",
       "253        6.094776    11.7         5.519309         6.5\n",
       "408        6.529718     7.0         6.691739         6.4\n",
       "279        4.668577     2.4         5.209458         6.4\n",
       "570        4.527278     5.6         4.503635         6.3\n",
       "643        5.963240     6.1         6.043865         6.2\n",
       "104        5.684110     6.3         6.284630         6.1\n",
       "20         5.477052     5.2         6.240832         6.1\n",
       "129        6.435950     6.6         6.854628         6.1\n",
       "47         5.689817     5.1         6.267376         6.1\n",
       "539        5.873816     7.7         6.579900         6.0\n",
       "..              ...     ...              ...         ...\n",
       "489        0.727196     0.6         0.650927         0.3\n",
       "517        0.727196     0.2         0.580728         0.3\n",
       "529        0.727196     0.3         0.459442         0.3\n",
       "361        0.727196     0.8         0.869909         0.3\n",
       "202        0.727196     0.4         0.592618         0.3\n",
       "591        0.727196     0.7         0.513454         0.3\n",
       "203        0.727196     0.8         0.621592         0.3\n",
       "162        0.727196     1.4         0.701089         0.3\n",
       "541        0.727196     1.5         0.636563         0.2\n",
       "386        0.727196     0.8         0.809391         0.2\n",
       "385        0.727196     0.7         0.344926         0.2\n",
       "405        0.727196     0.4         0.722700         0.2\n",
       "27         0.727196     0.4         0.497658         0.2\n",
       "595        0.727196     0.4         0.465638         0.2\n",
       "328        0.727196     1.3         0.538703         0.2\n",
       "185        0.727196     0.1         0.425580         0.2\n",
       "505        0.727196     0.3         0.644180         0.2\n",
       "475        0.727196     0.2         0.446538         0.2\n",
       "87         0.727196     0.4         0.563520         0.2\n",
       "550        0.727196     0.9         0.687243         0.2\n",
       "542        0.727196     0.5         0.307763         0.2\n",
       "297        0.727196     0.2         0.613441         0.1\n",
       "481        0.727196     0.4         0.496365         0.1\n",
       "630        0.727196     0.1         0.608814         0.1\n",
       "603        0.727196     0.5         0.752417         0.1\n",
       "302        0.727196     0.2         0.763914         0.1\n",
       "391        0.727196     0.9         0.566658         0.0\n",
       "468        0.727196     0.5         0.613299         0.0\n",
       "521        0.727196     0.3         0.661815         0.0\n",
       "239        0.727196     1.5         0.997804         0.0\n",
       "\n",
       "[671 rows x 4 columns]"
      ]
     },
     "execution_count": 1108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing = pd.DataFrame(predictions)\n",
    "testing.columns=['NN_predictions']\n",
    "testing['actual'] = y_test.reset_index()['assists']\n",
    "testing['GBR_predictions']=gbr_predictions\n",
    "testing['LY_assists']=X_test['assists_ly'].reset_index()['assists_ly']\n",
    "testing.sort_values(by='LY_assists',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1109,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2017assists = assists[assists['season']==2017].drop(['team','player','assists','Games'],axis=1)\n",
    "assists_2017 = NN_ast.predict(pred_2017assists)\n",
    "gbr_ast_2017 = pd.DataFrame(gbr.predict(pred_2017assists))\n",
    "LR_ast_2017 = pd.DataFrame(LR.predict(pred_2017assists))\n",
    "test_2 =pd.DataFrame(assists_2017)\n",
    "test_3 = pd.merge(assists,pred_2017assists,left_index=True,right_index=True).reset_index()\n",
    "test_3['predictions']=test_2[0]\n",
    "test_3['gbr_pred'] = gbr_ast_2017[0]\n",
    "test_3['LR_pred'] = LR_ast_2017[0]\n",
    "test_3['mean_pred'] = (test_3['predictions']+test_3['gbr_pred']+test_3['LR_pred'])/3\n",
    "test_3 = test_3[test_3['Games']>30]\n",
    "test_3[['player','assists','predictions','assists_ly_x','gbr_pred','LR_pred','mean_pred']].sort_values(by='assists_ly_x',ascending=False)[0:50]\n",
    "\n",
    "assists_2017 = test_3[['player','LR_pred']]\n",
    "assists_2017.columns = ['player','assist_prediction']\n",
    "df_2017 = pd.merge(df_2017,assists_2017,how='left',left_on='player',right_on='player')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE using NN:0.7667583732985284\n",
      "MSE using mean:3.3617587113741045\n",
      "MSE using last year stats:0.8503846153846144\n",
      "MSE using LR:0.538446867619082\n",
      "MSE using GB:0.5471953117768439\n",
      "MSE using combo:0.565266482457822\n"
     ]
    }
   ],
   "source": [
    "print('MSE using NN:{}'.format(np.mean((test_3['assists']-test_3['predictions'])**2)))\n",
    "print('MSE using mean:{}'.format(np.mean((test_3['assists']-np.mean(test_3['assists']))**2)))\n",
    "print('MSE using last year stats:{}'.format(np.mean((test_3['assists']-test_3['assists_ly_x'])**2)))\n",
    "print('MSE using LR:{}'.format(np.mean((test_3['assists']-test_3['LR_pred'])**2)))\n",
    "print('MSE using GB:{}'.format(np.mean((test_3['assists']-test_3['gbr_pred'])**2)))\n",
    "print('MSE using combo:{}'.format(np.mean((test_3['assists']-test_3['mean_pred'])**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1111,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''next is steals.  In the future, may want to add minutes from last season?'''\n",
    "\n",
    "\n",
    "query= '''\n",
    "        \n",
    "        DROP TABLE IF EXISTS steals_pred;\n",
    "        CREATE TABLE steals_pred(\n",
    "        season int, --these come from player_stats\n",
    "        player varchar(50),\n",
    "        Age int,\n",
    "        team varchar(50),\n",
    "        stl float, -- these come from player_stats\n",
    "        stl_ly float,\n",
    "        change_stl_ly float,\n",
    "        Games float,\n",
    "        C_PF int,\n",
    "        PG int,\n",
    "        SG_SF int,\n",
    "        starter_change int, \n",
    "        \n",
    "\n",
    "        -- from player_advstats\n",
    "        per_ly float,\n",
    "        change_per float,\n",
    "        stl_perc_ly float,\n",
    "        change_stl_perc_ly float,\n",
    "        defensive_winshares float,\n",
    "        defensive_boxplusminus float,\n",
    "        boxplusminus float,\n",
    "        value_overreplacement float,\n",
    "        \n",
    "        max_teammate_usage float,\n",
    "        max_teammateto float,\n",
    "        max_teammateshot_attempts float,\n",
    "        \n",
    "        career_stl float,\n",
    "        yearspro int\n",
    "        );\n",
    "        \n",
    "        INSERT INTO steals_pred(season,player,age,team,stl,stl_ly,change_stl_ly,starter_change,Games,C_PF,PG,SG_SF)\n",
    "        SELECT season,player,age,startingteam,stl,stl_ly,change_stl_ly,starter-starter_ly,Games,\n",
    "        case when pos in ('C','PF') then 1 else 0 end,case when pos='PG' then 1 else 0 end,case when pos in('SG','SF') then 1 else 0 end from player_stats;\n",
    "        \n",
    "        \n",
    "        update steals_pred sp\n",
    "        set per_ly=pa.per_ly,change_per=pa.change_per,stl_perc_ly = pa.stl_perc_ly,change_stl_perc_ly = pa.change_stl_perc_ly\n",
    "        ,defensive_winshares=pa.defensive_winshares,defensive_boxplusminus=pa.defensive_boxplusminus\n",
    "        ,boxplusminus=pa.boxplusminus,value_overreplacement=pa.value_overreplacement\n",
    "        from player_advstats pa\n",
    "        where sp.player = pa.player and sp.season = pa.season and sp.team = pa.startingteam;\n",
    "        \n",
    "        update steals_pred sp\n",
    "        set max_teammate_usage=tm.max_teammate_usage,max_teammateto=tm.max_teammateto,max_teammateshot_attempts=tm.max_teammateshot_attempts\n",
    "        from teammate_maxes tm\n",
    "        where tm.season = sp.season and tm.player = sp.player;\n",
    "        \n",
    "        update steals_pred sp\n",
    "        set career_stl = pc.career_stl, yearspro = pc.yearspro\n",
    "        from player_careerstats pc\n",
    "        where sp.player = pc.player and sp.season = pc.season;\n",
    "        \n",
    "        \n",
    "        select * from steals_pred where season>2009\n",
    "        '''\n",
    "\n",
    "\n",
    "cur.execute(query)\n",
    "data = cur.fetchall()\n",
    "steals_df = pd.DataFrame(np.array(data))\n",
    "steals_df.columns = ['season','player','age','team','steals','steals_ly','change_steals_ly','Games','C_PF','PG','SG_SF','starter_change'\n",
    "                    ,'per_ly','change_per','stl_perc_ly','change_stl_perc','defensive_winshares','defensive_boxplusminus','boxplusminus','value_overreplacement'\n",
    "                     ,'max_teammate_usage','max_teammateto','max_teammateshot_attempts','career_steals','yearspro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "steals_df['age_squared']=steals_df['age']*steals_df['age']\n",
    "steals = steals_df[steals_df['steals_ly'].notna()]\n",
    "for i in steals.columns:\n",
    "    if i not in(['player','team']):\n",
    "        steals[i]=pd.to_numeric(steals[i])\n",
    "steals = steals.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = steals[(steals['season']!=2017) & (steals['Games']>30)].drop(['player','team','steals','Games'],axis=1)\n",
    "y = steals[(steals['season']!=2017) & (steals['Games']>30)]['steals']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1564/1564 [==============================] - 5s 3ms/step - loss: 24624.2154\n",
      "Epoch 2/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 4789.9030\n",
      "Epoch 3/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 1004.2184\n",
      "Epoch 4/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 454.3426\n",
      "Epoch 5/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 287.6954\n",
      "Epoch 6/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 202.4941\n",
      "Epoch 7/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 149.0756\n",
      "Epoch 8/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 110.9582\n",
      "Epoch 9/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 82.8485\n",
      "Epoch 10/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 61.8481\n",
      "Epoch 11/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 46.2644\n",
      "Epoch 12/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 34.4178\n",
      "Epoch 13/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 25.5618\n",
      "Epoch 14/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 18.8718\n",
      "Epoch 15/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 13.9256\n",
      "Epoch 16/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 10.2149\n",
      "Epoch 17/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 7.5211\n",
      "Epoch 18/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 5.5492\n",
      "Epoch 19/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 4.1555\n",
      "Epoch 20/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 3.1576\n",
      "Epoch 21/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 2.4362\n",
      "Epoch 22/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.9232\n",
      "Epoch 23/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.5995\n",
      "Epoch 24/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.3670\n",
      "Epoch 25/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.2185\n",
      "Epoch 26/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.1159\n",
      "Epoch 27/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.0373\n",
      "Epoch 28/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.9835\n",
      "Epoch 29/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.9416\n",
      "Epoch 30/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.9077\n",
      "Epoch 31/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.8783\n",
      "Epoch 32/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.8535\n",
      "Epoch 33/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.8311\n",
      "Epoch 34/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.8142\n",
      "Epoch 35/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.7951\n",
      "Epoch 36/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.7801\n",
      "Epoch 37/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.7648\n",
      "Epoch 38/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.7489\n",
      "Epoch 39/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.7356\n",
      "Epoch 40/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.7227\n",
      "Epoch 41/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.7088\n",
      "Epoch 42/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.6984\n",
      "Epoch 43/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.6834\n",
      "Epoch 44/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.6729\n",
      "Epoch 45/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6590\n",
      "Epoch 46/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6458\n",
      "Epoch 47/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6341\n",
      "Epoch 48/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6243\n",
      "Epoch 49/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.6136\n",
      "Epoch 50/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6035\n",
      "Epoch 51/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5940\n",
      "Epoch 52/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5866\n",
      "Epoch 53/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5768\n",
      "Epoch 54/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5678\n",
      "Epoch 55/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5593\n",
      "Epoch 56/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5508\n",
      "Epoch 57/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5426\n",
      "Epoch 58/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5373\n",
      "Epoch 59/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.5290\n",
      "Epoch 60/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5214\n",
      "Epoch 61/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5150\n",
      "Epoch 62/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5079\n",
      "Epoch 63/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5025\n",
      "Epoch 64/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4964\n",
      "Epoch 65/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.4903\n",
      "Epoch 66/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.4860\n",
      "Epoch 67/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.4803\n",
      "Epoch 68/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.4751\n",
      "Epoch 69/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.4693\n",
      "Epoch 70/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4656\n",
      "Epoch 71/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.4608\n",
      "Epoch 72/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.4566\n",
      "Epoch 73/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.4523\n",
      "Epoch 74/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.4474\n",
      "Epoch 75/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.4434\n",
      "Epoch 76/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.4396\n",
      "Epoch 77/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.4334\n",
      "Epoch 78/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.4277\n",
      "Epoch 79/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.4243\n",
      "Epoch 80/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.4207\n",
      "Epoch 81/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.4167\n",
      "Epoch 82/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.4133\n",
      "Epoch 83/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.4097\n",
      "Epoch 84/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.4072\n",
      "Epoch 85/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.4033\n",
      "Epoch 86/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.4004\n",
      "Epoch 87/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.3978\n",
      "Epoch 88/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.3943\n",
      "Epoch 89/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.3909\n",
      "Epoch 90/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.3878\n",
      "Epoch 91/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.3852\n",
      "Epoch 92/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.3838\n",
      "Epoch 93/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.3797\n",
      "Epoch 94/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.3765\n",
      "Epoch 95/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.3746\n",
      "Epoch 96/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.3722\n",
      "Epoch 97/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.3686\n",
      "Epoch 98/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.3663\n",
      "Epoch 99/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.3639\n",
      "Epoch 100/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.3616\n",
      "Epoch 101/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.3588\n",
      "Epoch 102/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.3565\n",
      "Epoch 103/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.3541\n",
      "Epoch 104/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.3521\n",
      "Epoch 105/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.3495\n",
      "Epoch 106/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.3472\n",
      "Epoch 107/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.3443\n",
      "Epoch 108/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.3414\n",
      "Epoch 109/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.3381\n",
      "Epoch 110/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.3363\n",
      "Epoch 111/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.3340\n",
      "Epoch 112/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.3319\n",
      "Epoch 113/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.3303\n",
      "Epoch 114/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.3283\n",
      "Epoch 115/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.3261\n",
      "Epoch 116/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.3240\n",
      "Epoch 117/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.3204\n",
      "Epoch 118/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.3178\n",
      "Epoch 119/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.3149\n",
      "Epoch 120/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.3130\n",
      "Epoch 121/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.3110\n",
      "Epoch 122/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.3094\n",
      "Epoch 123/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.3078\n",
      "Epoch 124/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.3062\n",
      "Epoch 125/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.3046\n",
      "Epoch 126/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.3032\n",
      "Epoch 127/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.3010\n",
      "Epoch 128/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.3000\n",
      "Epoch 129/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2980\n",
      "Epoch 130/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2966\n",
      "Epoch 131/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2950\n",
      "Epoch 132/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2937\n",
      "Epoch 133/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2920\n",
      "Epoch 134/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2904\n",
      "Epoch 135/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2892\n",
      "Epoch 136/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2881\n",
      "Epoch 137/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2863\n",
      "Epoch 138/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2852\n",
      "Epoch 139/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2837\n",
      "Epoch 140/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2824\n",
      "Epoch 141/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2810\n",
      "Epoch 142/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2799\n",
      "Epoch 143/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2788\n",
      "Epoch 144/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2774\n",
      "Epoch 145/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2762\n",
      "Epoch 146/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2747\n",
      "Epoch 147/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2737\n",
      "Epoch 148/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2724\n",
      "Epoch 149/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2716\n",
      "Epoch 150/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2700\n",
      "Epoch 151/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2691\n",
      "Epoch 152/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2680\n",
      "Epoch 153/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2671\n",
      "Epoch 154/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.2659\n",
      "Epoch 155/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2649\n",
      "Epoch 156/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2640\n",
      "Epoch 157/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.2628\n",
      "Epoch 158/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2620\n",
      "Epoch 159/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2609\n",
      "Epoch 160/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2600\n",
      "Epoch 161/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2592\n",
      "Epoch 162/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2581\n",
      "Epoch 163/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2571\n",
      "Epoch 164/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2563\n",
      "Epoch 165/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2557\n",
      "Epoch 166/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2546\n",
      "Epoch 167/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2538\n",
      "Epoch 168/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2530\n",
      "Epoch 169/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2521\n",
      "Epoch 170/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2515\n",
      "Epoch 171/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2505\n",
      "Epoch 172/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2501\n",
      "Epoch 173/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2491\n",
      "Epoch 174/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2483\n",
      "Epoch 175/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2478\n",
      "Epoch 176/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.2470\n",
      "Epoch 177/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2462\n",
      "Epoch 178/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2458\n",
      "Epoch 179/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2449\n",
      "Epoch 180/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2442\n",
      "Epoch 181/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2437\n",
      "Epoch 182/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2429\n",
      "Epoch 183/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2425\n",
      "Epoch 184/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2417\n",
      "Epoch 185/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2411\n",
      "Epoch 186/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2405\n",
      "Epoch 187/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2401\n",
      "Epoch 188/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2394\n",
      "Epoch 189/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2388\n",
      "Epoch 190/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2384\n",
      "Epoch 191/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2376\n",
      "Epoch 192/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2373\n",
      "Epoch 193/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2368\n",
      "Epoch 194/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.2364\n",
      "Epoch 195/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2358\n",
      "Epoch 196/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2354\n",
      "Epoch 197/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2350\n",
      "Epoch 198/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2346\n",
      "Epoch 199/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2340\n",
      "Epoch 200/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2337\n",
      "Epoch 201/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2332\n",
      "Epoch 202/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2329\n",
      "Epoch 203/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2323\n",
      "Epoch 204/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2319\n",
      "Epoch 205/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2315\n",
      "Epoch 206/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2311\n",
      "Epoch 207/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2306\n",
      "Epoch 208/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2302\n",
      "Epoch 209/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2300\n",
      "Epoch 210/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2294\n",
      "Epoch 211/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.2291\n",
      "Epoch 212/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2286\n",
      "Epoch 213/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2282\n",
      "Epoch 214/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2278\n",
      "Epoch 215/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2275\n",
      "Epoch 216/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2271\n",
      "Epoch 217/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2266\n",
      "Epoch 218/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2266\n",
      "Epoch 219/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2259\n",
      "Epoch 220/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2254\n",
      "Epoch 221/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2252\n",
      "Epoch 222/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2248\n",
      "Epoch 223/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2243\n",
      "Epoch 224/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2240\n",
      "Epoch 225/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2235\n",
      "Epoch 226/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2231\n",
      "Epoch 227/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2227\n",
      "Epoch 228/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2224\n",
      "Epoch 229/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2220\n",
      "Epoch 230/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2217\n",
      "Epoch 231/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2213\n",
      "Epoch 232/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2209\n",
      "Epoch 233/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2206\n",
      "Epoch 234/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2203\n",
      "Epoch 235/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2199\n",
      "Epoch 236/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2196\n",
      "Epoch 237/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2192\n",
      "Epoch 238/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2188\n",
      "Epoch 239/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2184\n",
      "Epoch 240/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2180\n",
      "Epoch 241/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2176\n",
      "Epoch 242/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2174\n",
      "Epoch 243/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2170\n",
      "Epoch 244/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2170\n",
      "Epoch 245/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2166\n",
      "Epoch 246/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2162\n",
      "Epoch 247/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2158\n",
      "Epoch 248/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.2157\n",
      "Epoch 249/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2151\n",
      "Epoch 250/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2148\n",
      "Epoch 251/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2146\n",
      "Epoch 252/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2143\n",
      "Epoch 253/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2140\n",
      "Epoch 254/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2136\n",
      "Epoch 255/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2134\n",
      "Epoch 256/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2132\n",
      "Epoch 257/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2128\n",
      "Epoch 258/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2126\n",
      "Epoch 259/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.2122\n",
      "Epoch 260/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2119\n",
      "Epoch 261/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2116\n",
      "Epoch 262/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2113\n",
      "Epoch 263/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2111\n",
      "Epoch 264/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2107\n",
      "Epoch 265/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2105\n",
      "Epoch 266/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2102\n",
      "Epoch 267/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2099\n",
      "Epoch 268/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2098\n",
      "Epoch 269/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2095\n",
      "Epoch 270/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2093\n",
      "Epoch 271/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2090\n",
      "Epoch 272/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2087\n",
      "Epoch 273/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2083\n",
      "Epoch 274/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2082\n",
      "Epoch 275/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2078\n",
      "Epoch 276/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2076\n",
      "Epoch 277/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2073\n",
      "Epoch 278/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2071\n",
      "Epoch 279/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2068\n",
      "Epoch 280/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2067\n",
      "Epoch 281/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2066\n",
      "Epoch 282/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2061\n",
      "Epoch 283/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2058\n",
      "Epoch 284/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2056\n",
      "Epoch 285/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2053\n",
      "Epoch 286/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2051\n",
      "Epoch 287/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2048\n",
      "Epoch 288/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2046\n",
      "Epoch 289/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2043\n",
      "Epoch 290/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.2041\n",
      "Epoch 291/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2039\n",
      "Epoch 292/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2037\n",
      "Epoch 293/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2033\n",
      "Epoch 294/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2032\n",
      "Epoch 295/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2030\n",
      "Epoch 296/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2027\n",
      "Epoch 297/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2026\n",
      "Epoch 298/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2022\n",
      "Epoch 299/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2020\n",
      "Epoch 300/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2019\n",
      "Epoch 301/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2020\n",
      "Epoch 302/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2015\n",
      "Epoch 303/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2012\n",
      "Epoch 304/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2009\n",
      "Epoch 305/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2007\n",
      "Epoch 306/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2005\n",
      "Epoch 307/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2003\n",
      "Epoch 308/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2003\n",
      "Epoch 309/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1998\n",
      "Epoch 310/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1997\n",
      "Epoch 311/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1994\n",
      "Epoch 312/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1992\n",
      "Epoch 313/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1991\n",
      "Epoch 314/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1989\n",
      "Epoch 315/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1987\n",
      "Epoch 316/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1986\n",
      "Epoch 317/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1982\n",
      "Epoch 318/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1984\n",
      "Epoch 319/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1980\n",
      "Epoch 320/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1980\n",
      "Epoch 321/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1974\n",
      "Epoch 322/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1977\n",
      "Epoch 323/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1972\n",
      "Epoch 324/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1971\n",
      "Epoch 325/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1967\n",
      "Epoch 326/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1966\n",
      "Epoch 327/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1964\n",
      "Epoch 328/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1965\n",
      "Epoch 329/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1960\n",
      "Epoch 330/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1957\n",
      "Epoch 331/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1958\n",
      "Epoch 332/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1956\n",
      "Epoch 333/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1957\n",
      "Epoch 334/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1951\n",
      "Epoch 335/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1949\n",
      "Epoch 336/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1950\n",
      "Epoch 337/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1948\n",
      "Epoch 338/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1944\n",
      "Epoch 339/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1944\n",
      "Epoch 340/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1945\n",
      "Epoch 341/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1945\n",
      "Epoch 342/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1938\n",
      "Epoch 343/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1938\n",
      "Epoch 344/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.1935\n",
      "Epoch 345/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1933\n",
      "Epoch 346/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1931\n",
      "Epoch 347/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1930\n",
      "Epoch 348/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1928\n",
      "Epoch 349/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1930\n",
      "Epoch 350/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1925\n",
      "Epoch 351/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1925\n",
      "Epoch 352/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.1923\n",
      "Epoch 353/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1921\n",
      "Epoch 354/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1923\n",
      "Epoch 355/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1928\n",
      "Epoch 356/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1918\n",
      "Epoch 357/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.1917\n",
      "Epoch 358/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.1917\n",
      "Epoch 359/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1913\n",
      "Epoch 360/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1914\n",
      "Epoch 361/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1912\n",
      "Epoch 362/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1910\n",
      "Epoch 363/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1908\n",
      "Epoch 364/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1909\n",
      "Epoch 365/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1906\n",
      "Epoch 366/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.1904\n",
      "Epoch 367/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1904\n",
      "Epoch 368/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1908\n",
      "Epoch 369/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1902\n",
      "Epoch 370/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1900\n",
      "Epoch 371/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1900\n",
      "Epoch 372/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1897\n",
      "Epoch 373/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1896\n",
      "Epoch 374/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1894\n",
      "Epoch 375/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1895\n",
      "Epoch 376/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1894\n",
      "Epoch 377/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1894\n",
      "Epoch 378/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1890\n",
      "Epoch 379/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1890\n",
      "Epoch 380/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1888\n",
      "Epoch 381/1000\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 0.1887\n",
      "Epoch 382/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.1886\n",
      "Epoch 383/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1885\n",
      "Epoch 384/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1886\n",
      "Epoch 385/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.1883\n",
      "Epoch 386/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.1882\n",
      "Epoch 387/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.1881\n",
      "Epoch 388/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1883\n",
      "Epoch 389/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1883\n",
      "Epoch 390/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1881\n",
      "Epoch 391/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1877\n",
      "Epoch 392/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1878\n",
      "Epoch 393/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1874\n",
      "Epoch 394/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1878\n",
      "Epoch 395/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.1878\n",
      "Epoch 396/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1877\n",
      "Epoch 397/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1880\n",
      "Epoch 398/1000\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 0.1873\n",
      "Epoch 399/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1871\n",
      "Epoch 400/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1871\n",
      "Epoch 401/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1873\n",
      "Epoch 402/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1869\n",
      "Epoch 403/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1868\n",
      "Epoch 404/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1871\n",
      "Epoch 405/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1867\n",
      "Epoch 406/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1867\n",
      "Epoch 407/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1867\n",
      "Epoch 408/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1880\n",
      "Epoch 409/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1868\n",
      "Epoch 410/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1864\n",
      "Epoch 411/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1866\n",
      "Epoch 412/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1863\n",
      "Epoch 413/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1863\n",
      "Epoch 414/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1863\n",
      "Epoch 415/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1859\n",
      "Epoch 416/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1859\n",
      "Epoch 417/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1859\n",
      "Epoch 418/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1858\n",
      "Epoch 419/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1857\n",
      "Epoch 420/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1858\n",
      "Epoch 421/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1855\n",
      "Epoch 422/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1859\n",
      "Epoch 423/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1856\n",
      "Epoch 424/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1856\n",
      "Epoch 425/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1855\n",
      "Epoch 426/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1855\n",
      "Epoch 427/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1854\n",
      "Epoch 428/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1856\n",
      "Epoch 429/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1853\n",
      "Epoch 430/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1852\n",
      "Epoch 431/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1852\n",
      "Epoch 432/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1853\n",
      "Epoch 433/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1858\n",
      "Epoch 434/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1856\n",
      "Epoch 435/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1856\n",
      "Epoch 436/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1850\n",
      "Epoch 437/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1850\n",
      "Epoch 438/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1849\n",
      "Epoch 439/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1850\n",
      "Epoch 440/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1848\n",
      "Epoch 441/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1850\n",
      "Epoch 442/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1856\n",
      "Epoch 443/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1849\n",
      "Epoch 444/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1850\n",
      "Epoch 445/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1853\n",
      "Epoch 446/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1845\n",
      "Epoch 447/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1847\n",
      "Epoch 448/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1847\n",
      "Epoch 449/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1845\n",
      "Epoch 450/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1855\n",
      "Epoch 451/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1868\n",
      "Epoch 452/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1863\n",
      "Epoch 453/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1853\n",
      "Epoch 454/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1847\n",
      "Epoch 455/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1844\n",
      "Epoch 456/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1845\n",
      "Epoch 457/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1849\n",
      "Epoch 458/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1851\n",
      "Epoch 459/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1854\n",
      "Epoch 460/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1850\n",
      "Epoch 461/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1845\n",
      "Epoch 462/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1842\n",
      "Epoch 463/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1845\n",
      "Epoch 464/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1845\n",
      "Epoch 465/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1845\n",
      "Epoch 466/1000\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 0.1845\n",
      "Epoch 467/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1840\n",
      "Epoch 468/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1842\n",
      "Epoch 469/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1844\n",
      "Epoch 470/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1845\n",
      "Epoch 471/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1841\n",
      "Epoch 472/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1843\n",
      "Epoch 473/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1839\n",
      "Epoch 474/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.1842\n",
      "Epoch 475/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.1842\n",
      "Epoch 476/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1844\n",
      "Epoch 477/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1841\n",
      "Epoch 478/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1845\n",
      "Epoch 479/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1839\n",
      "Epoch 480/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1838\n",
      "Epoch 481/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.1838\n",
      "Epoch 482/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1842\n",
      "Epoch 483/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1840\n",
      "Epoch 484/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1837\n",
      "Epoch 485/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1839\n",
      "Epoch 486/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1839\n",
      "Epoch 487/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1839\n",
      "Epoch 488/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1844\n",
      "Epoch 489/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1842\n",
      "Epoch 490/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1843\n",
      "Epoch 491/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1844\n",
      "Epoch 492/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1836\n",
      "Epoch 493/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1836\n",
      "Epoch 494/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1843\n",
      "Epoch 495/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1835\n",
      "Epoch 496/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1838\n",
      "Epoch 497/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1835\n",
      "Epoch 498/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1839\n",
      "Epoch 499/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1839\n",
      "Epoch 500/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.1839\n",
      "Epoch 501/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1835\n",
      "Epoch 502/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1835\n",
      "Epoch 503/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1838\n",
      "Epoch 504/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1835\n",
      "Epoch 505/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1839\n",
      "Epoch 506/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1836\n",
      "Epoch 507/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1848\n",
      "Epoch 508/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1835\n",
      "Epoch 509/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1834\n",
      "Epoch 510/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1839\n",
      "Epoch 511/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1838\n",
      "Epoch 512/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1838\n",
      "Epoch 513/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1849\n",
      "Epoch 514/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1844\n",
      "Epoch 515/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1836\n",
      "Epoch 516/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1834\n",
      "Epoch 517/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1836\n",
      "Epoch 518/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1834\n",
      "Epoch 519/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1836\n",
      "Epoch 520/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1841\n",
      "Epoch 521/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1859\n",
      "Epoch 522/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1832\n",
      "Epoch 523/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1838\n",
      "Epoch 524/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1842\n",
      "Epoch 525/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1832\n",
      "Epoch 526/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1832\n",
      "Epoch 527/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1834\n",
      "Epoch 528/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1835\n",
      "Epoch 529/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1832\n",
      "Epoch 530/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1834\n",
      "Epoch 531/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1835\n",
      "Epoch 532/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1838\n",
      "Epoch 533/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1850\n",
      "Epoch 534/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1848\n",
      "Epoch 535/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1865\n",
      "Epoch 536/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1839\n",
      "Epoch 537/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1837\n",
      "Epoch 538/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1843\n",
      "Epoch 539/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1840\n",
      "Epoch 540/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1832\n",
      "Epoch 541/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1833\n",
      "Epoch 542/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1833\n",
      "Epoch 543/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1831\n",
      "Epoch 544/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1835\n",
      "Epoch 545/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1842\n",
      "Epoch 546/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1832\n",
      "Epoch 547/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.1841\n",
      "Epoch 548/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1833\n",
      "Epoch 549/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1836\n",
      "Epoch 550/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1835\n",
      "Epoch 551/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1832\n",
      "Epoch 552/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.1835\n",
      "Epoch 553/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1833\n",
      "Epoch 554/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1838\n",
      "Epoch 555/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.1834\n",
      "Epoch 556/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1833\n",
      "Epoch 557/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1831\n",
      "Epoch 558/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1832\n",
      "Epoch 559/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1843\n",
      "Epoch 560/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1834\n",
      "Epoch 561/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1836\n",
      "Epoch 562/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1833\n",
      "Epoch 563/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1853\n",
      "Epoch 564/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1834\n",
      "Epoch 565/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1831\n",
      "Epoch 566/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1831\n",
      "Epoch 567/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1831\n",
      "Epoch 568/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1836\n",
      "Epoch 569/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1836\n",
      "Epoch 570/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1839\n",
      "Epoch 571/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1835\n",
      "Epoch 572/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1841\n",
      "Epoch 573/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1839\n",
      "Epoch 574/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1830\n",
      "Epoch 575/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1829\n",
      "Epoch 576/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1835\n",
      "Epoch 577/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1832\n",
      "Epoch 578/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1831\n",
      "Epoch 579/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.1830\n",
      "Epoch 580/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1836\n",
      "Epoch 581/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1834\n",
      "Epoch 582/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1828\n",
      "Epoch 583/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1836\n",
      "Epoch 584/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1832\n",
      "Epoch 585/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1827\n",
      "Epoch 586/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1833\n",
      "Epoch 587/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1888\n",
      "Epoch 588/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1840\n",
      "Epoch 589/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1830\n",
      "Epoch 590/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1835\n",
      "Epoch 591/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1829\n",
      "Epoch 592/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1835\n",
      "Epoch 593/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1844\n",
      "Epoch 594/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1853\n",
      "Epoch 595/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1857\n",
      "Epoch 596/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1869\n",
      "Epoch 597/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1844\n",
      "Epoch 598/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1831\n",
      "Epoch 599/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1832\n",
      "Epoch 600/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1829\n",
      "Epoch 601/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1829\n",
      "Epoch 602/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1828\n",
      "Epoch 603/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1842\n",
      "Epoch 604/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1844\n",
      "Epoch 605/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1840\n",
      "Epoch 606/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1828\n",
      "Epoch 607/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1838\n",
      "Epoch 608/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1832\n",
      "Epoch 609/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1829\n",
      "Epoch 610/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1830\n",
      "Epoch 611/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1829\n",
      "Epoch 612/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1830\n",
      "Epoch 613/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1826\n",
      "Epoch 614/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1830\n",
      "Epoch 615/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1828\n",
      "Epoch 616/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1847\n",
      "Epoch 617/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1846\n",
      "Epoch 618/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1830\n",
      "Epoch 619/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1837\n",
      "Epoch 620/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1842\n",
      "Epoch 621/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1836\n",
      "Epoch 622/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1837\n",
      "Epoch 623/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1846\n",
      "Epoch 624/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1831\n",
      "Epoch 625/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1834\n",
      "Epoch 626/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1831\n",
      "Epoch 627/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1834\n",
      "Epoch 628/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1827\n",
      "Epoch 629/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1829\n",
      "Epoch 630/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1831\n",
      "Epoch 631/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1836\n",
      "Epoch 632/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1835\n",
      "Epoch 633/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.1829\n",
      "Epoch 634/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1836\n",
      "Epoch 635/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1832\n",
      "Epoch 636/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1828\n",
      "Epoch 637/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1825\n",
      "Epoch 638/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1825\n",
      "Epoch 639/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1826\n",
      "Epoch 640/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1833\n",
      "Epoch 641/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1835\n",
      "Epoch 642/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1830\n",
      "Epoch 643/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1833\n",
      "Epoch 644/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1833\n",
      "Epoch 645/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1834\n",
      "Epoch 646/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1828\n",
      "Epoch 647/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.1829\n",
      "Epoch 648/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1837\n",
      "Epoch 649/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1848\n",
      "Epoch 650/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1829\n",
      "Epoch 651/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1827\n",
      "Epoch 652/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1828\n",
      "Epoch 653/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1857\n",
      "Epoch 654/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1893\n",
      "Epoch 655/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1835\n",
      "Epoch 656/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1825\n",
      "Epoch 657/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1833\n",
      "Epoch 658/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1823\n",
      "Epoch 659/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1830\n",
      "Epoch 660/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1831\n",
      "Epoch 661/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1852\n",
      "Epoch 662/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.1844\n",
      "Epoch 663/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1827\n",
      "Epoch 664/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1828\n",
      "Epoch 665/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1822\n",
      "Epoch 666/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1824\n",
      "Epoch 667/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1830\n",
      "Epoch 668/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1839\n",
      "Epoch 669/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1824\n",
      "Epoch 670/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.1847\n",
      "Epoch 671/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.1831\n",
      "Epoch 672/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.1840\n",
      "Epoch 673/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1828\n",
      "Epoch 674/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1829\n",
      "Epoch 675/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1825\n",
      "Epoch 676/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1832\n",
      "Epoch 677/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1840\n",
      "Epoch 678/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1826\n",
      "Epoch 679/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1824\n",
      "Epoch 680/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1831\n",
      "Epoch 681/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1849\n",
      "Epoch 682/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1857\n",
      "Epoch 683/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1853\n",
      "Epoch 684/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1818\n",
      "Epoch 685/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1832\n",
      "Epoch 686/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1827\n",
      "Epoch 687/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1845\n",
      "Epoch 688/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1827\n",
      "Epoch 689/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1828\n",
      "Epoch 690/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1833\n",
      "Epoch 691/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1862\n",
      "Epoch 692/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1827\n",
      "Epoch 693/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1843\n",
      "Epoch 694/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1842\n",
      "Epoch 695/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1915\n",
      "Epoch 696/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1885\n",
      "Epoch 697/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1850\n",
      "Epoch 698/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1839\n",
      "Epoch 699/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1857\n",
      "Epoch 700/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1848\n",
      "Epoch 701/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1820\n",
      "Epoch 702/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1846\n",
      "Epoch 703/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1828\n",
      "Epoch 704/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1827\n",
      "Epoch 705/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1838\n",
      "Epoch 706/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1829\n",
      "Epoch 707/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1822\n",
      "Epoch 708/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1867\n",
      "Epoch 709/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1893\n",
      "Epoch 710/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1938\n",
      "Epoch 711/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1913\n",
      "Epoch 712/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1926\n",
      "Epoch 713/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1910\n",
      "Epoch 714/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1855\n",
      "Epoch 715/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1823\n",
      "Epoch 716/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1820\n",
      "Epoch 717/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1831\n",
      "Epoch 718/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1824\n",
      "Epoch 719/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1853\n",
      "Epoch 720/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1826\n",
      "Epoch 721/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.1831\n",
      "Epoch 722/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.1829\n",
      "Epoch 723/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1823\n",
      "Epoch 724/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1834\n",
      "Epoch 725/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1835\n",
      "Epoch 726/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1831\n",
      "Epoch 727/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1825\n",
      "Epoch 728/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1829\n",
      "Epoch 729/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1857\n",
      "Epoch 730/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1891\n",
      "Epoch 731/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1894\n",
      "Epoch 732/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1823\n",
      "Epoch 733/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1847\n",
      "Epoch 734/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1827\n",
      "Epoch 735/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1851\n",
      "Epoch 736/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1868\n",
      "Epoch 737/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1844\n",
      "Epoch 738/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1830\n",
      "Epoch 739/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1873\n",
      "Epoch 740/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1837\n",
      "Epoch 741/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1832\n",
      "Epoch 742/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1869\n",
      "Epoch 743/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1824\n",
      "Epoch 744/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1833\n",
      "Epoch 745/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1829\n",
      "Epoch 746/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1836\n",
      "Epoch 747/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1825\n",
      "Epoch 748/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1858\n",
      "Epoch 749/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1864\n",
      "Epoch 750/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1824\n",
      "Epoch 751/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1820\n",
      "Epoch 752/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1850\n",
      "Epoch 753/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1831\n",
      "Epoch 754/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1831\n",
      "Epoch 755/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1824\n",
      "Epoch 756/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1856\n",
      "Epoch 757/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1847\n",
      "Epoch 758/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1849\n",
      "Epoch 759/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1918\n",
      "Epoch 760/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1876\n",
      "Epoch 761/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1831\n",
      "Epoch 762/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1849\n",
      "Epoch 763/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1849\n",
      "Epoch 764/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1857\n",
      "Epoch 765/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1841\n",
      "Epoch 766/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1833\n",
      "Epoch 767/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1834\n",
      "Epoch 768/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1833\n",
      "Epoch 769/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1819\n",
      "Epoch 770/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1823\n",
      "Epoch 771/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1868\n",
      "Epoch 772/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.1829\n",
      "Epoch 773/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1863\n",
      "Epoch 774/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1939\n",
      "Epoch 775/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1815\n",
      "Epoch 776/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1836\n",
      "Epoch 777/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1859\n",
      "Epoch 778/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1842\n",
      "Epoch 779/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1829\n",
      "Epoch 780/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1852\n",
      "Epoch 781/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1826\n",
      "Epoch 782/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1852\n",
      "Epoch 783/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1852\n",
      "Epoch 784/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1853\n",
      "Epoch 785/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1825\n",
      "Epoch 786/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1821\n",
      "Epoch 787/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1839\n",
      "Epoch 788/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1857\n",
      "Epoch 789/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1822\n",
      "Epoch 790/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1823\n",
      "Epoch 791/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1837\n",
      "Epoch 792/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1875\n",
      "Epoch 793/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1828\n",
      "Epoch 794/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1866\n",
      "Epoch 795/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1823\n",
      "Epoch 796/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1842\n",
      "Epoch 797/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1825\n",
      "Epoch 798/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1828\n",
      "Epoch 799/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1823\n",
      "Epoch 800/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1829\n",
      "Epoch 801/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1820\n",
      "Epoch 802/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1853\n",
      "Epoch 803/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1924\n",
      "Epoch 804/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1880\n",
      "Epoch 805/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1878\n",
      "Epoch 806/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1889\n",
      "Epoch 807/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1838\n",
      "Epoch 808/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1819\n",
      "Epoch 809/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1868\n",
      "Epoch 810/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1899\n",
      "Epoch 811/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1924\n",
      "Epoch 812/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1825\n",
      "Epoch 813/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1836\n",
      "Epoch 814/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1888\n",
      "Epoch 815/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1875\n",
      "Epoch 816/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1839\n",
      "Epoch 817/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1888\n",
      "Epoch 818/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1877\n",
      "Epoch 819/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1833\n",
      "Epoch 820/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1857\n",
      "Epoch 821/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1842\n",
      "Epoch 822/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1849\n",
      "Epoch 823/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1849\n",
      "Epoch 824/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1911\n",
      "Epoch 825/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1822\n",
      "Epoch 826/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1842\n",
      "Epoch 827/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1840\n",
      "Epoch 828/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1832\n",
      "Epoch 829/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1864\n",
      "Epoch 830/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1873\n",
      "Epoch 831/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1979\n",
      "Epoch 832/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1878\n",
      "Epoch 833/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1894\n",
      "Epoch 834/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1987\n",
      "Epoch 835/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1917\n",
      "Epoch 836/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1835\n",
      "Epoch 837/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1833\n",
      "Epoch 838/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1849\n",
      "Epoch 839/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1879\n",
      "Epoch 840/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1897\n",
      "Epoch 841/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1845\n",
      "Epoch 842/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1833\n",
      "Epoch 843/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1829\n",
      "Epoch 844/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1882\n",
      "Epoch 845/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1905\n",
      "Epoch 846/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.1826\n",
      "Epoch 847/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1938\n",
      "Epoch 848/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1940\n",
      "Epoch 849/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1879\n",
      "Epoch 850/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1828\n",
      "Epoch 851/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1822\n",
      "Epoch 852/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1828\n",
      "Epoch 853/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1859\n",
      "Epoch 854/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1845\n",
      "Epoch 855/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1879\n",
      "Epoch 856/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2077\n",
      "Epoch 857/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1883\n",
      "Epoch 858/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1834\n",
      "Epoch 859/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1839\n",
      "Epoch 860/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1818\n",
      "Epoch 861/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1854\n",
      "Epoch 862/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1916\n",
      "Epoch 863/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2005\n",
      "Epoch 864/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1881\n",
      "Epoch 865/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1932\n",
      "Epoch 866/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1958\n",
      "Epoch 867/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1867\n",
      "Epoch 868/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1996\n",
      "Epoch 869/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1860\n",
      "Epoch 870/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1890\n",
      "Epoch 871/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1912\n",
      "Epoch 872/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1862\n",
      "Epoch 873/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1862\n",
      "Epoch 874/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1824\n",
      "Epoch 875/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1841\n",
      "Epoch 876/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1898\n",
      "Epoch 877/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1832\n",
      "Epoch 878/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1829\n",
      "Epoch 879/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1848\n",
      "Epoch 880/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.1853\n",
      "Epoch 881/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1871\n",
      "Epoch 882/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1831\n",
      "Epoch 883/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1858\n",
      "Epoch 884/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1838\n",
      "Epoch 885/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1870\n",
      "Epoch 886/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1829\n",
      "Epoch 887/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1818\n",
      "Epoch 888/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1846\n",
      "Epoch 889/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1907\n",
      "Epoch 890/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1873\n",
      "Epoch 891/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1836\n",
      "Epoch 892/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1828\n",
      "Epoch 893/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1901\n",
      "Epoch 894/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1843\n",
      "Epoch 895/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1847\n",
      "Epoch 896/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1848\n",
      "Epoch 897/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1815\n",
      "Epoch 898/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1830\n",
      "Epoch 899/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1826\n",
      "Epoch 900/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1851\n",
      "Epoch 901/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1832\n",
      "Epoch 902/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1854\n",
      "Epoch 903/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1880\n",
      "Epoch 904/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2051\n",
      "Epoch 905/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1870\n",
      "Epoch 906/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.1827\n",
      "Epoch 907/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1843\n",
      "Epoch 908/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1816\n",
      "Epoch 909/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1824\n",
      "Epoch 910/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1826\n",
      "Epoch 911/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1851\n",
      "Epoch 912/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1879\n",
      "Epoch 913/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1853\n",
      "Epoch 914/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1827\n",
      "Epoch 915/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1829\n",
      "Epoch 916/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1839\n",
      "Epoch 917/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2006\n",
      "Epoch 918/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1949\n",
      "Epoch 919/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1874\n",
      "Epoch 920/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1853\n",
      "Epoch 921/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1883\n",
      "Epoch 922/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1867\n",
      "Epoch 923/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1829\n",
      "Epoch 924/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1856\n",
      "Epoch 925/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1862\n",
      "Epoch 926/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1831\n",
      "Epoch 927/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1860\n",
      "Epoch 928/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1894\n",
      "Epoch 929/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1844\n",
      "Epoch 930/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1859\n",
      "Epoch 931/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1923\n",
      "Epoch 932/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1863\n",
      "Epoch 933/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1833\n",
      "Epoch 934/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1818\n",
      "Epoch 935/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1862\n",
      "Epoch 936/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1930\n",
      "Epoch 937/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1838\n",
      "Epoch 938/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1824\n",
      "Epoch 939/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1854\n",
      "Epoch 940/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1817\n",
      "Epoch 941/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1842\n",
      "Epoch 942/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1845\n",
      "Epoch 943/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1833\n",
      "Epoch 944/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1819\n",
      "Epoch 945/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1884\n",
      "Epoch 946/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1839\n",
      "Epoch 947/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1882\n",
      "Epoch 948/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1827\n",
      "Epoch 949/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1862\n",
      "Epoch 950/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2023\n",
      "Epoch 951/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1887\n",
      "Epoch 952/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1840\n",
      "Epoch 953/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1839\n",
      "Epoch 954/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1936\n",
      "Epoch 955/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1979\n",
      "Epoch 956/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1849\n",
      "Epoch 957/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1822\n",
      "Epoch 958/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1879\n",
      "Epoch 959/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1861\n",
      "Epoch 960/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1896\n",
      "Epoch 961/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1878\n",
      "Epoch 962/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1819\n",
      "Epoch 963/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1894\n",
      "Epoch 964/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1855\n",
      "Epoch 965/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1880\n",
      "Epoch 966/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1866\n",
      "Epoch 967/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1817\n",
      "Epoch 968/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1823\n",
      "Epoch 969/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1875\n",
      "Epoch 970/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1904\n",
      "Epoch 971/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1837\n",
      "Epoch 972/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1822\n",
      "Epoch 973/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1840\n",
      "Epoch 974/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1914\n",
      "Epoch 975/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1891\n",
      "Epoch 976/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1858\n",
      "Epoch 977/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1837\n",
      "Epoch 978/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1863\n",
      "Epoch 979/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1821\n",
      "Epoch 980/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1826\n",
      "Epoch 981/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1927\n",
      "Epoch 982/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1856\n",
      "Epoch 983/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1852\n",
      "Epoch 984/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1850\n",
      "Epoch 985/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1833\n",
      "Epoch 986/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1937\n",
      "Epoch 987/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2176\n",
      "Epoch 988/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2155\n",
      "Epoch 989/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1858\n",
      "Epoch 990/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1898\n",
      "Epoch 991/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1838\n",
      "Epoch 992/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1833\n",
      "Epoch 993/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1880\n",
      "Epoch 994/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1836\n",
      "Epoch 995/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1874\n",
      "Epoch 996/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2028\n",
      "Epoch 997/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1839\n",
      "Epoch 998/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1913\n",
      "Epoch 999/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1817\n",
      "Epoch 1000/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a4c228ef0>"
      ]
     },
     "execution_count": 1115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_stl = Sequential()\n",
    "NN_stl.add(Dense(units=16,input_dim=X_train.shape[1],activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_stl.add(Dense(units=8, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_stl.add(Dense(units=4, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_stl.add(Dense(units=1,activation='linear'))\n",
    "NN_stl.compile(loss='mse', optimizer='adam')\n",
    "NN_stl.fit(np.array(X_train), np.array(y_train), epochs=1000,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN_predictions</th>\n",
       "      <th>actual</th>\n",
       "      <th>GBR_predictions</th>\n",
       "      <th>LY_steals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>0.759017</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.353089</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>0.758752</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.173907</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.726249</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.239356</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>0.723091</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.440376</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>0.760643</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.266172</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.763718</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.390715</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.765402</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.319033</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>0.736633</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.673502</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.732376</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.962459</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>0.723670</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.422100</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.713882</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.371628</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>0.766261</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.177300</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>0.713882</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.114773</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>0.720298</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.034007</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0.745914</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.396807</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0.726219</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.982262</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.747085</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.940142</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>0.760067</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.199929</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>0.761671</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.122935</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>0.713882</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.308229</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.700111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.348828</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>0.716751</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.130853</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.715400</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.198172</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.673416</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.097659</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>0.751518</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.310216</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.738258</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.715295</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.730484</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.125060</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.730407</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.162663</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.753376</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.995260</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.764060</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.435558</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.729537</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.325769</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>0.768610</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.030159</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>0.740345</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.064890</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.743667</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.103742</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>0.748333</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.193721</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.741798</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.866453</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.724067</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.192389</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>0.768144</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.153069</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>0.756519</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.125287</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0.708007</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.084705</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>0.726188</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.172221</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>0.712989</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.959906</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0.747364</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.350841</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>0.754217</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.018734</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>0.743930</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.953146</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.745307</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.004651</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>0.751678</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.448956</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.720596</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.169476</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>0.730422</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.253899</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>0.753606</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.931774</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     NN_predictions  actual  GBR_predictions  LY_steals\n",
       "663        0.759017     1.7         1.353089        1.5\n",
       "623        0.758752     1.6         1.173907        1.4\n",
       "395        0.726249     1.3         1.239356        1.4\n",
       "443        0.723091     1.9         1.440376        1.4\n",
       "226        0.760643     1.1         1.266172        1.4\n",
       "34         0.763718     1.5         1.390715        1.4\n",
       "186        0.765402     1.1         1.319033        1.4\n",
       "467        0.736633     1.6         1.673502        1.4\n",
       "199        0.732376     1.0         0.962459        1.4\n",
       "529        0.723670     1.2         1.422100        1.4\n",
       "100        0.713882     1.3         1.371628        1.4\n",
       "403        0.766261     1.2         1.177300        1.4\n",
       "241        0.713882     1.5         1.114773        1.4\n",
       "431        0.720298     1.0         1.034007        1.3\n",
       "393        0.745914     1.6         1.396807        1.3\n",
       "216        0.726219     1.0         0.982262        1.3\n",
       "9          0.747085     1.0         0.940142        1.3\n",
       "419        0.760067     1.4         1.199929        1.3\n",
       "668        0.761671     1.3         1.122935        1.3\n",
       "404        0.713882     1.9         1.308229        1.3\n",
       "86         0.700111     1.0         1.348828        1.3\n",
       "641        0.716751     1.0         1.130853        1.3\n",
       "127        0.715400     0.5         1.198172        1.3\n",
       "46         0.673416     0.9         1.097659        1.3\n",
       "373        0.751518     1.4         1.310216        1.3\n",
       "42         0.738258     0.8         0.715295        1.3\n",
       "566        0.730484     0.9         1.125060        1.3\n",
       "173        0.730407     1.1         1.162663        1.3\n",
       "176        0.753376     0.7         0.995260        1.3\n",
       "141        0.764060     1.1         1.435558        1.3\n",
       "30         0.729537     1.7         1.325769        1.3\n",
       "352        0.768610     1.0         1.030159        1.2\n",
       "606        0.740345     1.2         1.064890        1.2\n",
       "399        0.743667     0.9         1.103742        1.2\n",
       "333        0.748333     1.5         1.193721        1.2\n",
       "35         0.741798     0.9         0.866453        1.2\n",
       "27         0.724067     1.3         1.192389        1.2\n",
       "439        0.768144     0.9         1.153069        1.2\n",
       "652        0.756519     1.2         1.125287        1.2\n",
       "212        0.708007     1.2         1.084705        1.2\n",
       "487        0.726188     0.7         1.172221        1.2\n",
       "478        0.712989     1.0         0.959906        1.2\n",
       "565        0.747364     1.7         1.350841        1.2\n",
       "354        0.754217     1.0         1.018734        1.2\n",
       "629        0.743930     0.9         0.953146        1.2\n",
       "80         0.745307     1.2         1.004651        1.2\n",
       "232        0.751678     1.4         1.448956        1.2\n",
       "78         0.720596     1.4         1.169476        1.2\n",
       "364        0.730422     1.4         1.253899        1.2\n",
       "541        0.753606     0.6         0.931774        1.2"
      ]
     },
     "execution_count": 1116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = NN_stl.predict(X_test)\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.5)\n",
    "gbr.fit(X_train,y_train)\n",
    "gbr_predictions = gbr.predict(X_test)\n",
    "LR = LinearRegression(fit_intercept=True).fit(X_train,y_train)\n",
    "\n",
    "testing = pd.DataFrame(predictions)\n",
    "testing.columns=['NN_predictions']\n",
    "testing['actual'] = y_test.reset_index()['steals']\n",
    "testing['GBR_predictions']=gbr_predictions\n",
    "testing['LY_steals']=X_test['steals_ly'].reset_index()['steals_ly']\n",
    "testing.sort_values(by='LY_steals',ascending=False)[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1117,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2017steals = steals[steals['season']==2017].drop(['team','player','steals','Games'],axis=1)\n",
    "steals_2017 = NN_stl.predict(pred_2017steals)\n",
    "gbr_stl_2017 = pd.DataFrame(gbr.predict(pred_2017steals))\n",
    "LR_stl_2017 = pd.DataFrame(LR.predict(pred_2017steals))\n",
    "test_2 =pd.DataFrame(steals_2017)\n",
    "test_3 = pd.merge(steals,pred_2017steals,left_index=True,right_index=True).reset_index()\n",
    "test_3['predictions']=test_2[0]\n",
    "test_3['gbr_pred'] = gbr_stl_2017[0]\n",
    "test_3['LR_pred'] = LR_stl_2017[0]\n",
    "test_3['mean_pred'] = (test_3['predictions']+test_3['gbr_pred']+test_3['LR_pred'])/3\n",
    "test_3 = test_3[test_3['Games']>30]\n",
    "test_3[['player','steals','predictions','LR_pred','gbr_pred','mean_pred','steals_ly_x']].sort_values(by='steals_ly_x',ascending=False)[0:50]\n",
    "\n",
    "steals_2017 = test_3[['player','LR_pred']]\n",
    "steals_2017.columns = ['player','steal_prediction']\n",
    "df_2017 = pd.merge(df_2017,steals_2017, how = 'left',left_on='player',right_on='player')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE using LR:0.055367781036989874\n",
      "MSE using GB:0.05970114369784547\n",
      "MSE using NN:0.17131122692566111\n",
      "MSE using combo:0.06922994157335643\n",
      "MSE using mean:0.1709712976660093\n",
      "MSE using last year stats:0.08067307692307696\n"
     ]
    }
   ],
   "source": [
    "print('MSE using LR:{}'.format(np.mean((test_3['steals']-test_3['LR_pred'])**2)))\n",
    "print('MSE using GB:{}'.format(np.mean((test_3['steals']-test_3['gbr_pred'])**2)))\n",
    "print('MSE using NN:{}'.format(np.mean((test_3['steals']-test_3['predictions'])**2)))\n",
    "print('MSE using combo:{}'.format(np.mean((test_3['steals']-test_3['mean_pred'])**2)))\n",
    "print('MSE using mean:{}'.format(np.mean((test_3['steals']-np.mean(test_3['steals']))**2)))\n",
    "print('MSE using last year stats:{}'.format(np.mean((test_3['steals']-test_3['steals_ly_x'])**2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01125328 0.04008531 0.10639288 0.04426043 0.02392808 0.00408012\n",
      " 0.0016119  0.0723225  0.04320477 0.05824298 0.0763244  0.08581513\n",
      " 0.04672878 0.07181035 0.06675481 0.04345141 0.15460267 0.01074619\n",
      " 0.03838401]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['season', 'age', 'steals_ly', 'change_steals_ly', 'C_PF', 'PG', 'SG_SF',\n",
       "       'starter_change', 'per_ly', 'change_per', 'stl_perc_ly',\n",
       "       'change_stl_perc', 'defensive_winshares', 'defensive_boxplusminus',\n",
       "       'boxplusminus', 'value_overreplacement', 'career_steals', 'yearspro',\n",
       "       'age_squared'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gbr.feature_importances_)\n",
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1121,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''next is blocks.  In the future, may want to add minutes from last season?'''\n",
    "\n",
    "\n",
    "query= '''\n",
    "        \n",
    "        DROP TABLE IF EXISTS blocks_pred;\n",
    "        CREATE TABLE blocks_pred(\n",
    "        season int, --these come from player_stats\n",
    "        player varchar(50),\n",
    "        Age int,\n",
    "        team varchar(50),\n",
    "        blk float, -- these come from player_stats\n",
    "        blk_ly float,\n",
    "        change_blk_ly float,\n",
    "        Games float,\n",
    "        C_PF int,\n",
    "        PG int,\n",
    "        SG_SF int,\n",
    "        starter_change int, \n",
    "        \n",
    "\n",
    "        -- from player_advstats\n",
    "        per_ly float,\n",
    "        change_per float,\n",
    "        blk_perc_ly float,\n",
    "        change_blk_perc_ly float,\n",
    "        defensive_winshares float,\n",
    "        defensive_boxplusminus float,\n",
    "        boxplusminus float,\n",
    "        value_overreplacement float,\n",
    "        \n",
    "        max_teammate_usage float,\n",
    "        max_teammateto float,\n",
    "        max_teammateshot_attempts float,\n",
    "        \n",
    "        career_blk float,\n",
    "        yearspro int\n",
    "        );\n",
    "        \n",
    "        INSERT INTO blocks_pred(season,player,age,team,blk,blk_ly,change_blk_ly,starter_change,Games,C_PF,PG,SG_SF)\n",
    "        SELECT season,player,age,startingteam,blk,blk_ly,change_blk_ly,starter-starter_ly,Games,\n",
    "        case when pos in ('C','PF') then 1 else 0 end,case when pos='PG' then 1 else 0 end,case when pos in('SG','SF') then 1 else 0 end from player_stats;\n",
    "        \n",
    "        \n",
    "        update blocks_pred bp\n",
    "        set per_ly=pa.per_ly,change_per=pa.change_per,blk_perc_ly = pa.blk_perc_ly,change_blk_perc_ly = pa.change_blk_perc_ly\n",
    "        ,defensive_winshares=pa.defensive_winshares,defensive_boxplusminus=pa.defensive_boxplusminus\n",
    "        ,boxplusminus=pa.boxplusminus,value_overreplacement=pa.value_overreplacement\n",
    "        from player_advstats pa\n",
    "        where bp.player = pa.player and bp.season = pa.season and bp.team = pa.startingteam;\n",
    "        \n",
    "        update blocks_pred bp\n",
    "        set max_teammate_usage=tm.max_teammate_usage,max_teammateto=tm.max_teammateto,max_teammateshot_attempts=tm.max_teammateshot_attempts\n",
    "        from teammate_maxes tm\n",
    "        where tm.season = bp.season and tm.player = bp.player;\n",
    "        \n",
    "        update blocks_pred bp\n",
    "        set career_blk = pc.career_blk, yearspro = pc.yearspro\n",
    "        from player_careerstats pc\n",
    "        where bp.player = pc.player and bp.season = pc.season;\n",
    "        \n",
    "        \n",
    "        select * from blocks_pred where season>2009\n",
    "        '''\n",
    "\n",
    "\n",
    "cur.execute(query)\n",
    "data = cur.fetchall()\n",
    "blocks_df = pd.DataFrame(np.array(data))\n",
    "blocks_df.columns = ['season','player','age','team','blocks','blocks_ly','change_blocks_ly','Games','C_PF','PG','SG_SF','starter_change'\n",
    "                    ,'per_ly','change_per','blk_perc_ly','change_blk_perc','defensive_winshares','defensive_boxplusminus','boxplusminus','value_overreplacement'\n",
    "                     ,'max_teammate_usage','max_teammateto','max_teammateshot_attempts','career_blocks','yearspro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "blocks_df['age_squared']=blocks_df['age']*blocks_df['age']\n",
    "blocks = blocks_df[blocks_df['blocks_ly'].notna()]\n",
    "for i in blocks.columns:\n",
    "    if i not in(['player','team']):\n",
    "        blocks[i]=pd.to_numeric(blocks[i])\n",
    "blocks = blocks.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = blocks[(blocks['season']!=2017) & (blocks['Games']>30)].drop(['player','team','blocks','Games'],axis=1)\n",
    "#X = blocks[(blocks['season']!=2017) & (blocks['Games']>30)][['blocks_ly','career_blocks','starter_change']]\n",
    "y = blocks[(blocks['season']!=2017) & (blocks['Games']>30)]['blocks']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1564/1564 [==============================] - 4s 2ms/step - loss: 701.7219\n",
      "Epoch 2/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 137.8817\n",
      "Epoch 3/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 51.9490\n",
      "Epoch 4/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 24.8119\n",
      "Epoch 5/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 8.7567\n",
      "Epoch 6/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.4517\n",
      "Epoch 7/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 4.8597\n",
      "Epoch 8/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 3.8379\n",
      "Epoch 9/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 3.4846\n",
      "Epoch 10/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 2.9180\n",
      "Epoch 11/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 2.4962\n",
      "Epoch 12/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 2.2224\n",
      "Epoch 13/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 2.0253\n",
      "Epoch 14/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 1.9193\n",
      "Epoch 15/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 1.7130\n",
      "Epoch 16/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.5593\n",
      "Epoch 17/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 1.4873\n",
      "Epoch 18/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.3157\n",
      "Epoch 19/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 1.1801\n",
      "Epoch 20/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.1067\n",
      "Epoch 21/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.0190\n",
      "Epoch 22/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.9126\n",
      "Epoch 23/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.8488\n",
      "Epoch 24/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7750\n",
      "Epoch 25/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7365\n",
      "Epoch 26/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.7278\n",
      "Epoch 27/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6784\n",
      "Epoch 28/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6328\n",
      "Epoch 29/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6085\n",
      "Epoch 30/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5489\n",
      "Epoch 31/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5210\n",
      "Epoch 32/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5191\n",
      "Epoch 33/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4930\n",
      "Epoch 34/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4639\n",
      "Epoch 35/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4552\n",
      "Epoch 36/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4366\n",
      "Epoch 37/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4308\n",
      "Epoch 38/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4309\n",
      "Epoch 39/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4061\n",
      "Epoch 40/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.3953\n",
      "Epoch 41/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.3846\n",
      "Epoch 42/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.3891\n",
      "Epoch 43/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.3792\n",
      "Epoch 44/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.3712\n",
      "Epoch 45/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.3633\n",
      "Epoch 46/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.3887\n",
      "Epoch 47/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.3460\n",
      "Epoch 48/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.3550\n",
      "Epoch 49/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.3306\n",
      "Epoch 50/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.3289\n",
      "Epoch 51/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.3223\n",
      "Epoch 52/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.3263\n",
      "Epoch 53/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.3228\n",
      "Epoch 54/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.3161\n",
      "Epoch 55/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.3100\n",
      "Epoch 56/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.3092\n",
      "Epoch 57/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.3070\n",
      "Epoch 58/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.3077\n",
      "Epoch 59/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2943\n",
      "Epoch 60/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.3096\n",
      "Epoch 61/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.3358\n",
      "Epoch 62/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.3114\n",
      "Epoch 63/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.3239\n",
      "Epoch 64/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.3146\n",
      "Epoch 65/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2819\n",
      "Epoch 66/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2791\n",
      "Epoch 67/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2754\n",
      "Epoch 68/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2733\n",
      "Epoch 69/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.3220\n",
      "Epoch 70/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2714\n",
      "Epoch 71/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2824\n",
      "Epoch 72/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2626\n",
      "Epoch 73/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2868\n",
      "Epoch 74/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2861\n",
      "Epoch 75/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2544\n",
      "Epoch 76/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2502\n",
      "Epoch 77/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2508\n",
      "Epoch 78/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2596\n",
      "Epoch 79/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2443\n",
      "Epoch 80/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2532\n",
      "Epoch 81/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2451\n",
      "Epoch 82/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2687\n",
      "Epoch 83/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.2639\n",
      "Epoch 84/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2769\n",
      "Epoch 85/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2572\n",
      "Epoch 86/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2466\n",
      "Epoch 87/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2339\n",
      "Epoch 88/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2539\n",
      "Epoch 89/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2609\n",
      "Epoch 90/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2297\n",
      "Epoch 91/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2338\n",
      "Epoch 92/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2467\n",
      "Epoch 93/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2309\n",
      "Epoch 94/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2348\n",
      "Epoch 95/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2268\n",
      "Epoch 96/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2250\n",
      "Epoch 97/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2345\n",
      "Epoch 98/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2370\n",
      "Epoch 99/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2157\n",
      "Epoch 100/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2271\n",
      "Epoch 101/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.2149\n",
      "Epoch 102/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2244\n",
      "Epoch 103/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2263\n",
      "Epoch 104/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2183\n",
      "Epoch 105/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2162\n",
      "Epoch 106/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2430\n",
      "Epoch 107/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2307\n",
      "Epoch 108/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2354\n",
      "Epoch 109/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2333\n",
      "Epoch 110/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2241\n",
      "Epoch 111/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2112\n",
      "Epoch 112/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2130\n",
      "Epoch 113/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2636\n",
      "Epoch 114/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2229\n",
      "Epoch 115/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2261\n",
      "Epoch 116/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2073\n",
      "Epoch 117/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2006\n",
      "Epoch 118/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2099\n",
      "Epoch 119/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2428\n",
      "Epoch 120/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2171\n",
      "Epoch 121/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2301\n",
      "Epoch 122/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2169\n",
      "Epoch 123/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1990\n",
      "Epoch 124/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1979\n",
      "Epoch 125/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.2037\n",
      "Epoch 126/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2026\n",
      "Epoch 127/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1990\n",
      "Epoch 128/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1899\n",
      "Epoch 129/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1936\n",
      "Epoch 130/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1975\n",
      "Epoch 131/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2083\n",
      "Epoch 132/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2121\n",
      "Epoch 133/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2140\n",
      "Epoch 134/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1861\n",
      "Epoch 135/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1917\n",
      "Epoch 136/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2097\n",
      "Epoch 137/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2163\n",
      "Epoch 138/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1890\n",
      "Epoch 139/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1874\n",
      "Epoch 140/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1872\n",
      "Epoch 141/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1969\n",
      "Epoch 142/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2025\n",
      "Epoch 143/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2031\n",
      "Epoch 144/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1841\n",
      "Epoch 145/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1927\n",
      "Epoch 146/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2156\n",
      "Epoch 147/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1824\n",
      "Epoch 148/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1788\n",
      "Epoch 149/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1797\n",
      "Epoch 150/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1783\n",
      "Epoch 151/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1915\n",
      "Epoch 152/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1778\n",
      "Epoch 153/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1807\n",
      "Epoch 154/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1900\n",
      "Epoch 155/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1752\n",
      "Epoch 156/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1811\n",
      "Epoch 157/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1981\n",
      "Epoch 158/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2129\n",
      "Epoch 159/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1852\n",
      "Epoch 160/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1814\n",
      "Epoch 161/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1746\n",
      "Epoch 162/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1729\n",
      "Epoch 163/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2347\n",
      "Epoch 164/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2158\n",
      "Epoch 165/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1954\n",
      "Epoch 166/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2204\n",
      "Epoch 167/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1725\n",
      "Epoch 168/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1918\n",
      "Epoch 169/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1700\n",
      "Epoch 170/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1734\n",
      "Epoch 171/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1905\n",
      "Epoch 172/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1741\n",
      "Epoch 173/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1810\n",
      "Epoch 174/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1716\n",
      "Epoch 175/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1719\n",
      "Epoch 176/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1658\n",
      "Epoch 177/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1651\n",
      "Epoch 178/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1742\n",
      "Epoch 179/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1656\n",
      "Epoch 180/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2039\n",
      "Epoch 181/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1612\n",
      "Epoch 182/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1711\n",
      "Epoch 183/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1647\n",
      "Epoch 184/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1762\n",
      "Epoch 185/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1605\n",
      "Epoch 186/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1582\n",
      "Epoch 187/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1529\n",
      "Epoch 188/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1798\n",
      "Epoch 189/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1556\n",
      "Epoch 190/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1601\n",
      "Epoch 191/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1616\n",
      "Epoch 192/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1684\n",
      "Epoch 193/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1744\n",
      "Epoch 194/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1484\n",
      "Epoch 195/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1534\n",
      "Epoch 196/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1703\n",
      "Epoch 197/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1638\n",
      "Epoch 198/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1889\n",
      "Epoch 199/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1654\n",
      "Epoch 200/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1470\n",
      "Epoch 201/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1498\n",
      "Epoch 202/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1633\n",
      "Epoch 203/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1632\n",
      "Epoch 204/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2035\n",
      "Epoch 205/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1894\n",
      "Epoch 206/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1557\n",
      "Epoch 207/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1634\n",
      "Epoch 208/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1425\n",
      "Epoch 209/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1459\n",
      "Epoch 210/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1548\n",
      "Epoch 211/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1904\n",
      "Epoch 212/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2173\n",
      "Epoch 213/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1409\n",
      "Epoch 214/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1470\n",
      "Epoch 215/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1583\n",
      "Epoch 216/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2319\n",
      "Epoch 217/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1803\n",
      "Epoch 218/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1532\n",
      "Epoch 219/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1445\n",
      "Epoch 220/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1454\n",
      "Epoch 221/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1889\n",
      "Epoch 222/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1966\n",
      "Epoch 223/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2250\n",
      "Epoch 224/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1869\n",
      "Epoch 225/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1670\n",
      "Epoch 226/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1507\n",
      "Epoch 227/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1782\n",
      "Epoch 228/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1913\n",
      "Epoch 229/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1442\n",
      "Epoch 230/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1382\n",
      "Epoch 231/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1338\n",
      "Epoch 232/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.1424\n",
      "Epoch 233/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1434\n",
      "Epoch 234/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1363\n",
      "Epoch 235/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1454\n",
      "Epoch 236/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1347\n",
      "Epoch 237/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1372\n",
      "Epoch 238/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1494\n",
      "Epoch 239/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1497\n",
      "Epoch 240/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1476\n",
      "Epoch 241/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1482\n",
      "Epoch 242/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2107\n",
      "Epoch 243/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1384\n",
      "Epoch 244/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1506\n",
      "Epoch 245/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1923\n",
      "Epoch 246/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1319\n",
      "Epoch 247/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1318\n",
      "Epoch 248/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1601\n",
      "Epoch 249/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2408\n",
      "Epoch 250/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1719\n",
      "Epoch 251/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2648\n",
      "Epoch 252/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1716\n",
      "Epoch 253/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1372\n",
      "Epoch 254/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1502\n",
      "Epoch 255/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1377\n",
      "Epoch 256/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1543\n",
      "Epoch 257/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1484\n",
      "Epoch 258/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1451\n",
      "Epoch 259/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1519\n",
      "Epoch 260/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2099\n",
      "Epoch 261/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1397\n",
      "Epoch 262/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1362\n",
      "Epoch 263/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1406\n",
      "Epoch 264/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1375\n",
      "Epoch 265/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1340\n",
      "Epoch 266/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1271\n",
      "Epoch 267/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1507\n",
      "Epoch 268/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1351\n",
      "Epoch 269/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1579\n",
      "Epoch 270/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1227\n",
      "Epoch 271/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1689\n",
      "Epoch 272/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1601\n",
      "Epoch 273/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1357\n",
      "Epoch 274/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1352\n",
      "Epoch 275/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1192\n",
      "Epoch 276/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1304\n",
      "Epoch 277/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1238\n",
      "Epoch 278/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1199\n",
      "Epoch 279/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1288\n",
      "Epoch 280/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1385\n",
      "Epoch 281/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1452\n",
      "Epoch 282/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1333\n",
      "Epoch 283/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1274\n",
      "Epoch 284/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1302\n",
      "Epoch 285/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1186\n",
      "Epoch 286/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1176\n",
      "Epoch 287/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1629\n",
      "Epoch 288/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1987\n",
      "Epoch 289/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1649\n",
      "Epoch 290/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1415\n",
      "Epoch 291/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1292\n",
      "Epoch 292/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1159\n",
      "Epoch 293/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1225\n",
      "Epoch 294/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1179\n",
      "Epoch 295/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1189\n",
      "Epoch 296/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1383\n",
      "Epoch 297/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1700\n",
      "Epoch 298/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1231\n",
      "Epoch 299/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1540\n",
      "Epoch 300/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1147\n",
      "Epoch 301/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1159\n",
      "Epoch 302/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1308\n",
      "Epoch 303/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1370\n",
      "Epoch 304/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1618\n",
      "Epoch 305/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1680\n",
      "Epoch 306/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1127\n",
      "Epoch 307/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1092\n",
      "Epoch 308/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1335\n",
      "Epoch 309/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1317\n",
      "Epoch 310/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1456\n",
      "Epoch 311/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1303\n",
      "Epoch 312/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1891\n",
      "Epoch 313/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1266\n",
      "Epoch 314/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1210\n",
      "Epoch 315/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1471\n",
      "Epoch 316/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1260\n",
      "Epoch 317/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1239\n",
      "Epoch 318/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1112\n",
      "Epoch 319/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1834\n",
      "Epoch 320/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1846\n",
      "Epoch 321/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1754\n",
      "Epoch 322/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1191\n",
      "Epoch 323/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1028\n",
      "Epoch 324/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1044\n",
      "Epoch 325/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1323\n",
      "Epoch 326/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1102\n",
      "Epoch 327/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1260\n",
      "Epoch 328/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1290\n",
      "Epoch 329/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1460\n",
      "Epoch 330/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1140\n",
      "Epoch 331/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1121\n",
      "Epoch 332/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1040\n",
      "Epoch 333/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1178\n",
      "Epoch 334/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1150\n",
      "Epoch 335/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1012\n",
      "Epoch 336/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1159\n",
      "Epoch 337/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1351\n",
      "Epoch 338/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1519\n",
      "Epoch 339/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1799\n",
      "Epoch 340/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1913\n",
      "Epoch 341/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1469\n",
      "Epoch 342/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1136\n",
      "Epoch 343/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1197\n",
      "Epoch 344/1000\n",
      "1564/1564 [==============================] - 0s 103us/step - loss: 0.1372\n",
      "Epoch 345/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.1739\n",
      "Epoch 346/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.1209\n",
      "Epoch 347/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1311\n",
      "Epoch 348/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 0.1245\n",
      "Epoch 349/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 0.1057\n",
      "Epoch 350/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 0.0973\n",
      "Epoch 351/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.0959\n",
      "Epoch 352/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.0958\n",
      "Epoch 353/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1072\n",
      "Epoch 354/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1275\n",
      "Epoch 355/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1520\n",
      "Epoch 356/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1534\n",
      "Epoch 357/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1720\n",
      "Epoch 358/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1104\n",
      "Epoch 359/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1060\n",
      "Epoch 360/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.0988\n",
      "Epoch 361/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1095\n",
      "Epoch 362/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.1106\n",
      "Epoch 363/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1085\n",
      "Epoch 364/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1233\n",
      "Epoch 365/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1023\n",
      "Epoch 366/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1335\n",
      "Epoch 367/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1283\n",
      "Epoch 368/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.0948\n",
      "Epoch 369/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1297\n",
      "Epoch 370/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1368\n",
      "Epoch 371/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1520\n",
      "Epoch 372/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1289\n",
      "Epoch 373/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1429\n",
      "Epoch 374/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1311\n",
      "Epoch 375/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.0929\n",
      "Epoch 376/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1019\n",
      "Epoch 377/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.0918\n",
      "Epoch 378/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1031\n",
      "Epoch 379/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.0972\n",
      "Epoch 380/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.1214\n",
      "Epoch 381/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.1265\n",
      "Epoch 382/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.0964\n",
      "Epoch 383/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1038\n",
      "Epoch 384/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.0984\n",
      "Epoch 385/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1219\n",
      "Epoch 386/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1021\n",
      "Epoch 387/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1220\n",
      "Epoch 388/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.0944\n",
      "Epoch 389/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.0892\n",
      "Epoch 390/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.0990\n",
      "Epoch 391/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1177\n",
      "Epoch 392/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.0874\n",
      "Epoch 393/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1234\n",
      "Epoch 394/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1141\n",
      "Epoch 395/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.2519\n",
      "Epoch 396/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.2706\n",
      "Epoch 397/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1815\n",
      "Epoch 398/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1434\n",
      "Epoch 399/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1119\n",
      "Epoch 400/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.0843\n",
      "Epoch 401/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1688\n",
      "Epoch 402/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1023\n",
      "Epoch 403/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1082\n",
      "Epoch 404/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1107\n",
      "Epoch 405/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1047\n",
      "Epoch 406/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.0974\n",
      "Epoch 407/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1138\n",
      "Epoch 408/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1126\n",
      "Epoch 409/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1009\n",
      "Epoch 410/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1031\n",
      "Epoch 411/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.1489\n",
      "Epoch 412/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1258\n",
      "Epoch 413/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1175\n",
      "Epoch 414/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1113\n",
      "Epoch 415/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1049\n",
      "Epoch 416/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1685\n",
      "Epoch 417/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1546\n",
      "Epoch 418/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.0872\n",
      "Epoch 419/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.0870\n",
      "Epoch 420/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.0963\n",
      "Epoch 421/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1475\n",
      "Epoch 422/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1563\n",
      "Epoch 423/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.1114\n",
      "Epoch 424/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1016\n",
      "Epoch 425/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1128\n",
      "Epoch 426/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1070\n",
      "Epoch 427/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1451\n",
      "Epoch 428/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1550\n",
      "Epoch 429/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1244\n",
      "Epoch 430/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1052\n",
      "Epoch 431/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0901\n",
      "Epoch 432/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0851\n",
      "Epoch 433/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0953\n",
      "Epoch 434/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0816\n",
      "Epoch 435/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1100\n",
      "Epoch 436/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1245\n",
      "Epoch 437/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1253\n",
      "Epoch 438/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2580\n",
      "Epoch 439/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.2109\n",
      "Epoch 440/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1242\n",
      "Epoch 441/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0955\n",
      "Epoch 442/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0861\n",
      "Epoch 443/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1301\n",
      "Epoch 444/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1120\n",
      "Epoch 445/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1066\n",
      "Epoch 446/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0873\n",
      "Epoch 447/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1197\n",
      "Epoch 448/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0886\n",
      "Epoch 449/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0967\n",
      "Epoch 450/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1125\n",
      "Epoch 451/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1101\n",
      "Epoch 452/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1250\n",
      "Epoch 453/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0984\n",
      "Epoch 454/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1306\n",
      "Epoch 455/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0999\n",
      "Epoch 456/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1189\n",
      "Epoch 457/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1085\n",
      "Epoch 458/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1324\n",
      "Epoch 459/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.0809\n",
      "Epoch 460/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.0925\n",
      "Epoch 461/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.0826\n",
      "Epoch 462/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.0824\n",
      "Epoch 463/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0887\n",
      "Epoch 464/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0895\n",
      "Epoch 465/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1429\n",
      "Epoch 466/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1245\n",
      "Epoch 467/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0807\n",
      "Epoch 468/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0770\n",
      "Epoch 469/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0771\n",
      "Epoch 470/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0792\n",
      "Epoch 471/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0841\n",
      "Epoch 472/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0789\n",
      "Epoch 473/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0841\n",
      "Epoch 474/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0816\n",
      "Epoch 475/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.0870\n",
      "Epoch 476/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1162\n",
      "Epoch 477/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.0848\n",
      "Epoch 478/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1030\n",
      "Epoch 479/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1007\n",
      "Epoch 480/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.0899\n",
      "Epoch 481/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0966\n",
      "Epoch 482/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.0838\n",
      "Epoch 483/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.0880\n",
      "Epoch 484/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0858\n",
      "Epoch 485/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0829\n",
      "Epoch 486/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0781\n",
      "Epoch 487/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1415\n",
      "Epoch 488/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1055\n",
      "Epoch 489/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1436\n",
      "Epoch 490/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1083\n",
      "Epoch 491/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0931\n",
      "Epoch 492/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1605\n",
      "Epoch 493/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.0886\n",
      "Epoch 494/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0875\n",
      "Epoch 495/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1319\n",
      "Epoch 496/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0844\n",
      "Epoch 497/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0914\n",
      "Epoch 498/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0892\n",
      "Epoch 499/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0770\n",
      "Epoch 500/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1058\n",
      "Epoch 501/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1131\n",
      "Epoch 502/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1405\n",
      "Epoch 503/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1394\n",
      "Epoch 504/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0932\n",
      "Epoch 505/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0916\n",
      "Epoch 506/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0890\n",
      "Epoch 507/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1220\n",
      "Epoch 508/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0779\n",
      "Epoch 509/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1126\n",
      "Epoch 510/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1625\n",
      "Epoch 511/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1466\n",
      "Epoch 512/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1105\n",
      "Epoch 513/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1094\n",
      "Epoch 514/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0936\n",
      "Epoch 515/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1344\n",
      "Epoch 516/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1102\n",
      "Epoch 517/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0772\n",
      "Epoch 518/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0975\n",
      "Epoch 519/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0975\n",
      "Epoch 520/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0800\n",
      "Epoch 521/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0944\n",
      "Epoch 522/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0797\n",
      "Epoch 523/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0913\n",
      "Epoch 524/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1005\n",
      "Epoch 525/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1633\n",
      "Epoch 526/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0916\n",
      "Epoch 527/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1343\n",
      "Epoch 528/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0848\n",
      "Epoch 529/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1111\n",
      "Epoch 530/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0853\n",
      "Epoch 531/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.0937\n",
      "Epoch 532/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0947\n",
      "Epoch 533/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0684\n",
      "Epoch 534/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.0711\n",
      "Epoch 535/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0880\n",
      "Epoch 536/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1114\n",
      "Epoch 537/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1234\n",
      "Epoch 538/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0811\n",
      "Epoch 539/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0785\n",
      "Epoch 540/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1160\n",
      "Epoch 541/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1071\n",
      "Epoch 542/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0687\n",
      "Epoch 543/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1104\n",
      "Epoch 544/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1301\n",
      "Epoch 545/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1048\n",
      "Epoch 546/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.0680\n",
      "Epoch 547/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0792\n",
      "Epoch 548/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0821\n",
      "Epoch 549/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1253\n",
      "Epoch 550/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0922\n",
      "Epoch 551/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0659\n",
      "Epoch 552/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1502\n",
      "Epoch 553/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1390\n",
      "Epoch 554/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1004\n",
      "Epoch 555/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0924\n",
      "Epoch 556/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0869\n",
      "Epoch 557/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0760\n",
      "Epoch 558/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0928\n",
      "Epoch 559/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0671\n",
      "Epoch 560/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0746\n",
      "Epoch 561/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0693\n",
      "Epoch 562/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0691\n",
      "Epoch 563/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0664\n",
      "Epoch 564/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.0983\n",
      "Epoch 565/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1792\n",
      "Epoch 566/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1019\n",
      "Epoch 567/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1126\n",
      "Epoch 568/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1791\n",
      "Epoch 569/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1371\n",
      "Epoch 570/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0928\n",
      "Epoch 571/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0662\n",
      "Epoch 572/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0971\n",
      "Epoch 573/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1213\n",
      "Epoch 574/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1266\n",
      "Epoch 575/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0776\n",
      "Epoch 576/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1029\n",
      "Epoch 577/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.0865\n",
      "Epoch 578/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0800\n",
      "Epoch 579/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1213\n",
      "Epoch 580/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.0664\n",
      "Epoch 581/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.0675\n",
      "Epoch 582/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.0616\n",
      "Epoch 583/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1080\n",
      "Epoch 584/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1161\n",
      "Epoch 585/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1320\n",
      "Epoch 586/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1126\n",
      "Epoch 587/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1420\n",
      "Epoch 588/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1637\n",
      "Epoch 589/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1373\n",
      "Epoch 590/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0999\n",
      "Epoch 591/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1166\n",
      "Epoch 592/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0737\n",
      "Epoch 593/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0743\n",
      "Epoch 594/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0965\n",
      "Epoch 595/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1003\n",
      "Epoch 596/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1768\n",
      "Epoch 597/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1169\n",
      "Epoch 598/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0907\n",
      "Epoch 599/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.0855\n",
      "Epoch 600/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.0825\n",
      "Epoch 601/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.0931\n",
      "Epoch 602/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1641\n",
      "Epoch 603/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0735\n",
      "Epoch 604/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0759\n",
      "Epoch 605/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0706\n",
      "Epoch 606/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0715\n",
      "Epoch 607/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1205\n",
      "Epoch 608/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0911\n",
      "Epoch 609/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1007\n",
      "Epoch 610/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0750\n",
      "Epoch 611/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0755\n",
      "Epoch 612/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0766\n",
      "Epoch 613/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1265\n",
      "Epoch 614/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1063\n",
      "Epoch 615/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0924\n",
      "Epoch 616/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0823\n",
      "Epoch 617/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1293\n",
      "Epoch 618/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.0914\n",
      "Epoch 619/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.0864\n",
      "Epoch 620/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0790\n",
      "Epoch 621/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.0791\n",
      "Epoch 622/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0855\n",
      "Epoch 623/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.0780\n",
      "Epoch 624/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.0793\n",
      "Epoch 625/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0605\n",
      "Epoch 626/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0657\n",
      "Epoch 627/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0817\n",
      "Epoch 628/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0914\n",
      "Epoch 629/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1503\n",
      "Epoch 630/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0989\n",
      "Epoch 631/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0696\n",
      "Epoch 632/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0689\n",
      "Epoch 633/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0713\n",
      "Epoch 634/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0679\n",
      "Epoch 635/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.0780\n",
      "Epoch 636/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.0932\n",
      "Epoch 637/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1671\n",
      "Epoch 638/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1258\n",
      "Epoch 639/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.0913\n",
      "Epoch 640/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.0700\n",
      "Epoch 641/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.0627\n",
      "Epoch 642/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0810\n",
      "Epoch 643/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0712\n",
      "Epoch 644/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0903\n",
      "Epoch 645/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1076\n",
      "Epoch 646/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1356\n",
      "Epoch 647/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1317\n",
      "Epoch 648/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1173\n",
      "Epoch 649/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0679\n",
      "Epoch 650/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0874\n",
      "Epoch 651/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0667\n",
      "Epoch 652/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.0931\n",
      "Epoch 653/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.0675\n",
      "Epoch 654/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0767\n",
      "Epoch 655/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0597\n",
      "Epoch 656/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0593\n",
      "Epoch 657/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0655\n",
      "Epoch 658/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0891\n",
      "Epoch 659/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0635\n",
      "Epoch 660/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0644\n",
      "Epoch 661/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0733\n",
      "Epoch 662/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0894\n",
      "Epoch 663/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0694\n",
      "Epoch 664/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1591\n",
      "Epoch 665/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0895\n",
      "Epoch 666/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0991\n",
      "Epoch 667/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0684\n",
      "Epoch 668/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0621\n",
      "Epoch 669/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0715\n",
      "Epoch 670/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1022\n",
      "Epoch 671/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.1273\n",
      "Epoch 672/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.0728\n",
      "Epoch 673/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.0770\n",
      "Epoch 674/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1286\n",
      "Epoch 675/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0971\n",
      "Epoch 676/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0844\n",
      "Epoch 677/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0888\n",
      "Epoch 678/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0851\n",
      "Epoch 679/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0754\n",
      "Epoch 680/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0646\n",
      "Epoch 681/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0761\n",
      "Epoch 682/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0893\n",
      "Epoch 683/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0909\n",
      "Epoch 684/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0994\n",
      "Epoch 685/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0851\n",
      "Epoch 686/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0649\n",
      "Epoch 687/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1117\n",
      "Epoch 688/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.0612\n",
      "Epoch 689/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.0888\n",
      "Epoch 690/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0723\n",
      "Epoch 691/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0710\n",
      "Epoch 692/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.0792\n",
      "Epoch 693/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0849\n",
      "Epoch 694/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0746\n",
      "Epoch 695/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0832\n",
      "Epoch 696/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0746\n",
      "Epoch 697/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0834\n",
      "Epoch 698/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0630\n",
      "Epoch 699/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0708\n",
      "Epoch 700/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0689\n",
      "Epoch 701/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0617\n",
      "Epoch 702/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0632\n",
      "Epoch 703/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0902\n",
      "Epoch 704/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1090\n",
      "Epoch 705/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2127\n",
      "Epoch 706/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.0867\n",
      "Epoch 707/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0638\n",
      "Epoch 708/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1043\n",
      "Epoch 709/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0963\n",
      "Epoch 710/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1145\n",
      "Epoch 711/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.0754\n",
      "Epoch 712/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0715\n",
      "Epoch 713/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0654\n",
      "Epoch 714/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0803\n",
      "Epoch 715/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0715\n",
      "Epoch 716/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1133\n",
      "Epoch 717/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1362\n",
      "Epoch 718/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1091\n",
      "Epoch 719/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0783\n",
      "Epoch 720/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1011\n",
      "Epoch 721/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0700\n",
      "Epoch 722/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0593\n",
      "Epoch 723/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0848\n",
      "Epoch 724/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1359\n",
      "Epoch 725/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0588\n",
      "Epoch 726/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0584\n",
      "Epoch 727/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.0649\n",
      "Epoch 728/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0870\n",
      "Epoch 729/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0637\n",
      "Epoch 730/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1121\n",
      "Epoch 731/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0980\n",
      "Epoch 732/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0758\n",
      "Epoch 733/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0668\n",
      "Epoch 734/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0942\n",
      "Epoch 735/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1479\n",
      "Epoch 736/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0808\n",
      "Epoch 737/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0937\n",
      "Epoch 738/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0790\n",
      "Epoch 739/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1240\n",
      "Epoch 740/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1151\n",
      "Epoch 741/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0651\n",
      "Epoch 742/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.0888\n",
      "Epoch 743/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0659\n",
      "Epoch 744/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0599\n",
      "Epoch 745/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.0596\n",
      "Epoch 746/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0648\n",
      "Epoch 747/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0774\n",
      "Epoch 748/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.0603\n",
      "Epoch 749/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.0971\n",
      "Epoch 750/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.0608\n",
      "Epoch 751/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.0890\n",
      "Epoch 752/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0693\n",
      "Epoch 753/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.0618\n",
      "Epoch 754/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.0759\n",
      "Epoch 755/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1000\n",
      "Epoch 756/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0728\n",
      "Epoch 757/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.0626\n",
      "Epoch 758/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.1136\n",
      "Epoch 759/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.0954\n",
      "Epoch 760/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1028\n",
      "Epoch 761/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1063\n",
      "Epoch 762/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0808\n",
      "Epoch 763/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0782\n",
      "Epoch 764/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0829\n",
      "Epoch 765/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0742\n",
      "Epoch 766/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0754\n",
      "Epoch 767/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0881\n",
      "Epoch 768/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0726\n",
      "Epoch 769/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.0883\n",
      "Epoch 770/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.0585\n",
      "Epoch 771/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0844\n",
      "Epoch 772/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0853\n",
      "Epoch 773/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0990\n",
      "Epoch 774/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1278\n",
      "Epoch 775/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1735\n",
      "Epoch 776/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1301\n",
      "Epoch 777/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.0789\n",
      "Epoch 778/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0812\n",
      "Epoch 779/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.0692\n",
      "Epoch 780/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0846\n",
      "Epoch 781/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0952\n",
      "Epoch 782/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1388\n",
      "Epoch 783/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1003\n",
      "Epoch 784/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0581\n",
      "Epoch 785/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0582\n",
      "Epoch 786/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0659\n",
      "Epoch 787/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0612\n",
      "Epoch 788/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0581\n",
      "Epoch 789/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0584\n",
      "Epoch 790/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0646\n",
      "Epoch 791/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0829\n",
      "Epoch 792/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0708\n",
      "Epoch 793/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.0712\n",
      "Epoch 794/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0615\n",
      "Epoch 795/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.0956\n",
      "Epoch 796/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.0749\n",
      "Epoch 797/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0796\n",
      "Epoch 798/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0687\n",
      "Epoch 799/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0724\n",
      "Epoch 800/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0653\n",
      "Epoch 801/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1065\n",
      "Epoch 802/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0682\n",
      "Epoch 803/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0648\n",
      "Epoch 804/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0722\n",
      "Epoch 805/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0601\n",
      "Epoch 806/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0886\n",
      "Epoch 807/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0642\n",
      "Epoch 808/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1327\n",
      "Epoch 809/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1313\n",
      "Epoch 810/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1170\n",
      "Epoch 811/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.0775\n",
      "Epoch 812/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0909\n",
      "Epoch 813/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0935\n",
      "Epoch 814/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0798\n",
      "Epoch 815/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0701\n",
      "Epoch 816/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0625\n",
      "Epoch 817/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0583\n",
      "Epoch 818/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1260\n",
      "Epoch 819/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0964\n",
      "Epoch 820/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0688\n",
      "Epoch 821/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0578\n",
      "Epoch 822/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0649\n",
      "Epoch 823/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0621\n",
      "Epoch 824/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0834\n",
      "Epoch 825/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0781\n",
      "Epoch 826/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0657\n",
      "Epoch 827/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0630\n",
      "Epoch 828/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0729\n",
      "Epoch 829/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.0951\n",
      "Epoch 830/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.0809\n",
      "Epoch 831/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0656\n",
      "Epoch 832/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0597\n",
      "Epoch 833/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0660\n",
      "Epoch 834/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.0557\n",
      "Epoch 835/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.0569\n",
      "Epoch 836/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1251\n",
      "Epoch 837/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0784\n",
      "Epoch 838/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0994\n",
      "Epoch 839/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0880\n",
      "Epoch 840/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0735\n",
      "Epoch 841/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0731\n",
      "Epoch 842/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1214\n",
      "Epoch 843/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0746\n",
      "Epoch 844/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1386\n",
      "Epoch 845/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0702\n",
      "Epoch 846/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.0794\n",
      "Epoch 847/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.0738\n",
      "Epoch 848/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.0615\n",
      "Epoch 849/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0586\n",
      "Epoch 850/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0541\n",
      "Epoch 851/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0573\n",
      "Epoch 852/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0982\n",
      "Epoch 853/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0847\n",
      "Epoch 854/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0701\n",
      "Epoch 855/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.0945\n",
      "Epoch 856/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0933\n",
      "Epoch 857/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0961\n",
      "Epoch 858/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0607\n",
      "Epoch 859/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0662\n",
      "Epoch 860/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0851\n",
      "Epoch 861/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0963\n",
      "Epoch 862/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0811\n",
      "Epoch 863/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.0614\n",
      "Epoch 864/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.0638\n",
      "Epoch 865/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0715\n",
      "Epoch 866/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0682\n",
      "Epoch 867/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0626\n",
      "Epoch 868/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0607\n",
      "Epoch 869/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0912\n",
      "Epoch 870/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0705\n",
      "Epoch 871/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0672\n",
      "Epoch 872/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0777\n",
      "Epoch 873/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1334\n",
      "Epoch 874/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2871\n",
      "Epoch 875/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2091\n",
      "Epoch 876/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1011\n",
      "Epoch 877/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0766\n",
      "Epoch 878/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0644\n",
      "Epoch 879/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.0874\n",
      "Epoch 880/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.0964\n",
      "Epoch 881/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0616\n",
      "Epoch 882/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.1091\n",
      "Epoch 883/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.0987\n",
      "Epoch 884/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1081\n",
      "Epoch 885/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0600\n",
      "Epoch 886/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.0813\n",
      "Epoch 887/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0701\n",
      "Epoch 888/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1073\n",
      "Epoch 889/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1292\n",
      "Epoch 890/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0928\n",
      "Epoch 891/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0653\n",
      "Epoch 892/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0518\n",
      "Epoch 893/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0595\n",
      "Epoch 894/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0782\n",
      "Epoch 895/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0623\n",
      "Epoch 896/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0658\n",
      "Epoch 897/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0747\n",
      "Epoch 898/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.0681\n",
      "Epoch 899/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.0732\n",
      "Epoch 900/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1054\n",
      "Epoch 901/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1094\n",
      "Epoch 902/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1247\n",
      "Epoch 903/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1440\n",
      "Epoch 904/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1203\n",
      "Epoch 905/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0650\n",
      "Epoch 906/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0545\n",
      "Epoch 907/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.0675\n",
      "Epoch 908/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0794\n",
      "Epoch 909/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0579\n",
      "Epoch 910/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0793\n",
      "Epoch 911/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0674\n",
      "Epoch 912/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0859\n",
      "Epoch 913/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.0770\n",
      "Epoch 914/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0660\n",
      "Epoch 915/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0611\n",
      "Epoch 916/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.0700\n",
      "Epoch 917/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.0744\n",
      "Epoch 918/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0569\n",
      "Epoch 919/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1040\n",
      "Epoch 920/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.0697\n",
      "Epoch 921/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0844\n",
      "Epoch 922/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0535\n",
      "Epoch 923/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0609\n",
      "Epoch 924/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0623\n",
      "Epoch 925/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0581\n",
      "Epoch 926/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0725\n",
      "Epoch 927/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0649\n",
      "Epoch 928/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0724\n",
      "Epoch 929/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0665\n",
      "Epoch 930/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0921\n",
      "Epoch 931/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0988\n",
      "Epoch 932/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0863\n",
      "Epoch 933/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0651\n",
      "Epoch 934/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1001\n",
      "Epoch 935/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.0662\n",
      "Epoch 936/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0571\n",
      "Epoch 937/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.0686\n",
      "Epoch 938/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1635\n",
      "Epoch 939/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0764\n",
      "Epoch 940/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0717\n",
      "Epoch 941/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0673\n",
      "Epoch 942/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0588\n",
      "Epoch 943/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0753\n",
      "Epoch 944/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0767\n",
      "Epoch 945/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0792\n",
      "Epoch 946/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0669\n",
      "Epoch 947/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0551\n",
      "Epoch 948/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0599\n",
      "Epoch 949/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0642\n",
      "Epoch 950/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0808\n",
      "Epoch 951/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1599\n",
      "Epoch 952/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1402\n",
      "Epoch 953/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0629\n",
      "Epoch 954/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0631\n",
      "Epoch 955/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.0790\n",
      "Epoch 956/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0807\n",
      "Epoch 957/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1538\n",
      "Epoch 958/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.0921\n",
      "Epoch 959/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0559\n",
      "Epoch 960/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0778\n",
      "Epoch 961/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0846\n",
      "Epoch 962/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0519\n",
      "Epoch 963/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0581\n",
      "Epoch 964/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1113\n",
      "Epoch 965/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0732\n",
      "Epoch 966/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0981\n",
      "Epoch 967/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1123\n",
      "Epoch 968/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0862\n",
      "Epoch 969/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1538\n",
      "Epoch 970/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.0997\n",
      "Epoch 971/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0780\n",
      "Epoch 972/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0574\n",
      "Epoch 973/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.0750\n",
      "Epoch 974/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0767\n",
      "Epoch 975/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0797\n",
      "Epoch 976/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1175\n",
      "Epoch 977/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1080\n",
      "Epoch 978/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0656\n",
      "Epoch 979/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1038\n",
      "Epoch 980/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0549\n",
      "Epoch 981/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0526\n",
      "Epoch 982/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0559\n",
      "Epoch 983/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0627\n",
      "Epoch 984/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0691\n",
      "Epoch 985/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0632\n",
      "Epoch 986/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0816\n",
      "Epoch 987/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.0756\n",
      "Epoch 988/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.0609\n",
      "Epoch 989/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0734\n",
      "Epoch 990/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.0580\n",
      "Epoch 991/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.0775\n",
      "Epoch 992/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.0751\n",
      "Epoch 993/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.0581\n",
      "Epoch 994/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0625\n",
      "Epoch 995/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.0914\n",
      "Epoch 996/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0603\n",
      "Epoch 997/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0686\n",
      "Epoch 998/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0681\n",
      "Epoch 999/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0904\n",
      "Epoch 1000/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0764\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a4c69a6a0>"
      ]
     },
     "execution_count": 1124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_blk = Sequential()\n",
    "NN_blk.add(Dense(units=16,input_dim=X_train.shape[1],activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_blk.add(Dense(units=8, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_blk.add(Dense(units=8, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_blk.add(Dense(units=1,activation='linear'))\n",
    "NN_blk.compile(loss='mse', optimizer='adam')\n",
    "NN_blk.fit(np.array(X_train), np.array(y_train), epochs=1000,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN_predictions</th>\n",
       "      <th>actual</th>\n",
       "      <th>GBR_predictions</th>\n",
       "      <th>LY_blocks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1.308844</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.308438</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>1.290654</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.227896</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1.361557</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.371556</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>1.442019</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.280298</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>1.306439</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.000758</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>1.247858</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.118852</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>1.245815</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.082531</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>1.482907</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.131038</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1.175403</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.970831</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>1.229028</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.102350</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>1.181183</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.108753</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>1.415199</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.267548</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1.287054</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.088066</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>1.379989</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.111885</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>1.381660</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.225015</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.285058</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.094147</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>366</th>\n",
       "      <td>1.262568</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.104307</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>1.132667</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.959499</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>1.235242</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.123304</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>1.070048</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.887663</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>1.369061</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.917202</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>1.073578</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.951658</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1.189171</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.181464</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>1.164992</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.039646</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>1.252610</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.964747</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>1.333594</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.004111</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>1.358624</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.187498</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.162913</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.027522</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.155708</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.861980</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.121495</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.011653</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.232008</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.866100</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1.104216</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.993830</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.224252</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.943365</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0.969542</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.813820</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>1.166177</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.926642</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>1.204101</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.052848</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>1.290347</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.068040</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.191602</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.927912</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1.111694</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.720989</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.153573</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.025945</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.910085</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.665721</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>1.385946</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.139136</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.000993</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.720629</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>0.973935</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.723168</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0.980094</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.714923</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>1.212175</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.960629</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>0.898940</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.788330</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>1.228483</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.993105</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.081090</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.805059</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>1.168535</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.827723</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     NN_predictions  actual  GBR_predictions  LY_blocks\n",
       "495        1.308844     1.5         1.308438        1.3\n",
       "169        1.290654     0.7         1.227896        1.3\n",
       "141        1.361557     1.5         1.371556        1.3\n",
       "665        1.442019     0.9         1.280298        1.3\n",
       "338        1.306439     0.7         1.000758        1.3\n",
       "515        1.247858     0.8         1.118852        1.3\n",
       "116        1.245815     1.6         1.082531        1.2\n",
       "581        1.482907     1.0         1.131038        1.2\n",
       "165        1.175403     1.0         0.970831        1.2\n",
       "276        1.229028     0.8         1.102350        1.2\n",
       "333        1.181183     0.7         1.108753        1.2\n",
       "213        1.415199     1.2         1.267548        1.2\n",
       "81         1.287054     1.1         1.088066        1.2\n",
       "365        1.379989     1.1         1.111885        1.2\n",
       "301        1.381660     1.3         1.225015        1.2\n",
       "35         1.285058     0.9         1.094147        1.2\n",
       "366        1.262568     1.2         1.104307        1.1\n",
       "618        1.132667     1.2         0.959499        1.1\n",
       "579        1.235242     0.8         1.123304        1.1\n",
       "437        1.070048     0.5         0.887663        1.1\n",
       "214        1.369061     0.8         0.917202        1.1\n",
       "609        1.073578     0.8         0.951658        1.1\n",
       "414        1.189171     1.0         1.181464        1.1\n",
       "570        1.164992     0.8         1.039646        1.1\n",
       "608        1.252610     1.3         0.964747        1.1\n",
       "558        1.333594     1.3         1.004111        1.1\n",
       "650        1.358624     1.0         1.187498        1.1\n",
       "10         1.162913     0.9         1.027522        1.1\n",
       "3          1.155708     0.8         0.861980        1.1\n",
       "28         1.121495     0.7         1.011653        1.1\n",
       "13         1.232008     1.0         0.866100        1.0\n",
       "106        1.104216     0.6         0.993830        1.0\n",
       "21         1.224252     1.0         0.943365        1.0\n",
       "239        0.969542     0.4         0.813820        1.0\n",
       "405        1.166177     1.2         0.926642        1.0\n",
       "607        1.204101     1.0         1.052848        1.0\n",
       "585        1.290347     0.9         1.068040        1.0\n",
       "5          1.191602     0.8         0.927912        1.0\n",
       "159        1.111694     0.8         0.720989        1.0\n",
       "4          1.153573     0.6         1.025945        1.0\n",
       "79         0.910085     0.9         0.665721        1.0\n",
       "280        1.385946     1.3         1.139136        1.0\n",
       "37         1.000993     0.6         0.720629        0.9\n",
       "227        0.973935     0.7         0.723168        0.9\n",
       "286        0.980094     0.8         0.714923        0.9\n",
       "153        1.212175     1.6         0.960629        0.9\n",
       "318        0.898940     0.2         0.788330        0.9\n",
       "556        1.228483     0.8         0.993105        0.9\n",
       "42         1.081090     0.4         0.805059        0.9\n",
       "507        1.168535     0.4         0.827723        0.9"
      ]
     },
     "execution_count": 1125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = NN_blk.predict(X_test)\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.3)\n",
    "gbr.fit(X_train,y_train)\n",
    "gbr_predictions = gbr.predict(X_test)\n",
    "LR = LinearRegression(fit_intercept=True).fit(X_train,y_train)\n",
    "\n",
    "testing = pd.DataFrame(predictions)\n",
    "testing.columns=['NN_predictions']\n",
    "testing['actual'] = y_test.reset_index()['blocks']\n",
    "testing['GBR_predictions']=gbr_predictions\n",
    "testing['LY_blocks']=X_test['blocks_ly'].reset_index()['blocks_ly']\n",
    "testing.sort_values(by='LY_blocks',ascending=False)[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1126,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2017blocks = blocks[blocks['season']==2017].drop(['team','player','blocks','Games'],axis=1)\n",
    "#pred_2017blocks = blocks[blocks['season']==2017][['blocks_ly','career_blocks','starter_change']]\n",
    "blocks_2017 = NN_blk.predict(pred_2017blocks)\n",
    "gbr_blk_2017 = pd.DataFrame(gbr.predict(pred_2017blocks))\n",
    "LR_blk_2017 = pd.DataFrame(LR.predict(pred_2017blocks))\n",
    "test_2 =pd.DataFrame(blocks_2017)\n",
    "test_3 = pd.merge(blocks,pred_2017blocks,left_index=True,right_index=True).reset_index()\n",
    "test_3['predictions']=test_2[0]\n",
    "test_3['gbr_pred'] = gbr_blk_2017[0]\n",
    "test_3['LR_pred'] = LR_blk_2017[0]\n",
    "test_3['mean_pred'] = (test_3['predictions']+test_3['gbr_pred']+test_3['LR_pred'])/3\n",
    "test_3 = test_3[test_3['Games']>30]\n",
    "test_3[['player','blocks','predictions','LR_pred','gbr_pred','mean_pred','blocks_ly_x']].sort_values(by='blocks_ly_x',ascending=False)[0:50]\n",
    "\n",
    "blocks_2017 = test_3[['player','LR_pred']]\n",
    "blocks_2017.columns=['player','block_predictions']\n",
    "df_2017=pd.merge(df_2017,blocks_2017,how='left',left_on='player',right_on='player')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE using LR:0.03740414863094713\n",
      "MSE using GB:0.04271755093709498\n",
      "MSE using NN:0.3406862582271147\n",
      "MSE using combo:0.07015540109628207\n",
      "MSE using mean:0.18036817882971723\n",
      "MSE using last year stats:0.047980769230769105\n"
     ]
    }
   ],
   "source": [
    "print('MSE using LR:{}'.format(np.mean((test_3['blocks']-test_3['LR_pred'])**2)))\n",
    "print('MSE using GB:{}'.format(np.mean((test_3['blocks']-test_3['gbr_pred'])**2)))\n",
    "print('MSE using NN:{}'.format(np.mean((test_3['blocks']-test_3['predictions'])**2)))\n",
    "print('MSE using combo:{}'.format(np.mean((test_3['blocks']-test_3['mean_pred'])**2)))\n",
    "print('MSE using mean:{}'.format(np.mean((test_3['blocks']-np.mean(test_3['blocks']))**2)))\n",
    "print('MSE using last year stats:{}'.format(np.mean((test_3['blocks']-test_3['blocks_ly_x'])**2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1128,
   "metadata": {},
   "outputs": [],
   "source": [
    " query= '''\n",
    "        \n",
    "        DROP TABLE IF EXISTS threes_pred;\n",
    "        CREATE TABLE threes_pred(\n",
    "        season int, --these come from player_stats\n",
    "        player varchar(50),\n",
    "        Age int,\n",
    "        team varchar(50),\n",
    "        threes_made float, -- these come from player_stats\n",
    "        threes_ly float,\n",
    "        change_threes float,\n",
    "        points_ly float,\n",
    "        change_points_ly float,\n",
    "        starter_change int,\n",
    "        C_PF int,\n",
    "        PG int,\n",
    "        SG_SF int,\n",
    "        Games int,\n",
    "        \n",
    "         -- these come from team_changes\n",
    "        high_usageplayer_added int,\n",
    "        usagemin_opened float,\n",
    "        maxusage_added float,\n",
    "        high_usageplayer_dropped int,\n",
    "        points_opened float,\n",
    "        max_pointsdropped float,\n",
    "        max_pointsadded float,\n",
    "        \n",
    "        three_ar_ly float, -- from player_advstats\n",
    "        change_3ar float,\n",
    "        per_ly float,\n",
    "        change_per float,\n",
    "        usagerank float,\n",
    "        usagerank_ly float,\n",
    "        offensive_winshares float,\n",
    "        offensive_boxplusminus float,\n",
    "        boxplusminus float,\n",
    "        value_overreplacement float,\n",
    "        \n",
    "        max_teammatepts float,\n",
    "        max_teammate_usage float,\n",
    "        max_teammateto float,\n",
    "        max_teammateshot_attempts float,\n",
    "        \n",
    "        career_threes float,\n",
    "        yearspro int\n",
    "        );\n",
    "        \n",
    "        INSERT INTO threes_pred(season,player,age,team,threes_made,threes_ly,change_threes,points_ly,change_points_ly,starter_change,C_PF,PG,SG_SF,Games)\n",
    "        SELECT season,player,age,startingteam,threes_made,threes_ly,change_threes,points_ly,change_points_ly,starter-starter_ly,\n",
    "        case when pos in ('C','PF') then 1 else 0 end,case when pos='PG' then 1 else 0 end,case when pos in('SG','SF') then 1 else 0 end,Games\n",
    "        from player_stats;\n",
    "        \n",
    "        update threes_pred tp\n",
    "        set high_usageplayer_added = tc.high_usageplayer_added,usagemin_opened=tc.usagemin_opened,\n",
    "        maxusage_added=tc.max_usageadded,high_usageplayer_dropped=tc.high_usageplayer_dropped,points_opened=tc.points_opened,\n",
    "        max_pointsdropped=tc.max_pointsdropped,max_pointsadded=tc.max_pointsadded\n",
    "        from team_changes tc\n",
    "        where tc.team = tp.team and tp.season=tc.season;\n",
    "        \n",
    "        update threes_pred tp\n",
    "        set three_ar_ly = pa.threear_ly,change_3ar=pa.change_3ar,per_ly=pa.per_ly,change_per=pa.change_per,\n",
    "        usagerank=pa.usagerank,usagerank_ly=pa.usagerank_ly,offensive_winshares=pa.offensive_winshares,\n",
    "        offensive_boxplusminus=pa.offensive_boxplusminus,boxplusminus=pa.boxplusminus,value_overreplacement=pa.value_overreplacement\n",
    "        from player_advstats pa\n",
    "        where tp.player = pa.player and tp.season = pa.season and tp.team = pa.startingteam;\n",
    "        \n",
    "        update threes_pred tp\n",
    "        set max_teammatepts = tm.max_teammatepts,max_teammate_usage=tm.max_teammate_usage,max_teammateto=tm.max_teammateto,\n",
    "        max_teammateshot_attempts=tm.max_teammateshot_attempts\n",
    "        from teammate_maxes tm\n",
    "        where tm.season = tp.season and tm.player = tp.player;\n",
    "        \n",
    "        update threes_pred tp\n",
    "        set career_threes = pc.career_threesmade, yearspro = pc.yearspro\n",
    "        from player_careerstats pc\n",
    "        where tp.player = pc.player and tp.season = pc.season;\n",
    "        \n",
    "        \n",
    "        select * from threes_pred where season>2009\n",
    "        '''\n",
    "\n",
    "\n",
    "cur.execute(query)\n",
    "data = cur.fetchall()\n",
    "threes_df = pd.DataFrame(np.array(data))\n",
    "threes_df.columns = ['season','player','age','team','3PM','3PM_ly','3PM_change','points_ly','change_points_ly','starter_change','C_PF','PG','SG_SF','Games','high_usageplayer_added','usagemin_opened','maxusage_added','high_usageplayer_dropped','points_opened','max_pointsdropped',\n",
    "                    'max_pointsadded','three_ar_ly','change_3ar','per_ly','change_per','usagerank','usagerank_ly','offensive_winshares','offensive_boxplusminus','boxplusminus','value_overreplacement'\n",
    "                     ,'max_teammatepts','max_teammate_usage','max_teammateto','max_teammateshot_attempts','career_3PM','yearspro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "threes_df['age_squared']=threes_df['age']*threes_df['age']\n",
    "threes = threes_df[threes_df['3PM_ly'].notna()]\n",
    "for i in threes.columns:\n",
    "    if i not in(['player','team']):\n",
    "        threes[i]=pd.to_numeric(threes[i])\n",
    "threes = threes.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1130,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = threes[(threes['season']!=2017) & (threes['Games']>30)].drop(['player','team','3PM','Games'],axis=1)\n",
    "y = threes[(threes['season']!=2017) & (threes['Games']>30)]['3PM']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1564/1564 [==============================] - 4s 2ms/step - loss: 72872.4942\n",
      "Epoch 2/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 17320.6356\n",
      "Epoch 3/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 4186.0316\n",
      "Epoch 4/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 1350.9023\n",
      "Epoch 5/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 484.4683\n",
      "Epoch 6/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 183.2796\n",
      "Epoch 7/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 68.5733\n",
      "Epoch 8/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 44.1678\n",
      "Epoch 9/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 34.4818\n",
      "Epoch 10/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 29.8169\n",
      "Epoch 11/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 26.7103\n",
      "Epoch 12/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 24.2218\n",
      "Epoch 13/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 22.2027\n",
      "Epoch 14/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 20.6116\n",
      "Epoch 15/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 19.3080\n",
      "Epoch 16/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 18.2083\n",
      "Epoch 17/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 17.2249\n",
      "Epoch 18/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 16.5586\n",
      "Epoch 19/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 15.9865\n",
      "Epoch 20/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 15.5628\n",
      "Epoch 21/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 15.1118\n",
      "Epoch 22/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 14.6962\n",
      "Epoch 23/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 14.3731\n",
      "Epoch 24/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 14.0452\n",
      "Epoch 25/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 13.7597\n",
      "Epoch 26/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 13.4691\n",
      "Epoch 27/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 13.1511\n",
      "Epoch 28/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 12.8905\n",
      "Epoch 29/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 12.5871\n",
      "Epoch 30/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 12.3327\n",
      "Epoch 31/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 12.0729\n",
      "Epoch 32/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 11.8313\n",
      "Epoch 33/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 11.5623\n",
      "Epoch 34/1000\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 11.3168\n",
      "Epoch 35/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 11.0536\n",
      "Epoch 36/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 10.7913\n",
      "Epoch 37/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 10.5527\n",
      "Epoch 38/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 10.2936\n",
      "Epoch 39/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 10.0961\n",
      "Epoch 40/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 9.8629\n",
      "Epoch 41/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 9.6483\n",
      "Epoch 42/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 9.4849\n",
      "Epoch 43/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 9.2731\n",
      "Epoch 44/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 9.0443\n",
      "Epoch 45/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 8.8795\n",
      "Epoch 46/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 8.6843\n",
      "Epoch 47/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 8.5000\n",
      "Epoch 48/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 8.2918\n",
      "Epoch 49/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 8.1421\n",
      "Epoch 50/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 7.9383\n",
      "Epoch 51/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 7.8199\n",
      "Epoch 52/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 7.6445\n",
      "Epoch 53/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 7.5441\n",
      "Epoch 54/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.3789\n",
      "Epoch 55/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.2151\n",
      "Epoch 56/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.0311\n",
      "Epoch 57/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 6.8431\n",
      "Epoch 58/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.7369\n",
      "Epoch 59/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.6289\n",
      "Epoch 60/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.5144\n",
      "Epoch 61/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 6.3834\n",
      "Epoch 62/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 6.2816\n",
      "Epoch 63/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.1800\n",
      "Epoch 64/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.0652\n",
      "Epoch 65/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 5.9679\n",
      "Epoch 66/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 5.8886\n",
      "Epoch 67/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 5.7865\n",
      "Epoch 68/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 5.7155\n",
      "Epoch 69/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 5.6302\n",
      "Epoch 70/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 5.5585\n",
      "Epoch 71/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 5.4797\n",
      "Epoch 72/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 5.4114\n",
      "Epoch 73/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 5.3271\n",
      "Epoch 74/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 5.2831\n",
      "Epoch 75/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 5.1968\n",
      "Epoch 76/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 5.1342\n",
      "Epoch 77/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 5.0864\n",
      "Epoch 78/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 5.0367\n",
      "Epoch 79/1000\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 4.9839\n",
      "Epoch 80/1000\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 4.9150\n",
      "Epoch 81/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 4.8625\n",
      "Epoch 82/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 4.8224\n",
      "Epoch 83/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 4.7894\n",
      "Epoch 84/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 4.7446\n",
      "Epoch 85/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 4.6732\n",
      "Epoch 86/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 4.6511\n",
      "Epoch 87/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 4.6088\n",
      "Epoch 88/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 4.5515\n",
      "Epoch 89/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 4.5188\n",
      "Epoch 90/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 4.4838\n",
      "Epoch 91/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 4.4698\n",
      "Epoch 92/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 4.4246\n",
      "Epoch 93/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 4.3886\n",
      "Epoch 94/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 4.3315\n",
      "Epoch 95/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 4.2955\n",
      "Epoch 96/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 4.2564\n",
      "Epoch 97/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 4.2114\n",
      "Epoch 98/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 4.1660\n",
      "Epoch 99/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 4.1329\n",
      "Epoch 100/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 4.1013\n",
      "Epoch 101/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 4.0835\n",
      "Epoch 102/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 4.0170\n",
      "Epoch 103/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 3.9951\n",
      "Epoch 104/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 3.9587\n",
      "Epoch 105/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 3.9237\n",
      "Epoch 106/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 3.8836\n",
      "Epoch 107/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 3.8548\n",
      "Epoch 108/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 3.8242\n",
      "Epoch 109/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 3.8054\n",
      "Epoch 110/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 3.7591\n",
      "Epoch 111/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 3.7407\n",
      "Epoch 112/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 3.7224\n",
      "Epoch 113/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.7068\n",
      "Epoch 114/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 3.6919\n",
      "Epoch 115/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 3.6361\n",
      "Epoch 116/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 3.5900\n",
      "Epoch 117/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 3.5860\n",
      "Epoch 118/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 3.6010\n",
      "Epoch 119/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 3.5089\n",
      "Epoch 120/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 3.4823\n",
      "Epoch 121/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.4572\n",
      "Epoch 122/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 3.4614\n",
      "Epoch 123/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 3.4732\n",
      "Epoch 124/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 3.3901\n",
      "Epoch 125/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 3.3734\n",
      "Epoch 126/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 3.3840\n",
      "Epoch 127/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 3.3315\n",
      "Epoch 128/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 3.2855\n",
      "Epoch 129/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.2805\n",
      "Epoch 130/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 3.2598\n",
      "Epoch 131/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 3.2292\n",
      "Epoch 132/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 3.2631\n",
      "Epoch 133/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 3.2251\n",
      "Epoch 134/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 3.1869\n",
      "Epoch 135/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 3.1350\n",
      "Epoch 136/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 3.1135\n",
      "Epoch 137/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 3.1001\n",
      "Epoch 138/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 3.0685\n",
      "Epoch 139/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 3.0525\n",
      "Epoch 140/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 3.0257\n",
      "Epoch 141/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 3.0166\n",
      "Epoch 142/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 2.9868\n",
      "Epoch 143/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 2.9730\n",
      "Epoch 144/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 2.9546\n",
      "Epoch 145/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.9324\n",
      "Epoch 146/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 2.9483\n",
      "Epoch 147/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.9446\n",
      "Epoch 148/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 2.8835\n",
      "Epoch 149/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.8712\n",
      "Epoch 150/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 2.8446\n",
      "Epoch 151/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.8221\n",
      "Epoch 152/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 2.8014\n",
      "Epoch 153/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 2.7887\n",
      "Epoch 154/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 2.7702\n",
      "Epoch 155/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 2.7607\n",
      "Epoch 156/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 2.7483\n",
      "Epoch 157/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 2.7380\n",
      "Epoch 158/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 2.7087\n",
      "Epoch 159/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.6893\n",
      "Epoch 160/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.6742\n",
      "Epoch 161/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 2.6873\n",
      "Epoch 162/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.6821\n",
      "Epoch 163/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.6135\n",
      "Epoch 164/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.6089\n",
      "Epoch 165/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.6044\n",
      "Epoch 166/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.6308\n",
      "Epoch 167/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.5854\n",
      "Epoch 168/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.5750\n",
      "Epoch 169/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.5545\n",
      "Epoch 170/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 2.5014\n",
      "Epoch 171/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 2.4908\n",
      "Epoch 172/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 2.4946\n",
      "Epoch 173/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 2.4706\n",
      "Epoch 174/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 2.4634\n",
      "Epoch 175/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 2.4864\n",
      "Epoch 176/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 2.4180\n",
      "Epoch 177/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 2.4079\n",
      "Epoch 178/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 2.3849\n",
      "Epoch 179/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 2.3918\n",
      "Epoch 180/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 2.3792\n",
      "Epoch 181/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.3776\n",
      "Epoch 182/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.3382\n",
      "Epoch 183/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.3290\n",
      "Epoch 184/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.3217\n",
      "Epoch 185/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.3191\n",
      "Epoch 186/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 2.2798\n",
      "Epoch 187/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 2.2771\n",
      "Epoch 188/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 2.2684\n",
      "Epoch 189/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.2362\n",
      "Epoch 190/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 2.2351\n",
      "Epoch 191/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.2132\n",
      "Epoch 192/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.1941\n",
      "Epoch 193/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 2.1893\n",
      "Epoch 194/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 2.1666\n",
      "Epoch 195/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 2.1599\n",
      "Epoch 196/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 2.1403\n",
      "Epoch 197/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 2.1445\n",
      "Epoch 198/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 2.1015\n",
      "Epoch 199/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 2.0929\n",
      "Epoch 200/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 2.0993\n",
      "Epoch 201/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 2.0678\n",
      "Epoch 202/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 2.0288\n",
      "Epoch 203/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 2.0213\n",
      "Epoch 204/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.9984\n",
      "Epoch 205/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.9820\n",
      "Epoch 206/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 1.9594\n",
      "Epoch 207/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 1.9403\n",
      "Epoch 208/1000\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 1.9421\n",
      "Epoch 209/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.9225\n",
      "Epoch 210/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 1.8897\n",
      "Epoch 211/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 1.8813\n",
      "Epoch 212/1000\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 1.8689\n",
      "Epoch 213/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 1.8283\n",
      "Epoch 214/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 1.8101\n",
      "Epoch 215/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.7959\n",
      "Epoch 216/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.7701\n",
      "Epoch 217/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.7922\n",
      "Epoch 218/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.7820\n",
      "Epoch 219/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.7434\n",
      "Epoch 220/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.7824\n",
      "Epoch 221/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 1.7466\n",
      "Epoch 222/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.6777\n",
      "Epoch 223/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 1.6606\n",
      "Epoch 224/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.6488\n",
      "Epoch 225/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.6249\n",
      "Epoch 226/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.6252\n",
      "Epoch 227/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.6052\n",
      "Epoch 228/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.5859\n",
      "Epoch 229/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.5751\n",
      "Epoch 230/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.5729\n",
      "Epoch 231/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.5650\n",
      "Epoch 232/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.5488\n",
      "Epoch 233/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.5350\n",
      "Epoch 234/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.5171\n",
      "Epoch 235/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.5159\n",
      "Epoch 236/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.5116\n",
      "Epoch 237/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.5050\n",
      "Epoch 238/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.4794\n",
      "Epoch 239/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.4866\n",
      "Epoch 240/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 1.4792\n",
      "Epoch 241/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.4435\n",
      "Epoch 242/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.4311\n",
      "Epoch 243/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 1.4253\n",
      "Epoch 244/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 1.4130\n",
      "Epoch 245/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 1.4117\n",
      "Epoch 246/1000\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 1.3957\n",
      "Epoch 247/1000\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 1.3989\n",
      "Epoch 248/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 1.3791\n",
      "Epoch 249/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 1.4003\n",
      "Epoch 250/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 1.3715\n",
      "Epoch 251/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 1.3846\n",
      "Epoch 252/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 1.3408\n",
      "Epoch 253/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 1.3404\n",
      "Epoch 254/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 1.3281\n",
      "Epoch 255/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 1.3361\n",
      "Epoch 256/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.3113\n",
      "Epoch 257/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 1.3119\n",
      "Epoch 258/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 1.2851\n",
      "Epoch 259/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 1.2883\n",
      "Epoch 260/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.2754\n",
      "Epoch 261/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.2803\n",
      "Epoch 262/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.2758\n",
      "Epoch 263/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.2605\n",
      "Epoch 264/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 1.2484\n",
      "Epoch 265/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 1.2488\n",
      "Epoch 266/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 1.2365\n",
      "Epoch 267/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 1.2230\n",
      "Epoch 268/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 1.2005\n",
      "Epoch 269/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 1.1959\n",
      "Epoch 270/1000\n",
      "1564/1564 [==============================] - 0s 88us/step - loss: 1.1829\n",
      "Epoch 271/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 1.1833\n",
      "Epoch 272/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.1918\n",
      "Epoch 273/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.1898\n",
      "Epoch 274/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 1.1882\n",
      "Epoch 275/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 1.1424\n",
      "Epoch 276/1000\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 1.1324\n",
      "Epoch 277/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 1.1231\n",
      "Epoch 278/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 1.1165\n",
      "Epoch 279/1000\n",
      "1564/1564 [==============================] - 0s 118us/step - loss: 1.1158\n",
      "Epoch 280/1000\n",
      "1564/1564 [==============================] - 0s 98us/step - loss: 1.0927\n",
      "Epoch 281/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 1.0895\n",
      "Epoch 282/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 1.0810\n",
      "Epoch 283/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 1.1257\n",
      "Epoch 284/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 1.0563\n",
      "Epoch 285/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 1.0685\n",
      "Epoch 286/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 1.0632\n",
      "Epoch 287/1000\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 1.0493\n",
      "Epoch 288/1000\n",
      "1564/1564 [==============================] - 0s 170us/step - loss: 1.0453\n",
      "Epoch 289/1000\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 1.0603\n",
      "Epoch 290/1000\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 1.0347\n",
      "Epoch 291/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 1.0047\n",
      "Epoch 292/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.9976\n",
      "Epoch 293/1000\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 0.9844\n",
      "Epoch 294/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.9847\n",
      "Epoch 295/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.9748\n",
      "Epoch 296/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.9719\n",
      "Epoch 297/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.9953\n",
      "Epoch 298/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.9662\n",
      "Epoch 299/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.9565\n",
      "Epoch 300/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.9713\n",
      "Epoch 301/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.9529\n",
      "Epoch 302/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.9257\n",
      "Epoch 303/1000\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 0.9162\n",
      "Epoch 304/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.9091\n",
      "Epoch 305/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.8985\n",
      "Epoch 306/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.8945\n",
      "Epoch 307/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.8916\n",
      "Epoch 308/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.8865\n",
      "Epoch 309/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.8755\n",
      "Epoch 310/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.8582\n",
      "Epoch 311/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.8506\n",
      "Epoch 312/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.8482\n",
      "Epoch 313/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.8808\n",
      "Epoch 314/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.8753\n",
      "Epoch 315/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.8616\n",
      "Epoch 316/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.8692\n",
      "Epoch 317/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.8579\n",
      "Epoch 318/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.8333\n",
      "Epoch 319/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.8148\n",
      "Epoch 320/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.8072\n",
      "Epoch 321/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.7926\n",
      "Epoch 322/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.7794\n",
      "Epoch 323/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.7794\n",
      "Epoch 324/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.7547\n",
      "Epoch 325/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.7483\n",
      "Epoch 326/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.7384\n",
      "Epoch 327/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.7375\n",
      "Epoch 328/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.7206\n",
      "Epoch 329/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.7096\n",
      "Epoch 330/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.7084\n",
      "Epoch 331/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.7019\n",
      "Epoch 332/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.6943\n",
      "Epoch 333/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.6950\n",
      "Epoch 334/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.6776\n",
      "Epoch 335/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.6648\n",
      "Epoch 336/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6631\n",
      "Epoch 337/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.6499\n",
      "Epoch 338/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6457\n",
      "Epoch 339/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6404\n",
      "Epoch 340/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.6306\n",
      "Epoch 341/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6343\n",
      "Epoch 342/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.6269\n",
      "Epoch 343/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.6144\n",
      "Epoch 344/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.6090\n",
      "Epoch 345/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.6026\n",
      "Epoch 346/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.6188\n",
      "Epoch 347/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5801\n",
      "Epoch 348/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5692\n",
      "Epoch 349/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5667\n",
      "Epoch 350/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5620\n",
      "Epoch 351/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.5505\n",
      "Epoch 352/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.5479\n",
      "Epoch 353/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.5572\n",
      "Epoch 354/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5452\n",
      "Epoch 355/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.5255\n",
      "Epoch 356/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5199\n",
      "Epoch 357/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.5381\n",
      "Epoch 358/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 0.5185\n",
      "Epoch 359/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.4980\n",
      "Epoch 360/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.5266\n",
      "Epoch 361/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.5287\n",
      "Epoch 362/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.4986\n",
      "Epoch 363/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.4925\n",
      "Epoch 364/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.4882\n",
      "Epoch 365/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4804\n",
      "Epoch 366/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4697\n",
      "Epoch 367/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.4675\n",
      "Epoch 368/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.4670\n",
      "Epoch 369/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 0.4609\n",
      "Epoch 370/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 0.4588\n",
      "Epoch 371/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 0.4708\n",
      "Epoch 372/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 0.4656\n",
      "Epoch 373/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 0.4552\n",
      "Epoch 374/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 0.4451\n",
      "Epoch 375/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.4398\n",
      "Epoch 376/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.4405\n",
      "Epoch 377/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 0.4384\n",
      "Epoch 378/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.4297\n",
      "Epoch 379/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.4299\n",
      "Epoch 380/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.4262\n",
      "Epoch 381/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 0.4329\n",
      "Epoch 382/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 0.4253\n",
      "Epoch 383/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.4118\n",
      "Epoch 384/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.4168\n",
      "Epoch 385/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.4152\n",
      "Epoch 386/1000\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 0.4141\n",
      "Epoch 387/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.4202\n",
      "Epoch 388/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.4282\n",
      "Epoch 389/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.4016\n",
      "Epoch 390/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.3960\n",
      "Epoch 391/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.3952\n",
      "Epoch 392/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.3892\n",
      "Epoch 393/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.3903\n",
      "Epoch 394/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.3944\n",
      "Epoch 395/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.3891\n",
      "Epoch 396/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.3971\n",
      "Epoch 397/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.3879\n",
      "Epoch 398/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.3844\n",
      "Epoch 399/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.3778\n",
      "Epoch 400/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.3730\n",
      "Epoch 401/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.3733\n",
      "Epoch 402/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.3720\n",
      "Epoch 403/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.4002\n",
      "Epoch 404/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.3700\n",
      "Epoch 405/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.3676\n",
      "Epoch 406/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.3633\n",
      "Epoch 407/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.3666\n",
      "Epoch 408/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.3577\n",
      "Epoch 409/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.3656\n",
      "Epoch 410/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.3703\n",
      "Epoch 411/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.3667\n",
      "Epoch 412/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.3723\n",
      "Epoch 413/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.3668\n",
      "Epoch 414/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.3633\n",
      "Epoch 415/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.3493\n",
      "Epoch 416/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.3466\n",
      "Epoch 417/1000\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 0.3587\n",
      "Epoch 418/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.3437\n",
      "Epoch 419/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.3565\n",
      "Epoch 420/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.3494\n",
      "Epoch 421/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.3427\n",
      "Epoch 422/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.3473\n",
      "Epoch 423/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.3436\n",
      "Epoch 424/1000\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 0.3378\n",
      "Epoch 425/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.3410\n",
      "Epoch 426/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.3514\n",
      "Epoch 427/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.4005\n",
      "Epoch 428/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.3780\n",
      "Epoch 429/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.3340\n",
      "Epoch 430/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.3296\n",
      "Epoch 431/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.3245\n",
      "Epoch 432/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.3221\n",
      "Epoch 433/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.3256\n",
      "Epoch 434/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.3293\n",
      "Epoch 435/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.3338\n",
      "Epoch 436/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.3233\n",
      "Epoch 437/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.3559\n",
      "Epoch 438/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.3490\n",
      "Epoch 439/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.3428\n",
      "Epoch 440/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.3487\n",
      "Epoch 441/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.3246\n",
      "Epoch 442/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.3291\n",
      "Epoch 443/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.3208\n",
      "Epoch 444/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.3162\n",
      "Epoch 445/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.3203\n",
      "Epoch 446/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.3215\n",
      "Epoch 447/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.3084\n",
      "Epoch 448/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.3074\n",
      "Epoch 449/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.3058\n",
      "Epoch 450/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.3056\n",
      "Epoch 451/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.3299\n",
      "Epoch 452/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.3220\n",
      "Epoch 453/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.3175\n",
      "Epoch 454/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.3039\n",
      "Epoch 455/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.3135\n",
      "Epoch 456/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.3079\n",
      "Epoch 457/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.3062\n",
      "Epoch 458/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.3091\n",
      "Epoch 459/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2963\n",
      "Epoch 460/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.3191\n",
      "Epoch 461/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2909\n",
      "Epoch 462/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.3006\n",
      "Epoch 463/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2899\n",
      "Epoch 464/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2982\n",
      "Epoch 465/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.3110\n",
      "Epoch 466/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2868\n",
      "Epoch 467/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2919\n",
      "Epoch 468/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2913\n",
      "Epoch 469/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.3044\n",
      "Epoch 470/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2965\n",
      "Epoch 471/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2854\n",
      "Epoch 472/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.2904\n",
      "Epoch 473/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2881\n",
      "Epoch 474/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2803\n",
      "Epoch 475/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2811\n",
      "Epoch 476/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2873\n",
      "Epoch 477/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.3010\n",
      "Epoch 478/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.3229\n",
      "Epoch 479/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.3338\n",
      "Epoch 480/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.3029\n",
      "Epoch 481/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2930\n",
      "Epoch 482/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2798\n",
      "Epoch 483/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2805\n",
      "Epoch 484/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2878\n",
      "Epoch 485/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2950\n",
      "Epoch 486/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2971\n",
      "Epoch 487/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2753\n",
      "Epoch 488/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.2673\n",
      "Epoch 489/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2773\n",
      "Epoch 490/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2736\n",
      "Epoch 491/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2704\n",
      "Epoch 492/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2701\n",
      "Epoch 493/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2767\n",
      "Epoch 494/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2880\n",
      "Epoch 495/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2878\n",
      "Epoch 496/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2808\n",
      "Epoch 497/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2821\n",
      "Epoch 498/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2659\n",
      "Epoch 499/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2665\n",
      "Epoch 500/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2616\n",
      "Epoch 501/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2607\n",
      "Epoch 502/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.2696\n",
      "Epoch 503/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2726\n",
      "Epoch 504/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.3258\n",
      "Epoch 505/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.2784\n",
      "Epoch 506/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2726\n",
      "Epoch 507/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2798\n",
      "Epoch 508/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.2789\n",
      "Epoch 509/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.2603\n",
      "Epoch 510/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2677\n",
      "Epoch 511/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2620\n",
      "Epoch 512/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2578\n",
      "Epoch 513/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2724\n",
      "Epoch 514/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2609\n",
      "Epoch 515/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2564\n",
      "Epoch 516/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2749\n",
      "Epoch 517/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.2602\n",
      "Epoch 518/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2616\n",
      "Epoch 519/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.2669\n",
      "Epoch 520/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.2601\n",
      "Epoch 521/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2602\n",
      "Epoch 522/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2481\n",
      "Epoch 523/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.2453\n",
      "Epoch 524/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2552\n",
      "Epoch 525/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2501\n",
      "Epoch 526/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.2546\n",
      "Epoch 527/1000\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 0.2526\n",
      "Epoch 528/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 0.2555\n",
      "Epoch 529/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2552\n",
      "Epoch 530/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2512\n",
      "Epoch 531/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2527\n",
      "Epoch 532/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2488\n",
      "Epoch 533/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2454\n",
      "Epoch 534/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2506\n",
      "Epoch 535/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.2496\n",
      "Epoch 536/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2749\n",
      "Epoch 537/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2452\n",
      "Epoch 538/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.2468\n",
      "Epoch 539/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.2329\n",
      "Epoch 540/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2379\n",
      "Epoch 541/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2312\n",
      "Epoch 542/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2317\n",
      "Epoch 543/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2324\n",
      "Epoch 544/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2479\n",
      "Epoch 545/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2364\n",
      "Epoch 546/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2375\n",
      "Epoch 547/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2278\n",
      "Epoch 548/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2341\n",
      "Epoch 549/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2351\n",
      "Epoch 550/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 0.2347\n",
      "Epoch 551/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.2296\n",
      "Epoch 552/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2297\n",
      "Epoch 553/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2292\n",
      "Epoch 554/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2247\n",
      "Epoch 555/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2443\n",
      "Epoch 556/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2284\n",
      "Epoch 557/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2398\n",
      "Epoch 558/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2360\n",
      "Epoch 559/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2493\n",
      "Epoch 560/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2241\n",
      "Epoch 561/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2186\n",
      "Epoch 562/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2214\n",
      "Epoch 563/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2229\n",
      "Epoch 564/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2168\n",
      "Epoch 565/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2157\n",
      "Epoch 566/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.2181\n",
      "Epoch 567/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.2195\n",
      "Epoch 568/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.2146\n",
      "Epoch 569/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2145\n",
      "Epoch 570/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2115\n",
      "Epoch 571/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2066\n",
      "Epoch 572/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2183\n",
      "Epoch 573/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2319\n",
      "Epoch 574/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.2118\n",
      "Epoch 575/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2344\n",
      "Epoch 576/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2229\n",
      "Epoch 577/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2160\n",
      "Epoch 578/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.2068\n",
      "Epoch 579/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2128\n",
      "Epoch 580/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2178\n",
      "Epoch 581/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2046\n",
      "Epoch 582/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.2110\n",
      "Epoch 583/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2486\n",
      "Epoch 584/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2264\n",
      "Epoch 585/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2207\n",
      "Epoch 586/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2093\n",
      "Epoch 587/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2194\n",
      "Epoch 588/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.2101\n",
      "Epoch 589/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2173\n",
      "Epoch 590/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2056\n",
      "Epoch 591/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2274\n",
      "Epoch 592/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2176\n",
      "Epoch 593/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2119\n",
      "Epoch 594/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2007\n",
      "Epoch 595/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2140\n",
      "Epoch 596/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2066\n",
      "Epoch 597/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1990\n",
      "Epoch 598/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.2056\n",
      "Epoch 599/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2130\n",
      "Epoch 600/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2087\n",
      "Epoch 601/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2204\n",
      "Epoch 602/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2057\n",
      "Epoch 603/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1917\n",
      "Epoch 604/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2154\n",
      "Epoch 605/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2120\n",
      "Epoch 606/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1988\n",
      "Epoch 607/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2144\n",
      "Epoch 608/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2309\n",
      "Epoch 609/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2120\n",
      "Epoch 610/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2024\n",
      "Epoch 611/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2344\n",
      "Epoch 612/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2068\n",
      "Epoch 613/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1993\n",
      "Epoch 614/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.2000\n",
      "Epoch 615/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2020\n",
      "Epoch 616/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1875\n",
      "Epoch 617/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2001\n",
      "Epoch 618/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2053\n",
      "Epoch 619/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1910\n",
      "Epoch 620/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1857\n",
      "Epoch 621/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1859\n",
      "Epoch 622/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1898\n",
      "Epoch 623/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.1930\n",
      "Epoch 624/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.2179\n",
      "Epoch 625/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.2001\n",
      "Epoch 626/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2080\n",
      "Epoch 627/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2055\n",
      "Epoch 628/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2064\n",
      "Epoch 629/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2156\n",
      "Epoch 630/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.2022\n",
      "Epoch 631/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1918\n",
      "Epoch 632/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1890\n",
      "Epoch 633/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1971\n",
      "Epoch 634/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1981\n",
      "Epoch 635/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.2132\n",
      "Epoch 636/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2192\n",
      "Epoch 637/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2143\n",
      "Epoch 638/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1915\n",
      "Epoch 639/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1825\n",
      "Epoch 640/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1865\n",
      "Epoch 641/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1891\n",
      "Epoch 642/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1791\n",
      "Epoch 643/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1876\n",
      "Epoch 644/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2138\n",
      "Epoch 645/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1899\n",
      "Epoch 646/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.2030\n",
      "Epoch 647/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2024\n",
      "Epoch 648/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2443\n",
      "Epoch 649/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2464\n",
      "Epoch 650/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1911\n",
      "Epoch 651/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1819\n",
      "Epoch 652/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1771\n",
      "Epoch 653/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1815\n",
      "Epoch 654/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1869\n",
      "Epoch 655/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2005\n",
      "Epoch 656/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2357\n",
      "Epoch 657/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2132\n",
      "Epoch 658/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1854\n",
      "Epoch 659/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1857\n",
      "Epoch 660/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1869\n",
      "Epoch 661/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1828\n",
      "Epoch 662/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1865\n",
      "Epoch 663/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.2184\n",
      "Epoch 664/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.2329\n",
      "Epoch 665/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.1987\n",
      "Epoch 666/1000\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 0.1969\n",
      "Epoch 667/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.1825\n",
      "Epoch 668/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2016\n",
      "Epoch 669/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2469\n",
      "Epoch 670/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2155\n",
      "Epoch 671/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1781\n",
      "Epoch 672/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1922\n",
      "Epoch 673/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1935\n",
      "Epoch 674/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1765\n",
      "Epoch 675/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2120\n",
      "Epoch 676/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1820\n",
      "Epoch 677/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1862\n",
      "Epoch 678/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1825\n",
      "Epoch 679/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1941\n",
      "Epoch 680/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1916\n",
      "Epoch 681/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1707\n",
      "Epoch 682/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1848\n",
      "Epoch 683/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.1943\n",
      "Epoch 684/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1712\n",
      "Epoch 685/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1928\n",
      "Epoch 686/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1927\n",
      "Epoch 687/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1844\n",
      "Epoch 688/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1795\n",
      "Epoch 689/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2099\n",
      "Epoch 690/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1805\n",
      "Epoch 691/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1752\n",
      "Epoch 692/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1799\n",
      "Epoch 693/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1878\n",
      "Epoch 694/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1888\n",
      "Epoch 695/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1732\n",
      "Epoch 696/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1756\n",
      "Epoch 697/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2085\n",
      "Epoch 698/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1924\n",
      "Epoch 699/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.1798\n",
      "Epoch 700/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1791\n",
      "Epoch 701/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2174\n",
      "Epoch 702/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1786\n",
      "Epoch 703/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1919\n",
      "Epoch 704/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2072\n",
      "Epoch 705/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1935\n",
      "Epoch 706/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1915\n",
      "Epoch 707/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2046\n",
      "Epoch 708/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1711\n",
      "Epoch 709/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1669\n",
      "Epoch 710/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1629\n",
      "Epoch 711/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1762\n",
      "Epoch 712/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1654\n",
      "Epoch 713/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1991\n",
      "Epoch 714/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1877\n",
      "Epoch 715/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1790\n",
      "Epoch 716/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1861\n",
      "Epoch 717/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1918\n",
      "Epoch 718/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1721\n",
      "Epoch 719/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1744\n",
      "Epoch 720/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1672\n",
      "Epoch 721/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1637\n",
      "Epoch 722/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1641\n",
      "Epoch 723/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1887\n",
      "Epoch 724/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1808\n",
      "Epoch 725/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1825\n",
      "Epoch 726/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2056\n",
      "Epoch 727/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2229\n",
      "Epoch 728/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.2653\n",
      "Epoch 729/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1773\n",
      "Epoch 730/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1682\n",
      "Epoch 731/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1767\n",
      "Epoch 732/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1686\n",
      "Epoch 733/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1847\n",
      "Epoch 734/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1772\n",
      "Epoch 735/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1822\n",
      "Epoch 736/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1662\n",
      "Epoch 737/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1825\n",
      "Epoch 738/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1755\n",
      "Epoch 739/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1606\n",
      "Epoch 740/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1746\n",
      "Epoch 741/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1681\n",
      "Epoch 742/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1634\n",
      "Epoch 743/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1688\n",
      "Epoch 744/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1635\n",
      "Epoch 745/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1627\n",
      "Epoch 746/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1661\n",
      "Epoch 747/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1599\n",
      "Epoch 748/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1752\n",
      "Epoch 749/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1940\n",
      "Epoch 750/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1752\n",
      "Epoch 751/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1720\n",
      "Epoch 752/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1795\n",
      "Epoch 753/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1747\n",
      "Epoch 754/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1749\n",
      "Epoch 755/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1754\n",
      "Epoch 756/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1619\n",
      "Epoch 757/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1687\n",
      "Epoch 758/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1607\n",
      "Epoch 759/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1672\n",
      "Epoch 760/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1629\n",
      "Epoch 761/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1609\n",
      "Epoch 762/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1705\n",
      "Epoch 763/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1700\n",
      "Epoch 764/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1741\n",
      "Epoch 765/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1671\n",
      "Epoch 766/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1766\n",
      "Epoch 767/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1617\n",
      "Epoch 768/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1742\n",
      "Epoch 769/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1873\n",
      "Epoch 770/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1867\n",
      "Epoch 771/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1684\n",
      "Epoch 772/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1797\n",
      "Epoch 773/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1804\n",
      "Epoch 774/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1786\n",
      "Epoch 775/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1770\n",
      "Epoch 776/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1657\n",
      "Epoch 777/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1715\n",
      "Epoch 778/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1865\n",
      "Epoch 779/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.2271\n",
      "Epoch 780/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.2048\n",
      "Epoch 781/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1732\n",
      "Epoch 782/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.2166\n",
      "Epoch 783/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1868\n",
      "Epoch 784/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1690\n",
      "Epoch 785/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.1837\n",
      "Epoch 786/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1555\n",
      "Epoch 787/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1507\n",
      "Epoch 788/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1586\n",
      "Epoch 789/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1563\n",
      "Epoch 790/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1554\n",
      "Epoch 791/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1577\n",
      "Epoch 792/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.1908\n",
      "Epoch 793/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1679\n",
      "Epoch 794/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.1572\n",
      "Epoch 795/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1510\n",
      "Epoch 796/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1632\n",
      "Epoch 797/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1541\n",
      "Epoch 798/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1762\n",
      "Epoch 799/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1592\n",
      "Epoch 800/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1635\n",
      "Epoch 801/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1635\n",
      "Epoch 802/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1617\n",
      "Epoch 803/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1557\n",
      "Epoch 804/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1611\n",
      "Epoch 805/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.2389\n",
      "Epoch 806/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.2052\n",
      "Epoch 807/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.1661\n",
      "Epoch 808/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.1554\n",
      "Epoch 809/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1597\n",
      "Epoch 810/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1569\n",
      "Epoch 811/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1759\n",
      "Epoch 812/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2712\n",
      "Epoch 813/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.3373\n",
      "Epoch 814/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.3100\n",
      "Epoch 815/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.2075\n",
      "Epoch 816/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2586\n",
      "Epoch 817/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2346\n",
      "Epoch 818/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2766\n",
      "Epoch 819/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1841\n",
      "Epoch 820/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.2187\n",
      "Epoch 821/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1783\n",
      "Epoch 822/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1593\n",
      "Epoch 823/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1649\n",
      "Epoch 824/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.2033\n",
      "Epoch 825/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1804\n",
      "Epoch 826/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1813\n",
      "Epoch 827/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.1779\n",
      "Epoch 828/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1923\n",
      "Epoch 829/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.2456\n",
      "Epoch 830/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1927\n",
      "Epoch 831/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.3135\n",
      "Epoch 832/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.2598\n",
      "Epoch 833/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.2010\n",
      "Epoch 834/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1777\n",
      "Epoch 835/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1841\n",
      "Epoch 836/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1728\n",
      "Epoch 837/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1684\n",
      "Epoch 838/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1586\n",
      "Epoch 839/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1897\n",
      "Epoch 840/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1874\n",
      "Epoch 841/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2054\n",
      "Epoch 842/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1778\n",
      "Epoch 843/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1708\n",
      "Epoch 844/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.2346\n",
      "Epoch 845/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1878\n",
      "Epoch 846/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1617\n",
      "Epoch 847/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1651\n",
      "Epoch 848/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1874\n",
      "Epoch 849/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.1765\n",
      "Epoch 850/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.1924\n",
      "Epoch 851/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1761\n",
      "Epoch 852/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.1676\n",
      "Epoch 853/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1655\n",
      "Epoch 854/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1751\n",
      "Epoch 855/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.1749\n",
      "Epoch 856/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.2476\n",
      "Epoch 857/1000\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 0.1957\n",
      "Epoch 858/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.2478\n",
      "Epoch 859/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.2753\n",
      "Epoch 860/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.1966\n",
      "Epoch 861/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.1561\n",
      "Epoch 862/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1445\n",
      "Epoch 863/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1551\n",
      "Epoch 864/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.1606\n",
      "Epoch 865/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1928\n",
      "Epoch 866/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.2692\n",
      "Epoch 867/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.2062\n",
      "Epoch 868/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1732\n",
      "Epoch 869/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1691\n",
      "Epoch 870/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1730\n",
      "Epoch 871/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1588\n",
      "Epoch 872/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1598\n",
      "Epoch 873/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1508\n",
      "Epoch 874/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1484\n",
      "Epoch 875/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1648\n",
      "Epoch 876/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1730\n",
      "Epoch 877/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1977\n",
      "Epoch 878/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.1610\n",
      "Epoch 879/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.1568\n",
      "Epoch 880/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.1552\n",
      "Epoch 881/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1451\n",
      "Epoch 882/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1522\n",
      "Epoch 883/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1509\n",
      "Epoch 884/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.2604\n",
      "Epoch 885/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2004\n",
      "Epoch 886/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1696\n",
      "Epoch 887/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1644\n",
      "Epoch 888/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.2270\n",
      "Epoch 889/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.1681\n",
      "Epoch 890/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.1602\n",
      "Epoch 891/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1582\n",
      "Epoch 892/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1672\n",
      "Epoch 893/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1802\n",
      "Epoch 894/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1456\n",
      "Epoch 895/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1975\n",
      "Epoch 896/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1775\n",
      "Epoch 897/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2403\n",
      "Epoch 898/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.3254\n",
      "Epoch 899/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.3117\n",
      "Epoch 900/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.2887\n",
      "Epoch 901/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.1775\n",
      "Epoch 902/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1444\n",
      "Epoch 903/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1573\n",
      "Epoch 904/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1507\n",
      "Epoch 905/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1550\n",
      "Epoch 906/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1516\n",
      "Epoch 907/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2217\n",
      "Epoch 908/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1610\n",
      "Epoch 909/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.1520\n",
      "Epoch 910/1000\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 0.1970\n",
      "Epoch 911/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1683\n",
      "Epoch 912/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1532\n",
      "Epoch 913/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1497\n",
      "Epoch 914/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1412\n",
      "Epoch 915/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.1694\n",
      "Epoch 916/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.1911\n",
      "Epoch 917/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.2236\n",
      "Epoch 918/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1861\n",
      "Epoch 919/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1700\n",
      "Epoch 920/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1762\n",
      "Epoch 921/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1669\n",
      "Epoch 922/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1707\n",
      "Epoch 923/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1565\n",
      "Epoch 924/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.1636\n",
      "Epoch 925/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1872\n",
      "Epoch 926/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1977\n",
      "Epoch 927/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1562\n",
      "Epoch 928/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1509\n",
      "Epoch 929/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1494\n",
      "Epoch 930/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1699\n",
      "Epoch 931/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1497\n",
      "Epoch 932/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1566\n",
      "Epoch 933/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1971\n",
      "Epoch 934/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1556\n",
      "Epoch 935/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1652\n",
      "Epoch 936/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1548\n",
      "Epoch 937/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1574\n",
      "Epoch 938/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1673\n",
      "Epoch 939/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1727\n",
      "Epoch 940/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1435\n",
      "Epoch 941/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1563\n",
      "Epoch 942/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1681\n",
      "Epoch 943/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.1865\n",
      "Epoch 944/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1436\n",
      "Epoch 945/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1419\n",
      "Epoch 946/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1752\n",
      "Epoch 947/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1513\n",
      "Epoch 948/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2756\n",
      "Epoch 949/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.3428\n",
      "Epoch 950/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.1759\n",
      "Epoch 951/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1586\n",
      "Epoch 952/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1520\n",
      "Epoch 953/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1584\n",
      "Epoch 954/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1649\n",
      "Epoch 955/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2182\n",
      "Epoch 956/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2438\n",
      "Epoch 957/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.2276\n",
      "Epoch 958/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1943\n",
      "Epoch 959/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.2709\n",
      "Epoch 960/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.3542\n",
      "Epoch 961/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.2377\n",
      "Epoch 962/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1635\n",
      "Epoch 963/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.1580\n",
      "Epoch 964/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1509\n",
      "Epoch 965/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1533\n",
      "Epoch 966/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1658\n",
      "Epoch 967/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1690\n",
      "Epoch 968/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.1962\n",
      "Epoch 969/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1624\n",
      "Epoch 970/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1482\n",
      "Epoch 971/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1633\n",
      "Epoch 972/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1750\n",
      "Epoch 973/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1507\n",
      "Epoch 974/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2118\n",
      "Epoch 975/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.2030\n",
      "Epoch 976/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1613\n",
      "Epoch 977/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1988\n",
      "Epoch 978/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1911\n",
      "Epoch 979/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1574\n",
      "Epoch 980/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1639\n",
      "Epoch 981/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1505\n",
      "Epoch 982/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1605\n",
      "Epoch 983/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1534\n",
      "Epoch 984/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1584\n",
      "Epoch 985/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1442\n",
      "Epoch 986/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1425\n",
      "Epoch 987/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1510\n",
      "Epoch 988/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1553\n",
      "Epoch 989/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1672\n",
      "Epoch 990/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1973\n",
      "Epoch 991/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1518\n",
      "Epoch 992/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1547\n",
      "Epoch 993/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.1446\n",
      "Epoch 994/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1925\n",
      "Epoch 995/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1640\n",
      "Epoch 996/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1798\n",
      "Epoch 997/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1953\n",
      "Epoch 998/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1508\n",
      "Epoch 999/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1403\n",
      "Epoch 1000/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.2046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a4c0fa588>"
      ]
     },
     "execution_count": 1131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_3s = Sequential()\n",
    "NN_3s.add(Dense(units=16,input_dim=X_train.shape[1],activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_3s.add(Dense(units=8, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_3s.add(Dense(units=4, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_3s.add(Dense(units=1,activation='linear'))\n",
    "NN_3s.compile(loss='mse', optimizer='adam')\n",
    "NN_3s.fit(np.array(X_train), np.array(y_train), epochs=1000,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN_predictions</th>\n",
       "      <th>actual</th>\n",
       "      <th>GBR_predictions</th>\n",
       "      <th>LY_3PM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>1.167616</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.541947</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.218016</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.575233</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>1.158675</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.338188</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>1.409895</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.665877</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>1.055502</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.322050</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>1.142844</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.335763</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>1.386260</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.814882</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>1.194769</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.640906</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1.356005</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.493987</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>1.339873</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.469463</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>1.502974</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.940496</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>1.199240</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.480796</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1.250258</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.509779</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>1.181296</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.362397</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>1.046294</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.491841</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>1.354445</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.404584</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.963332</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.445590</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>1.176520</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.334304</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>1.218977</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.481034</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>1.124793</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.350871</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>1.197302</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.461532</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>1.282012</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.575768</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0.943434</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.259904</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.883902</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.437787</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>1.170523</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.548352</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>0.923811</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.348633</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1.307036</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.651855</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>1.410590</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.751038</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>1.305663</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.647387</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>1.523383</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.587622</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>1.117049</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.656002</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>1.171271</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.189093</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>1.364447</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.711153</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>0.997382</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.393101</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>1.232398</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.614177</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>1.135783</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.510391</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>1.019293</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.287792</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>1.555396</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.923878</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>0.972769</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.562780</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>1.314192</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.888842</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>1.417555</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.675688</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>1.536231</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.422304</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>1.367587</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.764033</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.948165</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.375466</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>0.167235</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.496149</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1.079115</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.471282</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>1.010893</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.431025</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>1.304137</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.618909</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>1.150748</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.373956</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0.702048</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.024478</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     NN_predictions  actual  GBR_predictions  LY_3PM\n",
       "668        1.167616     1.5         1.541947     1.7\n",
       "9          1.218016     1.3         1.575233     1.7\n",
       "115        1.158675     2.0         1.338188     1.7\n",
       "240        1.409895     2.1         1.665877     1.7\n",
       "444        1.055502     1.0         1.322050     1.7\n",
       "231        1.142844     1.3         1.335763     1.7\n",
       "568        1.386260     0.7         1.814882     1.7\n",
       "340        1.194769     2.2         1.640906     1.7\n",
       "133        1.356005     1.4         1.493987     1.7\n",
       "251        1.339873     1.4         1.469463     1.7\n",
       "116        1.502974     1.4         1.940496     1.7\n",
       "442        1.199240     1.6         1.480796     1.6\n",
       "210        1.250258     1.9         1.509779     1.6\n",
       "396        1.181296     0.8         1.362397     1.6\n",
       "427        1.046294     1.6         1.491841     1.6\n",
       "403        1.354445     1.4         1.404584     1.6\n",
       "101        0.963332     1.5         1.445590     1.6\n",
       "226        1.176520     1.8         1.334304     1.6\n",
       "247        1.218977     1.6         1.481034     1.6\n",
       "670        1.124793     2.0         1.350871     1.6\n",
       "464        1.197302     2.2         1.461532     1.6\n",
       "454        1.282012     1.2         1.575768     1.6\n",
       "161        0.943434     1.6         1.259904     1.6\n",
       "184        0.883902     1.4         1.437787     1.6\n",
       "196        1.170523     2.1         1.548352     1.6\n",
       "163        0.923811     1.3         1.348633     1.6\n",
       "59         1.307036     1.7         1.651855     1.6\n",
       "136        1.410590     1.5         1.751038     1.6\n",
       "512        1.305663     2.0         1.647387     1.6\n",
       "518        1.523383     1.9         1.587622     1.6\n",
       "580        1.117049     1.9         1.656002     1.6\n",
       "571        1.171271     1.4         1.189093     1.6\n",
       "500        1.364447     1.8         1.711153     1.6\n",
       "559        0.997382     1.5         1.393101     1.5\n",
       "301        1.232398     1.5         1.614177     1.5\n",
       "259        1.135783     0.7         1.510391     1.5\n",
       "258        1.019293     1.8         1.287792     1.5\n",
       "243        1.555396     1.7         1.923878     1.5\n",
       "569        0.972769     1.1         1.562780     1.5\n",
       "596        1.314192     2.6         1.888842     1.5\n",
       "235        1.417555     1.7         1.675688     1.5\n",
       "602        1.536231     1.2         1.422304     1.5\n",
       "124        1.367587     2.0         1.764033     1.5\n",
       "148        0.948165     1.8         1.375466     1.5\n",
       "325        0.167235     1.7         1.496149     1.5\n",
       "37         1.079115     1.4         1.471282     1.5\n",
       "356        1.010893     2.0         1.431025     1.5\n",
       "507        1.304137     1.3         1.618909     1.5\n",
       "485        1.150748     0.9         1.373956     1.5\n",
       "381        0.702048     0.9         1.024478     1.5"
      ]
     },
     "execution_count": 1132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = NN_3s.predict(X_test)\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.5)\n",
    "gbr.fit(X_train,y_train)\n",
    "gbr_predictions = gbr.predict(X_test)\n",
    "LR = LinearRegression(fit_intercept=True).fit(X_train,y_train)\n",
    "\n",
    "testing = pd.DataFrame(predictions)\n",
    "testing.columns=['NN_predictions']\n",
    "testing['actual'] = y_test.reset_index()['3PM']\n",
    "testing['GBR_predictions']=gbr_predictions\n",
    "testing['LY_3PM']=X_test['3PM_ly'].reset_index()['3PM_ly']\n",
    "testing.sort_values(by='LY_3PM',ascending=False)[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1133,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2017threes = threes[threes['season']==2017].drop(['team','player','3PM','Games'],axis=1)\n",
    "#pred_2017blocks = blocks[blocks['season']==2017][['blocks_ly','career_blocks','starter_change']]\n",
    "threes_2017 = NN_3s.predict(pred_2017threes)\n",
    "gbr_3PM_2017 = pd.DataFrame(gbr.predict(pred_2017threes))\n",
    "LR_3PM_2017 = pd.DataFrame(LR.predict(pred_2017threes))\n",
    "test_2 =pd.DataFrame(threes_2017)\n",
    "test_3 = pd.merge(threes,pred_2017threes,left_index=True,right_index=True).reset_index()\n",
    "test_3['predictions']=test_2[0]\n",
    "test_3['gbr_pred'] = gbr_3PM_2017[0]\n",
    "test_3['LR_pred'] = LR_3PM_2017[0]\n",
    "test_3['mean_pred'] = (test_3['predictions']+test_3['gbr_pred']+test_3['LR_pred'])/3\n",
    "test_3 = test_3[test_3['Games']>30]\n",
    "test_3[['player','3PM','predictions','LR_pred','gbr_pred','mean_pred','3PM_ly_x']].sort_values(by='3PM_ly_x',ascending=False)[0:50]\n",
    "\n",
    "threes_2017 = test_3[['player','LR_pred']]\n",
    "threes_2017.columns = ['player','three_prediction']\n",
    "df_2017 = pd.merge(df_2017,threes_2017,how='left',left_on='player',right_on='player')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE using LR:0.162525600754578\n",
      "MSE using GB:0.16707504733095485\n",
      "MSE using NN:0.4381243096569014\n",
      "MSE using combo:0.20121757820849856\n",
      "MSE using mean:0.7179477933925056\n",
      "MSE using last year stats:0.2091987179487179\n"
     ]
    }
   ],
   "source": [
    "print('MSE using LR:{}'.format(np.mean((test_3['3PM']-test_3['LR_pred'])**2)))\n",
    "print('MSE using GB:{}'.format(np.mean((test_3['3PM']-test_3['gbr_pred'])**2)))\n",
    "print('MSE using NN:{}'.format(np.mean((test_3['3PM']-test_3['predictions'])**2)))\n",
    "print('MSE using combo:{}'.format(np.mean((test_3['3PM']-test_3['mean_pred'])**2)))\n",
    "print('MSE using mean:{}'.format(np.mean((test_3['3PM']-np.mean(test_3['3PM']))**2)))\n",
    "print('MSE using last year stats:{}'.format(np.mean((test_3['3PM']-test_3['3PM_ly_x'])**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1135,
   "metadata": {},
   "outputs": [],
   "source": [
    "query= '''\n",
    "        \n",
    "        DROP TABLE IF EXISTS turnovers_pred;\n",
    "        CREATE TABLE turnovers_pred(\n",
    "        season int, -- these come from player_stats\n",
    "        player varchar(50),\n",
    "        Age int,\n",
    "        team varchar(50),\n",
    "        turnovers float, \n",
    "        turnovers_ly float,\n",
    "        change_tov_ly float,\n",
    "        starter_change int,\n",
    "        Games int,\n",
    "        C_PF int,\n",
    "        PG int,\n",
    "        SG_SF int,\n",
    "        \n",
    "         -- these come from team_changes\n",
    "        high_usageplayer_added int,\n",
    "        usagemin_opened float,\n",
    "        maxusage_added float,\n",
    "        high_usageplayer_dropped int,\n",
    "        \n",
    "        per_ly float,\n",
    "        change_per float,\n",
    "        usagerank float,\n",
    "        usagerank_ly float,\n",
    "        offensive_winshares float,\n",
    "        offensive_boxplusminus float,\n",
    "        \n",
    "        max_teammatepts float,\n",
    "        max_teammate_usage float,\n",
    "        max_teammateto float,\n",
    "        max_teammateshot_attempts float,\n",
    "        \n",
    "        career_to float,\n",
    "        yearspro int\n",
    "        );\n",
    "        \n",
    "        INSERT INTO turnovers_pred(season,player,age,team,turnovers,turnovers_ly,change_tov_ly,starter_change,Games,C_PF,PG,SG_SF)\n",
    "        SELECT season,player,age,startingteam,tov,tov_ly,change_tov_ly,starter-starter_ly,Games,\n",
    "        case when pos in ('C','PF') then 1 else 0 end,case when pos='PG' then 1 else 0 end,case when pos in('SG','SF') then 1 else 0 end from player_stats;\n",
    "        \n",
    "        update turnovers_pred pp\n",
    "        set high_usageplayer_added = tc.high_usageplayer_added,usagemin_opened=tc.usagemin_opened,\n",
    "        maxusage_added=tc.max_usageadded,high_usageplayer_dropped=tc.high_usageplayer_dropped\n",
    "        from team_changes tc\n",
    "        where tc.team = pp.team and pp.season=tc.season;\n",
    "        \n",
    "        update turnovers_pred pp\n",
    "        set per_ly=pa.per_ly,change_per=pa.change_per,\n",
    "        usagerank=pa.usagerank,usagerank_ly=pa.usagerank_ly,offensive_winshares=pa.offensive_winshares,\n",
    "        offensive_boxplusminus=pa.offensive_boxplusminus\n",
    "        from player_advstats pa\n",
    "        where pp.player = pa.player and pp.season = pa.season and pp.team = pa.startingteam;\n",
    "        \n",
    "        update turnovers_pred pp\n",
    "        set max_teammatepts = tm.max_teammatepts,max_teammate_usage=tm.max_teammate_usage,max_teammateto=tm.max_teammateto,\n",
    "        max_teammateshot_attempts=tm.max_teammateshot_attempts\n",
    "        from teammate_maxes tm\n",
    "        where tm.season = pp.season and tm.player = pp.player;\n",
    "        \n",
    "        update turnovers_pred pp\n",
    "        set career_to = pc.career_to, yearspro = pc.yearspro\n",
    "        from player_careerstats pc\n",
    "        where pp.player = pc.player and pp.season = pc.season;\n",
    "        \n",
    "        \n",
    "        select * from turnovers_pred where season>2009\n",
    "        '''\n",
    "\n",
    "\n",
    "cur.execute(query)\n",
    "data = cur.fetchall()\n",
    "to_df = pd.DataFrame(np.array(data))\n",
    "to_df.columns = ['season','player','age','team','turnovers','turnovers_ly','change_turnovers_ly','starter_change','Games','C_PF','PG','SG_SF','high_usageplayer_added','usagemin_opened','maxusage_added','high_usageplayer_dropped'\n",
    "                    ,'per_ly','change_per','usagerank','usagerank_ly','offensive_winshares','offensive_boxplusminus'\n",
    "                 ,'max_teammatepts','max_teammate_usage','max_teammateto','max_teammateshot_attempts','career_turnovers','yearspro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "to_df['age_squared']=to_df['age']*to_df['age']\n",
    "tos = to_df[to_df['turnovers_ly'].notna()]\n",
    "for i in tos.columns:\n",
    "    if i not in(['player','team']):\n",
    "        tos[i]=pd.to_numeric(tos[i])\n",
    "tos = tos.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1137,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tos[(tos['season']!=2017) & (tos['Games']>30)].drop(['player','team','turnovers','Games'],axis=1)\n",
    "y = tos[(tos['season']!=2017) & (tos['Games']>30)]['turnovers']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1564/1564 [==============================] - 4s 2ms/step - loss: 56531.3866\n",
      "Epoch 2/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 22807.0294\n",
      "Epoch 3/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 15772.3369\n",
      "Epoch 4/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 13331.3271\n",
      "Epoch 5/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 10276.0411\n",
      "Epoch 6/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 7515.8865\n",
      "Epoch 7/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 5619.0386\n",
      "Epoch 8/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 4187.4759\n",
      "Epoch 9/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 3199.9343\n",
      "Epoch 10/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 2534.0292\n",
      "Epoch 11/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1975.2809\n",
      "Epoch 12/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1505.1442\n",
      "Epoch 13/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1170.7482\n",
      "Epoch 14/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 935.9054\n",
      "Epoch 15/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 791.0640\n",
      "Epoch 16/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 677.4845\n",
      "Epoch 17/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 604.2565\n",
      "Epoch 18/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 545.4567\n",
      "Epoch 19/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 498.6191\n",
      "Epoch 20/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 457.0886\n",
      "Epoch 21/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 423.3673\n",
      "Epoch 22/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 389.6894\n",
      "Epoch 23/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 360.7138\n",
      "Epoch 24/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 335.2128\n",
      "Epoch 25/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 311.8709\n",
      "Epoch 26/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 289.9539\n",
      "Epoch 27/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 271.3668\n",
      "Epoch 28/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 253.4524\n",
      "Epoch 29/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 237.2696\n",
      "Epoch 30/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 221.1529\n",
      "Epoch 31/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 210.0197\n",
      "Epoch 32/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 196.0850\n",
      "Epoch 33/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 185.7919\n",
      "Epoch 34/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 171.5387\n",
      "Epoch 35/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 162.0310\n",
      "Epoch 36/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 150.6694\n",
      "Epoch 37/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 141.2497\n",
      "Epoch 38/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 133.1147\n",
      "Epoch 39/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 127.7974\n",
      "Epoch 40/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 120.6059\n",
      "Epoch 41/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 115.0672\n",
      "Epoch 42/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 108.6164\n",
      "Epoch 43/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 103.0467\n",
      "Epoch 44/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 97.0675\n",
      "Epoch 45/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 92.2434\n",
      "Epoch 46/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 88.1272\n",
      "Epoch 47/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 83.8850\n",
      "Epoch 48/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 80.1021\n",
      "Epoch 49/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 76.6855\n",
      "Epoch 50/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 73.4092\n",
      "Epoch 51/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 69.0969\n",
      "Epoch 52/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 66.5387\n",
      "Epoch 53/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 63.6445\n",
      "Epoch 54/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 60.6174\n",
      "Epoch 55/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 57.6367\n",
      "Epoch 56/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 54.8975\n",
      "Epoch 57/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 53.7317\n",
      "Epoch 58/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 50.2736\n",
      "Epoch 59/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 47.9528\n",
      "Epoch 60/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 45.7618\n",
      "Epoch 61/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 44.3563\n",
      "Epoch 62/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 42.2592\n",
      "Epoch 63/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 41.5548\n",
      "Epoch 64/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 40.3341\n",
      "Epoch 65/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 37.1293\n",
      "Epoch 66/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 35.8209\n",
      "Epoch 67/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 34.1722\n",
      "Epoch 68/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 32.9098\n",
      "Epoch 69/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 31.5315\n",
      "Epoch 70/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 30.4905\n",
      "Epoch 71/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 29.2898\n",
      "Epoch 72/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 28.2032\n",
      "Epoch 73/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 27.0500\n",
      "Epoch 74/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 26.0957\n",
      "Epoch 75/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 25.1770\n",
      "Epoch 76/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 24.2695\n",
      "Epoch 77/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 23.7112\n",
      "Epoch 78/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 22.8802\n",
      "Epoch 79/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 22.1284\n",
      "Epoch 80/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 21.4025\n",
      "Epoch 81/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 20.6287\n",
      "Epoch 82/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 20.2139\n",
      "Epoch 83/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 19.9603\n",
      "Epoch 84/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 18.9715\n",
      "Epoch 85/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 18.1133\n",
      "Epoch 86/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 17.6037\n",
      "Epoch 87/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 17.1960\n",
      "Epoch 88/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 16.7595\n",
      "Epoch 89/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 16.2012\n",
      "Epoch 90/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 15.8495\n",
      "Epoch 91/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 15.5332\n",
      "Epoch 92/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 15.0659\n",
      "Epoch 93/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 14.5552\n",
      "Epoch 94/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 14.1428\n",
      "Epoch 95/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 13.8810\n",
      "Epoch 96/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 13.6078\n",
      "Epoch 97/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 13.0714\n",
      "Epoch 98/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 12.7598\n",
      "Epoch 99/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 12.3760\n",
      "Epoch 100/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 12.1117\n",
      "Epoch 101/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 11.9263\n",
      "Epoch 102/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 11.6651\n",
      "Epoch 103/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 11.3192\n",
      "Epoch 104/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 11.0155\n",
      "Epoch 105/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 10.7183\n",
      "Epoch 106/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 11.0569\n",
      "Epoch 107/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 10.6498\n",
      "Epoch 108/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 10.2334\n",
      "Epoch 109/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 9.7794\n",
      "Epoch 110/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 9.4838\n",
      "Epoch 111/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 9.2325\n",
      "Epoch 112/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 9.2134\n",
      "Epoch 113/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 8.7792\n",
      "Epoch 114/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 8.5711\n",
      "Epoch 115/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 8.3397\n",
      "Epoch 116/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 8.1956\n",
      "Epoch 117/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.9534\n",
      "Epoch 118/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.7259\n",
      "Epoch 119/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 7.6244\n",
      "Epoch 120/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.5345\n",
      "Epoch 121/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.4242\n",
      "Epoch 122/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.0323\n",
      "Epoch 123/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.1705\n",
      "Epoch 124/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.9314\n",
      "Epoch 125/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.6779\n",
      "Epoch 126/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 6.5775\n",
      "Epoch 127/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.2662\n",
      "Epoch 128/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.1269\n",
      "Epoch 129/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.1342\n",
      "Epoch 130/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 5.9420\n",
      "Epoch 131/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 5.9850\n",
      "Epoch 132/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 5.6962\n",
      "Epoch 133/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 5.7357\n",
      "Epoch 134/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 5.4787\n",
      "Epoch 135/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 5.2729\n",
      "Epoch 136/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 5.1737\n",
      "Epoch 137/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 5.1249\n",
      "Epoch 138/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 4.9908\n",
      "Epoch 139/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 4.9170\n",
      "Epoch 140/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 4.8196\n",
      "Epoch 141/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 4.7530\n",
      "Epoch 142/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 4.6789\n",
      "Epoch 143/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 4.4758\n",
      "Epoch 144/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 4.3354\n",
      "Epoch 145/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 4.2785\n",
      "Epoch 146/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 4.1524\n",
      "Epoch 147/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 4.1356\n",
      "Epoch 148/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 4.1784\n",
      "Epoch 149/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 3.9545\n",
      "Epoch 150/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 3.8858\n",
      "Epoch 151/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.9331\n",
      "Epoch 152/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.7017\n",
      "Epoch 153/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.6588\n",
      "Epoch 154/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 3.6856\n",
      "Epoch 155/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.5562\n",
      "Epoch 156/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 3.4076\n",
      "Epoch 157/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 3.3554\n",
      "Epoch 158/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 3.2670\n",
      "Epoch 159/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 3.2854\n",
      "Epoch 160/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 3.2796\n",
      "Epoch 161/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 3.0979\n",
      "Epoch 162/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 3.0871\n",
      "Epoch 163/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 3.0108\n",
      "Epoch 164/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.9817\n",
      "Epoch 165/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 2.9317\n",
      "Epoch 166/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 2.8683\n",
      "Epoch 167/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 2.9174\n",
      "Epoch 168/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.9065\n",
      "Epoch 169/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.7818\n",
      "Epoch 170/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.8173\n",
      "Epoch 171/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.6514\n",
      "Epoch 172/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 2.5975\n",
      "Epoch 173/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 2.6319\n",
      "Epoch 174/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 2.5441\n",
      "Epoch 175/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 2.5305\n",
      "Epoch 176/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.4898\n",
      "Epoch 177/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.4796\n",
      "Epoch 178/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.3932\n",
      "Epoch 179/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 2.3678\n",
      "Epoch 180/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 2.3569\n",
      "Epoch 181/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 2.4070\n",
      "Epoch 182/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.2811\n",
      "Epoch 183/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 2.2616\n",
      "Epoch 184/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.2005\n",
      "Epoch 185/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 2.1743\n",
      "Epoch 186/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 2.1103\n",
      "Epoch 187/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.0887\n",
      "Epoch 188/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 2.0569\n",
      "Epoch 189/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 2.0144\n",
      "Epoch 190/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.0003\n",
      "Epoch 191/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.9609\n",
      "Epoch 192/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.9468\n",
      "Epoch 193/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.9316\n",
      "Epoch 194/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.9458\n",
      "Epoch 195/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.8343\n",
      "Epoch 196/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.8158\n",
      "Epoch 197/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.7944\n",
      "Epoch 198/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.7700\n",
      "Epoch 199/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.7352\n",
      "Epoch 200/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.7242\n",
      "Epoch 201/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.7008\n",
      "Epoch 202/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.7065\n",
      "Epoch 203/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.7171\n",
      "Epoch 204/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.6157\n",
      "Epoch 205/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.6914\n",
      "Epoch 206/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.5628\n",
      "Epoch 207/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.5507\n",
      "Epoch 208/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.5388\n",
      "Epoch 209/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.5162\n",
      "Epoch 210/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.5082\n",
      "Epoch 211/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.4950\n",
      "Epoch 212/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.4680\n",
      "Epoch 213/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.4518\n",
      "Epoch 214/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.5515\n",
      "Epoch 215/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.4195\n",
      "Epoch 216/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.4463\n",
      "Epoch 217/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.4011\n",
      "Epoch 218/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.4798\n",
      "Epoch 219/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.3834\n",
      "Epoch 220/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.3213\n",
      "Epoch 221/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.3108\n",
      "Epoch 222/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.3676\n",
      "Epoch 223/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.3032\n",
      "Epoch 224/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.2540\n",
      "Epoch 225/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.2989\n",
      "Epoch 226/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2556\n",
      "Epoch 227/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.2353\n",
      "Epoch 228/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2025\n",
      "Epoch 229/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.1791\n",
      "Epoch 230/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.1723\n",
      "Epoch 231/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.1567\n",
      "Epoch 232/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.1375\n",
      "Epoch 233/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.1524\n",
      "Epoch 234/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.1265\n",
      "Epoch 235/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.1067\n",
      "Epoch 236/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.0937\n",
      "Epoch 237/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.1211\n",
      "Epoch 238/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.0837\n",
      "Epoch 239/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.0982\n",
      "Epoch 240/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.0938\n",
      "Epoch 241/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.1352\n",
      "Epoch 242/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.0943\n",
      "Epoch 243/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.0337\n",
      "Epoch 244/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.0165\n",
      "Epoch 245/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.9918\n",
      "Epoch 246/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.9737\n",
      "Epoch 247/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.9788\n",
      "Epoch 248/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.9865\n",
      "Epoch 249/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.9553\n",
      "Epoch 250/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.9720\n",
      "Epoch 251/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.9349\n",
      "Epoch 252/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.9246\n",
      "Epoch 253/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.9161\n",
      "Epoch 254/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.9219\n",
      "Epoch 255/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.9067\n",
      "Epoch 256/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.9125\n",
      "Epoch 257/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.8642\n",
      "Epoch 258/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.8803\n",
      "Epoch 259/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.8770\n",
      "Epoch 260/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.9296\n",
      "Epoch 261/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.9857\n",
      "Epoch 262/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.8885\n",
      "Epoch 263/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.8730\n",
      "Epoch 264/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.8873\n",
      "Epoch 265/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.8429\n",
      "Epoch 266/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.9040\n",
      "Epoch 267/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.8414\n",
      "Epoch 268/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.8327\n",
      "Epoch 269/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7953\n",
      "Epoch 270/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.7811\n",
      "Epoch 271/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7727\n",
      "Epoch 272/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7797\n",
      "Epoch 273/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.8044\n",
      "Epoch 274/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.8371\n",
      "Epoch 275/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7849\n",
      "Epoch 276/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.7667\n",
      "Epoch 277/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.7880\n",
      "Epoch 278/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.8357\n",
      "Epoch 279/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.7380\n",
      "Epoch 280/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7597\n",
      "Epoch 281/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.7263\n",
      "Epoch 282/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7525\n",
      "Epoch 283/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.9433\n",
      "Epoch 284/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.9032\n",
      "Epoch 285/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.7470\n",
      "Epoch 286/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.8145\n",
      "Epoch 287/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7330\n",
      "Epoch 288/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.7281\n",
      "Epoch 289/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7016\n",
      "Epoch 290/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6994\n",
      "Epoch 291/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.7477\n",
      "Epoch 292/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.6684\n",
      "Epoch 293/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7560\n",
      "Epoch 294/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.7039\n",
      "Epoch 295/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.7485\n",
      "Epoch 296/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.8318\n",
      "Epoch 297/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7638\n",
      "Epoch 298/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.7541\n",
      "Epoch 299/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.7621\n",
      "Epoch 300/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7507\n",
      "Epoch 301/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6867\n",
      "Epoch 302/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6777\n",
      "Epoch 303/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6867\n",
      "Epoch 304/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6797\n",
      "Epoch 305/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.8001\n",
      "Epoch 306/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.7131\n",
      "Epoch 307/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6701\n",
      "Epoch 308/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6700\n",
      "Epoch 309/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6835\n",
      "Epoch 310/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.7357\n",
      "Epoch 311/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6563\n",
      "Epoch 312/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6614\n",
      "Epoch 313/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.7134\n",
      "Epoch 314/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.7170\n",
      "Epoch 315/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6349\n",
      "Epoch 316/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6370\n",
      "Epoch 317/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6022\n",
      "Epoch 318/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.6026\n",
      "Epoch 319/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6083\n",
      "Epoch 320/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7585\n",
      "Epoch 321/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.7559\n",
      "Epoch 322/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6244\n",
      "Epoch 323/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6479\n",
      "Epoch 324/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5919\n",
      "Epoch 325/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6049\n",
      "Epoch 326/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5887\n",
      "Epoch 327/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6098\n",
      "Epoch 328/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6256\n",
      "Epoch 329/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5855\n",
      "Epoch 330/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5979\n",
      "Epoch 331/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5925\n",
      "Epoch 332/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5782\n",
      "Epoch 333/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5884\n",
      "Epoch 334/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7208\n",
      "Epoch 335/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6615\n",
      "Epoch 336/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.5833\n",
      "Epoch 337/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5797\n",
      "Epoch 338/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6293\n",
      "Epoch 339/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6957\n",
      "Epoch 340/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.6683\n",
      "Epoch 341/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6247\n",
      "Epoch 342/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6157\n",
      "Epoch 343/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5974\n",
      "Epoch 344/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.7972\n",
      "Epoch 345/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.7491\n",
      "Epoch 346/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6110\n",
      "Epoch 347/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5575\n",
      "Epoch 348/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5876\n",
      "Epoch 349/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.6391\n",
      "Epoch 350/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.6405\n",
      "Epoch 351/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5838\n",
      "Epoch 352/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5523\n",
      "Epoch 353/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5856\n",
      "Epoch 354/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5838\n",
      "Epoch 355/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5484\n",
      "Epoch 356/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5441\n",
      "Epoch 357/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5555\n",
      "Epoch 358/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5285\n",
      "Epoch 359/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5310\n",
      "Epoch 360/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5345\n",
      "Epoch 361/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5360\n",
      "Epoch 362/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5446\n",
      "Epoch 363/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5551\n",
      "Epoch 364/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5553\n",
      "Epoch 365/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5273\n",
      "Epoch 366/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5449\n",
      "Epoch 367/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6020\n",
      "Epoch 368/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.6210\n",
      "Epoch 369/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5218\n",
      "Epoch 370/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5683\n",
      "Epoch 371/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5241\n",
      "Epoch 372/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5652\n",
      "Epoch 373/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5398\n",
      "Epoch 374/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5256\n",
      "Epoch 375/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5777\n",
      "Epoch 376/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5907\n",
      "Epoch 377/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5456\n",
      "Epoch 378/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5380\n",
      "Epoch 379/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6010\n",
      "Epoch 380/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5489\n",
      "Epoch 381/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5038\n",
      "Epoch 382/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5907\n",
      "Epoch 383/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5284\n",
      "Epoch 384/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5192\n",
      "Epoch 385/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4961\n",
      "Epoch 386/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.5825\n",
      "Epoch 387/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5332\n",
      "Epoch 388/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6736\n",
      "Epoch 389/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5644\n",
      "Epoch 390/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5475\n",
      "Epoch 391/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5823\n",
      "Epoch 392/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5271\n",
      "Epoch 393/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5549\n",
      "Epoch 394/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5713\n",
      "Epoch 395/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5994\n",
      "Epoch 396/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6594\n",
      "Epoch 397/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5275\n",
      "Epoch 398/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5089\n",
      "Epoch 399/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5314\n",
      "Epoch 400/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5124\n",
      "Epoch 401/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5138\n",
      "Epoch 402/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5328\n",
      "Epoch 403/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.6207\n",
      "Epoch 404/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5844\n",
      "Epoch 405/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5184\n",
      "Epoch 406/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5053\n",
      "Epoch 407/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5064\n",
      "Epoch 408/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5043\n",
      "Epoch 409/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4849\n",
      "Epoch 410/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4779\n",
      "Epoch 411/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4926\n",
      "Epoch 412/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5176\n",
      "Epoch 413/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4697\n",
      "Epoch 414/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4708\n",
      "Epoch 415/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5039\n",
      "Epoch 416/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4722\n",
      "Epoch 417/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5183\n",
      "Epoch 418/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6053\n",
      "Epoch 419/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4915\n",
      "Epoch 420/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4779\n",
      "Epoch 421/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4919\n",
      "Epoch 422/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5156\n",
      "Epoch 423/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.4980\n",
      "Epoch 424/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5339\n",
      "Epoch 425/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5055\n",
      "Epoch 426/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4899\n",
      "Epoch 427/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4699\n",
      "Epoch 428/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5043\n",
      "Epoch 429/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4837\n",
      "Epoch 430/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4965\n",
      "Epoch 431/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5837\n",
      "Epoch 432/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4970\n",
      "Epoch 433/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4820\n",
      "Epoch 434/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5025\n",
      "Epoch 435/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4969\n",
      "Epoch 436/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4819\n",
      "Epoch 437/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5237\n",
      "Epoch 438/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5014\n",
      "Epoch 439/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4749\n",
      "Epoch 440/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4580\n",
      "Epoch 441/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5792\n",
      "Epoch 442/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6031\n",
      "Epoch 443/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5501\n",
      "Epoch 444/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4698\n",
      "Epoch 445/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5594\n",
      "Epoch 446/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5170\n",
      "Epoch 447/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5047\n",
      "Epoch 448/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4575\n",
      "Epoch 449/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6036\n",
      "Epoch 450/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4725\n",
      "Epoch 451/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4663\n",
      "Epoch 452/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4878\n",
      "Epoch 453/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5185\n",
      "Epoch 454/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5060\n",
      "Epoch 455/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4846\n",
      "Epoch 456/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5560\n",
      "Epoch 457/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7416\n",
      "Epoch 458/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.5066\n",
      "Epoch 459/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.6260\n",
      "Epoch 460/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.6804\n",
      "Epoch 461/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.8760\n",
      "Epoch 462/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5980\n",
      "Epoch 463/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5418\n",
      "Epoch 464/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4606\n",
      "Epoch 465/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4750\n",
      "Epoch 466/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4915\n",
      "Epoch 467/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4977\n",
      "Epoch 468/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4834\n",
      "Epoch 469/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4720\n",
      "Epoch 470/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5263\n",
      "Epoch 471/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.6168\n",
      "Epoch 472/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.8006\n",
      "Epoch 473/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7964\n",
      "Epoch 474/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6381\n",
      "Epoch 475/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5624\n",
      "Epoch 476/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4732\n",
      "Epoch 477/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5057\n",
      "Epoch 478/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.5752\n",
      "Epoch 479/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5152\n",
      "Epoch 480/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4848\n",
      "Epoch 481/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5040\n",
      "Epoch 482/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4910\n",
      "Epoch 483/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5542\n",
      "Epoch 484/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4677\n",
      "Epoch 485/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4638\n",
      "Epoch 486/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4758\n",
      "Epoch 487/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4653\n",
      "Epoch 488/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4685\n",
      "Epoch 489/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4457\n",
      "Epoch 490/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4359\n",
      "Epoch 491/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4517\n",
      "Epoch 492/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4780\n",
      "Epoch 493/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5069\n",
      "Epoch 494/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4431\n",
      "Epoch 495/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4812\n",
      "Epoch 496/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5962\n",
      "Epoch 497/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4974\n",
      "Epoch 498/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4733\n",
      "Epoch 499/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6073\n",
      "Epoch 500/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5238\n",
      "Epoch 501/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4905\n",
      "Epoch 502/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4421\n",
      "Epoch 503/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4329\n",
      "Epoch 504/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4767\n",
      "Epoch 505/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5082\n",
      "Epoch 506/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5390\n",
      "Epoch 507/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5479\n",
      "Epoch 508/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4767\n",
      "Epoch 509/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4427\n",
      "Epoch 510/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4363\n",
      "Epoch 511/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5188\n",
      "Epoch 512/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4430\n",
      "Epoch 513/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4638\n",
      "Epoch 514/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5026\n",
      "Epoch 515/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5558\n",
      "Epoch 516/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.9489\n",
      "Epoch 517/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.7454\n",
      "Epoch 518/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4678\n",
      "Epoch 519/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4816\n",
      "Epoch 520/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5239\n",
      "Epoch 521/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6999\n",
      "Epoch 522/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6520\n",
      "Epoch 523/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6132\n",
      "Epoch 524/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4631\n",
      "Epoch 525/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4386\n",
      "Epoch 526/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5000\n",
      "Epoch 527/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5053\n",
      "Epoch 528/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4655\n",
      "Epoch 529/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4394\n",
      "Epoch 530/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5001\n",
      "Epoch 531/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4690\n",
      "Epoch 532/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4949\n",
      "Epoch 533/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5619\n",
      "Epoch 534/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.5184\n",
      "Epoch 535/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4585\n",
      "Epoch 536/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4359\n",
      "Epoch 537/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4507\n",
      "Epoch 538/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4365\n",
      "Epoch 539/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5320\n",
      "Epoch 540/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5630\n",
      "Epoch 541/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4376\n",
      "Epoch 542/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6180\n",
      "Epoch 543/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4737\n",
      "Epoch 544/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4746\n",
      "Epoch 545/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4584\n",
      "Epoch 546/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4573\n",
      "Epoch 547/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4780\n",
      "Epoch 548/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4410\n",
      "Epoch 549/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5757\n",
      "Epoch 550/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.7334\n",
      "Epoch 551/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.8409\n",
      "Epoch 552/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6902\n",
      "Epoch 553/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.7314\n",
      "Epoch 554/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.6762\n",
      "Epoch 555/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.6328\n",
      "Epoch 556/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5200\n",
      "Epoch 557/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5052\n",
      "Epoch 558/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4487\n",
      "Epoch 559/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.4730\n",
      "Epoch 560/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4336\n",
      "Epoch 561/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5454\n",
      "Epoch 562/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.6565\n",
      "Epoch 563/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5897\n",
      "Epoch 564/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4457\n",
      "Epoch 565/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4937\n",
      "Epoch 566/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.8406\n",
      "Epoch 567/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6215\n",
      "Epoch 568/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4593\n",
      "Epoch 569/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4957\n",
      "Epoch 570/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5365\n",
      "Epoch 571/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5318\n",
      "Epoch 572/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4431\n",
      "Epoch 573/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4262\n",
      "Epoch 574/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4462\n",
      "Epoch 575/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4355\n",
      "Epoch 576/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5269\n",
      "Epoch 577/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4616\n",
      "Epoch 578/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4771\n",
      "Epoch 579/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5812\n",
      "Epoch 580/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4976\n",
      "Epoch 581/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5373\n",
      "Epoch 582/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6900\n",
      "Epoch 583/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5782\n",
      "Epoch 584/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5270\n",
      "Epoch 585/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5332\n",
      "Epoch 586/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.7177\n",
      "Epoch 587/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5228\n",
      "Epoch 588/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.4815\n",
      "Epoch 589/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.6107\n",
      "Epoch 590/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.7134\n",
      "Epoch 591/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.4735\n",
      "Epoch 592/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5781\n",
      "Epoch 593/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5593\n",
      "Epoch 594/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4895\n",
      "Epoch 595/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4506\n",
      "Epoch 596/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4602\n",
      "Epoch 597/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4832\n",
      "Epoch 598/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4889\n",
      "Epoch 599/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5121\n",
      "Epoch 600/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4518\n",
      "Epoch 601/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4590\n",
      "Epoch 602/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4809\n",
      "Epoch 603/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5935\n",
      "Epoch 604/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5841\n",
      "Epoch 605/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5828\n",
      "Epoch 606/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.4481\n",
      "Epoch 607/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4729\n",
      "Epoch 608/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.7798\n",
      "Epoch 609/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.4357\n",
      "Epoch 610/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4728\n",
      "Epoch 611/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4266\n",
      "Epoch 612/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4516\n",
      "Epoch 613/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4434\n",
      "Epoch 614/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4442\n",
      "Epoch 615/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4686\n",
      "Epoch 616/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5120\n",
      "Epoch 617/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.8236\n",
      "Epoch 618/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7994\n",
      "Epoch 619/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6557\n",
      "Epoch 620/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5392\n",
      "Epoch 621/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5770\n",
      "Epoch 622/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.6261\n",
      "Epoch 623/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.6223\n",
      "Epoch 624/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.7668\n",
      "Epoch 625/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4661\n",
      "Epoch 626/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.6491\n",
      "Epoch 627/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5512\n",
      "Epoch 628/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5409\n",
      "Epoch 629/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4451\n",
      "Epoch 630/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4242\n",
      "Epoch 631/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4632\n",
      "Epoch 632/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4436\n",
      "Epoch 633/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4546\n",
      "Epoch 634/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4557\n",
      "Epoch 635/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4385\n",
      "Epoch 636/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5881\n",
      "Epoch 637/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4952\n",
      "Epoch 638/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4589\n",
      "Epoch 639/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4272\n",
      "Epoch 640/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4606\n",
      "Epoch 641/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4591\n",
      "Epoch 642/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.5756\n",
      "Epoch 643/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.6335\n",
      "Epoch 644/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5396\n",
      "Epoch 645/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5233\n",
      "Epoch 646/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4909\n",
      "Epoch 647/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5123\n",
      "Epoch 648/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5651\n",
      "Epoch 649/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4663\n",
      "Epoch 650/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5593\n",
      "Epoch 651/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5191\n",
      "Epoch 652/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4686\n",
      "Epoch 653/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4401\n",
      "Epoch 654/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4336\n",
      "Epoch 655/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5117\n",
      "Epoch 656/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5337\n",
      "Epoch 657/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5084\n",
      "Epoch 658/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5170\n",
      "Epoch 659/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4660\n",
      "Epoch 660/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.6260\n",
      "Epoch 661/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.7978\n",
      "Epoch 662/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5606\n",
      "Epoch 663/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4593\n",
      "Epoch 664/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6549\n",
      "Epoch 665/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.5747\n",
      "Epoch 666/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6353\n",
      "Epoch 667/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.9993\n",
      "Epoch 668/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.9843\n",
      "Epoch 669/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5297\n",
      "Epoch 670/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5543\n",
      "Epoch 671/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5380\n",
      "Epoch 672/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6519\n",
      "Epoch 673/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.4870\n",
      "Epoch 674/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.4550\n",
      "Epoch 675/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6559\n",
      "Epoch 676/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5797\n",
      "Epoch 677/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4973\n",
      "Epoch 678/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.4381\n",
      "Epoch 679/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.4312\n",
      "Epoch 680/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4724\n",
      "Epoch 681/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5684\n",
      "Epoch 682/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4777\n",
      "Epoch 683/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5884\n",
      "Epoch 684/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.0094\n",
      "Epoch 685/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5819\n",
      "Epoch 686/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4549\n",
      "Epoch 687/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5117\n",
      "Epoch 688/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6085\n",
      "Epoch 689/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4979\n",
      "Epoch 690/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5359\n",
      "Epoch 691/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4926\n",
      "Epoch 692/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4325\n",
      "Epoch 693/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4389\n",
      "Epoch 694/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4452\n",
      "Epoch 695/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4313\n",
      "Epoch 696/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5246\n",
      "Epoch 697/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.5698\n",
      "Epoch 698/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6654\n",
      "Epoch 699/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.6670\n",
      "Epoch 700/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5755\n",
      "Epoch 701/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6524\n",
      "Epoch 702/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5101\n",
      "Epoch 703/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5531\n",
      "Epoch 704/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.7856\n",
      "Epoch 705/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5035\n",
      "Epoch 706/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4692\n",
      "Epoch 707/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5420\n",
      "Epoch 708/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4534\n",
      "Epoch 709/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5247\n",
      "Epoch 710/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6860\n",
      "Epoch 711/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4387\n",
      "Epoch 712/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4970\n",
      "Epoch 713/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5067\n",
      "Epoch 714/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4565\n",
      "Epoch 715/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5514\n",
      "Epoch 716/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.9294\n",
      "Epoch 717/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.8205\n",
      "Epoch 718/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.2489\n",
      "Epoch 719/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.1056\n",
      "Epoch 720/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.7542\n",
      "Epoch 721/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6491\n",
      "Epoch 722/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4397\n",
      "Epoch 723/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4532\n",
      "Epoch 724/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4346\n",
      "Epoch 725/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4784\n",
      "Epoch 726/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4519\n",
      "Epoch 727/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5382\n",
      "Epoch 728/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5140\n",
      "Epoch 729/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5149\n",
      "Epoch 730/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4758\n",
      "Epoch 731/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4224\n",
      "Epoch 732/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4750\n",
      "Epoch 733/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.6988\n",
      "Epoch 734/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5425\n",
      "Epoch 735/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.2361\n",
      "Epoch 736/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6537\n",
      "Epoch 737/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4555\n",
      "Epoch 738/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.6406\n",
      "Epoch 739/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5235\n",
      "Epoch 740/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5160\n",
      "Epoch 741/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5991\n",
      "Epoch 742/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5616\n",
      "Epoch 743/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.9603\n",
      "Epoch 744/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4743\n",
      "Epoch 745/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4448\n",
      "Epoch 746/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4221\n",
      "Epoch 747/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5120\n",
      "Epoch 748/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.0513\n",
      "Epoch 749/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.7523\n",
      "Epoch 750/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5759\n",
      "Epoch 751/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6035\n",
      "Epoch 752/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.6019\n",
      "Epoch 753/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4639\n",
      "Epoch 754/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4265\n",
      "Epoch 755/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4387\n",
      "Epoch 756/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5113\n",
      "Epoch 757/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4433\n",
      "Epoch 758/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5409\n",
      "Epoch 759/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4587\n",
      "Epoch 760/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4964\n",
      "Epoch 761/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4220\n",
      "Epoch 762/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4962\n",
      "Epoch 763/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4303\n",
      "Epoch 764/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4392\n",
      "Epoch 765/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4255\n",
      "Epoch 766/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5292\n",
      "Epoch 767/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4678\n",
      "Epoch 768/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4165\n",
      "Epoch 769/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.4483\n",
      "Epoch 770/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.4485\n",
      "Epoch 771/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.4421\n",
      "Epoch 772/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4342\n",
      "Epoch 773/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4789\n",
      "Epoch 774/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4197\n",
      "Epoch 775/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5220\n",
      "Epoch 776/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4467\n",
      "Epoch 777/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4253\n",
      "Epoch 778/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4603\n",
      "Epoch 779/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4538\n",
      "Epoch 780/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.8897\n",
      "Epoch 781/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.9656\n",
      "Epoch 782/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.9879\n",
      "Epoch 783/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.9830\n",
      "Epoch 784/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.9956\n",
      "Epoch 785/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.2783\n",
      "Epoch 786/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6733\n",
      "Epoch 787/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4539\n",
      "Epoch 788/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.5446\n",
      "Epoch 789/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5431\n",
      "Epoch 790/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.4287\n",
      "Epoch 791/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4784\n",
      "Epoch 792/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4264\n",
      "Epoch 793/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4524\n",
      "Epoch 794/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5525\n",
      "Epoch 795/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4918\n",
      "Epoch 796/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4753\n",
      "Epoch 797/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5255\n",
      "Epoch 798/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6077\n",
      "Epoch 799/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5334\n",
      "Epoch 800/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4636\n",
      "Epoch 801/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5380\n",
      "Epoch 802/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4796\n",
      "Epoch 803/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4302\n",
      "Epoch 804/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4629\n",
      "Epoch 805/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4738\n",
      "Epoch 806/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.4094\n",
      "Epoch 807/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.7355\n",
      "Epoch 808/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5981\n",
      "Epoch 809/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7611\n",
      "Epoch 810/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.6341\n",
      "Epoch 811/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.7855\n",
      "Epoch 812/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.9135\n",
      "Epoch 813/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6189\n",
      "Epoch 814/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4353\n",
      "Epoch 815/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4182\n",
      "Epoch 816/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4256\n",
      "Epoch 817/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4130\n",
      "Epoch 818/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4493\n",
      "Epoch 819/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4252\n",
      "Epoch 820/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4610\n",
      "Epoch 821/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4575\n",
      "Epoch 822/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5100\n",
      "Epoch 823/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6069\n",
      "Epoch 824/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5408\n",
      "Epoch 825/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4936\n",
      "Epoch 826/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4641\n",
      "Epoch 827/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5534\n",
      "Epoch 828/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4553\n",
      "Epoch 829/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4256\n",
      "Epoch 830/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4377\n",
      "Epoch 831/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.4417\n",
      "Epoch 832/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5055\n",
      "Epoch 833/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.5975\n",
      "Epoch 834/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.2546\n",
      "Epoch 835/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.0775\n",
      "Epoch 836/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.7107\n",
      "Epoch 837/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5249\n",
      "Epoch 838/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5831\n",
      "Epoch 839/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5044\n",
      "Epoch 840/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5931\n",
      "Epoch 841/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6228\n",
      "Epoch 842/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5383\n",
      "Epoch 843/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.4705\n",
      "Epoch 844/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4579\n",
      "Epoch 845/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5264\n",
      "Epoch 846/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4392\n",
      "Epoch 847/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4233\n",
      "Epoch 848/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4384\n",
      "Epoch 849/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4282\n",
      "Epoch 850/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.0144\n",
      "Epoch 851/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.9902\n",
      "Epoch 852/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.9654\n",
      "Epoch 853/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7617\n",
      "Epoch 854/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6443\n",
      "Epoch 855/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5801\n",
      "Epoch 856/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7042\n",
      "Epoch 857/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.0691\n",
      "Epoch 858/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.8533\n",
      "Epoch 859/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.0287\n",
      "Epoch 860/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5477\n",
      "Epoch 861/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.4492\n",
      "Epoch 862/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5163\n",
      "Epoch 863/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5046\n",
      "Epoch 864/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5182\n",
      "Epoch 865/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4331\n",
      "Epoch 866/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4553\n",
      "Epoch 867/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5011\n",
      "Epoch 868/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5391\n",
      "Epoch 869/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5249\n",
      "Epoch 870/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4234\n",
      "Epoch 871/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4934\n",
      "Epoch 872/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4338\n",
      "Epoch 873/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6411\n",
      "Epoch 874/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5912\n",
      "Epoch 875/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5778\n",
      "Epoch 876/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4715\n",
      "Epoch 877/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4634\n",
      "Epoch 878/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5127\n",
      "Epoch 879/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5126\n",
      "Epoch 880/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4354\n",
      "Epoch 881/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4292\n",
      "Epoch 882/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5803\n",
      "Epoch 883/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4981\n",
      "Epoch 884/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4253\n",
      "Epoch 885/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4344\n",
      "Epoch 886/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4159\n",
      "Epoch 887/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4144\n",
      "Epoch 888/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4817\n",
      "Epoch 889/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4415\n",
      "Epoch 890/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4206\n",
      "Epoch 891/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4137\n",
      "Epoch 892/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4297\n",
      "Epoch 893/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4722\n",
      "Epoch 894/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6260\n",
      "Epoch 895/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6598\n",
      "Epoch 896/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.3278\n",
      "Epoch 897/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.6776\n",
      "Epoch 898/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4605\n",
      "Epoch 899/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.4420\n",
      "Epoch 900/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.4173\n",
      "Epoch 901/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4821\n",
      "Epoch 902/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.5239\n",
      "Epoch 903/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4471\n",
      "Epoch 904/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4625\n",
      "Epoch 905/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4530\n",
      "Epoch 906/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4580\n",
      "Epoch 907/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4420\n",
      "Epoch 908/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4340\n",
      "Epoch 909/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5847\n",
      "Epoch 910/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4547\n",
      "Epoch 911/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4915\n",
      "Epoch 912/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4750\n",
      "Epoch 913/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5048\n",
      "Epoch 914/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.8065\n",
      "Epoch 915/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.7495\n",
      "Epoch 916/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5807\n",
      "Epoch 917/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6274\n",
      "Epoch 918/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4655\n",
      "Epoch 919/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4311\n",
      "Epoch 920/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4598\n",
      "Epoch 921/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5214\n",
      "Epoch 922/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6294\n",
      "Epoch 923/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.8631\n",
      "Epoch 924/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.1416\n",
      "Epoch 925/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 3.1120\n",
      "Epoch 926/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 3.0523\n",
      "Epoch 927/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.2491\n",
      "Epoch 928/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.7620\n",
      "Epoch 929/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7021\n",
      "Epoch 930/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6401\n",
      "Epoch 931/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6003\n",
      "Epoch 932/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4418\n",
      "Epoch 933/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4574\n",
      "Epoch 934/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.6339\n",
      "Epoch 935/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5607\n",
      "Epoch 936/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4346\n",
      "Epoch 937/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.4495\n",
      "Epoch 938/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4244\n",
      "Epoch 939/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4150\n",
      "Epoch 940/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4159\n",
      "Epoch 941/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4162\n",
      "Epoch 942/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4262\n",
      "Epoch 943/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4567\n",
      "Epoch 944/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6236\n",
      "Epoch 945/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5113\n",
      "Epoch 946/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5206\n",
      "Epoch 947/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4928\n",
      "Epoch 948/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4566\n",
      "Epoch 949/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5352\n",
      "Epoch 950/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4803\n",
      "Epoch 951/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4552\n",
      "Epoch 952/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.4185\n",
      "Epoch 953/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.4340\n",
      "Epoch 954/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.6597\n",
      "Epoch 955/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.8426\n",
      "Epoch 956/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.6149\n",
      "Epoch 957/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4749\n",
      "Epoch 958/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4432\n",
      "Epoch 959/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4305\n",
      "Epoch 960/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4165\n",
      "Epoch 961/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4297\n",
      "Epoch 962/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5801\n",
      "Epoch 963/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.7290\n",
      "Epoch 964/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5691\n",
      "Epoch 965/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5033\n",
      "Epoch 966/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4715\n",
      "Epoch 967/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4455\n",
      "Epoch 968/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4268\n",
      "Epoch 969/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4151\n",
      "Epoch 970/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5101\n",
      "Epoch 971/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.7339\n",
      "Epoch 972/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.6097\n",
      "Epoch 973/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5403\n",
      "Epoch 974/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.4391\n",
      "Epoch 975/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4682\n",
      "Epoch 976/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4219\n",
      "Epoch 977/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5291\n",
      "Epoch 978/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4122\n",
      "Epoch 979/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5400\n",
      "Epoch 980/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4637\n",
      "Epoch 981/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5753\n",
      "Epoch 982/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5822\n",
      "Epoch 983/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.9832\n",
      "Epoch 984/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5272\n",
      "Epoch 985/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4855\n",
      "Epoch 986/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4777\n",
      "Epoch 987/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4453\n",
      "Epoch 988/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.4084\n",
      "Epoch 989/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.4210\n",
      "Epoch 990/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.4173\n",
      "Epoch 991/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4400\n",
      "Epoch 992/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4357\n",
      "Epoch 993/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.4739\n",
      "Epoch 994/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.8426\n",
      "Epoch 995/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 2.9928\n",
      "Epoch 996/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.4059\n",
      "Epoch 997/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.6070\n",
      "Epoch 998/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.5259\n",
      "Epoch 999/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6343\n",
      "Epoch 1000/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a4c74e160>"
      ]
     },
     "execution_count": 1138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_tos = Sequential()\n",
    "NN_tos.add(Dense(units=8,input_dim=X_train.shape[1],activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_tos.add(Dense(units=4, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "#NN_tos.add(Dense(units=4, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_tos.add(Dense(units=1,activation='linear'))\n",
    "NN_tos.compile(loss='mse', optimizer='adam')\n",
    "NN_tos.fit(np.array(X_train), np.array(y_train), epochs=1000,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN_predictions</th>\n",
       "      <th>actual</th>\n",
       "      <th>GBR_predictions</th>\n",
       "      <th>LY_turnovers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>1.480142</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.223566</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>1.720437</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.965623</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>1.208963</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.586961</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>2.748666</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.348369</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>2.366769</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.195694</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>1.286111</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.220980</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>1.417581</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.478078</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1.741372</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.311394</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>2.416848</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.102031</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>1.267160</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.068748</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>1.483590</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.261524</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>1.675210</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.324835</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>1.443460</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.418100</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>1.692880</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.270938</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.350839</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.290560</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2.466714</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.838863</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>2.654214</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.283815</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>2.642984</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.341779</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>1.545144</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.250795</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>1.365396</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.230948</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>1.620218</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.614677</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0.996866</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.155104</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>2.652719</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.356750</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>1.383340</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.423072</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>1.357736</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.927095</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2.247293</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.939339</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>1.443841</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.419314</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.137338</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.061025</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2.062936</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.999804</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>1.780313</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.493289</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.338815</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.974388</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2.771539</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.383370</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>1.535104</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.241874</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>1.431314</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.200564</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>1.599405</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.339043</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>2.115548</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.836979</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>1.986032</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.883089</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>2.219918</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.063182</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2.215097</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.021340</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2.079660</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.966186</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>1.504983</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.097470</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>1.551980</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.035777</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>1.610635</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.268552</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>1.361734</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.885032</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>2.465188</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.140052</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.431543</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.381297</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>1.441079</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.772754</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>1.288431</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.657582</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>1.524972</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.114736</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1.590951</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.860204</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     NN_predictions  actual  GBR_predictions  LY_turnovers\n",
       "264        1.480142     2.2         2.223566           2.6\n",
       "450        1.720437     1.8         1.965623           2.6\n",
       "162        1.208963     2.3         2.586961           2.5\n",
       "620        2.748666     3.2         2.348369           2.5\n",
       "565        2.366769     1.4         2.195694           2.5\n",
       "619        1.286111     2.5         2.220980           2.5\n",
       "605        1.417581     2.9         2.478078           2.5\n",
       "79         1.741372     3.0         2.311394           2.5\n",
       "548        2.416848     3.0         2.102031           2.5\n",
       "386        1.267160     1.9         2.068748           2.5\n",
       "531        1.483590     2.3         2.261524           2.4\n",
       "213        1.675210     2.3         2.324835           2.4\n",
       "419        1.443460     2.8         2.418100           2.4\n",
       "528        1.692880     2.9         2.270938           2.4\n",
       "15         1.350839     3.1         2.290560           2.4\n",
       "89         2.466714     1.2         1.838863           2.4\n",
       "632        2.654214     2.8         2.283815           2.4\n",
       "427        2.642984     2.3         2.341779           2.4\n",
       "287        1.545144     2.1         2.250795           2.4\n",
       "117        1.365396     2.6         2.230948           2.4\n",
       "375        1.620218     2.3         2.614677           2.3\n",
       "382        0.996866     2.0         2.155104           2.3\n",
       "539        2.652719     2.4         2.356750           2.3\n",
       "179        1.383340     2.3         2.423072           2.3\n",
       "209        1.357736     2.6         1.927095           2.3\n",
       "198        2.247293     1.3         1.939339           2.3\n",
       "347        1.443841     3.3         2.419314           2.3\n",
       "4          2.137338     2.4         2.061025           2.3\n",
       "196        2.062936     2.2         1.999804           2.3\n",
       "551        1.780313     1.1         1.493289           2.3\n",
       "10         2.338815     1.2         1.974388           2.3\n",
       "123        2.771539     2.3         2.383370           2.3\n",
       "638        1.535104     2.0         2.241874           2.2\n",
       "296        1.431314     2.2         2.200564           2.2\n",
       "302        1.599405     3.8         2.339043           2.2\n",
       "225        2.115548     1.8         1.836979           2.2\n",
       "219        1.986032     1.5         1.883089           2.2\n",
       "642        2.219918     2.3         2.063182           2.2\n",
       "72         2.215097     2.3         2.021340           2.2\n",
       "88         2.079660     1.5         1.966186           2.2\n",
       "155        1.504983     2.2         2.097470           2.2\n",
       "462        1.551980     2.3         2.035777           2.2\n",
       "255        1.610635     2.1         2.268552           2.2\n",
       "321        1.361734     2.0         1.885032           2.2\n",
       "595        2.465188     1.5         2.140052           2.2\n",
       "40         1.431543     2.7         2.381297           2.2\n",
       "544        1.441079     1.9         1.772754           2.2\n",
       "394        1.288431     1.0         1.657582           2.2\n",
       "322        1.524972     2.2         2.114736           2.1\n",
       "145        1.590951     2.0         1.860204           2.1"
      ]
     },
     "execution_count": 1139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = NN_tos.predict(X_test)\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.5)\n",
    "gbr.fit(X_train,y_train)\n",
    "gbr_predictions = gbr.predict(X_test)\n",
    "LR = LinearRegression(fit_intercept=True).fit(X_train,y_train)\n",
    "\n",
    "testing = pd.DataFrame(predictions)\n",
    "testing.columns=['NN_predictions']\n",
    "testing['actual'] = y_test.reset_index()['turnovers']\n",
    "testing['GBR_predictions']=gbr_predictions\n",
    "testing['LY_turnovers']=X_test['turnovers_ly'].reset_index()['turnovers_ly']\n",
    "testing.sort_values(by='LY_turnovers',ascending=False)[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1140,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2017tos = tos[tos['season']==2017].drop(['team','player','turnovers','Games'],axis=1)\n",
    "#pred_2017blocks = blocks[blocks['season']==2017][['blocks_ly','career_blocks','starter_change']]\n",
    "tos_2017 = NN_tos.predict(pred_2017tos)\n",
    "gbr_tos_2017 = pd.DataFrame(gbr.predict(pred_2017tos))\n",
    "LR_tos_2017 = pd.DataFrame(LR.predict(pred_2017tos))\n",
    "test_2 =pd.DataFrame(tos_2017)\n",
    "test_3 = pd.merge(tos,pred_2017tos,left_index=True,right_index=True).reset_index()\n",
    "test_3['predictions']=test_2[0]\n",
    "test_3['gbr_pred'] = gbr_tos_2017[0]\n",
    "test_3['LR_pred'] = LR_tos_2017[0]\n",
    "test_3['mean_pred'] = (test_3['predictions']+test_3['gbr_pred']+test_3['LR_pred'])/3\n",
    "test_3 = test_3[test_3['Games']>30]\n",
    "test_3[['player','turnovers','predictions','LR_pred','gbr_pred','mean_pred','turnovers_ly_x']].sort_values(by='turnovers_ly_x',ascending=False)[0:50]\n",
    "\n",
    "to_2017 = test_3[['player','LR_pred']]\n",
    "to_2017.columns = ['player','turnover_prediction']\n",
    "df_2017 = pd.merge(df_2017,to_2017,how='left',left_on='player',right_on='player')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE using LR:0.15807940879934615\n",
      "MSE using GB:0.14868131059397866\n",
      "MSE using NN:2.00328677909116\n",
      "MSE using combo:0.37595236256225756\n",
      "MSE using mean:0.6552399737015094\n",
      "MSE using last year stats:0.210833333333333\n"
     ]
    }
   ],
   "source": [
    "print('MSE using LR:{}'.format(np.mean((test_3['turnovers']-test_3['LR_pred'])**2)))\n",
    "print('MSE using GB:{}'.format(np.mean((test_3['turnovers']-test_3['gbr_pred'])**2)))\n",
    "print('MSE using NN:{}'.format(np.mean((test_3['turnovers']-test_3['predictions'])**2)))\n",
    "print('MSE using combo:{}'.format(np.mean((test_3['turnovers']-test_3['mean_pred'])**2)))\n",
    "print('MSE using mean:{}'.format(np.mean((test_3['turnovers']-np.mean(test_3['turnovers']))**2)))\n",
    "print('MSE using last year stats:{}'.format(np.mean((test_3['turnovers']-test_3['turnovers_ly_x'])**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1143,
   "metadata": {},
   "outputs": [],
   "source": [
    " query= '''\n",
    "        \n",
    "        DROP TABLE IF EXISTS percentages;\n",
    "        CREATE TABLE percentages(\n",
    "        season int, --these come from player_stats\n",
    "        player varchar(50),\n",
    "        Age int,\n",
    "        team varchar(50),\n",
    "        FGM float, -- these come from player_stats\n",
    "        FGA float,\n",
    "        FG_percent float,\n",
    "        FG_percent_ly float,\n",
    "        FGM_ly float,\n",
    "        FGA_ly float,\n",
    "        FTM float,\n",
    "        FTA float,\n",
    "        FT_percent float,\n",
    "        FT_percent_ly float,\n",
    "        FTM_ly float,\n",
    "        FTA_ly float,\n",
    "        threes_ly float,\n",
    "        change_threes float,\n",
    "        points_ly float,\n",
    "        change_points_ly float,\n",
    "        starter_change int,\n",
    "        C_PF int,\n",
    "        PG int,\n",
    "        SG_SF int,\n",
    "        Games int,\n",
    "        \n",
    "         -- these come from team_changes\n",
    "        high_usageplayer_added int,\n",
    "        usagemin_opened float,\n",
    "        maxusage_added float,\n",
    "        high_usageplayer_dropped int,\n",
    "        points_opened float,\n",
    "        max_pointsdropped float,\n",
    "        max_pointsadded float,\n",
    "        \n",
    "        three_ar_ly float, -- from player_advstats\n",
    "        change_3ar float,\n",
    "        per_ly float,\n",
    "        change_per float,\n",
    "        usagerank float,\n",
    "        usagerank_ly float,\n",
    "        offensive_winshares float,\n",
    "        offensive_boxplusminus float,\n",
    "        boxplusminus float,\n",
    "        value_overreplacement float,\n",
    "        \n",
    "        max_teammatepts float,\n",
    "        max_teammate_usage float,\n",
    "        max_teammateto float,\n",
    "        max_teammateshot_attempts float,\n",
    "        \n",
    "        \n",
    "        career_FGM float,\n",
    "        career_FGA float,\n",
    "        career_FGPercent float,\n",
    "        career_FTM float,\n",
    "        career_FTA float,\n",
    "        career_FTPercent float,\n",
    "        yearspro int\n",
    "        );\n",
    "        \n",
    "        INSERT INTO percentages(season,player,age,team,FGM,FGA,FG_percent,FG_percent_ly,FGM_ly,FGA_ly,FTM,FTA,FT_percent\n",
    "        ,FT_percent_ly,FTM_ly,FTA_ly,threes_ly,change_threes,points_ly,change_points_ly,starter_change,C_PF,PG,SG_SF,Games)\n",
    "        SELECT season,player,age,startingteam,FG,FGA,case when FGA>0 then FG/FGA else 0 end as FG_percent,\n",
    "        case when fga_ly>0 then fg_ly/fga_ly else 0 end as FG_percent_ly,FG_ly,fga_ly,FTM,FTA,\n",
    "        case when FTA>0 then FTM/FTA else 0 end, case when fta_ly>0 then FTM_ly/FTA_ly else 0 end, FTM_ly,FTA_ly,\n",
    "        threes_ly,change_threes,points_ly,change_points_ly,starter-starter_ly,case when pos in ('C','PF') then 1 else 0 end,\n",
    "        case when pos='PG' then 1 else 0 end,case when pos in('SG','SF') then 1 else 0 end,Games\n",
    "        from player_stats;\n",
    "        \n",
    "        update percentages tp\n",
    "        set high_usageplayer_added = tc.high_usageplayer_added,usagemin_opened=tc.usagemin_opened,\n",
    "        maxusage_added=tc.max_usageadded,high_usageplayer_dropped=tc.high_usageplayer_dropped,points_opened=tc.points_opened,\n",
    "        max_pointsdropped=tc.max_pointsdropped,max_pointsadded=tc.max_pointsadded\n",
    "        from team_changes tc\n",
    "        where tc.team = tp.team and tp.season=tc.season;\n",
    "        \n",
    "        update percentages tp\n",
    "        set three_ar_ly = pa.threear_ly,change_3ar=pa.change_3ar,per_ly=pa.per_ly,change_per=pa.change_per,\n",
    "        usagerank=pa.usagerank,usagerank_ly=pa.usagerank_ly,offensive_winshares=pa.offensive_winshares,\n",
    "        offensive_boxplusminus=pa.offensive_boxplusminus,boxplusminus=pa.boxplusminus,value_overreplacement=pa.value_overreplacement\n",
    "        from player_advstats pa\n",
    "        where tp.player = pa.player and tp.season = pa.season and tp.team = pa.startingteam;\n",
    "        \n",
    "        update percentages tp\n",
    "        set max_teammatepts = tm.max_teammatepts,max_teammate_usage=tm.max_teammate_usage,max_teammateto=tm.max_teammateto,\n",
    "        max_teammateshot_attempts=tm.max_teammateshot_attempts\n",
    "        from teammate_maxes tm\n",
    "        where tm.season = tp.season and tm.player = tp.player;\n",
    "        \n",
    "        update percentages tp\n",
    "        set career_fgm = pc.career_fgm,career_fga = pc.career_fga,career_FGpercent = case when pc.career_FGA>0 then pc.career_FGM/pc.career_FGA else 0 end,\n",
    "        career_FTM = pc.career_FTM,career_FTA = pc.career_FTA,career_FTPercent = case when pc.career_FTA>0 then pc.career_FTM/pc.career_FTA else 0 end,yearspro = pc.yearspro\n",
    "        from player_careerstats pc\n",
    "        where tp.player = pc.player and tp.season = pc.season;\n",
    "        \n",
    "        \n",
    "        select * from percentages where season>2009\n",
    "        '''\n",
    "\n",
    "cur.execute(query)\n",
    "data = cur.fetchall()\n",
    "percentages_df = pd.DataFrame(np.array(data))\n",
    "percentages_df.columns = ['season','player','age','team','FGM','FGA','FG_percent','FG_percent_ly','FGM_ly','FGA_ly','FTM','FTA',\n",
    "                     'FT_percent','FT_percent_ly','FTM_ly','FTA_ly','3PM_ly','3PM_change','points_ly','change_points_ly','starter_change'\n",
    "                     ,'C_PF','PG','SG_SF','Games','high_usageplayer_added','usagemin_opened','maxusage_added','high_usageplayer_dropped'\n",
    "                     ,'points_opened','max_pointsdropped','max_pointsadded','three_ar_ly','change_3ar','per_ly','change_per','usagerank','usagerank_ly'\n",
    "                     ,'offensive_winshares','offensive_boxplusminus','boxplusminus','value_overreplacement'\n",
    "                    ,'max_teammatepts','max_teammate_usage','max_teammateto','max_teammateshot_attempts'\n",
    "                    ,'career_FGM','career_FGA','career_FGpercent','career_FTM','career_FTA','career_FTPercent','yearspro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "percentages_df['age_squared']=percentages_df['age']*percentages_df['age']\n",
    "percentages = percentages_df[percentages_df['FGM_ly'].notna()]\n",
    "for i in percentages.columns:\n",
    "    if i not in(['player','team']):\n",
    "        percentages[i]=pd.to_numeric(percentages[i])\n",
    "percentages = percentages.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1145,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = percentages[(percentages['season']!=2017) & (percentages['Games']>30)].drop(['player','team','FGM','FGA','FG_percent','FTM','FTA','Games'],axis=1)\n",
    "y = percentages[(percentages['season']!=2017) & (percentages['Games']>30)]['FGM']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1564/1564 [==============================] - 4s 3ms/step - loss: 64814.1612\n",
      "Epoch 2/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 5777.8563\n",
      "Epoch 3/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1801.2294\n",
      "Epoch 4/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 839.9773\n",
      "Epoch 5/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 319.6998\n",
      "Epoch 6/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 193.0979\n",
      "Epoch 7/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 144.3669\n",
      "Epoch 8/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 118.0004\n",
      "Epoch 9/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 99.0409\n",
      "Epoch 10/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 83.2343\n",
      "Epoch 11/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 70.2887\n",
      "Epoch 12/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 59.7566\n",
      "Epoch 13/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 51.1567\n",
      "Epoch 14/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 44.0001\n",
      "Epoch 15/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 37.9833\n",
      "Epoch 16/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 33.0397\n",
      "Epoch 17/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 29.3352\n",
      "Epoch 18/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 26.2733\n",
      "Epoch 19/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 23.7743\n",
      "Epoch 20/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 21.8338\n",
      "Epoch 21/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 20.1432\n",
      "Epoch 22/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 18.8912\n",
      "Epoch 23/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 18.0178\n",
      "Epoch 24/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 17.3543\n",
      "Epoch 25/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 16.6384\n",
      "Epoch 26/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 16.2010\n",
      "Epoch 27/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 15.7060\n",
      "Epoch 28/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 15.3549\n",
      "Epoch 29/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 14.9509\n",
      "Epoch 30/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 14.5533\n",
      "Epoch 31/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 14.3302\n",
      "Epoch 32/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 14.0825\n",
      "Epoch 33/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 13.6364\n",
      "Epoch 34/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 13.4238\n",
      "Epoch 35/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 13.1932\n",
      "Epoch 36/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 13.0769\n",
      "Epoch 37/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 12.8275\n",
      "Epoch 38/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 12.6623\n",
      "Epoch 39/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 12.5966\n",
      "Epoch 40/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 12.4244\n",
      "Epoch 41/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 12.1054\n",
      "Epoch 42/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 12.0401\n",
      "Epoch 43/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 11.8335\n",
      "Epoch 44/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 11.7635\n",
      "Epoch 45/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 11.7210\n",
      "Epoch 46/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 11.4069\n",
      "Epoch 47/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 11.2468\n",
      "Epoch 48/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 11.1106\n",
      "Epoch 49/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 10.9749\n",
      "Epoch 50/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 10.9125\n",
      "Epoch 51/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 10.7498\n",
      "Epoch 52/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 10.6473\n",
      "Epoch 53/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 10.4594\n",
      "Epoch 54/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 10.2882\n",
      "Epoch 55/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 10.2097\n",
      "Epoch 56/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 10.0168\n",
      "Epoch 57/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 9.8103\n",
      "Epoch 58/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 9.5577\n",
      "Epoch 59/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 9.3568\n",
      "Epoch 60/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 9.2280\n",
      "Epoch 61/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 9.1762\n",
      "Epoch 62/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 8.9491\n",
      "Epoch 63/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 8.8117\n",
      "Epoch 64/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 8.9907\n",
      "Epoch 65/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 8.9165\n",
      "Epoch 66/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 8.7200\n",
      "Epoch 67/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 8.7003\n",
      "Epoch 68/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 8.3623\n",
      "Epoch 69/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 8.4504\n",
      "Epoch 70/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 8.1700\n",
      "Epoch 71/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 8.0856\n",
      "Epoch 72/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.9108\n",
      "Epoch 73/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 7.8104\n",
      "Epoch 74/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 7.9707\n",
      "Epoch 75/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 7.9407\n",
      "Epoch 76/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 7.8349\n",
      "Epoch 77/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 7.7492\n",
      "Epoch 78/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 7.4049\n",
      "Epoch 79/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 7.3927\n",
      "Epoch 80/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 7.4896\n",
      "Epoch 81/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.2955\n",
      "Epoch 82/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 7.1794\n",
      "Epoch 83/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 7.0285\n",
      "Epoch 84/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 6.9274\n",
      "Epoch 85/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.8845\n",
      "Epoch 86/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 6.8926\n",
      "Epoch 87/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.8250\n",
      "Epoch 88/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 6.8808\n",
      "Epoch 89/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 6.4102\n",
      "Epoch 90/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 6.3094\n",
      "Epoch 91/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 6.1801\n",
      "Epoch 92/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 6.0878\n",
      "Epoch 93/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 6.0275\n",
      "Epoch 94/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 5.9532\n",
      "Epoch 95/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 5.9416\n",
      "Epoch 96/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 5.7452\n",
      "Epoch 97/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 5.8591\n",
      "Epoch 98/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 5.7214\n",
      "Epoch 99/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 5.6072\n",
      "Epoch 100/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 5.5928\n",
      "Epoch 101/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 5.6596\n",
      "Epoch 102/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 5.4565\n",
      "Epoch 103/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 5.3594\n",
      "Epoch 104/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 5.3907\n",
      "Epoch 105/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 5.2661\n",
      "Epoch 106/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 5.2298\n",
      "Epoch 107/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 5.2140\n",
      "Epoch 108/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 5.1687\n",
      "Epoch 109/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 5.1380\n",
      "Epoch 110/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 5.1328\n",
      "Epoch 111/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 5.0997\n",
      "Epoch 112/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 5.2313\n",
      "Epoch 113/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 5.4313\n",
      "Epoch 114/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 5.1925\n",
      "Epoch 115/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 5.0049\n",
      "Epoch 116/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 4.8958\n",
      "Epoch 117/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 4.8312\n",
      "Epoch 118/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 4.9756\n",
      "Epoch 119/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 4.9333\n",
      "Epoch 120/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 4.7168\n",
      "Epoch 121/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 4.9129\n",
      "Epoch 122/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 4.8163\n",
      "Epoch 123/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 4.7852\n",
      "Epoch 124/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 4.6838\n",
      "Epoch 125/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 4.6294\n",
      "Epoch 126/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 4.5416\n",
      "Epoch 127/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 4.4675\n",
      "Epoch 128/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 4.4691\n",
      "Epoch 129/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 4.4169\n",
      "Epoch 130/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 4.4836\n",
      "Epoch 131/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 4.4528\n",
      "Epoch 132/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 4.5266\n",
      "Epoch 133/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 4.3492\n",
      "Epoch 134/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 4.3352\n",
      "Epoch 135/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 4.3096\n",
      "Epoch 136/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 4.2871\n",
      "Epoch 137/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 4.2136\n",
      "Epoch 138/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 4.2157\n",
      "Epoch 139/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 4.2396\n",
      "Epoch 140/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 4.1410\n",
      "Epoch 141/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 4.0691\n",
      "Epoch 142/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 4.0867\n",
      "Epoch 143/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 4.0308\n",
      "Epoch 144/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 4.0686\n",
      "Epoch 145/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 3.9778\n",
      "Epoch 146/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 3.9837\n",
      "Epoch 147/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 3.9607\n",
      "Epoch 148/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 4.1111\n",
      "Epoch 149/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 4.1207\n",
      "Epoch 150/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 4.0705\n",
      "Epoch 151/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 3.7914\n",
      "Epoch 152/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 3.7971\n",
      "Epoch 153/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 3.7716\n",
      "Epoch 154/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 3.7599\n",
      "Epoch 155/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 3.8112\n",
      "Epoch 156/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 3.5981\n",
      "Epoch 157/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 3.5739\n",
      "Epoch 158/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 3.5169\n",
      "Epoch 159/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 3.4726\n",
      "Epoch 160/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 3.5066\n",
      "Epoch 161/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 3.5087\n",
      "Epoch 162/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 3.5692\n",
      "Epoch 163/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 3.5420\n",
      "Epoch 164/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 3.4004\n",
      "Epoch 165/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 3.3775\n",
      "Epoch 166/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 3.3818\n",
      "Epoch 167/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 3.5306\n",
      "Epoch 168/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.3976\n",
      "Epoch 169/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 3.3085\n",
      "Epoch 170/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 3.2654\n",
      "Epoch 171/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 3.3266\n",
      "Epoch 172/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.2059\n",
      "Epoch 173/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.2126\n",
      "Epoch 174/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 3.3200\n",
      "Epoch 175/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 3.3035\n",
      "Epoch 176/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 3.2205\n",
      "Epoch 177/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.2749\n",
      "Epoch 178/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 3.1652\n",
      "Epoch 179/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.1801\n",
      "Epoch 180/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.1072\n",
      "Epoch 181/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.0465\n",
      "Epoch 182/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 3.0769\n",
      "Epoch 183/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 3.3054\n",
      "Epoch 184/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 3.1151\n",
      "Epoch 185/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 3.1409\n",
      "Epoch 186/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 3.0441\n",
      "Epoch 187/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 3.0074\n",
      "Epoch 188/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 3.2129\n",
      "Epoch 189/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 3.1441\n",
      "Epoch 190/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.1405\n",
      "Epoch 191/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 3.0128\n",
      "Epoch 192/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 2.9564\n",
      "Epoch 193/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 2.8779\n",
      "Epoch 194/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 2.9689\n",
      "Epoch 195/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 2.8749\n",
      "Epoch 196/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 2.8113\n",
      "Epoch 197/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.8443\n",
      "Epoch 198/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 3.0052\n",
      "Epoch 199/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.8756\n",
      "Epoch 200/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 3.0397\n",
      "Epoch 201/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 2.9040\n",
      "Epoch 202/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.8660\n",
      "Epoch 203/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.7979\n",
      "Epoch 204/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.7471\n",
      "Epoch 205/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.8458\n",
      "Epoch 206/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.8521\n",
      "Epoch 207/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 3.1400\n",
      "Epoch 208/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 2.8901\n",
      "Epoch 209/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 2.8089\n",
      "Epoch 210/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 2.8260\n",
      "Epoch 211/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 2.8017\n",
      "Epoch 212/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 2.7268\n",
      "Epoch 213/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.6921\n",
      "Epoch 214/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.7328\n",
      "Epoch 215/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 2.7421\n",
      "Epoch 216/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 2.6782\n",
      "Epoch 217/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 2.6053\n",
      "Epoch 218/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 2.6207\n",
      "Epoch 219/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 2.6545\n",
      "Epoch 220/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.6575\n",
      "Epoch 221/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.7407\n",
      "Epoch 222/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.6534\n",
      "Epoch 223/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.6522\n",
      "Epoch 224/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 2.6583\n",
      "Epoch 225/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 2.5881\n",
      "Epoch 226/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 2.7203\n",
      "Epoch 227/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 2.6677\n",
      "Epoch 228/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 2.8726\n",
      "Epoch 229/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.6721\n",
      "Epoch 230/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 2.5571\n",
      "Epoch 231/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 2.6210\n",
      "Epoch 232/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 2.6306\n",
      "Epoch 233/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 2.5106\n",
      "Epoch 234/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 2.4656\n",
      "Epoch 235/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 2.4275\n",
      "Epoch 236/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 2.5545\n",
      "Epoch 237/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.4457\n",
      "Epoch 238/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.4786\n",
      "Epoch 239/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.4192\n",
      "Epoch 240/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 2.5110\n",
      "Epoch 241/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 2.4654\n",
      "Epoch 242/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 2.3315\n",
      "Epoch 243/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 2.3682\n",
      "Epoch 244/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 2.3363\n",
      "Epoch 245/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 2.4324\n",
      "Epoch 246/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 2.3789\n",
      "Epoch 247/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 2.3695\n",
      "Epoch 248/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 2.4626\n",
      "Epoch 249/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.2983\n",
      "Epoch 250/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 2.2889\n",
      "Epoch 251/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 2.3358\n",
      "Epoch 252/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 2.3097\n",
      "Epoch 253/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 2.2988\n",
      "Epoch 254/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 2.3396\n",
      "Epoch 255/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 2.3526\n",
      "Epoch 256/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 2.2441\n",
      "Epoch 257/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 2.3029\n",
      "Epoch 258/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.4128\n",
      "Epoch 259/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 2.2562\n",
      "Epoch 260/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 2.3470\n",
      "Epoch 261/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.2087\n",
      "Epoch 262/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.2154\n",
      "Epoch 263/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 2.2434\n",
      "Epoch 264/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.2781\n",
      "Epoch 265/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.2620\n",
      "Epoch 266/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.2399\n",
      "Epoch 267/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.1564\n",
      "Epoch 268/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 2.1246\n",
      "Epoch 269/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 2.1363\n",
      "Epoch 270/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.1351\n",
      "Epoch 271/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 2.1670\n",
      "Epoch 272/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 2.2308\n",
      "Epoch 273/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.1828\n",
      "Epoch 274/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 2.1181\n",
      "Epoch 275/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 2.1289\n",
      "Epoch 276/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 2.1248\n",
      "Epoch 277/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 2.2326\n",
      "Epoch 278/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.5746\n",
      "Epoch 279/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 2.1333\n",
      "Epoch 280/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 2.0807\n",
      "Epoch 281/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.1939\n",
      "Epoch 282/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.1881\n",
      "Epoch 283/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.0106\n",
      "Epoch 284/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.0181\n",
      "Epoch 285/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 2.0540\n",
      "Epoch 286/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 2.0528\n",
      "Epoch 287/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.0454\n",
      "Epoch 288/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 2.2261\n",
      "Epoch 289/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 2.1017\n",
      "Epoch 290/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 2.0267\n",
      "Epoch 291/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 2.0939\n",
      "Epoch 292/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 2.0341\n",
      "Epoch 293/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 2.0896\n",
      "Epoch 294/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 2.0684\n",
      "Epoch 295/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 2.0461\n",
      "Epoch 296/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.0008\n",
      "Epoch 297/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.9975\n",
      "Epoch 298/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.0378\n",
      "Epoch 299/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.9752\n",
      "Epoch 300/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.9982\n",
      "Epoch 301/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.9759\n",
      "Epoch 302/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.9708\n",
      "Epoch 303/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.9382\n",
      "Epoch 304/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.9378\n",
      "Epoch 305/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.9987\n",
      "Epoch 306/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.9079\n",
      "Epoch 307/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.9552\n",
      "Epoch 308/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.9807\n",
      "Epoch 309/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.9544\n",
      "Epoch 310/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.8788\n",
      "Epoch 311/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 1.9012\n",
      "Epoch 312/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.8973\n",
      "Epoch 313/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.9076\n",
      "Epoch 314/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.8660\n",
      "Epoch 315/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.8843\n",
      "Epoch 316/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.9127\n",
      "Epoch 317/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.9189\n",
      "Epoch 318/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.9751\n",
      "Epoch 319/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.8510\n",
      "Epoch 320/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 1.9732\n",
      "Epoch 321/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.9128\n",
      "Epoch 322/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.8985\n",
      "Epoch 323/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.8091\n",
      "Epoch 324/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.9104\n",
      "Epoch 325/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 2.0209\n",
      "Epoch 326/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 2.2666\n",
      "Epoch 327/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 2.0806\n",
      "Epoch 328/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 1.8815\n",
      "Epoch 329/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.7957\n",
      "Epoch 330/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.8096\n",
      "Epoch 331/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.7841\n",
      "Epoch 332/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.8139\n",
      "Epoch 333/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.7560\n",
      "Epoch 334/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.7496\n",
      "Epoch 335/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.7990\n",
      "Epoch 336/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.7304\n",
      "Epoch 337/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 1.7767\n",
      "Epoch 338/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.7678\n",
      "Epoch 339/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.7723\n",
      "Epoch 340/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.7571\n",
      "Epoch 341/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.7659\n",
      "Epoch 342/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.7576\n",
      "Epoch 343/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.7716\n",
      "Epoch 344/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.7864\n",
      "Epoch 345/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.6917\n",
      "Epoch 346/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 1.6966\n",
      "Epoch 347/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.7464\n",
      "Epoch 348/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.7661\n",
      "Epoch 349/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.7719\n",
      "Epoch 350/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.7601\n",
      "Epoch 351/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.6981\n",
      "Epoch 352/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.6649\n",
      "Epoch 353/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 1.6701\n",
      "Epoch 354/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.6718\n",
      "Epoch 355/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.7078\n",
      "Epoch 356/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.7284\n",
      "Epoch 357/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.7768\n",
      "Epoch 358/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.6834\n",
      "Epoch 359/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.9791\n",
      "Epoch 360/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.8223\n",
      "Epoch 361/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.6873\n",
      "Epoch 362/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.7079\n",
      "Epoch 363/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.6795\n",
      "Epoch 364/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.6879\n",
      "Epoch 365/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.7421\n",
      "Epoch 366/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.6791\n",
      "Epoch 367/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.7410\n",
      "Epoch 368/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.7756\n",
      "Epoch 369/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 1.9174\n",
      "Epoch 370/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.6417\n",
      "Epoch 371/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 1.6022\n",
      "Epoch 372/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.6518\n",
      "Epoch 373/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.7686\n",
      "Epoch 374/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.6832\n",
      "Epoch 375/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.7303\n",
      "Epoch 376/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.9715\n",
      "Epoch 377/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.8106\n",
      "Epoch 378/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.7407\n",
      "Epoch 379/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.6370\n",
      "Epoch 380/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.6738\n",
      "Epoch 381/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.6112\n",
      "Epoch 382/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.6310\n",
      "Epoch 383/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.5990\n",
      "Epoch 384/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.6273\n",
      "Epoch 385/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.6757\n",
      "Epoch 386/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.6785\n",
      "Epoch 387/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.6020\n",
      "Epoch 388/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.6098\n",
      "Epoch 389/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.6271\n",
      "Epoch 390/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.5917\n",
      "Epoch 391/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.6110\n",
      "Epoch 392/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.5750\n",
      "Epoch 393/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.5540\n",
      "Epoch 394/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.5843\n",
      "Epoch 395/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.6349\n",
      "Epoch 396/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.6383\n",
      "Epoch 397/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.5637\n",
      "Epoch 398/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.5514\n",
      "Epoch 399/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.5683\n",
      "Epoch 400/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.5364\n",
      "Epoch 401/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.5844\n",
      "Epoch 402/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.5814\n",
      "Epoch 403/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.6060\n",
      "Epoch 404/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.6243\n",
      "Epoch 405/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.8836\n",
      "Epoch 406/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.6690\n",
      "Epoch 407/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.5724\n",
      "Epoch 408/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.5186\n",
      "Epoch 409/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.4896\n",
      "Epoch 410/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.4928\n",
      "Epoch 411/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.5509\n",
      "Epoch 412/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.6267\n",
      "Epoch 413/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.6380\n",
      "Epoch 414/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.5767\n",
      "Epoch 415/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.5143\n",
      "Epoch 416/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.5334\n",
      "Epoch 417/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.5054\n",
      "Epoch 418/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 1.4903\n",
      "Epoch 419/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.5272\n",
      "Epoch 420/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.4945\n",
      "Epoch 421/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.4589\n",
      "Epoch 422/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.5278\n",
      "Epoch 423/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.7533\n",
      "Epoch 424/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.5683\n",
      "Epoch 425/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.5136\n",
      "Epoch 426/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.5323\n",
      "Epoch 427/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.5228\n",
      "Epoch 428/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.4533\n",
      "Epoch 429/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.5141\n",
      "Epoch 430/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.4886\n",
      "Epoch 431/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.5086\n",
      "Epoch 432/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.5717\n",
      "Epoch 433/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.6054\n",
      "Epoch 434/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 1.6114\n",
      "Epoch 435/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.4393\n",
      "Epoch 436/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.4627\n",
      "Epoch 437/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.4690\n",
      "Epoch 438/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.4486\n",
      "Epoch 439/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.6197\n",
      "Epoch 440/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 1.5011\n",
      "Epoch 441/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.5274\n",
      "Epoch 442/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.5853\n",
      "Epoch 443/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.4647\n",
      "Epoch 444/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.5251\n",
      "Epoch 445/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.4808\n",
      "Epoch 446/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.4486\n",
      "Epoch 447/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.4837\n",
      "Epoch 448/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.5466\n",
      "Epoch 449/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.5973\n",
      "Epoch 450/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 1.4211\n",
      "Epoch 451/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.5327\n",
      "Epoch 452/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.4142\n",
      "Epoch 453/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.4279\n",
      "Epoch 454/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.4219\n",
      "Epoch 455/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.4755\n",
      "Epoch 456/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.4951\n",
      "Epoch 457/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.4903\n",
      "Epoch 458/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.4978\n",
      "Epoch 459/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.5503\n",
      "Epoch 460/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.3987\n",
      "Epoch 461/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.3953\n",
      "Epoch 462/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.4060\n",
      "Epoch 463/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.3823\n",
      "Epoch 464/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.4275\n",
      "Epoch 465/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.4013\n",
      "Epoch 466/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 1.3664\n",
      "Epoch 467/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.4277\n",
      "Epoch 468/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.4329\n",
      "Epoch 469/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.4015\n",
      "Epoch 470/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.4516\n",
      "Epoch 471/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.4792\n",
      "Epoch 472/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.4540\n",
      "Epoch 473/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.3725\n",
      "Epoch 474/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 1.5102\n",
      "Epoch 475/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.4051\n",
      "Epoch 476/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.3843\n",
      "Epoch 477/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.5065\n",
      "Epoch 478/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.3740\n",
      "Epoch 479/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.5670\n",
      "Epoch 480/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.4244\n",
      "Epoch 481/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.5117\n",
      "Epoch 482/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.4230\n",
      "Epoch 483/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 1.4485\n",
      "Epoch 484/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.5113\n",
      "Epoch 485/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.6928\n",
      "Epoch 486/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.3857\n",
      "Epoch 487/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.3150\n",
      "Epoch 488/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.3276\n",
      "Epoch 489/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.5005\n",
      "Epoch 490/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.5043\n",
      "Epoch 491/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.5238\n",
      "Epoch 492/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.4478\n",
      "Epoch 493/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.5388\n",
      "Epoch 494/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.4708\n",
      "Epoch 495/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.4405\n",
      "Epoch 496/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.4463\n",
      "Epoch 497/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.3162\n",
      "Epoch 498/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.3977\n",
      "Epoch 499/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 1.4603\n",
      "Epoch 500/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.3779\n",
      "Epoch 501/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.4802\n",
      "Epoch 502/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.3698\n",
      "Epoch 503/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.4682\n",
      "Epoch 504/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.5095\n",
      "Epoch 505/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.4460\n",
      "Epoch 506/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.4345\n",
      "Epoch 507/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.3294\n",
      "Epoch 508/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.3599\n",
      "Epoch 509/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.3273\n",
      "Epoch 510/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.3557\n",
      "Epoch 511/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.4874\n",
      "Epoch 512/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.3343\n",
      "Epoch 513/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.2807\n",
      "Epoch 514/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 1.3238\n",
      "Epoch 515/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.5626\n",
      "Epoch 516/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.3385\n",
      "Epoch 517/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 1.4621\n",
      "Epoch 518/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.3577\n",
      "Epoch 519/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.4032\n",
      "Epoch 520/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.3172\n",
      "Epoch 521/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.4568\n",
      "Epoch 522/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.3544\n",
      "Epoch 523/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.2599\n",
      "Epoch 524/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.3460\n",
      "Epoch 525/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.3456\n",
      "Epoch 526/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.3093\n",
      "Epoch 527/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.4014\n",
      "Epoch 528/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.3194\n",
      "Epoch 529/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.3401\n",
      "Epoch 530/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.3832\n",
      "Epoch 531/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.6429\n",
      "Epoch 532/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 2.0213\n",
      "Epoch 533/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.8752\n",
      "Epoch 534/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.4718\n",
      "Epoch 535/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.3499\n",
      "Epoch 536/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2940\n",
      "Epoch 537/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.3409\n",
      "Epoch 538/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.2676\n",
      "Epoch 539/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.2604\n",
      "Epoch 540/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.2808\n",
      "Epoch 541/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.3752\n",
      "Epoch 542/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.4936\n",
      "Epoch 543/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 1.3150\n",
      "Epoch 544/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.2600\n",
      "Epoch 545/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.2728\n",
      "Epoch 546/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.2930\n",
      "Epoch 547/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.3592\n",
      "Epoch 548/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 1.3812\n",
      "Epoch 549/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.2971\n",
      "Epoch 550/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.3615\n",
      "Epoch 551/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.4084\n",
      "Epoch 552/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.2342\n",
      "Epoch 553/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.2332\n",
      "Epoch 554/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.2820\n",
      "Epoch 555/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.2693\n",
      "Epoch 556/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2849\n",
      "Epoch 557/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.3139\n",
      "Epoch 558/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2983\n",
      "Epoch 559/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.3390\n",
      "Epoch 560/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.3145\n",
      "Epoch 561/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 1.3329\n",
      "Epoch 562/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.3094\n",
      "Epoch 563/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 1.2330\n",
      "Epoch 564/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.2384\n",
      "Epoch 565/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.2733\n",
      "Epoch 566/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.2645\n",
      "Epoch 567/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.2288\n",
      "Epoch 568/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.3611\n",
      "Epoch 569/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 1.4132\n",
      "Epoch 570/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.3939\n",
      "Epoch 571/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.3745\n",
      "Epoch 572/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.3872\n",
      "Epoch 573/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.3607\n",
      "Epoch 574/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2310\n",
      "Epoch 575/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.2052\n",
      "Epoch 576/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.2151\n",
      "Epoch 577/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 1.2452\n",
      "Epoch 578/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.2660\n",
      "Epoch 579/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 1.3777\n",
      "Epoch 580/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 1.2761\n",
      "Epoch 581/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2350\n",
      "Epoch 582/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.2517\n",
      "Epoch 583/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.2149\n",
      "Epoch 584/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2115\n",
      "Epoch 585/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.3981\n",
      "Epoch 586/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.2892\n",
      "Epoch 587/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.2064\n",
      "Epoch 588/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.2737\n",
      "Epoch 589/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.2888\n",
      "Epoch 590/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.2194\n",
      "Epoch 591/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.2643\n",
      "Epoch 592/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.3128\n",
      "Epoch 593/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.8696\n",
      "Epoch 594/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.2999\n",
      "Epoch 595/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 1.2553\n",
      "Epoch 596/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.3258\n",
      "Epoch 597/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.7116\n",
      "Epoch 598/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.9045\n",
      "Epoch 599/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.3372\n",
      "Epoch 600/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.3514\n",
      "Epoch 601/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.3692\n",
      "Epoch 602/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 1.4532\n",
      "Epoch 603/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 1.3921\n",
      "Epoch 604/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2582\n",
      "Epoch 605/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.4268\n",
      "Epoch 606/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.3450\n",
      "Epoch 607/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.2572\n",
      "Epoch 608/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.1930\n",
      "Epoch 609/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.2874\n",
      "Epoch 610/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.2533\n",
      "Epoch 611/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.3254\n",
      "Epoch 612/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 1.3223\n",
      "Epoch 613/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 1.1732\n",
      "Epoch 614/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.2291\n",
      "Epoch 615/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.3027\n",
      "Epoch 616/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.3022\n",
      "Epoch 617/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.1419\n",
      "Epoch 618/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.1931\n",
      "Epoch 619/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.2617\n",
      "Epoch 620/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 1.1394\n",
      "Epoch 621/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.1952\n",
      "Epoch 622/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.2923\n",
      "Epoch 623/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.2991\n",
      "Epoch 624/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.1826\n",
      "Epoch 625/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.1785\n",
      "Epoch 626/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.2955\n",
      "Epoch 627/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2542\n",
      "Epoch 628/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 1.2908\n",
      "Epoch 629/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 1.1974\n",
      "Epoch 630/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.1798\n",
      "Epoch 631/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.1503\n",
      "Epoch 632/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.1716\n",
      "Epoch 633/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.3120\n",
      "Epoch 634/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.1982\n",
      "Epoch 635/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2091\n",
      "Epoch 636/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.1388\n",
      "Epoch 637/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.2161\n",
      "Epoch 638/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.1611\n",
      "Epoch 639/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.1855\n",
      "Epoch 640/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.1263\n",
      "Epoch 641/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.1980\n",
      "Epoch 642/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.1266\n",
      "Epoch 643/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.2217\n",
      "Epoch 644/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.1314\n",
      "Epoch 645/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.1115\n",
      "Epoch 646/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.1696\n",
      "Epoch 647/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.4321\n",
      "Epoch 648/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.2268\n",
      "Epoch 649/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.1444\n",
      "Epoch 650/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.1732\n",
      "Epoch 651/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.1174\n",
      "Epoch 652/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.1772\n",
      "Epoch 653/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.1418\n",
      "Epoch 654/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.1443\n",
      "Epoch 655/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.1624\n",
      "Epoch 656/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.1195\n",
      "Epoch 657/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.2422\n",
      "Epoch 658/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.2271\n",
      "Epoch 659/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.4204\n",
      "Epoch 660/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.3904\n",
      "Epoch 661/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.2626\n",
      "Epoch 662/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.2178\n",
      "Epoch 663/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.1180\n",
      "Epoch 664/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.2777\n",
      "Epoch 665/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.1651\n",
      "Epoch 666/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.1666\n",
      "Epoch 667/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.1609\n",
      "Epoch 668/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2489\n",
      "Epoch 669/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.1609\n",
      "Epoch 670/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.1392\n",
      "Epoch 671/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.2344\n",
      "Epoch 672/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.1699\n",
      "Epoch 673/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.3024\n",
      "Epoch 674/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.5312\n",
      "Epoch 675/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 1.8791\n",
      "Epoch 676/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.5293\n",
      "Epoch 677/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.2744\n",
      "Epoch 678/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.3360\n",
      "Epoch 679/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.3694\n",
      "Epoch 680/1000\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 1.1216\n",
      "Epoch 681/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.3460\n",
      "Epoch 682/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.4533\n",
      "Epoch 683/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.5515\n",
      "Epoch 684/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.5119\n",
      "Epoch 685/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.4052\n",
      "Epoch 686/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.3400\n",
      "Epoch 687/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.3501\n",
      "Epoch 688/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.1147\n",
      "Epoch 689/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 1.2798\n",
      "Epoch 690/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.4990\n",
      "Epoch 691/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.2399\n",
      "Epoch 692/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.1928\n",
      "Epoch 693/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.2709\n",
      "Epoch 694/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.1974\n",
      "Epoch 695/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.0944\n",
      "Epoch 696/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.0937\n",
      "Epoch 697/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.0823\n",
      "Epoch 698/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.1953\n",
      "Epoch 699/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.3094\n",
      "Epoch 700/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.3454\n",
      "Epoch 701/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2606\n",
      "Epoch 702/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.1011\n",
      "Epoch 703/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.2196\n",
      "Epoch 704/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.1450\n",
      "Epoch 705/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 1.2867\n",
      "Epoch 706/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.1616\n",
      "Epoch 707/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2578\n",
      "Epoch 708/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.1318\n",
      "Epoch 709/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.0977\n",
      "Epoch 710/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.1723\n",
      "Epoch 711/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.1005\n",
      "Epoch 712/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.1361\n",
      "Epoch 713/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.1602\n",
      "Epoch 714/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.6277\n",
      "Epoch 715/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.4421\n",
      "Epoch 716/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.1704\n",
      "Epoch 717/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2253\n",
      "Epoch 718/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.4075\n",
      "Epoch 719/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.3240\n",
      "Epoch 720/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2205\n",
      "Epoch 721/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.1203\n",
      "Epoch 722/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.2692\n",
      "Epoch 723/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 1.1694\n",
      "Epoch 724/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.0936\n",
      "Epoch 725/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 1.1750\n",
      "Epoch 726/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.1946\n",
      "Epoch 727/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.1078\n",
      "Epoch 728/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.0487\n",
      "Epoch 729/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.0761\n",
      "Epoch 730/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.1969\n",
      "Epoch 731/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 1.1036\n",
      "Epoch 732/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.0537\n",
      "Epoch 733/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.4160\n",
      "Epoch 734/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.6643\n",
      "Epoch 735/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.2307\n",
      "Epoch 736/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.3347\n",
      "Epoch 737/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.0869\n",
      "Epoch 738/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.0431\n",
      "Epoch 739/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.0951\n",
      "Epoch 740/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 1.0911\n",
      "Epoch 741/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.0685\n",
      "Epoch 742/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.1308\n",
      "Epoch 743/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.1580\n",
      "Epoch 744/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.0422\n",
      "Epoch 745/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.0568\n",
      "Epoch 746/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.0786\n",
      "Epoch 747/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.2048\n",
      "Epoch 748/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 1.1571\n",
      "Epoch 749/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.3166\n",
      "Epoch 750/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.4157\n",
      "Epoch 751/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.1310\n",
      "Epoch 752/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.1373\n",
      "Epoch 753/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.0074\n",
      "Epoch 754/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.1628\n",
      "Epoch 755/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.1829\n",
      "Epoch 756/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 1.1240\n",
      "Epoch 757/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 1.6549\n",
      "Epoch 758/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2764\n",
      "Epoch 759/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.2805\n",
      "Epoch 760/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.0787\n",
      "Epoch 761/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.1742\n",
      "Epoch 762/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.0619\n",
      "Epoch 763/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 1.1974\n",
      "Epoch 764/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.0908\n",
      "Epoch 765/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 1.2196\n",
      "Epoch 766/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.3069\n",
      "Epoch 767/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2204\n",
      "Epoch 768/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.0322\n",
      "Epoch 769/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.0102\n",
      "Epoch 770/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2007\n",
      "Epoch 771/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.1565\n",
      "Epoch 772/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 1.2761\n",
      "Epoch 773/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 1.3324\n",
      "Epoch 774/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.3173\n",
      "Epoch 775/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.3182\n",
      "Epoch 776/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.1997\n",
      "Epoch 777/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.0829\n",
      "Epoch 778/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.0096\n",
      "Epoch 779/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.0341\n",
      "Epoch 780/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.3450\n",
      "Epoch 781/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.2535\n",
      "Epoch 782/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.9894\n",
      "Epoch 783/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.9907\n",
      "Epoch 784/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.0474\n",
      "Epoch 785/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.0251\n",
      "Epoch 786/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.0627\n",
      "Epoch 787/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.0451\n",
      "Epoch 788/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 1.0618\n",
      "Epoch 789/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.0738\n",
      "Epoch 790/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.0863\n",
      "Epoch 791/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.0139\n",
      "Epoch 792/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.1118\n",
      "Epoch 793/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.1198\n",
      "Epoch 794/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.1020\n",
      "Epoch 795/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.0661\n",
      "Epoch 796/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.0938\n",
      "Epoch 797/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.1014\n",
      "Epoch 798/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.1703\n",
      "Epoch 799/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.0392\n",
      "Epoch 800/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.2256\n",
      "Epoch 801/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.1083\n",
      "Epoch 802/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.3655\n",
      "Epoch 803/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2598\n",
      "Epoch 804/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.2004\n",
      "Epoch 805/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.0516\n",
      "Epoch 806/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.2000\n",
      "Epoch 807/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.6747\n",
      "Epoch 808/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.4783\n",
      "Epoch 809/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.0764\n",
      "Epoch 810/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 1.4979\n",
      "Epoch 811/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.4738\n",
      "Epoch 812/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.2481\n",
      "Epoch 813/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.1177\n",
      "Epoch 814/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.0354\n",
      "Epoch 815/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.0677\n",
      "Epoch 816/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.0057\n",
      "Epoch 817/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.9468\n",
      "Epoch 818/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.9736\n",
      "Epoch 819/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.0146\n",
      "Epoch 820/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.0662\n",
      "Epoch 821/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.0993\n",
      "Epoch 822/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.1106\n",
      "Epoch 823/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 1.0476\n",
      "Epoch 824/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.0391\n",
      "Epoch 825/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.0485\n",
      "Epoch 826/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.1367\n",
      "Epoch 827/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.0212\n",
      "Epoch 828/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.9452\n",
      "Epoch 829/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.0359\n",
      "Epoch 830/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.0157\n",
      "Epoch 831/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.2742\n",
      "Epoch 832/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.4705\n",
      "Epoch 833/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.0317\n",
      "Epoch 834/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.9807\n",
      "Epoch 835/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.9951\n",
      "Epoch 836/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.9950\n",
      "Epoch 837/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.0464\n",
      "Epoch 838/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.9985\n",
      "Epoch 839/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.0230\n",
      "Epoch 840/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.2542\n",
      "Epoch 841/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.3114\n",
      "Epoch 842/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.9901\n",
      "Epoch 843/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.4743\n",
      "Epoch 844/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.0510\n",
      "Epoch 845/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.0331\n",
      "Epoch 846/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.1493\n",
      "Epoch 847/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2170\n",
      "Epoch 848/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.6892\n",
      "Epoch 849/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.5614\n",
      "Epoch 850/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.3509\n",
      "Epoch 851/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 2.1174\n",
      "Epoch 852/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 2.3239\n",
      "Epoch 853/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.7345\n",
      "Epoch 854/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.2917\n",
      "Epoch 855/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.0983\n",
      "Epoch 856/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.1382\n",
      "Epoch 857/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.1806\n",
      "Epoch 858/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.9738\n",
      "Epoch 859/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.0223\n",
      "Epoch 860/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.0668\n",
      "Epoch 861/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.9415\n",
      "Epoch 862/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.9492\n",
      "Epoch 863/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.9348\n",
      "Epoch 864/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.9412\n",
      "Epoch 865/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.9756\n",
      "Epoch 866/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.9316\n",
      "Epoch 867/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.9596\n",
      "Epoch 868/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.9809\n",
      "Epoch 869/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.0926\n",
      "Epoch 870/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.3578\n",
      "Epoch 871/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.6781\n",
      "Epoch 872/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.3279\n",
      "Epoch 873/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.9354\n",
      "Epoch 874/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.0267\n",
      "Epoch 875/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.3533\n",
      "Epoch 876/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.2656\n",
      "Epoch 877/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2363\n",
      "Epoch 878/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.5611\n",
      "Epoch 879/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.6957\n",
      "Epoch 880/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2186\n",
      "Epoch 881/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 2.2373\n",
      "Epoch 882/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.7346\n",
      "Epoch 883/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.5069\n",
      "Epoch 884/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 1.2780\n",
      "Epoch 885/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.0665\n",
      "Epoch 886/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.9808\n",
      "Epoch 887/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.9680\n",
      "Epoch 888/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.9381\n",
      "Epoch 889/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.9660\n",
      "Epoch 890/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.9767\n",
      "Epoch 891/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 1.0565\n",
      "Epoch 892/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 1.0120\n",
      "Epoch 893/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.9526\n",
      "Epoch 894/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.9448\n",
      "Epoch 895/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.9683\n",
      "Epoch 896/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.9043\n",
      "Epoch 897/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.9239\n",
      "Epoch 898/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.0126\n",
      "Epoch 899/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.2130\n",
      "Epoch 900/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.1712\n",
      "Epoch 901/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.9739\n",
      "Epoch 902/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.0761\n",
      "Epoch 903/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.1121\n",
      "Epoch 904/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.0418\n",
      "Epoch 905/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.1959\n",
      "Epoch 906/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.0446\n",
      "Epoch 907/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.9439\n",
      "Epoch 908/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.9176\n",
      "Epoch 909/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.9453\n",
      "Epoch 910/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.9709\n",
      "Epoch 911/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.2638\n",
      "Epoch 912/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.9449\n",
      "Epoch 913/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.9634\n",
      "Epoch 914/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.9981\n",
      "Epoch 915/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.1105\n",
      "Epoch 916/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.4980\n",
      "Epoch 917/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 1.3171\n",
      "Epoch 918/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 1.1874\n",
      "Epoch 919/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.9300\n",
      "Epoch 920/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.9612\n",
      "Epoch 921/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.1048\n",
      "Epoch 922/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.0625\n",
      "Epoch 923/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.9500\n",
      "Epoch 924/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.9177\n",
      "Epoch 925/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.9466\n",
      "Epoch 926/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.9853\n",
      "Epoch 927/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.1762\n",
      "Epoch 928/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.0175\n",
      "Epoch 929/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.9211\n",
      "Epoch 930/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.8813\n",
      "Epoch 931/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.9724\n",
      "Epoch 932/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.0809\n",
      "Epoch 933/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.9453\n",
      "Epoch 934/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.9376\n",
      "Epoch 935/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.9596\n",
      "Epoch 936/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.9233\n",
      "Epoch 937/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 1.0170\n",
      "Epoch 938/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.1197\n",
      "Epoch 939/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.9261\n",
      "Epoch 940/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.9347\n",
      "Epoch 941/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.9224\n",
      "Epoch 942/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.9036\n",
      "Epoch 943/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.9349\n",
      "Epoch 944/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.9060\n",
      "Epoch 945/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.9968\n",
      "Epoch 946/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.0087\n",
      "Epoch 947/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.5401\n",
      "Epoch 948/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 1.0848\n",
      "Epoch 949/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.9508\n",
      "Epoch 950/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.9763\n",
      "Epoch 951/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.0638\n",
      "Epoch 952/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 1.0650\n",
      "Epoch 953/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 1.0424\n",
      "Epoch 954/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 1.0003\n",
      "Epoch 955/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.9303\n",
      "Epoch 956/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.9333\n",
      "Epoch 957/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.0230\n",
      "Epoch 958/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.9831\n",
      "Epoch 959/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.9839\n",
      "Epoch 960/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.9971\n",
      "Epoch 961/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.9790\n",
      "Epoch 962/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.9668\n",
      "Epoch 963/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.9279\n",
      "Epoch 964/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.9257\n",
      "Epoch 965/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.9223\n",
      "Epoch 966/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.9311\n",
      "Epoch 967/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.9075\n",
      "Epoch 968/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.9391\n",
      "Epoch 969/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.9556\n",
      "Epoch 970/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.8970\n",
      "Epoch 971/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.9239\n",
      "Epoch 972/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.9337\n",
      "Epoch 973/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.9311\n",
      "Epoch 974/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.9309\n",
      "Epoch 975/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.9433\n",
      "Epoch 976/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.9185\n",
      "Epoch 977/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.9027\n",
      "Epoch 978/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.9349\n",
      "Epoch 979/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.9049\n",
      "Epoch 980/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.9407\n",
      "Epoch 981/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.9286\n",
      "Epoch 982/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.9120\n",
      "Epoch 983/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.9466\n",
      "Epoch 984/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.0655\n",
      "Epoch 985/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.9611\n",
      "Epoch 986/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.9348\n",
      "Epoch 987/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.9912\n",
      "Epoch 988/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.9824\n",
      "Epoch 989/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.9433\n",
      "Epoch 990/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.8979\n",
      "Epoch 991/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.9115\n",
      "Epoch 992/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.9307\n",
      "Epoch 993/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.9189\n",
      "Epoch 994/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.9329\n",
      "Epoch 995/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.9248\n",
      "Epoch 996/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.8840\n",
      "Epoch 997/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.9169\n",
      "Epoch 998/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.9074\n",
      "Epoch 999/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.9281\n",
      "Epoch 1000/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.9270\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a41845c50>"
      ]
     },
     "execution_count": 1146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_FGM = Sequential()\n",
    "NN_FGM.add(Dense(units=32,input_dim=X_train.shape[1],activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_FGM.add(Dense(units=16, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_FGM.add(Dense(units=8, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_FGM.add(Dense(units=1,activation='linear'))\n",
    "NN_FGM.compile(loss='mse', optimizer='adam')\n",
    "NN_FGM.fit(np.array(X_train), np.array(y_train), epochs=1000,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN_predictions</th>\n",
       "      <th>actual</th>\n",
       "      <th>GBR_predictions</th>\n",
       "      <th>LY_FGM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>5.775374</td>\n",
       "      <td>7.1</td>\n",
       "      <td>6.914423</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>5.086746</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.675457</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>6.337204</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.284716</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>6.063814</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.152646</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>5.208510</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5.754109</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>6.016421</td>\n",
       "      <td>8.1</td>\n",
       "      <td>6.357587</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>5.589433</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.968942</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>6.138728</td>\n",
       "      <td>7.4</td>\n",
       "      <td>6.290253</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>6.552523</td>\n",
       "      <td>6.7</td>\n",
       "      <td>6.245836</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>6.352209</td>\n",
       "      <td>7.4</td>\n",
       "      <td>6.298005</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>6.104954</td>\n",
       "      <td>6.1</td>\n",
       "      <td>6.265047</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>5.562084</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.517282</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>6.186967</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6.500447</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>6.314175</td>\n",
       "      <td>7.1</td>\n",
       "      <td>6.579745</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>5.624339</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.130856</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>5.128125</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.603031</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>5.521939</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6.168381</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>5.959587</td>\n",
       "      <td>6.7</td>\n",
       "      <td>6.605669</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>7.102070</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.934022</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>6.541491</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.393243</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>4.152427</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.316090</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>5.531089</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.963161</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>5.225176</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5.514366</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>6.131835</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.282637</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>5.743595</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.233516</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>5.931302</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5.840006</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>5.770144</td>\n",
       "      <td>8.3</td>\n",
       "      <td>6.294070</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>4.268292</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.300841</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>5.272134</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.798472</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>5.855800</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.248617</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>5.053968</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.945801</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>5.544038</td>\n",
       "      <td>7.8</td>\n",
       "      <td>6.105179</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>5.745234</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.635077</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>5.501946</td>\n",
       "      <td>4.6</td>\n",
       "      <td>5.794433</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>6.391542</td>\n",
       "      <td>7.9</td>\n",
       "      <td>6.830035</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>5.676157</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.919813</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>4.830653</td>\n",
       "      <td>4.3</td>\n",
       "      <td>5.270468</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>5.763475</td>\n",
       "      <td>6.6</td>\n",
       "      <td>5.924023</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>5.418628</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.464468</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>4.717898</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.724720</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>5.391994</td>\n",
       "      <td>6.3</td>\n",
       "      <td>5.651025</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>5.055351</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5.820705</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>5.228909</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5.420287</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>5.998545</td>\n",
       "      <td>5.3</td>\n",
       "      <td>6.046279</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>5.892036</td>\n",
       "      <td>4.4</td>\n",
       "      <td>6.180070</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>5.275808</td>\n",
       "      <td>6.2</td>\n",
       "      <td>5.562906</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>4.866632</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.256130</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>4.276979</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.908040</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>5.061452</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.529113</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>3.486067</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.283828</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     NN_predictions  actual  GBR_predictions  LY_FGM\n",
       "62         5.775374     7.1         6.914423     7.0\n",
       "216        5.086746     4.6         4.675457     6.9\n",
       "168        6.337204     6.5         6.284716     6.8\n",
       "377        6.063814     5.5         6.152646     6.8\n",
       "581        5.208510     7.7         5.754109     6.8\n",
       "95         6.016421     8.1         6.357587     6.8\n",
       "591        5.589433     6.9         5.968942     6.8\n",
       "221        6.138728     7.4         6.290253     6.7\n",
       "119        6.552523     6.7         6.245836     6.7\n",
       "442        6.352209     7.4         6.298005     6.7\n",
       "217        6.104954     6.1         6.265047     6.7\n",
       "431        5.562084     6.0         6.517282     6.6\n",
       "550        6.186967     5.8         6.500447     6.6\n",
       "173        6.314175     7.1         6.579745     6.6\n",
       "561        5.624339     6.2         6.130856     6.5\n",
       "378        5.128125     5.8         5.603031     6.5\n",
       "200        5.521939     5.8         6.168381     6.5\n",
       "90         5.959587     6.7         6.605669     6.5\n",
       "393        7.102070     7.0         6.934022     6.5\n",
       "631        6.541491     7.5         6.393243     6.5\n",
       "653        4.152427     3.5         4.316090     6.5\n",
       "461        5.531089     4.7         5.963161     6.5\n",
       "528        5.225176     4.8         5.514366     6.5\n",
       "559        6.131835     7.0         6.282637     6.5\n",
       "326        5.743595     5.1         6.233516     6.5\n",
       "212        5.931302     5.6         5.840006     6.5\n",
       "243        5.770144     8.3         6.294070     6.5\n",
       "365        4.268292     6.0         4.300841     6.4\n",
       "536        5.272134     5.3         5.798472     6.4\n",
       "445        5.855800     6.4         6.248617     6.3\n",
       "210        5.053968     5.8         5.945801     6.2\n",
       "509        5.544038     7.8         6.105179     6.2\n",
       "668        5.745234     5.3         5.635077     6.2\n",
       "240        5.501946     4.6         5.794433     6.2\n",
       "620        6.391542     7.9         6.830035     6.2\n",
       "524        5.676157     7.0         5.919813     6.2\n",
       "198        4.830653     4.3         5.270468     6.2\n",
       "636        5.763475     6.6         5.924023     6.1\n",
       "87         5.418628     5.2         5.464468     6.1\n",
       "185        4.717898     5.2         5.724720     6.1\n",
       "150        5.391994     6.3         5.651025     6.0\n",
       "237        5.055351     5.4         5.820705     6.0\n",
       "480        5.228909     5.6         5.420287     6.0\n",
       "490        5.998545     5.3         6.046279     6.0\n",
       "270        5.892036     4.4         6.180070     6.0\n",
       "428        5.275808     6.2         5.562906     6.0\n",
       "110        4.866632     6.0         5.256130     5.9\n",
       "590        4.276979     5.2         3.908040     5.9\n",
       "444        5.061452     4.7         5.529113     5.9\n",
       "188        3.486067     4.9         4.283828     5.9"
      ]
     },
     "execution_count": 1147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = NN_FGM.predict(X_test)\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.5)\n",
    "gbr.fit(X_train,y_train)\n",
    "gbr_predictions = gbr.predict(X_test)\n",
    "LR = LinearRegression(fit_intercept=True).fit(X_train,y_train)\n",
    "\n",
    "testing = pd.DataFrame(predictions)\n",
    "testing.columns=['NN_predictions']\n",
    "testing['actual'] = y_test.reset_index()['FGM']\n",
    "testing['GBR_predictions']=gbr_predictions\n",
    "testing['LY_FGM']=X_test['FGM_ly'].reset_index()['FGM_ly']\n",
    "testing.sort_values(by='LY_FGM',ascending=False)[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1148,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2017FGM = percentages[percentages['season']==2017].drop(['player','team','FGM','FGA','FG_percent','FTM','FTA','Games'],axis=1)\n",
    "#pred_2017blocks = blocks[blocks['season']==2017][['blocks_ly','career_blocks','starter_change']]\n",
    "FGM_2017 = NN_FGM.predict(pred_2017FGM)\n",
    "gbr_FGM_2017 = pd.DataFrame(gbr.predict(pred_2017FGM))\n",
    "LR_FGM_2017 = pd.DataFrame(LR.predict(pred_2017FGM))\n",
    "test_2 =pd.DataFrame(FGM_2017)\n",
    "test_3 = pd.merge(percentages,pred_2017FGM,left_index=True,right_index=True).reset_index()\n",
    "test_3['predictions']=test_2[0]\n",
    "test_3['gbr_pred'] = gbr_FGM_2017[0]\n",
    "test_3['LR_pred'] = LR_FGM_2017[0]\n",
    "test_3['mean_pred'] = (test_3['predictions']+test_3['gbr_pred']+test_3['LR_pred'])/3\n",
    "test_3 = test_3[test_3['Games']>30]\n",
    "test_3[['player','FGM','predictions','LR_pred','gbr_pred','mean_pred','FGM_ly_x']].sort_values(by='FGM_ly_x',ascending=False)[0:50]\n",
    "\n",
    "FGM_2017 = test_3[['player','LR_pred']]\n",
    "FGM_2017.columns = ['player','FGM_prediction']\n",
    "df_2017 = pd.merge(df_2017,FGM_2017, how='left',left_on='player',right_on='player')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE using LR:0.9791658845717702\n",
      "MSE using GB:0.9344283542953499\n",
      "MSE using NN:1.4054807170667343\n",
      "MSE using combo:1.0068003976298765\n",
      "MSE using mean:4.2722633136094625\n",
      "MSE using last year stats:1.5276602564102566\n"
     ]
    }
   ],
   "source": [
    "print('MSE using LR:{}'.format(np.mean((test_3['FGM']-test_3['LR_pred'])**2)))\n",
    "print('MSE using GB:{}'.format(np.mean((test_3['FGM']-test_3['gbr_pred'])**2)))\n",
    "print('MSE using NN:{}'.format(np.mean((test_3['FGM']-test_3['predictions'])**2)))\n",
    "print('MSE using combo:{}'.format(np.mean((test_3['FGM']-test_3['mean_pred'])**2)))\n",
    "print('MSE using mean:{}'.format(np.mean((test_3['FGM']-np.mean(test_3['FGM']))**2)))\n",
    "print('MSE using last year stats:{}'.format(np.mean((test_3['FGM']-test_3['FGM_ly_x'])**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['season', 'player', 'age', 'team', 'FGM', 'FGA', 'FG_percent',\n",
       "       'FG_percent_ly', 'FGM_ly', 'FGA_ly', 'FTM', 'FTA', 'FT_percent',\n",
       "       'FT_percent_ly', 'FTM_ly', 'FTA_ly', '3PM_ly', '3PM_change',\n",
       "       'points_ly', 'change_points_ly', 'starter_change', 'C_PF', 'PG',\n",
       "       'SG_SF', 'Games', 'high_usageplayer_added', 'usagemin_opened',\n",
       "       'maxusage_added', 'high_usageplayer_dropped', 'points_opened',\n",
       "       'max_pointsdropped', 'max_pointsadded', 'three_ar_ly', 'change_3ar',\n",
       "       'per_ly', 'change_per', 'usagerank', 'usagerank_ly',\n",
       "       'offensive_winshares', 'offensive_boxplusminus', 'boxplusminus',\n",
       "       'value_overreplacement', 'career_FGM', 'career_FGA', 'career_FGpercent',\n",
       "       'career_FTM', 'career_FTA', 'career_FTPercent', 'yearspro'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentages.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = percentages[(percentages['season']!=2017) & (percentages['Games']>30)].drop(['player','team','FGM','FGA','FG_percent','FTM','FTA','Games'],axis=1)\n",
    "X = percentages[(percentages['season']!=2017) & (percentages['Games']>30)][['FG_percent_ly','career_FGpercent','age','age_squared','yearspro']]\n",
    "y = percentages[(percentages['season']!=2017) & (percentages['Games']>30)]['FG_percent']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1564/1564 [==============================] - 4s 3ms/step - loss: 0.1995\n",
      "Epoch 2/100\n",
      "1564/1564 [==============================] - 0s 85us/step - loss: 0.1782\n",
      "Epoch 3/100\n",
      "1564/1564 [==============================] - 0s 86us/step - loss: 0.1586\n",
      "Epoch 4/100\n",
      "1564/1564 [==============================] - 0s 91us/step - loss: 0.1408\n",
      "Epoch 5/100\n",
      "1564/1564 [==============================] - 0s 88us/step - loss: 0.1245\n",
      "Epoch 6/100\n",
      "1564/1564 [==============================] - 0s 87us/step - loss: 0.1098\n",
      "Epoch 7/100\n",
      "1564/1564 [==============================] - 0s 88us/step - loss: 0.0965\n",
      "Epoch 8/100\n",
      "1564/1564 [==============================] - 0s 81us/step - loss: 0.0845\n",
      "Epoch 9/100\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 0.0738\n",
      "Epoch 10/100\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.0643\n",
      "Epoch 11/100\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.0558\n",
      "Epoch 12/100\n",
      "1564/1564 [==============================] - 0s 84us/step - loss: 0.0483\n",
      "Epoch 13/100\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 0.0417\n",
      "Epoch 14/100\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 0.0359\n",
      "Epoch 15/100\n",
      "1564/1564 [==============================] - 0s 81us/step - loss: 0.0309\n",
      "Epoch 16/100\n",
      "1564/1564 [==============================] - 0s 79us/step - loss: 0.0266\n",
      "Epoch 17/100\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.0228\n",
      "Epoch 18/100\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.0196\n",
      "Epoch 19/100\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 0.0168\n",
      "Epoch 20/100\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 0.0145\n",
      "Epoch 21/100\n",
      "1564/1564 [==============================] - 0s 85us/step - loss: 0.0125\n",
      "Epoch 22/100\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.0109\n",
      "Epoch 23/100\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.0095\n",
      "Epoch 24/100\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.0084\n",
      "Epoch 25/100\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 0.0075\n",
      "Epoch 26/100\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 0.0067\n",
      "Epoch 27/100\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 0.0061\n",
      "Epoch 28/100\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 0.0056\n",
      "Epoch 29/100\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 0.0052\n",
      "Epoch 30/100\n",
      "1564/1564 [==============================] - 0s 88us/step - loss: 0.0049\n",
      "Epoch 31/100\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 0.0046\n",
      "Epoch 32/100\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.0044\n",
      "Epoch 33/100\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.0043\n",
      "Epoch 34/100\n",
      "1564/1564 [==============================] - 0s 82us/step - loss: 0.0042\n",
      "Epoch 35/100\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 0.0041\n",
      "Epoch 36/100\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.0040\n",
      "Epoch 37/100\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.0039\n",
      "Epoch 38/100\n",
      "1564/1564 [==============================] - 0s 70us/step - loss: 0.0039\n",
      "Epoch 39/100\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 0.0039\n",
      "Epoch 40/100\n",
      "1564/1564 [==============================] - 0s 79us/step - loss: 0.0039\n",
      "Epoch 41/100\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 0.0038\n",
      "Epoch 42/100\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.0038\n",
      "Epoch 43/100\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.0038\n",
      "Epoch 44/100\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 0.0038\n",
      "Epoch 45/100\n",
      "1564/1564 [==============================] - 0s 76us/step - loss: 0.0038\n",
      "Epoch 46/100\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.0038\n",
      "Epoch 47/100\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.0038\n",
      "Epoch 48/100\n",
      "1564/1564 [==============================] - 0s 81us/step - loss: 0.0038\n",
      "Epoch 49/100\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.0038\n",
      "Epoch 50/100\n",
      "1564/1564 [==============================] - 0s 79us/step - loss: 0.0038\n",
      "Epoch 51/100\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.0038\n",
      "Epoch 52/100\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.0038\n",
      "Epoch 53/100\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.0038\n",
      "Epoch 54/100\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 0.0038\n",
      "Epoch 55/100\n",
      "1564/1564 [==============================] - 0s 77us/step - loss: 0.0038\n",
      "Epoch 56/100\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.0038\n",
      "Epoch 57/100\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 0.0038\n",
      "Epoch 58/100\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 0.0038\n",
      "Epoch 59/100\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.0038\n",
      "Epoch 60/100\n",
      "1564/1564 [==============================] - 0s 79us/step - loss: 0.0038\n",
      "Epoch 61/100\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.0038\n",
      "Epoch 62/100\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.0038\n",
      "Epoch 63/100\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 0.0038\n",
      "Epoch 64/100\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.0038\n",
      "Epoch 65/100\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 0.0038\n",
      "Epoch 66/100\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.0038\n",
      "Epoch 67/100\n",
      "1564/1564 [==============================] - 0s 83us/step - loss: 0.0038\n",
      "Epoch 68/100\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.0038\n",
      "Epoch 69/100\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 0.0038\n",
      "Epoch 70/100\n",
      "1564/1564 [==============================] - 0s 77us/step - loss: 0.0038\n",
      "Epoch 71/100\n",
      "1564/1564 [==============================] - 0s 67us/step - loss: 0.0038\n",
      "Epoch 72/100\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 0.0038\n",
      "Epoch 73/100\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 0.0038\n",
      "Epoch 74/100\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 0.0038\n",
      "Epoch 75/100\n",
      "1564/1564 [==============================] - 0s 76us/step - loss: 0.0038\n",
      "Epoch 76/100\n",
      "1564/1564 [==============================] - 0s 82us/step - loss: 0.0038\n",
      "Epoch 77/100\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.0038\n",
      "Epoch 78/100\n",
      "1564/1564 [==============================] - 0s 64us/step - loss: 0.0038\n",
      "Epoch 79/100\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.0038\n",
      "Epoch 80/100\n",
      "1564/1564 [==============================] - 0s 79us/step - loss: 0.0038\n",
      "Epoch 81/100\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.0038\n",
      "Epoch 82/100\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 0.0038\n",
      "Epoch 83/100\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.0038\n",
      "Epoch 84/100\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.0038\n",
      "Epoch 85/100\n",
      "1564/1564 [==============================] - 0s 80us/step - loss: 0.0038\n",
      "Epoch 86/100\n",
      "1564/1564 [==============================] - 0s 68us/step - loss: 0.0038\n",
      "Epoch 87/100\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.0038\n",
      "Epoch 88/100\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 0.0038\n",
      "Epoch 89/100\n",
      "1564/1564 [==============================] - 0s 66us/step - loss: 0.0038\n",
      "Epoch 90/100\n",
      "1564/1564 [==============================] - 0s 77us/step - loss: 0.0038\n",
      "Epoch 91/100\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 0.0038\n",
      "Epoch 92/100\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 0.0038\n",
      "Epoch 93/100\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 0.0038\n",
      "Epoch 94/100\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.0038\n",
      "Epoch 95/100\n",
      "1564/1564 [==============================] - 0s 83us/step - loss: 0.0038\n",
      "Epoch 96/100\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 0.0038\n",
      "Epoch 97/100\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.0038\n",
      "Epoch 98/100\n",
      "1564/1564 [==============================] - 0s 63us/step - loss: 0.0038\n",
      "Epoch 99/100\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 0.0038\n",
      "Epoch 100/100\n",
      "1564/1564 [==============================] - 0s 78us/step - loss: 0.0038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a4d667550>"
      ]
     },
     "execution_count": 1151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_FGP = Sequential()\n",
    "NN_FGP.add(Dense(units=4,input_dim=X_train.shape[1],activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_FGP.add(Dense(units=2, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "#NN_FGP.add(Dense(units=8, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_FGP.add(Dense(units=1,activation='linear'))\n",
    "NN_FGP.compile(loss='mse', optimizer='adam')\n",
    "NN_FGP.fit(np.array(X_train), np.array(y_train), epochs=100,batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN_predictions</th>\n",
       "      <th>actual</th>\n",
       "      <th>GBR_predictions</th>\n",
       "      <th>LY_FGP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.540335</td>\n",
       "      <td>0.543689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.610169</td>\n",
       "      <td>0.542324</td>\n",
       "      <td>0.543478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.489583</td>\n",
       "      <td>0.571376</td>\n",
       "      <td>0.543210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.546024</td>\n",
       "      <td>0.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.527473</td>\n",
       "      <td>0.528416</td>\n",
       "      <td>0.542553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.530769</td>\n",
       "      <td>0.520532</td>\n",
       "      <td>0.540230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.532005</td>\n",
       "      <td>0.540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.557692</td>\n",
       "      <td>0.509531</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.525547</td>\n",
       "      <td>0.525501</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.424528</td>\n",
       "      <td>0.518157</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.498548</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.489796</td>\n",
       "      <td>0.520238</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.520858</td>\n",
       "      <td>0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.505495</td>\n",
       "      <td>0.511912</td>\n",
       "      <td>0.536232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.508788</td>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.524035</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.532128</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.521609</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.522727</td>\n",
       "      <td>0.516782</td>\n",
       "      <td>0.531646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.519181</td>\n",
       "      <td>0.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.496296</td>\n",
       "      <td>0.522247</td>\n",
       "      <td>0.530769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.573171</td>\n",
       "      <td>0.527749</td>\n",
       "      <td>0.530120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.523093</td>\n",
       "      <td>0.529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>0.523914</td>\n",
       "      <td>0.529412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.567416</td>\n",
       "      <td>0.513419</td>\n",
       "      <td>0.529101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.455446</td>\n",
       "      <td>0.522872</td>\n",
       "      <td>0.527778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.452055</td>\n",
       "      <td>0.512348</td>\n",
       "      <td>0.527473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.502990</td>\n",
       "      <td>0.526316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.502388</td>\n",
       "      <td>0.523810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.422222</td>\n",
       "      <td>0.463732</td>\n",
       "      <td>0.523810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.509885</td>\n",
       "      <td>0.523810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.506494</td>\n",
       "      <td>0.523526</td>\n",
       "      <td>0.523810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.528874</td>\n",
       "      <td>0.522727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.520429</td>\n",
       "      <td>0.522727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.543956</td>\n",
       "      <td>0.521849</td>\n",
       "      <td>0.521505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.507995</td>\n",
       "      <td>0.521127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.489919</td>\n",
       "      <td>0.520548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.504141</td>\n",
       "      <td>0.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.509218</td>\n",
       "      <td>0.518519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.481740</td>\n",
       "      <td>0.517986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.516872</td>\n",
       "      <td>0.517241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.484346</td>\n",
       "      <td>0.516129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.448276</td>\n",
       "      <td>0.476306</td>\n",
       "      <td>0.515152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.519084</td>\n",
       "      <td>0.514611</td>\n",
       "      <td>0.512821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.457831</td>\n",
       "      <td>0.485730</td>\n",
       "      <td>0.511811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.493976</td>\n",
       "      <td>0.500622</td>\n",
       "      <td>0.511450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.456790</td>\n",
       "      <td>0.497634</td>\n",
       "      <td>0.511111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.512658</td>\n",
       "      <td>0.513125</td>\n",
       "      <td>0.510949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.514706</td>\n",
       "      <td>0.489893</td>\n",
       "      <td>0.510638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>0.454044</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.474234</td>\n",
       "      <td>0.510638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     NN_predictions    actual  GBR_predictions    LY_FGP\n",
       "658        0.454044  0.510204         0.540335  0.543689\n",
       "318        0.454044  0.610169         0.542324  0.543478\n",
       "201        0.454044  0.489583         0.571376  0.543210\n",
       "452        0.454044  0.450000         0.546024  0.542857\n",
       "397        0.454044  0.527473         0.528416  0.542553\n",
       "282        0.454044  0.530769         0.520532  0.540230\n",
       "533        0.454044  0.533333         0.532005  0.540000\n",
       "143        0.454044  0.557692         0.509531  0.538462\n",
       "349        0.454044  0.525547         0.525501  0.538462\n",
       "225        0.454044  0.424528         0.518157  0.538462\n",
       "573        0.454044  0.541667         0.498548  0.538462\n",
       "450        0.454044  0.489796         0.520238  0.538462\n",
       "31         0.454044  0.478261         0.520858  0.538462\n",
       "640        0.454044  0.505495         0.511912  0.536232\n",
       "627        0.454044  0.447368         0.508788  0.535714\n",
       "248        0.454044  0.307692         0.524035  0.533333\n",
       "30         0.454044  0.600000         0.532128  0.533333\n",
       "281        0.454044  0.525000         0.521609  0.533333\n",
       "355        0.454044  0.522727         0.516782  0.531646\n",
       "53         0.454044  0.479167         0.519181  0.531250\n",
       "578        0.454044  0.496296         0.522247  0.530769\n",
       "311        0.454044  0.573171         0.527749  0.530120\n",
       "262        0.454044  0.520833         0.523093  0.529412\n",
       "570        0.454044  0.531250         0.523914  0.529412\n",
       "343        0.454044  0.567416         0.513419  0.529101\n",
       "192        0.454044  0.455446         0.522872  0.527778\n",
       "174        0.454044  0.452055         0.512348  0.527473\n",
       "98         0.454044  0.500000         0.502990  0.526316\n",
       "184        0.454044  0.428571         0.502388  0.523810\n",
       "257        0.454044  0.422222         0.463732  0.523810\n",
       "392        0.454044  0.451613         0.509885  0.523810\n",
       "50         0.454044  0.506494         0.523526  0.523810\n",
       "18         0.454044  0.491228         0.528874  0.522727\n",
       "267        0.454044  0.540000         0.520429  0.522727\n",
       "617        0.454044  0.543956         0.521849  0.521505\n",
       "623        0.454044  0.515625         0.507995  0.521127\n",
       "270        0.454044  0.461538         0.489919  0.520548\n",
       "212        0.454044  0.500000         0.504141  0.520000\n",
       "179        0.454044  0.500000         0.509218  0.518519\n",
       "60         0.454044  0.500000         0.481740  0.517986\n",
       "520        0.454044  0.636364         0.516872  0.517241\n",
       "76         0.454044  0.371429         0.484346  0.516129\n",
       "264        0.454044  0.448276         0.476306  0.515152\n",
       "283        0.454044  0.519084         0.514611  0.512821\n",
       "299        0.454044  0.457831         0.485730  0.511811\n",
       "479        0.454044  0.493976         0.500622  0.511450\n",
       "295        0.454044  0.456790         0.497634  0.511111\n",
       "555        0.454044  0.512658         0.513125  0.510949\n",
       "235        0.454044  0.514706         0.489893  0.510638\n",
       "444        0.454044  0.464286         0.474234  0.510638"
      ]
     },
     "execution_count": 1152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = NN_FGP.predict(X_test)\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.5)\n",
    "gbr.fit(X_train,y_train)\n",
    "gbr_predictions = gbr.predict(X_test)\n",
    "LR = LinearRegression(fit_intercept=True).fit(X_train,y_train)\n",
    "\n",
    "testing = pd.DataFrame(predictions)\n",
    "testing.columns=['NN_predictions']\n",
    "testing['actual'] = y_test.reset_index()['FG_percent']\n",
    "testing['GBR_predictions']=gbr_predictions\n",
    "testing['LY_FGP']=X_test['FG_percent_ly'].reset_index()['FG_percent_ly']\n",
    "testing.sort_values(by='LY_FGP',ascending=False)[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1153,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2017FGP = percentages[percentages['season']==2017][['FG_percent_ly','career_FGpercent','age','age_squared','yearspro']]\n",
    "#pred_2017blocks = blocks[blocks['season']==2017][['blocks_ly','career_blocks','starter_change']]\n",
    "FGP_2017 = NN_FGP.predict(pred_2017FGP)\n",
    "gbr_FGP_2017 = pd.DataFrame(gbr.predict(pred_2017FGP))\n",
    "LR_FGP_2017 = pd.DataFrame(LR.predict(pred_2017FGP))\n",
    "test_2 =pd.DataFrame(FGP_2017)\n",
    "test_3 = pd.merge(percentages,pred_2017FGP,left_index=True,right_index=True).reset_index()\n",
    "test_3['predictions']=test_2[0]\n",
    "test_3['gbr_pred'] = gbr_FGP_2017[0]\n",
    "test_3['LR_pred'] = LR_FGP_2017[0]\n",
    "test_3['mean_pred'] = (test_3['predictions']+test_3['gbr_pred']+test_3['LR_pred'])/3\n",
    "test_3 = test_3[test_3['Games']>30]\n",
    "test_3[['player','FG_percent','predictions','LR_pred','gbr_pred','mean_pred','FG_percent_ly_x']].sort_values(by='FG_percent_ly_x',ascending=False)[0:50]\n",
    "\n",
    "FGP_2017 = test_3[['player','LR_pred']]\n",
    "FGP_2017.columns = ['player','FGP_prediction']\n",
    "df_2017 = pd.merge(df_2017,FGP_2017,how='left',left_on='player',right_on='player')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>player</th>\n",
       "      <th>position</th>\n",
       "      <th>age</th>\n",
       "      <th>team</th>\n",
       "      <th>gamesPlayed</th>\n",
       "      <th>gamesStarted</th>\n",
       "      <th>minutes</th>\n",
       "      <th>points</th>\n",
       "      <th>rebounds</th>\n",
       "      <th>...</th>\n",
       "      <th>point_prediction1</th>\n",
       "      <th>rebound_prediction</th>\n",
       "      <th>assist_prediction</th>\n",
       "      <th>steal_prediction</th>\n",
       "      <th>block_predictions</th>\n",
       "      <th>three_prediction</th>\n",
       "      <th>turnover_prediction</th>\n",
       "      <th>FGM_prediction</th>\n",
       "      <th>FGP_prediction</th>\n",
       "      <th>FGA_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>LeBron James</td>\n",
       "      <td>PF</td>\n",
       "      <td>33</td>\n",
       "      <td>CLE</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>36.9</td>\n",
       "      <td>27.5</td>\n",
       "      <td>8.6</td>\n",
       "      <td>...</td>\n",
       "      <td>24.870920</td>\n",
       "      <td>8.404722</td>\n",
       "      <td>8.170845</td>\n",
       "      <td>1.345292</td>\n",
       "      <td>0.612607</td>\n",
       "      <td>1.647424</td>\n",
       "      <td>3.552995</td>\n",
       "      <td>9.330926</td>\n",
       "      <td>0.505386</td>\n",
       "      <td>18.462954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>Khris Middleton</td>\n",
       "      <td>SF</td>\n",
       "      <td>26</td>\n",
       "      <td>MIL</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>36.4</td>\n",
       "      <td>20.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>...</td>\n",
       "      <td>13.640875</td>\n",
       "      <td>3.901478</td>\n",
       "      <td>2.844345</td>\n",
       "      <td>1.227558</td>\n",
       "      <td>0.166228</td>\n",
       "      <td>1.536074</td>\n",
       "      <td>1.818488</td>\n",
       "      <td>4.960662</td>\n",
       "      <td>0.451003</td>\n",
       "      <td>10.999172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>Bradley Beal</td>\n",
       "      <td>SG</td>\n",
       "      <td>24</td>\n",
       "      <td>WAS</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>36.3</td>\n",
       "      <td>22.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>...</td>\n",
       "      <td>21.028357</td>\n",
       "      <td>3.640051</td>\n",
       "      <td>3.421147</td>\n",
       "      <td>1.077844</td>\n",
       "      <td>0.303437</td>\n",
       "      <td>2.646208</td>\n",
       "      <td>2.034305</td>\n",
       "      <td>7.402198</td>\n",
       "      <td>0.460459</td>\n",
       "      <td>16.075688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>Andrew Wiggins</td>\n",
       "      <td>SF</td>\n",
       "      <td>22</td>\n",
       "      <td>MIN</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>36.3</td>\n",
       "      <td>17.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>...</td>\n",
       "      <td>20.456723</td>\n",
       "      <td>3.821239</td>\n",
       "      <td>2.183822</td>\n",
       "      <td>0.951058</td>\n",
       "      <td>0.449024</td>\n",
       "      <td>1.230865</td>\n",
       "      <td>2.170531</td>\n",
       "      <td>7.529388</td>\n",
       "      <td>0.461304</td>\n",
       "      <td>16.321960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>CJ McCollum</td>\n",
       "      <td>SG</td>\n",
       "      <td>26</td>\n",
       "      <td>POR</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>36.1</td>\n",
       "      <td>21.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.253920</td>\n",
       "      <td>3.537566</td>\n",
       "      <td>3.537808</td>\n",
       "      <td>0.920871</td>\n",
       "      <td>0.399520</td>\n",
       "      <td>2.248571</td>\n",
       "      <td>2.156241</td>\n",
       "      <td>7.565362</td>\n",
       "      <td>0.461679</td>\n",
       "      <td>16.386628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017</td>\n",
       "      <td>Jrue Holiday</td>\n",
       "      <td>SG</td>\n",
       "      <td>27</td>\n",
       "      <td>NOP</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>36.1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>13.656572</td>\n",
       "      <td>3.484355</td>\n",
       "      <td>5.860924</td>\n",
       "      <td>1.326976</td>\n",
       "      <td>0.524537</td>\n",
       "      <td>1.430401</td>\n",
       "      <td>2.249917</td>\n",
       "      <td>5.137229</td>\n",
       "      <td>0.447882</td>\n",
       "      <td>11.470059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017</td>\n",
       "      <td>Karl-Anthony Towns</td>\n",
       "      <td>C</td>\n",
       "      <td>22</td>\n",
       "      <td>MIN</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>35.6</td>\n",
       "      <td>21.3</td>\n",
       "      <td>12.3</td>\n",
       "      <td>...</td>\n",
       "      <td>23.705239</td>\n",
       "      <td>11.656341</td>\n",
       "      <td>3.322843</td>\n",
       "      <td>0.888906</td>\n",
       "      <td>1.328844</td>\n",
       "      <td>1.251075</td>\n",
       "      <td>2.640501</td>\n",
       "      <td>9.765563</td>\n",
       "      <td>0.530322</td>\n",
       "      <td>18.414395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017</td>\n",
       "      <td>Russell Westbrook</td>\n",
       "      <td>PG</td>\n",
       "      <td>29</td>\n",
       "      <td>OKC</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>36.4</td>\n",
       "      <td>25.4</td>\n",
       "      <td>10.1</td>\n",
       "      <td>...</td>\n",
       "      <td>28.462095</td>\n",
       "      <td>10.150878</td>\n",
       "      <td>10.620148</td>\n",
       "      <td>1.909999</td>\n",
       "      <td>0.370554</td>\n",
       "      <td>2.378485</td>\n",
       "      <td>4.366154</td>\n",
       "      <td>9.433284</td>\n",
       "      <td>0.434506</td>\n",
       "      <td>21.710369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017</td>\n",
       "      <td>Paul George</td>\n",
       "      <td>SF</td>\n",
       "      <td>27</td>\n",
       "      <td>OKC</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "      <td>36.6</td>\n",
       "      <td>21.9</td>\n",
       "      <td>5.7</td>\n",
       "      <td>...</td>\n",
       "      <td>20.803492</td>\n",
       "      <td>6.384050</td>\n",
       "      <td>3.355529</td>\n",
       "      <td>1.493419</td>\n",
       "      <td>0.386995</td>\n",
       "      <td>2.441891</td>\n",
       "      <td>2.448160</td>\n",
       "      <td>7.033615</td>\n",
       "      <td>0.442657</td>\n",
       "      <td>15.889551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>Giannis Antetokounmpo</td>\n",
       "      <td>PF</td>\n",
       "      <td>23</td>\n",
       "      <td>MIL</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>36.7</td>\n",
       "      <td>26.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.212587</td>\n",
       "      <td>9.356313</td>\n",
       "      <td>5.376734</td>\n",
       "      <td>1.473798</td>\n",
       "      <td>1.590362</td>\n",
       "      <td>0.983095</td>\n",
       "      <td>2.786507</td>\n",
       "      <td>8.368180</td>\n",
       "      <td>0.500216</td>\n",
       "      <td>16.729118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017</td>\n",
       "      <td>Kemba Walker</td>\n",
       "      <td>PG</td>\n",
       "      <td>27</td>\n",
       "      <td>CHA</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>34.2</td>\n",
       "      <td>22.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>...</td>\n",
       "      <td>21.451133</td>\n",
       "      <td>3.812989</td>\n",
       "      <td>5.822505</td>\n",
       "      <td>1.278816</td>\n",
       "      <td>0.317090</td>\n",
       "      <td>2.615111</td>\n",
       "      <td>2.199115</td>\n",
       "      <td>7.284535</td>\n",
       "      <td>0.428161</td>\n",
       "      <td>17.013541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017</td>\n",
       "      <td>Anthony Davis</td>\n",
       "      <td>PF</td>\n",
       "      <td>24</td>\n",
       "      <td>NOP</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>36.4</td>\n",
       "      <td>28.1</td>\n",
       "      <td>11.1</td>\n",
       "      <td>...</td>\n",
       "      <td>24.297272</td>\n",
       "      <td>10.627323</td>\n",
       "      <td>2.032894</td>\n",
       "      <td>1.265319</td>\n",
       "      <td>2.012647</td>\n",
       "      <td>0.681795</td>\n",
       "      <td>2.087559</td>\n",
       "      <td>9.435100</td>\n",
       "      <td>0.503058</td>\n",
       "      <td>18.755478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2017</td>\n",
       "      <td>Ben Simmons</td>\n",
       "      <td>PG</td>\n",
       "      <td>21</td>\n",
       "      <td>PHI</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>33.7</td>\n",
       "      <td>15.8</td>\n",
       "      <td>8.1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017</td>\n",
       "      <td>Taj Gibson</td>\n",
       "      <td>PF</td>\n",
       "      <td>32</td>\n",
       "      <td>MIN</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>33.2</td>\n",
       "      <td>12.2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>...</td>\n",
       "      <td>8.276681</td>\n",
       "      <td>5.955375</td>\n",
       "      <td>0.939951</td>\n",
       "      <td>0.434538</td>\n",
       "      <td>0.881380</td>\n",
       "      <td>0.037532</td>\n",
       "      <td>1.067072</td>\n",
       "      <td>3.722588</td>\n",
       "      <td>0.485561</td>\n",
       "      <td>7.666564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017</td>\n",
       "      <td>DeMar DeRozan</td>\n",
       "      <td>SG</td>\n",
       "      <td>28</td>\n",
       "      <td>TOR</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>33.9</td>\n",
       "      <td>23.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>...</td>\n",
       "      <td>23.649061</td>\n",
       "      <td>4.748690</td>\n",
       "      <td>3.828381</td>\n",
       "      <td>1.008460</td>\n",
       "      <td>0.246408</td>\n",
       "      <td>0.708833</td>\n",
       "      <td>2.406721</td>\n",
       "      <td>8.578866</td>\n",
       "      <td>0.450647</td>\n",
       "      <td>19.036792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017</td>\n",
       "      <td>Josh Richardson</td>\n",
       "      <td>SF</td>\n",
       "      <td>24</td>\n",
       "      <td>MIA</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>33.2</td>\n",
       "      <td>12.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>...</td>\n",
       "      <td>10.058883</td>\n",
       "      <td>3.004024</td>\n",
       "      <td>2.499555</td>\n",
       "      <td>0.983135</td>\n",
       "      <td>0.584819</td>\n",
       "      <td>1.391632</td>\n",
       "      <td>1.014945</td>\n",
       "      <td>4.086767</td>\n",
       "      <td>0.421881</td>\n",
       "      <td>9.687004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017</td>\n",
       "      <td>Will Barton</td>\n",
       "      <td>SG</td>\n",
       "      <td>27</td>\n",
       "      <td>DEN</td>\n",
       "      <td>81</td>\n",
       "      <td>40</td>\n",
       "      <td>33.1</td>\n",
       "      <td>15.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.233425</td>\n",
       "      <td>3.823879</td>\n",
       "      <td>2.964711</td>\n",
       "      <td>0.745993</td>\n",
       "      <td>0.365664</td>\n",
       "      <td>1.405115</td>\n",
       "      <td>1.421671</td>\n",
       "      <td>4.363999</td>\n",
       "      <td>0.433982</td>\n",
       "      <td>10.055718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017</td>\n",
       "      <td>Damian Lillard</td>\n",
       "      <td>PG</td>\n",
       "      <td>27</td>\n",
       "      <td>POR</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>36.6</td>\n",
       "      <td>26.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>24.776748</td>\n",
       "      <td>4.736356</td>\n",
       "      <td>6.409089</td>\n",
       "      <td>1.007520</td>\n",
       "      <td>0.284603</td>\n",
       "      <td>2.803194</td>\n",
       "      <td>2.815054</td>\n",
       "      <td>8.443648</td>\n",
       "      <td>0.436872</td>\n",
       "      <td>19.327523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2017</td>\n",
       "      <td>Donovan Mitchell</td>\n",
       "      <td>SG</td>\n",
       "      <td>21</td>\n",
       "      <td>UTA</td>\n",
       "      <td>79</td>\n",
       "      <td>71</td>\n",
       "      <td>33.4</td>\n",
       "      <td>20.5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2017</td>\n",
       "      <td>Harrison Barnes</td>\n",
       "      <td>PF</td>\n",
       "      <td>25</td>\n",
       "      <td>DAL</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>34.2</td>\n",
       "      <td>18.9</td>\n",
       "      <td>6.1</td>\n",
       "      <td>...</td>\n",
       "      <td>16.005065</td>\n",
       "      <td>4.942816</td>\n",
       "      <td>1.624621</td>\n",
       "      <td>0.690560</td>\n",
       "      <td>0.272593</td>\n",
       "      <td>1.091115</td>\n",
       "      <td>1.244671</td>\n",
       "      <td>6.408246</td>\n",
       "      <td>0.461387</td>\n",
       "      <td>13.889094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2017</td>\n",
       "      <td>Andre Drummond</td>\n",
       "      <td>C</td>\n",
       "      <td>24</td>\n",
       "      <td>DET</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>33.7</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.108195</td>\n",
       "      <td>12.748314</td>\n",
       "      <td>1.662575</td>\n",
       "      <td>1.307551</td>\n",
       "      <td>1.216320</td>\n",
       "      <td>0.207336</td>\n",
       "      <td>1.833514</td>\n",
       "      <td>6.292370</td>\n",
       "      <td>0.528403</td>\n",
       "      <td>11.908289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2017</td>\n",
       "      <td>Thaddeus Young</td>\n",
       "      <td>PF</td>\n",
       "      <td>29</td>\n",
       "      <td>IND</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>32.2</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6.3</td>\n",
       "      <td>...</td>\n",
       "      <td>11.720784</td>\n",
       "      <td>6.631301</td>\n",
       "      <td>2.053927</td>\n",
       "      <td>1.280051</td>\n",
       "      <td>0.414142</td>\n",
       "      <td>0.594727</td>\n",
       "      <td>1.301011</td>\n",
       "      <td>4.833767</td>\n",
       "      <td>0.491354</td>\n",
       "      <td>9.837656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2017</td>\n",
       "      <td>Lou Williams</td>\n",
       "      <td>SG</td>\n",
       "      <td>31</td>\n",
       "      <td>LAC</td>\n",
       "      <td>79</td>\n",
       "      <td>19</td>\n",
       "      <td>32.8</td>\n",
       "      <td>22.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>15.539036</td>\n",
       "      <td>2.051214</td>\n",
       "      <td>2.862504</td>\n",
       "      <td>0.903204</td>\n",
       "      <td>0.162483</td>\n",
       "      <td>1.950792</td>\n",
       "      <td>1.916404</td>\n",
       "      <td>4.916362</td>\n",
       "      <td>0.428635</td>\n",
       "      <td>11.469807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2017</td>\n",
       "      <td>E'Twaun Moore</td>\n",
       "      <td>SG</td>\n",
       "      <td>28</td>\n",
       "      <td>NOP</td>\n",
       "      <td>82</td>\n",
       "      <td>80</td>\n",
       "      <td>31.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2.9</td>\n",
       "      <td>...</td>\n",
       "      <td>9.684365</td>\n",
       "      <td>2.738713</td>\n",
       "      <td>2.048276</td>\n",
       "      <td>0.779008</td>\n",
       "      <td>0.394348</td>\n",
       "      <td>1.191112</td>\n",
       "      <td>0.925065</td>\n",
       "      <td>3.629148</td>\n",
       "      <td>0.443171</td>\n",
       "      <td>8.189048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2017</td>\n",
       "      <td>Joe Ingles</td>\n",
       "      <td>SF</td>\n",
       "      <td>30</td>\n",
       "      <td>UTA</td>\n",
       "      <td>82</td>\n",
       "      <td>81</td>\n",
       "      <td>31.4</td>\n",
       "      <td>11.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>...</td>\n",
       "      <td>10.177309</td>\n",
       "      <td>3.973186</td>\n",
       "      <td>3.058129</td>\n",
       "      <td>1.195888</td>\n",
       "      <td>0.176177</td>\n",
       "      <td>1.626858</td>\n",
       "      <td>1.470644</td>\n",
       "      <td>3.620115</td>\n",
       "      <td>0.434615</td>\n",
       "      <td>8.329471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2017</td>\n",
       "      <td>Jamal Murray</td>\n",
       "      <td>PG</td>\n",
       "      <td>20</td>\n",
       "      <td>DEN</td>\n",
       "      <td>81</td>\n",
       "      <td>80</td>\n",
       "      <td>31.7</td>\n",
       "      <td>16.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>...</td>\n",
       "      <td>13.146134</td>\n",
       "      <td>3.819008</td>\n",
       "      <td>3.198023</td>\n",
       "      <td>0.887886</td>\n",
       "      <td>0.426608</td>\n",
       "      <td>1.669870</td>\n",
       "      <td>1.781454</td>\n",
       "      <td>5.274415</td>\n",
       "      <td>0.433794</td>\n",
       "      <td>12.158814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2017</td>\n",
       "      <td>Victor Oladipo</td>\n",
       "      <td>SG</td>\n",
       "      <td>25</td>\n",
       "      <td>IND</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>34.0</td>\n",
       "      <td>23.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>...</td>\n",
       "      <td>16.368678</td>\n",
       "      <td>4.701369</td>\n",
       "      <td>3.217625</td>\n",
       "      <td>1.282743</td>\n",
       "      <td>0.389234</td>\n",
       "      <td>1.742683</td>\n",
       "      <td>1.886925</td>\n",
       "      <td>6.020298</td>\n",
       "      <td>0.441826</td>\n",
       "      <td>13.625961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2017</td>\n",
       "      <td>James Harden</td>\n",
       "      <td>SG</td>\n",
       "      <td>28</td>\n",
       "      <td>HOU</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>35.4</td>\n",
       "      <td>30.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>...</td>\n",
       "      <td>28.414599</td>\n",
       "      <td>7.848828</td>\n",
       "      <td>9.517825</td>\n",
       "      <td>1.635248</td>\n",
       "      <td>0.497128</td>\n",
       "      <td>3.157945</td>\n",
       "      <td>4.724416</td>\n",
       "      <td>8.680771</td>\n",
       "      <td>0.444218</td>\n",
       "      <td>19.541687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2017</td>\n",
       "      <td>Robert Covington</td>\n",
       "      <td>SF</td>\n",
       "      <td>27</td>\n",
       "      <td>PHI</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>31.7</td>\n",
       "      <td>12.6</td>\n",
       "      <td>5.4</td>\n",
       "      <td>...</td>\n",
       "      <td>13.521885</td>\n",
       "      <td>6.163541</td>\n",
       "      <td>2.043629</td>\n",
       "      <td>1.598626</td>\n",
       "      <td>0.752208</td>\n",
       "      <td>2.093504</td>\n",
       "      <td>1.719987</td>\n",
       "      <td>4.619150</td>\n",
       "      <td>0.410840</td>\n",
       "      <td>11.243173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2017</td>\n",
       "      <td>LaMarcus Aldridge</td>\n",
       "      <td>C</td>\n",
       "      <td>32</td>\n",
       "      <td>SAS</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>33.5</td>\n",
       "      <td>23.1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>...</td>\n",
       "      <td>17.010211</td>\n",
       "      <td>7.349330</td>\n",
       "      <td>2.262703</td>\n",
       "      <td>0.642360</td>\n",
       "      <td>1.039687</td>\n",
       "      <td>0.337631</td>\n",
       "      <td>1.575999</td>\n",
       "      <td>6.866074</td>\n",
       "      <td>0.468655</td>\n",
       "      <td>14.650599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>2017</td>\n",
       "      <td>Kendrick Perkins</td>\n",
       "      <td>C</td>\n",
       "      <td>33</td>\n",
       "      <td>CLE</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>2017</td>\n",
       "      <td>Devin Robinson</td>\n",
       "      <td>SF</td>\n",
       "      <td>22</td>\n",
       "      <td>WAS</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>2017</td>\n",
       "      <td>Luol Deng</td>\n",
       "      <td>SF</td>\n",
       "      <td>32</td>\n",
       "      <td>LAL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>2017</td>\n",
       "      <td>Tim Quarterman</td>\n",
       "      <td>SG</td>\n",
       "      <td>23</td>\n",
       "      <td>HOU</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>2017</td>\n",
       "      <td>Josh Smith</td>\n",
       "      <td>PF</td>\n",
       "      <td>32</td>\n",
       "      <td>NOP</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>2017</td>\n",
       "      <td>Matt Williams</td>\n",
       "      <td>SG</td>\n",
       "      <td>24</td>\n",
       "      <td>MIA</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>2017</td>\n",
       "      <td>Nicolas Brussino</td>\n",
       "      <td>SF</td>\n",
       "      <td>24</td>\n",
       "      <td>ATL</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>2017</td>\n",
       "      <td>Derrick Williams</td>\n",
       "      <td>PF</td>\n",
       "      <td>26</td>\n",
       "      <td>LAL</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>2017</td>\n",
       "      <td>David Stockton</td>\n",
       "      <td>PG</td>\n",
       "      <td>26</td>\n",
       "      <td>UTA</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>2017</td>\n",
       "      <td>Ben Moore</td>\n",
       "      <td>PF</td>\n",
       "      <td>22</td>\n",
       "      <td>IND</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>2017</td>\n",
       "      <td>Scotty Hopson</td>\n",
       "      <td>SG</td>\n",
       "      <td>28</td>\n",
       "      <td>DAL</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>2017</td>\n",
       "      <td>Erik McCree</td>\n",
       "      <td>SF</td>\n",
       "      <td>24</td>\n",
       "      <td>UTA</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>2017</td>\n",
       "      <td>Luis Montero</td>\n",
       "      <td>SG</td>\n",
       "      <td>24</td>\n",
       "      <td>DET</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>2017</td>\n",
       "      <td>Vince Hunter</td>\n",
       "      <td>PF</td>\n",
       "      <td>23</td>\n",
       "      <td>MEM</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>2017</td>\n",
       "      <td>Xavier Silas</td>\n",
       "      <td>SG</td>\n",
       "      <td>30</td>\n",
       "      <td>BOS</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>2017</td>\n",
       "      <td>Reggie Hearn</td>\n",
       "      <td>SG</td>\n",
       "      <td>26</td>\n",
       "      <td>DET</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>2017</td>\n",
       "      <td>Jacob Pullen</td>\n",
       "      <td>PG</td>\n",
       "      <td>28</td>\n",
       "      <td>PHI</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>2017</td>\n",
       "      <td>Josh McRoberts</td>\n",
       "      <td>PF</td>\n",
       "      <td>30</td>\n",
       "      <td>DAL</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>2017</td>\n",
       "      <td>Jarell Eddie</td>\n",
       "      <td>SF</td>\n",
       "      <td>26</td>\n",
       "      <td>BOS</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>2017</td>\n",
       "      <td>Gordon Hayward</td>\n",
       "      <td>SF</td>\n",
       "      <td>27</td>\n",
       "      <td>BOS</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>2017</td>\n",
       "      <td>Jeremy Evans</td>\n",
       "      <td>SF</td>\n",
       "      <td>30</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>2017</td>\n",
       "      <td>Anthony Brown</td>\n",
       "      <td>SF</td>\n",
       "      <td>25</td>\n",
       "      <td>MIN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>2017</td>\n",
       "      <td>Justin Patton</td>\n",
       "      <td>C</td>\n",
       "      <td>20</td>\n",
       "      <td>MIN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>2017</td>\n",
       "      <td>PJ Dozier</td>\n",
       "      <td>PG</td>\n",
       "      <td>21</td>\n",
       "      <td>OKC</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>2017</td>\n",
       "      <td>Mindaugas Kuzminskas</td>\n",
       "      <td>SF</td>\n",
       "      <td>28</td>\n",
       "      <td>NYK</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>2017</td>\n",
       "      <td>Edmond Sumner</td>\n",
       "      <td>PG</td>\n",
       "      <td>22</td>\n",
       "      <td>IND</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>2017</td>\n",
       "      <td>Tyler Lydon</td>\n",
       "      <td>PF</td>\n",
       "      <td>21</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>2017</td>\n",
       "      <td>Naz Mitrou-Long</td>\n",
       "      <td>SG</td>\n",
       "      <td>24</td>\n",
       "      <td>UTA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>2017</td>\n",
       "      <td>Chris Boucher</td>\n",
       "      <td>PF</td>\n",
       "      <td>25</td>\n",
       "      <td>GSW</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>2017</td>\n",
       "      <td>Trey McKinney-Jones</td>\n",
       "      <td>SG</td>\n",
       "      <td>27</td>\n",
       "      <td>IND</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows  31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     season                 player position  age team  gamesPlayed  \\\n",
       "0      2017           LeBron James       PF   33  CLE           82   \n",
       "1      2017        Khris Middleton       SF   26  MIL           82   \n",
       "2      2017           Bradley Beal       SG   24  WAS           82   \n",
       "3      2017         Andrew Wiggins       SF   22  MIN           82   \n",
       "4      2017            CJ McCollum       SG   26  POR           81   \n",
       "5      2017           Jrue Holiday       SG   27  NOP           81   \n",
       "6      2017     Karl-Anthony Towns        C   22  MIN           82   \n",
       "7      2017      Russell Westbrook       PG   29  OKC           80   \n",
       "8      2017            Paul George       SF   27  OKC           79   \n",
       "9      2017  Giannis Antetokounmpo       PF   23  MIL           75   \n",
       "10     2017           Kemba Walker       PG   27  CHA           80   \n",
       "11     2017          Anthony Davis       PF   24  NOP           75   \n",
       "12     2017            Ben Simmons       PG   21  PHI           81   \n",
       "13     2017             Taj Gibson       PF   32  MIN           82   \n",
       "14     2017          DeMar DeRozan       SG   28  TOR           80   \n",
       "15     2017        Josh Richardson       SF   24  MIA           81   \n",
       "16     2017            Will Barton       SG   27  DEN           81   \n",
       "17     2017         Damian Lillard       PG   27  POR           73   \n",
       "18     2017       Donovan Mitchell       SG   21  UTA           79   \n",
       "19     2017        Harrison Barnes       PF   25  DAL           77   \n",
       "20     2017         Andre Drummond        C   24  DET           78   \n",
       "21     2017         Thaddeus Young       PF   29  IND           81   \n",
       "22     2017           Lou Williams       SG   31  LAC           79   \n",
       "23     2017          E'Twaun Moore       SG   28  NOP           82   \n",
       "24     2017             Joe Ingles       SF   30  UTA           82   \n",
       "25     2017           Jamal Murray       PG   20  DEN           81   \n",
       "26     2017         Victor Oladipo       SG   25  IND           75   \n",
       "27     2017           James Harden       SG   28  HOU           72   \n",
       "28     2017       Robert Covington       SF   27  PHI           80   \n",
       "29     2017      LaMarcus Aldridge        C   32  SAS           75   \n",
       "..      ...                    ...      ...  ...  ...          ...   \n",
       "510    2017       Kendrick Perkins        C   33  CLE            1   \n",
       "511    2017         Devin Robinson       SF   22  WAS            1   \n",
       "512    2017              Luol Deng       SF   32  LAL            1   \n",
       "513    2017         Tim Quarterman       SG   23  HOU            3   \n",
       "514    2017             Josh Smith       PF   32  NOP            3   \n",
       "515    2017          Matt Williams       SG   24  MIA            3   \n",
       "516    2017       Nicolas Brussino       SF   24  ATL            4   \n",
       "517    2017       Derrick Williams       PF   26  LAL            2   \n",
       "518    2017         David Stockton       PG   26  UTA            3   \n",
       "519    2017              Ben Moore       PF   22  IND            2   \n",
       "520    2017          Scotty Hopson       SG   28  DAL            1   \n",
       "521    2017            Erik McCree       SF   24  UTA            4   \n",
       "522    2017           Luis Montero       SG   24  DET            2   \n",
       "523    2017           Vince Hunter       PF   23  MEM            4   \n",
       "524    2017           Xavier Silas       SG   30  BOS            2   \n",
       "525    2017           Reggie Hearn       SG   26  DET            3   \n",
       "526    2017           Jacob Pullen       PG   28  PHI            3   \n",
       "527    2017         Josh McRoberts       PF   30  DAL            2   \n",
       "528    2017           Jarell Eddie       SF   26  BOS            3   \n",
       "529    2017         Gordon Hayward       SF   27  BOS            1   \n",
       "530    2017           Jeremy Evans       SF   30  ATL            1   \n",
       "531    2017          Anthony Brown       SF   25  MIN            1   \n",
       "532    2017          Justin Patton        C   20  MIN            1   \n",
       "533    2017              PJ Dozier       PG   21  OKC            2   \n",
       "534    2017   Mindaugas Kuzminskas       SF   28  NYK            1   \n",
       "535    2017          Edmond Sumner       PG   22  IND            1   \n",
       "536    2017            Tyler Lydon       PF   21  DEN            1   \n",
       "537    2017        Naz Mitrou-Long       SG   24  UTA            1   \n",
       "538    2017          Chris Boucher       PF   25  GSW            1   \n",
       "539    2017    Trey McKinney-Jones       SG   27  IND            1   \n",
       "\n",
       "     gamesStarted  minutes  points  rebounds       ...        \\\n",
       "0              82     36.9    27.5       8.6       ...         \n",
       "1              82     36.4    20.1       5.2       ...         \n",
       "2              82     36.3    22.6       4.4       ...         \n",
       "3              82     36.3    17.7       4.4       ...         \n",
       "4              81     36.1    21.4       4.0       ...         \n",
       "5              81     36.1    19.0       4.5       ...         \n",
       "6              82     35.6    21.3      12.3       ...         \n",
       "7              80     36.4    25.4      10.1       ...         \n",
       "8              79     36.6    21.9       5.7       ...         \n",
       "9              75     36.7    26.9      10.0       ...         \n",
       "10             80     34.2    22.1       3.1       ...         \n",
       "11             75     36.4    28.1      11.1       ...         \n",
       "12             81     33.7    15.8       8.1       ...         \n",
       "13             82     33.2    12.2       7.1       ...         \n",
       "14             80     33.9    23.0       3.9       ...         \n",
       "15             81     33.2    12.9       3.5       ...         \n",
       "16             40     33.1    15.7       5.0       ...         \n",
       "17             73     36.6    26.9       4.5       ...         \n",
       "18             71     33.4    20.5       3.7       ...         \n",
       "19             77     34.2    18.9       6.1       ...         \n",
       "20             78     33.7    15.0      16.0       ...         \n",
       "21             81     32.2    11.8       6.3       ...         \n",
       "22             19     32.8    22.6       2.5       ...         \n",
       "23             80     31.5    12.5       2.9       ...         \n",
       "24             81     31.4    11.5       4.2       ...         \n",
       "25             80     31.7    16.7       3.7       ...         \n",
       "26             75     34.0    23.1       5.2       ...         \n",
       "27             72     35.4    30.4       5.4       ...         \n",
       "28             80     31.7    12.6       5.4       ...         \n",
       "29             75     33.5    23.1       8.5       ...         \n",
       "..            ...      ...     ...       ...       ...         \n",
       "510             0     15.0     3.0       1.0       ...         \n",
       "511             0     13.0     2.0       5.0       ...         \n",
       "512             1     13.0     2.0       0.0       ...         \n",
       "513             0      4.3     1.3       1.0       ...         \n",
       "514             0      4.0     0.7       1.3       ...         \n",
       "515             0      3.7     1.7       0.3       ...         \n",
       "516             0      2.5     0.0       0.8       ...         \n",
       "517             0      4.5     1.0       0.5       ...         \n",
       "518             0      3.0     3.3       0.0       ...         \n",
       "519             0      4.5     0.0       0.5       ...         \n",
       "520             0      8.0     1.0       0.0       ...         \n",
       "521             0      2.0     0.0       0.3       ...         \n",
       "522             0      4.0     0.0       1.0       ...         \n",
       "523             0      1.8     1.5       0.8       ...         \n",
       "524             0      3.5     0.0       1.0       ...         \n",
       "525             0      2.3     1.0       0.0       ...         \n",
       "526             0      2.0     0.7       0.0       ...         \n",
       "527             0      3.0     0.0       0.0       ...         \n",
       "528             0      3.0     0.0       0.5       ...         \n",
       "529             1      5.0     2.0       1.0       ...         \n",
       "530             0      5.0     2.0       1.0       ...         \n",
       "531             0      4.0     3.0       0.0       ...         \n",
       "532             0      4.0     2.0       0.0       ...         \n",
       "533             0      1.5     1.0       0.5       ...         \n",
       "534             0      2.0     0.0       0.0       ...         \n",
       "535             0      2.0     2.0       1.0       ...         \n",
       "536             0      2.0     0.0       0.0       ...         \n",
       "537             0      1.0     3.0       0.0       ...         \n",
       "538             0      1.0     0.0       1.0       ...         \n",
       "539             0      1.0     0.0       0.0       ...         \n",
       "\n",
       "     point_prediction1  rebound_prediction  assist_prediction  \\\n",
       "0            24.870920            8.404722           8.170845   \n",
       "1            13.640875            3.901478           2.844345   \n",
       "2            21.028357            3.640051           3.421147   \n",
       "3            20.456723            3.821239           2.183822   \n",
       "4            20.253920            3.537566           3.537808   \n",
       "5            13.656572            3.484355           5.860924   \n",
       "6            23.705239           11.656341           3.322843   \n",
       "7            28.462095           10.150878          10.620148   \n",
       "8            20.803492            6.384050           3.355529   \n",
       "9            22.212587            9.356313           5.376734   \n",
       "10           21.451133            3.812989           5.822505   \n",
       "11           24.297272           10.627323           2.032894   \n",
       "12                 NaN                 NaN                NaN   \n",
       "13            8.276681            5.955375           0.939951   \n",
       "14           23.649061            4.748690           3.828381   \n",
       "15           10.058883            3.004024           2.499555   \n",
       "16           12.233425            3.823879           2.964711   \n",
       "17           24.776748            4.736356           6.409089   \n",
       "18                 NaN                 NaN                NaN   \n",
       "19           16.005065            4.942816           1.624621   \n",
       "20           15.108195           12.748314           1.662575   \n",
       "21           11.720784            6.631301           2.053927   \n",
       "22           15.539036            2.051214           2.862504   \n",
       "23            9.684365            2.738713           2.048276   \n",
       "24           10.177309            3.973186           3.058129   \n",
       "25           13.146134            3.819008           3.198023   \n",
       "26           16.368678            4.701369           3.217625   \n",
       "27           28.414599            7.848828           9.517825   \n",
       "28           13.521885            6.163541           2.043629   \n",
       "29           17.010211            7.349330           2.262703   \n",
       "..                 ...                 ...                ...   \n",
       "510                NaN                 NaN                NaN   \n",
       "511                NaN                 NaN                NaN   \n",
       "512                NaN                 NaN                NaN   \n",
       "513                NaN                 NaN                NaN   \n",
       "514                NaN                 NaN                NaN   \n",
       "515                NaN                 NaN                NaN   \n",
       "516                NaN                 NaN                NaN   \n",
       "517                NaN                 NaN                NaN   \n",
       "518                NaN                 NaN                NaN   \n",
       "519                NaN                 NaN                NaN   \n",
       "520                NaN                 NaN                NaN   \n",
       "521                NaN                 NaN                NaN   \n",
       "522                NaN                 NaN                NaN   \n",
       "523                NaN                 NaN                NaN   \n",
       "524                NaN                 NaN                NaN   \n",
       "525                NaN                 NaN                NaN   \n",
       "526                NaN                 NaN                NaN   \n",
       "527                NaN                 NaN                NaN   \n",
       "528                NaN                 NaN                NaN   \n",
       "529                NaN                 NaN                NaN   \n",
       "530                NaN                 NaN                NaN   \n",
       "531                NaN                 NaN                NaN   \n",
       "532                NaN                 NaN                NaN   \n",
       "533                NaN                 NaN                NaN   \n",
       "534                NaN                 NaN                NaN   \n",
       "535                NaN                 NaN                NaN   \n",
       "536                NaN                 NaN                NaN   \n",
       "537                NaN                 NaN                NaN   \n",
       "538                NaN                 NaN                NaN   \n",
       "539                NaN                 NaN                NaN   \n",
       "\n",
       "     steal_prediction  block_predictions  three_prediction  \\\n",
       "0            1.345292           0.612607          1.647424   \n",
       "1            1.227558           0.166228          1.536074   \n",
       "2            1.077844           0.303437          2.646208   \n",
       "3            0.951058           0.449024          1.230865   \n",
       "4            0.920871           0.399520          2.248571   \n",
       "5            1.326976           0.524537          1.430401   \n",
       "6            0.888906           1.328844          1.251075   \n",
       "7            1.909999           0.370554          2.378485   \n",
       "8            1.493419           0.386995          2.441891   \n",
       "9            1.473798           1.590362          0.983095   \n",
       "10           1.278816           0.317090          2.615111   \n",
       "11           1.265319           2.012647          0.681795   \n",
       "12                NaN                NaN               NaN   \n",
       "13           0.434538           0.881380          0.037532   \n",
       "14           1.008460           0.246408          0.708833   \n",
       "15           0.983135           0.584819          1.391632   \n",
       "16           0.745993           0.365664          1.405115   \n",
       "17           1.007520           0.284603          2.803194   \n",
       "18                NaN                NaN               NaN   \n",
       "19           0.690560           0.272593          1.091115   \n",
       "20           1.307551           1.216320          0.207336   \n",
       "21           1.280051           0.414142          0.594727   \n",
       "22           0.903204           0.162483          1.950792   \n",
       "23           0.779008           0.394348          1.191112   \n",
       "24           1.195888           0.176177          1.626858   \n",
       "25           0.887886           0.426608          1.669870   \n",
       "26           1.282743           0.389234          1.742683   \n",
       "27           1.635248           0.497128          3.157945   \n",
       "28           1.598626           0.752208          2.093504   \n",
       "29           0.642360           1.039687          0.337631   \n",
       "..                ...                ...               ...   \n",
       "510               NaN                NaN               NaN   \n",
       "511               NaN                NaN               NaN   \n",
       "512               NaN                NaN               NaN   \n",
       "513               NaN                NaN               NaN   \n",
       "514               NaN                NaN               NaN   \n",
       "515               NaN                NaN               NaN   \n",
       "516               NaN                NaN               NaN   \n",
       "517               NaN                NaN               NaN   \n",
       "518               NaN                NaN               NaN   \n",
       "519               NaN                NaN               NaN   \n",
       "520               NaN                NaN               NaN   \n",
       "521               NaN                NaN               NaN   \n",
       "522               NaN                NaN               NaN   \n",
       "523               NaN                NaN               NaN   \n",
       "524               NaN                NaN               NaN   \n",
       "525               NaN                NaN               NaN   \n",
       "526               NaN                NaN               NaN   \n",
       "527               NaN                NaN               NaN   \n",
       "528               NaN                NaN               NaN   \n",
       "529               NaN                NaN               NaN   \n",
       "530               NaN                NaN               NaN   \n",
       "531               NaN                NaN               NaN   \n",
       "532               NaN                NaN               NaN   \n",
       "533               NaN                NaN               NaN   \n",
       "534               NaN                NaN               NaN   \n",
       "535               NaN                NaN               NaN   \n",
       "536               NaN                NaN               NaN   \n",
       "537               NaN                NaN               NaN   \n",
       "538               NaN                NaN               NaN   \n",
       "539               NaN                NaN               NaN   \n",
       "\n",
       "     turnover_prediction  FGM_prediction  FGP_prediction  FGA_prediction  \n",
       "0               3.552995        9.330926        0.505386       18.462954  \n",
       "1               1.818488        4.960662        0.451003       10.999172  \n",
       "2               2.034305        7.402198        0.460459       16.075688  \n",
       "3               2.170531        7.529388        0.461304       16.321960  \n",
       "4               2.156241        7.565362        0.461679       16.386628  \n",
       "5               2.249917        5.137229        0.447882       11.470059  \n",
       "6               2.640501        9.765563        0.530322       18.414395  \n",
       "7               4.366154        9.433284        0.434506       21.710369  \n",
       "8               2.448160        7.033615        0.442657       15.889551  \n",
       "9               2.786507        8.368180        0.500216       16.729118  \n",
       "10              2.199115        7.284535        0.428161       17.013541  \n",
       "11              2.087559        9.435100        0.503058       18.755478  \n",
       "12                   NaN             NaN             NaN             NaN  \n",
       "13              1.067072        3.722588        0.485561        7.666564  \n",
       "14              2.406721        8.578866        0.450647       19.036792  \n",
       "15              1.014945        4.086767        0.421881        9.687004  \n",
       "16              1.421671        4.363999        0.433982       10.055718  \n",
       "17              2.815054        8.443648        0.436872       19.327523  \n",
       "18                   NaN             NaN             NaN             NaN  \n",
       "19              1.244671        6.408246        0.461387       13.889094  \n",
       "20              1.833514        6.292370        0.528403       11.908289  \n",
       "21              1.301011        4.833767        0.491354        9.837656  \n",
       "22              1.916404        4.916362        0.428635       11.469807  \n",
       "23              0.925065        3.629148        0.443171        8.189048  \n",
       "24              1.470644        3.620115        0.434615        8.329471  \n",
       "25              1.781454        5.274415        0.433794       12.158814  \n",
       "26              1.886925        6.020298        0.441826       13.625961  \n",
       "27              4.724416        8.680771        0.444218       19.541687  \n",
       "28              1.719987        4.619150        0.410840       11.243173  \n",
       "29              1.575999        6.866074        0.468655       14.650599  \n",
       "..                   ...             ...             ...             ...  \n",
       "510                  NaN             NaN             NaN             NaN  \n",
       "511                  NaN             NaN             NaN             NaN  \n",
       "512                  NaN             NaN             NaN             NaN  \n",
       "513                  NaN             NaN             NaN             NaN  \n",
       "514                  NaN             NaN             NaN             NaN  \n",
       "515                  NaN             NaN             NaN             NaN  \n",
       "516                  NaN             NaN             NaN             NaN  \n",
       "517                  NaN             NaN             NaN             NaN  \n",
       "518                  NaN             NaN             NaN             NaN  \n",
       "519                  NaN             NaN             NaN             NaN  \n",
       "520                  NaN             NaN             NaN             NaN  \n",
       "521                  NaN             NaN             NaN             NaN  \n",
       "522                  NaN             NaN             NaN             NaN  \n",
       "523                  NaN             NaN             NaN             NaN  \n",
       "524                  NaN             NaN             NaN             NaN  \n",
       "525                  NaN             NaN             NaN             NaN  \n",
       "526                  NaN             NaN             NaN             NaN  \n",
       "527                  NaN             NaN             NaN             NaN  \n",
       "528                  NaN             NaN             NaN             NaN  \n",
       "529                  NaN             NaN             NaN             NaN  \n",
       "530                  NaN             NaN             NaN             NaN  \n",
       "531                  NaN             NaN             NaN             NaN  \n",
       "532                  NaN             NaN             NaN             NaN  \n",
       "533                  NaN             NaN             NaN             NaN  \n",
       "534                  NaN             NaN             NaN             NaN  \n",
       "535                  NaN             NaN             NaN             NaN  \n",
       "536                  NaN             NaN             NaN             NaN  \n",
       "537                  NaN             NaN             NaN             NaN  \n",
       "538                  NaN             NaN             NaN             NaN  \n",
       "539                  NaN             NaN             NaN             NaN  \n",
       "\n",
       "[540 rows x 31 columns]"
      ]
     },
     "execution_count": 1154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017['FGA_prediction']=df_2017['FGM_prediction']/df_2017['FGP_prediction']\n",
    "df_2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE using LR:0.00220035043182581\n",
      "MSE using GB:0.002230171251758615\n",
      "MSE using NN:0.004654242109894819\n",
      "MSE using combo:0.002452064257550974\n",
      "MSE using mean:0.004468180392374211\n",
      "MSE using last year stats:0.0029957528880071352\n"
     ]
    }
   ],
   "source": [
    "print('MSE using LR:{}'.format(np.mean((test_3['FG_percent']-test_3['LR_pred'])**2)))\n",
    "print('MSE using GB:{}'.format(np.mean((test_3['FG_percent']-test_3['gbr_pred'])**2)))\n",
    "print('MSE using NN:{}'.format(np.mean((test_3['FG_percent']-test_3['predictions'])**2)))\n",
    "print('MSE using combo:{}'.format(np.mean((test_3['FG_percent']-test_3['mean_pred'])**2)))\n",
    "print('MSE using mean:{}'.format(np.mean((test_3['FG_percent']-np.mean(test_3['FG_percent']))**2)))\n",
    "print('MSE using last year stats:{}'.format(np.mean((test_3['FG_percent']-test_3['FG_percent_ly_x'])**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = percentages[(percentages['season']!=2017) & (percentages['Games']>30)].drop(['player','team','FGM','FGA','FG_percent','FTM','FTA','Games'],axis=1)\n",
    "y = percentages[(percentages['season']!=2017) & (percentages['Games']>30)]['FTM']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1564/1564 [==============================] - 4s 3ms/step - loss: 380.5611\n",
      "Epoch 2/10\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 129.7028\n",
      "Epoch 3/10\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 62.3981\n",
      "Epoch 4/10\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 35.4176\n",
      "Epoch 5/10\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 22.3636\n",
      "Epoch 6/10\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 13.4869\n",
      "Epoch 7/10\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 8.7304\n",
      "Epoch 8/10\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 6.0450\n",
      "Epoch 9/10\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 4.6568\n",
      "Epoch 10/10\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 3.9467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a4c7bad30>"
      ]
     },
     "execution_count": 1157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_FTM = Sequential()\n",
    "NN_FTM.add(Dense(units=32,input_dim=X_train.shape[1],activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_FTM.add(Dense(units=16, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_FTM.add(Dense(units=8, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_FTM.add(Dense(units=1,activation='linear'))\n",
    "NN_FTM.compile(loss='mse', optimizer='adam')\n",
    "NN_FTM.fit(np.array(X_train), np.array(y_train), epochs=1000,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN_predictions</th>\n",
       "      <th>actual</th>\n",
       "      <th>GBR_predictions</th>\n",
       "      <th>LY_FTM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>2.987642</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.862760</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>-0.546500</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.730544</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>1.268108</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.279532</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3.036972</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.419854</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>2.156424</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.440988</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>3.378700</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.834485</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>1.816694</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.889511</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.345463</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.761153</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>0.589378</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.218305</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.682622</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.874601</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>1.305045</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.135250</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>0.751235</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.516119</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>2.239821</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.143393</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>0.730624</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.593563</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>2.315043</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.067054</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>0.178474</td>\n",
       "      <td>5.9</td>\n",
       "      <td>4.177602</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>2.087675</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.561208</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>2.119854</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.249931</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>2.567499</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.846190</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>-2.347950</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.534189</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>-0.630472</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.211777</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1.414842</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.301092</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>2.885428</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.341556</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1.114084</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.272351</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>2.854997</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.403324</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1.763830</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.304760</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>1.453579</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.080727</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1.846123</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.414183</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>1.959492</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.294819</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>3.414144</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.569999</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>4.499940</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.001913</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>3.462109</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.257023</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>2.158352</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.330257</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2.631491</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.643606</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>1.387059</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.200958</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>1.192924</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.525091</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>3.272317</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.068415</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1.877584</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.243318</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>2.889882</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.001874</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>2.110543</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.147568</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.887239</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.376346</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0.361717</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.356269</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>3.088728</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.236683</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2.382794</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.300615</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>2.143363</td>\n",
       "      <td>3.4</td>\n",
       "      <td>2.805951</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2.939225</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.428051</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>1.945095</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.171069</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>1.814803</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.806572</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>4.320148</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.699480</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>0.352614</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.656996</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     NN_predictions  actual  GBR_predictions  LY_FTM\n",
       "513        2.987642     1.9         3.862760     4.2\n",
       "523       -0.546500     3.5         3.730544     4.0\n",
       "492        1.268108     4.3         4.279532     4.0\n",
       "31         3.036972     2.8         3.419854     4.0\n",
       "275        2.156424     3.8         4.440988     3.9\n",
       "358        3.378700     3.1         3.834485     3.9\n",
       "188        1.816694     3.5         3.889511     3.9\n",
       "110        0.345463     3.3         3.761153     3.8\n",
       "216        0.589378     3.1         3.218305     3.8\n",
       "71         0.682622     3.6         3.874601     3.8\n",
       "264        1.305045     4.6         4.135250     3.8\n",
       "338        0.751235     2.7         3.516119     3.7\n",
       "504        2.239821     2.9         3.143393     3.7\n",
       "572        0.730624     2.8         3.593563     3.7\n",
       "529        2.315043     2.9         3.067054     3.7\n",
       "224        0.178474     5.9         4.177602     3.7\n",
       "228        2.087675     3.1         2.561208     3.6\n",
       "320        2.119854     3.1         3.249931     3.6\n",
       "205        2.567499     3.4         3.846190     3.6\n",
       "546       -2.347950     3.2         3.534189     3.6\n",
       "266       -0.630472     3.1         3.211777     3.5\n",
       "566        1.414842     2.5         3.301092     3.5\n",
       "151        2.885428     5.4         3.341556     3.5\n",
       "90         1.114084     4.1         3.272351     3.5\n",
       "412        2.854997     1.1         2.403324     3.5\n",
       "52         1.763830     1.5         2.304760     3.4\n",
       "666        1.453579     3.1         3.080727     3.4\n",
       "62         1.846123     4.2         4.414183     3.4\n",
       "630        1.959492     4.3         3.294819     3.4\n",
       "116        3.414144     3.4         3.569999     3.4\n",
       "210        4.499940     3.9         3.001913     3.4\n",
       "327        3.462109     3.9         3.257023     3.4\n",
       "226        2.158352     1.2         2.330257     3.3\n",
       "60         2.631491     5.9         3.643606     3.3\n",
       "638        1.387059     2.8         3.200958     3.3\n",
       "531        1.192924     2.9         3.525091     3.3\n",
       "453        3.272317     3.1         3.068415     3.3\n",
       "32         1.877584     4.8         3.243318     3.2\n",
       "493        2.889882     2.2         3.001874     3.2\n",
       "365        2.110543     1.5         3.147568     3.2\n",
       "17         0.887239     3.3         2.376346     3.2\n",
       "474        0.361717     2.6         2.356269     3.2\n",
       "118        3.088728     2.2         3.236683     3.2\n",
       "103        2.382794     2.9         2.300615     3.2\n",
       "590        2.143363     3.4         2.805951     3.2\n",
       "246        2.939225     2.0         2.428051     3.2\n",
       "109        1.945095     3.0         3.171069     3.2\n",
       "306        1.814803     3.3         2.806572     3.2\n",
       "425        4.320148     3.2         2.699480     3.2\n",
       "310        0.352614     2.8         2.656996     3.2"
      ]
     },
     "execution_count": 1158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = NN_FTM.predict(X_test)\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.5)\n",
    "gbr.fit(X_train,y_train)\n",
    "gbr_predictions = gbr.predict(X_test)\n",
    "LR = LinearRegression(fit_intercept=True).fit(X_train,y_train)\n",
    "\n",
    "testing = pd.DataFrame(predictions)\n",
    "testing.columns=['NN_predictions']\n",
    "testing['actual'] = y_test.reset_index()['FTM']\n",
    "testing['GBR_predictions']=gbr_predictions\n",
    "testing['LY_FTM']=X_test['FTM_ly'].reset_index()['FTM_ly']\n",
    "testing.sort_values(by='LY_FTM',ascending=False)[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1159,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2017FTM = percentages[percentages['season']==2017].drop(['player','team','FGM','FGA','FG_percent','FTM','FTA','Games'],axis=1)\n",
    "#pred_2017blocks = blocks[blocks['season']==2017][['blocks_ly','career_blocks','starter_change']]\n",
    "FTM_2017 = NN_FTM.predict(pred_2017FTM)\n",
    "gbr_FTM_2017 = pd.DataFrame(gbr.predict(pred_2017FTM))\n",
    "LR_FTM_2017 = pd.DataFrame(LR.predict(pred_2017FTM))\n",
    "test_2 =pd.DataFrame(FTM_2017)\n",
    "test_3 = pd.merge(percentages,pred_2017FTM,left_index=True,right_index=True).reset_index()\n",
    "test_3['predictions']=test_2[0]\n",
    "test_3['gbr_pred'] = gbr_FTM_2017[0]\n",
    "test_3['LR_pred'] = LR_FTM_2017[0]\n",
    "test_3['mean_pred'] = (test_3['predictions']+test_3['gbr_pred']+test_3['LR_pred'])/3\n",
    "test_3 = test_3[test_3['Games']>30]\n",
    "test_3[['player','FTM','predictions','LR_pred','gbr_pred','mean_pred','FTM_ly_x']].sort_values(by='FTM_ly_x',ascending=False)[0:50]\n",
    "\n",
    "FTM_2017 = test_3[['player','LR_pred']]\n",
    "FTM_2017.columns=['player','FTM_predictions']\n",
    "df_2017 = pd.merge(df_2017,FTM_2017,how='left',left_on='player',right_on='player')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE using LR:0.42001895430317404\n",
      "MSE using GB:0.37678979516194644\n",
      "MSE using NN:3.351381637518095\n",
      "MSE using combo:0.6675173816778073\n",
      "MSE using mean:1.8538198553583185\n",
      "MSE using last year stats:0.6499358974358973\n"
     ]
    }
   ],
   "source": [
    "print('MSE using LR:{}'.format(np.mean((test_3['FTM']-test_3['LR_pred'])**2)))\n",
    "print('MSE using GB:{}'.format(np.mean((test_3['FTM']-test_3['gbr_pred'])**2)))\n",
    "print('MSE using NN:{}'.format(np.mean((test_3['FTM']-test_3['predictions'])**2)))\n",
    "print('MSE using combo:{}'.format(np.mean((test_3['FTM']-test_3['mean_pred'])**2)))\n",
    "print('MSE using mean:{}'.format(np.mean((test_3['FTM']-np.mean(test_3['FTM']))**2)))\n",
    "print('MSE using last year stats:{}'.format(np.mean((test_3['FTM']-test_3['FTM_ly_x'])**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1161,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = percentages[(percentages['season']!=2017) & (percentages['Games']>30)][['FT_percent_ly','career_FTPercent','yearspro']]\n",
    "y = percentages[(percentages['season']!=2017) & (percentages['Games']>30)]['FT_percent']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1564/1564 [==============================] - 4s 3ms/step - loss: 0.1908\n",
      "Epoch 2/25\n",
      "1564/1564 [==============================] - 0s 90us/step - loss: 0.0657\n",
      "Epoch 3/25\n",
      "1564/1564 [==============================] - 0s 86us/step - loss: 0.0343\n",
      "Epoch 4/25\n",
      "1564/1564 [==============================] - 0s 87us/step - loss: 0.0193\n",
      "Epoch 5/25\n",
      "1564/1564 [==============================] - 0s 93us/step - loss: 0.0141\n",
      "Epoch 6/25\n",
      "1564/1564 [==============================] - 0s 90us/step - loss: 0.0128\n",
      "Epoch 7/25\n",
      "1564/1564 [==============================] - 0s 86us/step - loss: 0.0125\n",
      "Epoch 8/25\n",
      "1564/1564 [==============================] - 0s 86us/step - loss: 0.0124\n",
      "Epoch 9/25\n",
      "1564/1564 [==============================] - 0s 89us/step - loss: 0.0123\n",
      "Epoch 10/25\n",
      "1564/1564 [==============================] - 0s 89us/step - loss: 0.0123\n",
      "Epoch 11/25\n",
      "1564/1564 [==============================] - 0s 86us/step - loss: 0.0122\n",
      "Epoch 12/25\n",
      "1564/1564 [==============================] - 0s 90us/step - loss: 0.0122\n",
      "Epoch 13/25\n",
      "1564/1564 [==============================] - 0s 91us/step - loss: 0.0122\n",
      "Epoch 14/25\n",
      "1564/1564 [==============================] - 0s 94us/step - loss: 0.0121\n",
      "Epoch 15/25\n",
      "1564/1564 [==============================] - 0s 88us/step - loss: 0.0121\n",
      "Epoch 16/25\n",
      "1564/1564 [==============================] - 0s 100us/step - loss: 0.0121\n",
      "Epoch 17/25\n",
      "1564/1564 [==============================] - 0s 99us/step - loss: 0.0121\n",
      "Epoch 18/25\n",
      "1564/1564 [==============================] - 0s 93us/step - loss: 0.0121\n",
      "Epoch 19/25\n",
      "1564/1564 [==============================] - 0s 93us/step - loss: 0.0121\n",
      "Epoch 20/25\n",
      "1564/1564 [==============================] - 0s 89us/step - loss: 0.0120\n",
      "Epoch 21/25\n",
      "1564/1564 [==============================] - 0s 88us/step - loss: 0.0120\n",
      "Epoch 22/25\n",
      "1564/1564 [==============================] - 0s 81us/step - loss: 0.0119\n",
      "Epoch 23/25\n",
      "1564/1564 [==============================] - 0s 87us/step - loss: 0.0119\n",
      "Epoch 24/25\n",
      "1564/1564 [==============================] - 0s 85us/step - loss: 0.0119\n",
      "Epoch 25/25\n",
      "1564/1564 [==============================] - 0s 72us/step - loss: 0.0119\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a54bff240>"
      ]
     },
     "execution_count": 1162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_FTP = Sequential()\n",
    "NN_FTP.add(Dense(units=16,input_dim=X_train.shape[1],activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_FTP.add(Dense(units=8, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "#NN_FTP.add(Dense(units=8, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_FTP.add(Dense(units=1,activation='linear'))\n",
    "NN_FTP.compile(loss='mse', optimizer='adam')\n",
    "NN_FTP.fit(np.array(X_train), np.array(y_train), epochs=250,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN_predictions</th>\n",
       "      <th>actual</th>\n",
       "      <th>GBR_predictions</th>\n",
       "      <th>LY_FT_percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>0.764008</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.767697</td>\n",
       "      <td>0.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>0.827853</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.857396</td>\n",
       "      <td>0.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>0.841047</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.868265</td>\n",
       "      <td>0.880952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>0.835460</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.869945</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.796701</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.840606</td>\n",
       "      <td>0.877551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>0.803810</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.836172</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.821201</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.834139</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.790426</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.819617</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>0.806977</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.863934</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.817473</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.827993</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>0.809858</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.787548</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.820429</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.826844</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.847127</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.871442</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>0.798966</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.842239</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>0.822649</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.832427</td>\n",
       "      <td>0.875000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.835719</td>\n",
       "      <td>0.855263</td>\n",
       "      <td>0.874543</td>\n",
       "      <td>0.873563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.811445</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.841900</td>\n",
       "      <td>0.872340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>0.827967</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.854091</td>\n",
       "      <td>0.872340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>0.815129</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.875078</td>\n",
       "      <td>0.870968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>0.822305</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>0.854787</td>\n",
       "      <td>0.869565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>0.841266</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.873729</td>\n",
       "      <td>0.869565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.809566</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.839899</td>\n",
       "      <td>0.868132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.805561</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.837355</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>0.821063</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.842407</td>\n",
       "      <td>0.864865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>0.816083</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.824962</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>0.805041</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.837355</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>0.794270</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.816248</td>\n",
       "      <td>0.862069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.786133</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.820094</td>\n",
       "      <td>0.861111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>0.807576</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.801026</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0.810936</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.868988</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.807027</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.827180</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>0.819467</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.831668</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.802078</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.873893</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>0.812366</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.868988</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>0.804355</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.812655</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>0.762298</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.806665</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0.778538</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.777771</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>0.822791</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.848395</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0.798057</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869456</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>0.815447</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.827431</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0.796983</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.815270</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>0.779757</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.828031</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>0.757134</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.766030</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>0.837265</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.876753</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>0.812233</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.853831</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>0.762298</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.806665</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.812468</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.825257</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>0.781329</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.777036</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>0.820248</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.857406</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.809114</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.862122</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     NN_predictions    actual  GBR_predictions  LY_FT_percent\n",
       "643        0.764008  0.666667         0.767697       0.882353\n",
       "593        0.827853  0.791667         0.857396       0.882353\n",
       "425        0.841047  0.888889         0.868265       0.880952\n",
       "274        0.835460  0.846154         0.869945       0.880000\n",
       "250        0.796701  0.841270         0.840606       0.877551\n",
       "459        0.803810  0.875000         0.836172       0.875000\n",
       "31         0.821201  0.833333         0.834139       0.875000\n",
       "299        0.790426  0.850000         0.819617       0.875000\n",
       "414        0.806977  0.857143         0.863934       0.875000\n",
       "158        0.817473  0.733333         0.827993       0.875000\n",
       "289        0.809858  1.000000         0.787548       0.875000\n",
       "79         0.820429  0.769231         0.826844       0.875000\n",
       "65         0.847127  0.714286         0.871442       0.875000\n",
       "340        0.798966  0.857143         0.842239       0.875000\n",
       "547        0.822649  0.842105         0.832427       0.875000\n",
       "51         0.835719  0.855263         0.874543       0.873563\n",
       "44         0.811445  0.794118         0.841900       0.872340\n",
       "624        0.827967  0.882353         0.854091       0.872340\n",
       "654        0.815129  0.800000         0.875078       0.870968\n",
       "327        0.822305  0.878788         0.854787       0.869565\n",
       "189        0.841266  0.913043         0.873729       0.869565\n",
       "53         0.809566  0.862745         0.839899       0.868132\n",
       "107        0.805561  0.800000         0.837355       0.866667\n",
       "369        0.821063  0.850000         0.842407       0.864865\n",
       "615        0.816083  0.714286         0.824962       0.863636\n",
       "651        0.805041  0.833333         0.837355       0.863636\n",
       "620        0.794270  0.807692         0.816248       0.862069\n",
       "71         0.786133  0.829268         0.820094       0.861111\n",
       "557        0.807576  0.809524         0.801026       0.857143\n",
       "381        0.810936  0.897436         0.868988       0.857143\n",
       "126        0.807027  0.866667         0.827180       0.857143\n",
       "403        0.819467  0.857143         0.831668       0.857143\n",
       "154        0.802078  0.857143         0.873893       0.857143\n",
       "536        0.812366  0.777778         0.868988       0.857143\n",
       "525        0.804355  0.812500         0.812655       0.857143\n",
       "517        0.762298  0.785714         0.806665       0.857143\n",
       "283        0.778538  0.666667         0.777771       0.857143\n",
       "330        0.822791  0.887097         0.848395       0.857143\n",
       "239        0.798057  1.000000         0.869456       0.857143\n",
       "328        0.815447  1.000000         0.827431       0.857143\n",
       "248        0.796983  0.826087         0.815270       0.857143\n",
       "440        0.779757  0.750000         0.828031       0.857143\n",
       "434        0.757134  0.833333         0.766030       0.857143\n",
       "273        0.837265  0.933333         0.876753       0.857143\n",
       "228        0.812233  0.780488         0.853831       0.857143\n",
       "335        0.762298  0.666667         0.806665       0.857143\n",
       "11         0.812468  0.818182         0.825257       0.857143\n",
       "656        0.781329  0.800000         0.777036       0.857143\n",
       "606        0.820248  0.888889         0.857406       0.857143\n",
       "80         0.809114  0.724138         0.862122       0.857143"
      ]
     },
     "execution_count": 1163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = NN_FTP.predict(X_test)\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.5)\n",
    "gbr.fit(X_train,y_train)\n",
    "gbr_predictions = gbr.predict(X_test)\n",
    "LR = LinearRegression(fit_intercept=True).fit(X_train,y_train)\n",
    "\n",
    "testing = pd.DataFrame(predictions)\n",
    "testing.columns=['NN_predictions']\n",
    "testing['actual'] = y_test.reset_index()['FT_percent']\n",
    "testing['GBR_predictions']=gbr_predictions\n",
    "testing['LY_FT_percent']=X_test['FT_percent_ly'].reset_index()['FT_percent_ly']\n",
    "testing.sort_values(by='LY_FT_percent',ascending=False)[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1164,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2017FTP = percentages[percentages['season']==2017][['FT_percent_ly','career_FTPercent','yearspro']]\n",
    "#pred_2017blocks = blocks[blocks['season']==2017][['blocks_ly','career_blocks','starter_change']]\n",
    "FTP_2017 = NN_FTP.predict(pred_2017FTP)\n",
    "gbr_FTP_2017 = pd.DataFrame(gbr.predict(pred_2017FTP))\n",
    "LR_FTP_2017 = pd.DataFrame(LR.predict(pred_2017FTP))\n",
    "test_2 =pd.DataFrame(FTP_2017)\n",
    "test_3 = pd.merge(percentages,pred_2017FTP,left_index=True,right_index=True).reset_index()\n",
    "test_3['predictions']=test_2[0]\n",
    "test_3['gbr_pred'] = gbr_FTP_2017[0]\n",
    "test_3['LR_pred'] = LR_FTP_2017[0]\n",
    "test_3['mean_pred'] = (test_3['predictions']+test_3['gbr_pred']+test_3['LR_pred'])/3\n",
    "test_3 = test_3[test_3['Games']>30]\n",
    "test_3[['player','FT_percent','predictions','LR_pred','gbr_pred','mean_pred','FT_percent_ly_x']].sort_values(by='FT_percent_ly_x',ascending=False)[0:50]\n",
    "\n",
    "FTP_2017 = test_3[['player','LR_pred']]\n",
    "FTP_2017.columns=['player','FTP_prediction']\n",
    "df_2017 = pd.merge(df_2017,FTP_2017,how='left',left_on='player',right_on='player')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1165,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017['FTA_prediction'] = df_2017['FTM_predictions']/df_2017['FTP_prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE using LR:0.007194073407913135\n",
      "MSE using GB:0.010545246179434935\n",
      "MSE using NN:0.008063088036505553\n",
      "MSE using combo:0.0073847984682895\n",
      "MSE using mean:0.012220424699955452\n",
      "MSE using last year stats:0.01047733460460316\n"
     ]
    }
   ],
   "source": [
    "print('MSE using LR:{}'.format(np.mean((test_3['FT_percent']-test_3['LR_pred'])**2)))\n",
    "print('MSE using GB:{}'.format(np.mean((test_3['FT_percent']-test_3['gbr_pred'])**2)))\n",
    "print('MSE using NN:{}'.format(np.mean((test_3['FT_percent']-test_3['predictions'])**2)))\n",
    "print('MSE using combo:{}'.format(np.mean((test_3['FT_percent']-test_3['mean_pred'])**2)))\n",
    "print('MSE using mean:{}'.format(np.mean((test_3['FT_percent']-np.mean(test_3['FT_percent']))**2)))\n",
    "print('MSE using last year stats:{}'.format(np.mean((test_3['FT_percent']-test_3['FT_percent_ly_x'])**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['season', 'player', 'position', 'age', 'team', 'gamesPlayed',\n",
       "       'gamesStarted', 'minutes', 'points', 'rebounds', 'assists', 'steals',\n",
       "       'blocks', 'turnovers', 'threes_made', 'FGM', 'FGA', 'FTM', 'FTA',\n",
       "       'starter', 'min_rank', 'point_prediction1', 'rebound_prediction',\n",
       "       'assist_prediction', 'steal_prediction', 'block_predictions',\n",
       "       'three_prediction', 'turnover_prediction', 'FGM_prediction',\n",
       "       'FGP_prediction', 'FGA_prediction', 'FTM_predictions', 'FTP_prediction',\n",
       "       'FTA_prediction'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1014,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2017.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017['point_prediction2'] = (df_2017['FGM_prediction']*2)+df_2017['FTM_predictions']+df_2017['three_prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1169,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_ranker = df_2017[df_2017['point_prediction2'].notna()][['season','player','point_prediction2','rebound_prediction','assist_prediction','steal_prediction','block_predictions','turnover_prediction','three_prediction','FGM_prediction','FGA_prediction','FTM_predictions','FTA_prediction','min_rank']]\n",
    "prediction_ranker.columns=['season','player','points','rebounds','assists','steals','blocks','turnovers','threes_made','FGM','FGA','FTM','FTA','min_rank']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1173,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2017 = Player_ranker(prediction_ranker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1174,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2017.get_category_dist()\n",
    "test_2017.assign_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1211,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_ranker2 = test_2017.value.sort_values(by='value_tot',ascending=False).reset_index(drop=True).reset_index()\n",
    "prediction_ranker2['predicted_rank'] = prediction_ranker2['index']+1\n",
    "prediction_ranker2.drop('index',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>player</th>\n",
       "      <th>points</th>\n",
       "      <th>rebounds</th>\n",
       "      <th>assists</th>\n",
       "      <th>steals</th>\n",
       "      <th>blocks</th>\n",
       "      <th>turnovers</th>\n",
       "      <th>threes_made</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>min_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>LeBron James</td>\n",
       "      <td>24.943032</td>\n",
       "      <td>8.404722</td>\n",
       "      <td>8.170845</td>\n",
       "      <td>1.345292</td>\n",
       "      <td>0.612607</td>\n",
       "      <td>3.552995</td>\n",
       "      <td>1.647424</td>\n",
       "      <td>9.330926</td>\n",
       "      <td>18.462954</td>\n",
       "      <td>4.633756</td>\n",
       "      <td>6.224230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>Khris Middleton</td>\n",
       "      <td>13.992393</td>\n",
       "      <td>3.901478</td>\n",
       "      <td>2.844345</td>\n",
       "      <td>1.227558</td>\n",
       "      <td>0.166228</td>\n",
       "      <td>1.818488</td>\n",
       "      <td>1.536074</td>\n",
       "      <td>4.960662</td>\n",
       "      <td>10.999172</td>\n",
       "      <td>2.534996</td>\n",
       "      <td>3.081503</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>Bradley Beal</td>\n",
       "      <td>20.602665</td>\n",
       "      <td>3.640051</td>\n",
       "      <td>3.421147</td>\n",
       "      <td>1.077844</td>\n",
       "      <td>0.303437</td>\n",
       "      <td>2.034305</td>\n",
       "      <td>2.646208</td>\n",
       "      <td>7.402198</td>\n",
       "      <td>16.075688</td>\n",
       "      <td>3.152061</td>\n",
       "      <td>4.025243</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>Andrew Wiggins</td>\n",
       "      <td>20.511278</td>\n",
       "      <td>3.821239</td>\n",
       "      <td>2.183822</td>\n",
       "      <td>0.951058</td>\n",
       "      <td>0.449024</td>\n",
       "      <td>2.170531</td>\n",
       "      <td>1.230865</td>\n",
       "      <td>7.529388</td>\n",
       "      <td>16.321960</td>\n",
       "      <td>4.221636</td>\n",
       "      <td>5.603928</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>CJ McCollum</td>\n",
       "      <td>20.360420</td>\n",
       "      <td>3.537566</td>\n",
       "      <td>3.537808</td>\n",
       "      <td>0.920871</td>\n",
       "      <td>0.399520</td>\n",
       "      <td>2.156241</td>\n",
       "      <td>2.248571</td>\n",
       "      <td>7.565362</td>\n",
       "      <td>16.386628</td>\n",
       "      <td>2.981125</td>\n",
       "      <td>3.728018</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017</td>\n",
       "      <td>Jrue Holiday</td>\n",
       "      <td>13.381516</td>\n",
       "      <td>3.484355</td>\n",
       "      <td>5.860924</td>\n",
       "      <td>1.326976</td>\n",
       "      <td>0.524537</td>\n",
       "      <td>2.249917</td>\n",
       "      <td>1.430401</td>\n",
       "      <td>5.137229</td>\n",
       "      <td>11.470059</td>\n",
       "      <td>1.676657</td>\n",
       "      <td>2.166110</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017</td>\n",
       "      <td>Karl-Anthony Towns</td>\n",
       "      <td>24.866613</td>\n",
       "      <td>11.656341</td>\n",
       "      <td>3.322843</td>\n",
       "      <td>0.888906</td>\n",
       "      <td>1.328844</td>\n",
       "      <td>2.640501</td>\n",
       "      <td>1.251075</td>\n",
       "      <td>9.765563</td>\n",
       "      <td>18.414395</td>\n",
       "      <td>4.084412</td>\n",
       "      <td>5.175839</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017</td>\n",
       "      <td>Russell Westbrook</td>\n",
       "      <td>28.696488</td>\n",
       "      <td>10.150878</td>\n",
       "      <td>10.620148</td>\n",
       "      <td>1.909999</td>\n",
       "      <td>0.370554</td>\n",
       "      <td>4.366154</td>\n",
       "      <td>2.378485</td>\n",
       "      <td>9.433284</td>\n",
       "      <td>21.710369</td>\n",
       "      <td>7.451435</td>\n",
       "      <td>9.344026</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017</td>\n",
       "      <td>Paul George</td>\n",
       "      <td>20.501784</td>\n",
       "      <td>6.384050</td>\n",
       "      <td>3.355529</td>\n",
       "      <td>1.493419</td>\n",
       "      <td>0.386995</td>\n",
       "      <td>2.448160</td>\n",
       "      <td>2.441891</td>\n",
       "      <td>7.033615</td>\n",
       "      <td>15.889551</td>\n",
       "      <td>3.992662</td>\n",
       "      <td>4.947319</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>Giannis Antetokounmpo</td>\n",
       "      <td>23.275464</td>\n",
       "      <td>9.356313</td>\n",
       "      <td>5.376734</td>\n",
       "      <td>1.473798</td>\n",
       "      <td>1.590362</td>\n",
       "      <td>2.786507</td>\n",
       "      <td>0.983095</td>\n",
       "      <td>8.368180</td>\n",
       "      <td>16.729118</td>\n",
       "      <td>5.556009</td>\n",
       "      <td>7.458701</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017</td>\n",
       "      <td>Kemba Walker</td>\n",
       "      <td>20.999461</td>\n",
       "      <td>3.812989</td>\n",
       "      <td>5.822505</td>\n",
       "      <td>1.278816</td>\n",
       "      <td>0.317090</td>\n",
       "      <td>2.199115</td>\n",
       "      <td>2.615111</td>\n",
       "      <td>7.284535</td>\n",
       "      <td>17.013541</td>\n",
       "      <td>3.815280</td>\n",
       "      <td>4.772578</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017</td>\n",
       "      <td>Anthony Davis</td>\n",
       "      <td>25.313597</td>\n",
       "      <td>10.627323</td>\n",
       "      <td>2.032894</td>\n",
       "      <td>1.265319</td>\n",
       "      <td>2.012647</td>\n",
       "      <td>2.087559</td>\n",
       "      <td>0.681795</td>\n",
       "      <td>9.435100</td>\n",
       "      <td>18.755478</td>\n",
       "      <td>5.761603</td>\n",
       "      <td>7.463336</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2017</td>\n",
       "      <td>Taj Gibson</td>\n",
       "      <td>8.682143</td>\n",
       "      <td>5.955375</td>\n",
       "      <td>0.939951</td>\n",
       "      <td>0.434538</td>\n",
       "      <td>0.881380</td>\n",
       "      <td>1.067072</td>\n",
       "      <td>0.037532</td>\n",
       "      <td>3.722588</td>\n",
       "      <td>7.666564</td>\n",
       "      <td>1.199435</td>\n",
       "      <td>1.674445</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2017</td>\n",
       "      <td>DeMar DeRozan</td>\n",
       "      <td>24.191230</td>\n",
       "      <td>4.748690</td>\n",
       "      <td>3.828381</td>\n",
       "      <td>1.008460</td>\n",
       "      <td>0.246408</td>\n",
       "      <td>2.406721</td>\n",
       "      <td>0.708833</td>\n",
       "      <td>8.578866</td>\n",
       "      <td>19.036792</td>\n",
       "      <td>6.324665</td>\n",
       "      <td>7.901577</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2017</td>\n",
       "      <td>Josh Richardson</td>\n",
       "      <td>10.904956</td>\n",
       "      <td>3.004024</td>\n",
       "      <td>2.499555</td>\n",
       "      <td>0.983135</td>\n",
       "      <td>0.584819</td>\n",
       "      <td>1.014945</td>\n",
       "      <td>1.391632</td>\n",
       "      <td>4.086767</td>\n",
       "      <td>9.687004</td>\n",
       "      <td>1.339790</td>\n",
       "      <td>1.857738</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2017</td>\n",
       "      <td>Will Barton</td>\n",
       "      <td>12.358402</td>\n",
       "      <td>3.823879</td>\n",
       "      <td>2.964711</td>\n",
       "      <td>0.745993</td>\n",
       "      <td>0.365664</td>\n",
       "      <td>1.421671</td>\n",
       "      <td>1.405115</td>\n",
       "      <td>4.363999</td>\n",
       "      <td>10.055718</td>\n",
       "      <td>2.225289</td>\n",
       "      <td>2.947561</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017</td>\n",
       "      <td>Damian Lillard</td>\n",
       "      <td>25.356903</td>\n",
       "      <td>4.736356</td>\n",
       "      <td>6.409089</td>\n",
       "      <td>1.007520</td>\n",
       "      <td>0.284603</td>\n",
       "      <td>2.815054</td>\n",
       "      <td>2.803194</td>\n",
       "      <td>8.443648</td>\n",
       "      <td>19.327523</td>\n",
       "      <td>5.666413</td>\n",
       "      <td>6.854037</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2017</td>\n",
       "      <td>Harrison Barnes</td>\n",
       "      <td>16.595919</td>\n",
       "      <td>4.942816</td>\n",
       "      <td>1.624621</td>\n",
       "      <td>0.690560</td>\n",
       "      <td>0.272593</td>\n",
       "      <td>1.244671</td>\n",
       "      <td>1.091115</td>\n",
       "      <td>6.408246</td>\n",
       "      <td>13.889094</td>\n",
       "      <td>2.688312</td>\n",
       "      <td>3.476882</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2017</td>\n",
       "      <td>Andre Drummond</td>\n",
       "      <td>15.057725</td>\n",
       "      <td>12.748314</td>\n",
       "      <td>1.662575</td>\n",
       "      <td>1.307551</td>\n",
       "      <td>1.216320</td>\n",
       "      <td>1.833514</td>\n",
       "      <td>0.207336</td>\n",
       "      <td>6.292370</td>\n",
       "      <td>11.908289</td>\n",
       "      <td>2.265648</td>\n",
       "      <td>4.347235</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2017</td>\n",
       "      <td>Thaddeus Young</td>\n",
       "      <td>11.236097</td>\n",
       "      <td>6.631301</td>\n",
       "      <td>2.053927</td>\n",
       "      <td>1.280051</td>\n",
       "      <td>0.414142</td>\n",
       "      <td>1.301011</td>\n",
       "      <td>0.594727</td>\n",
       "      <td>4.833767</td>\n",
       "      <td>9.837656</td>\n",
       "      <td>0.973835</td>\n",
       "      <td>1.388632</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2017</td>\n",
       "      <td>Lou Williams</td>\n",
       "      <td>16.078587</td>\n",
       "      <td>2.051214</td>\n",
       "      <td>2.862504</td>\n",
       "      <td>0.903204</td>\n",
       "      <td>0.162483</td>\n",
       "      <td>1.916404</td>\n",
       "      <td>1.950792</td>\n",
       "      <td>4.916362</td>\n",
       "      <td>11.469807</td>\n",
       "      <td>4.295072</td>\n",
       "      <td>5.308780</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2017</td>\n",
       "      <td>E'Twaun Moore</td>\n",
       "      <td>9.284709</td>\n",
       "      <td>2.738713</td>\n",
       "      <td>2.048276</td>\n",
       "      <td>0.779008</td>\n",
       "      <td>0.394348</td>\n",
       "      <td>0.925065</td>\n",
       "      <td>1.191112</td>\n",
       "      <td>3.629148</td>\n",
       "      <td>8.189048</td>\n",
       "      <td>0.835300</td>\n",
       "      <td>1.116561</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2017</td>\n",
       "      <td>Joe Ingles</td>\n",
       "      <td>10.040861</td>\n",
       "      <td>3.973186</td>\n",
       "      <td>3.058129</td>\n",
       "      <td>1.195888</td>\n",
       "      <td>0.176177</td>\n",
       "      <td>1.470644</td>\n",
       "      <td>1.626858</td>\n",
       "      <td>3.620115</td>\n",
       "      <td>8.329471</td>\n",
       "      <td>1.173772</td>\n",
       "      <td>1.507410</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2017</td>\n",
       "      <td>Jamal Murray</td>\n",
       "      <td>14.328483</td>\n",
       "      <td>3.819008</td>\n",
       "      <td>3.198023</td>\n",
       "      <td>0.887886</td>\n",
       "      <td>0.426608</td>\n",
       "      <td>1.781454</td>\n",
       "      <td>1.669870</td>\n",
       "      <td>5.274415</td>\n",
       "      <td>12.158814</td>\n",
       "      <td>2.109783</td>\n",
       "      <td>2.569342</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2017</td>\n",
       "      <td>Victor Oladipo</td>\n",
       "      <td>15.977114</td>\n",
       "      <td>4.701369</td>\n",
       "      <td>3.217625</td>\n",
       "      <td>1.282743</td>\n",
       "      <td>0.389234</td>\n",
       "      <td>1.886925</td>\n",
       "      <td>1.742683</td>\n",
       "      <td>6.020298</td>\n",
       "      <td>13.625961</td>\n",
       "      <td>2.193836</td>\n",
       "      <td>2.829740</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2017</td>\n",
       "      <td>James Harden</td>\n",
       "      <td>28.859641</td>\n",
       "      <td>7.848828</td>\n",
       "      <td>9.517825</td>\n",
       "      <td>1.635248</td>\n",
       "      <td>0.497128</td>\n",
       "      <td>4.724416</td>\n",
       "      <td>3.157945</td>\n",
       "      <td>8.680771</td>\n",
       "      <td>19.541687</td>\n",
       "      <td>8.340154</td>\n",
       "      <td>10.261739</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2017</td>\n",
       "      <td>Robert Covington</td>\n",
       "      <td>13.643676</td>\n",
       "      <td>6.163541</td>\n",
       "      <td>2.043629</td>\n",
       "      <td>1.598626</td>\n",
       "      <td>0.752208</td>\n",
       "      <td>1.719987</td>\n",
       "      <td>2.093504</td>\n",
       "      <td>4.619150</td>\n",
       "      <td>11.243173</td>\n",
       "      <td>2.311873</td>\n",
       "      <td>2.944490</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2017</td>\n",
       "      <td>LaMarcus Aldridge</td>\n",
       "      <td>17.198492</td>\n",
       "      <td>7.349330</td>\n",
       "      <td>2.262703</td>\n",
       "      <td>0.642360</td>\n",
       "      <td>1.039687</td>\n",
       "      <td>1.575999</td>\n",
       "      <td>0.337631</td>\n",
       "      <td>6.866074</td>\n",
       "      <td>14.650599</td>\n",
       "      <td>3.128713</td>\n",
       "      <td>3.969890</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2017</td>\n",
       "      <td>Kyle Lowry</td>\n",
       "      <td>20.032290</td>\n",
       "      <td>4.507720</td>\n",
       "      <td>6.953607</td>\n",
       "      <td>1.447896</td>\n",
       "      <td>0.242395</td>\n",
       "      <td>2.742269</td>\n",
       "      <td>2.816599</td>\n",
       "      <td>6.330473</td>\n",
       "      <td>14.500622</td>\n",
       "      <td>4.554745</td>\n",
       "      <td>5.753392</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2017</td>\n",
       "      <td>Klay Thompson</td>\n",
       "      <td>19.509312</td>\n",
       "      <td>3.709403</td>\n",
       "      <td>2.333715</td>\n",
       "      <td>0.796243</td>\n",
       "      <td>0.490013</td>\n",
       "      <td>1.652738</td>\n",
       "      <td>3.034884</td>\n",
       "      <td>7.196175</td>\n",
       "      <td>15.748390</td>\n",
       "      <td>2.082078</td>\n",
       "      <td>2.565557</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2017</td>\n",
       "      <td>Carmelo Anthony</td>\n",
       "      <td>17.755981</td>\n",
       "      <td>5.570041</td>\n",
       "      <td>2.381638</td>\n",
       "      <td>0.651183</td>\n",
       "      <td>0.425801</td>\n",
       "      <td>1.740153</td>\n",
       "      <td>1.658484</td>\n",
       "      <td>6.417771</td>\n",
       "      <td>14.676589</td>\n",
       "      <td>3.261954</td>\n",
       "      <td>4.094391</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2017</td>\n",
       "      <td>Steven Adams</td>\n",
       "      <td>10.533648</td>\n",
       "      <td>7.376657</td>\n",
       "      <td>1.261320</td>\n",
       "      <td>0.792250</td>\n",
       "      <td>0.951233</td>\n",
       "      <td>1.499807</td>\n",
       "      <td>0.254676</td>\n",
       "      <td>4.177206</td>\n",
       "      <td>7.660152</td>\n",
       "      <td>1.924560</td>\n",
       "      <td>3.001265</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2017</td>\n",
       "      <td>Bojan Bogdanovic</td>\n",
       "      <td>12.532639</td>\n",
       "      <td>3.420704</td>\n",
       "      <td>1.762804</td>\n",
       "      <td>0.441215</td>\n",
       "      <td>0.087729</td>\n",
       "      <td>1.455896</td>\n",
       "      <td>1.686495</td>\n",
       "      <td>4.396828</td>\n",
       "      <td>10.060259</td>\n",
       "      <td>2.052488</td>\n",
       "      <td>2.519891</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2017</td>\n",
       "      <td>Dwight Howard</td>\n",
       "      <td>13.170162</td>\n",
       "      <td>10.758102</td>\n",
       "      <td>1.648883</td>\n",
       "      <td>0.870599</td>\n",
       "      <td>1.344265</td>\n",
       "      <td>2.136865</td>\n",
       "      <td>0.195451</td>\n",
       "      <td>5.054831</td>\n",
       "      <td>9.009701</td>\n",
       "      <td>2.865048</td>\n",
       "      <td>4.586556</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2017</td>\n",
       "      <td>Taurean Waller-Prince</td>\n",
       "      <td>11.323259</td>\n",
       "      <td>4.540606</td>\n",
       "      <td>1.980291</td>\n",
       "      <td>0.950724</td>\n",
       "      <td>0.595580</td>\n",
       "      <td>1.318302</td>\n",
       "      <td>1.086335</td>\n",
       "      <td>4.025514</td>\n",
       "      <td>9.691003</td>\n",
       "      <td>2.185897</td>\n",
       "      <td>2.775790</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2017</td>\n",
       "      <td>Kentavious Caldwell-Pope</td>\n",
       "      <td>14.540540</td>\n",
       "      <td>3.669115</td>\n",
       "      <td>2.599157</td>\n",
       "      <td>1.164309</td>\n",
       "      <td>0.220517</td>\n",
       "      <td>1.184635</td>\n",
       "      <td>1.987730</td>\n",
       "      <td>5.171095</td>\n",
       "      <td>12.249063</td>\n",
       "      <td>2.210619</td>\n",
       "      <td>2.875808</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2017</td>\n",
       "      <td>Nikola Jokic</td>\n",
       "      <td>18.416138</td>\n",
       "      <td>9.277181</td>\n",
       "      <td>4.840636</td>\n",
       "      <td>1.049376</td>\n",
       "      <td>0.762631</td>\n",
       "      <td>2.239560</td>\n",
       "      <td>0.916680</td>\n",
       "      <td>7.261116</td>\n",
       "      <td>13.326444</td>\n",
       "      <td>2.977225</td>\n",
       "      <td>3.759076</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2017</td>\n",
       "      <td>Otto Porter</td>\n",
       "      <td>14.340340</td>\n",
       "      <td>6.049906</td>\n",
       "      <td>2.131802</td>\n",
       "      <td>1.327278</td>\n",
       "      <td>0.453350</td>\n",
       "      <td>1.007581</td>\n",
       "      <td>1.932909</td>\n",
       "      <td>5.279730</td>\n",
       "      <td>10.861828</td>\n",
       "      <td>1.847971</td>\n",
       "      <td>2.439107</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2017</td>\n",
       "      <td>DeAndre Jordan</td>\n",
       "      <td>12.960170</td>\n",
       "      <td>12.058012</td>\n",
       "      <td>1.883292</td>\n",
       "      <td>0.675399</td>\n",
       "      <td>1.582387</td>\n",
       "      <td>1.704084</td>\n",
       "      <td>0.299466</td>\n",
       "      <td>4.913910</td>\n",
       "      <td>7.828407</td>\n",
       "      <td>2.832884</td>\n",
       "      <td>5.088167</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2017</td>\n",
       "      <td>Marc Gasol</td>\n",
       "      <td>18.818532</td>\n",
       "      <td>7.036024</td>\n",
       "      <td>4.442984</td>\n",
       "      <td>0.930100</td>\n",
       "      <td>1.222528</td>\n",
       "      <td>2.163817</td>\n",
       "      <td>1.183217</td>\n",
       "      <td>6.824474</td>\n",
       "      <td>14.548894</td>\n",
       "      <td>3.986368</td>\n",
       "      <td>5.186892</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2017</td>\n",
       "      <td>Goran Dragic</td>\n",
       "      <td>17.335579</td>\n",
       "      <td>3.367418</td>\n",
       "      <td>5.764307</td>\n",
       "      <td>1.092807</td>\n",
       "      <td>0.169216</td>\n",
       "      <td>2.586461</td>\n",
       "      <td>1.551977</td>\n",
       "      <td>6.136221</td>\n",
       "      <td>13.286098</td>\n",
       "      <td>3.511160</td>\n",
       "      <td>4.646967</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2017</td>\n",
       "      <td>Wilson Chandler</td>\n",
       "      <td>15.557086</td>\n",
       "      <td>6.187838</td>\n",
       "      <td>2.474640</td>\n",
       "      <td>0.828538</td>\n",
       "      <td>0.482355</td>\n",
       "      <td>1.693621</td>\n",
       "      <td>1.691298</td>\n",
       "      <td>5.924904</td>\n",
       "      <td>13.276394</td>\n",
       "      <td>2.015980</td>\n",
       "      <td>2.616904</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2017</td>\n",
       "      <td>Kevin Durant</td>\n",
       "      <td>24.948906</td>\n",
       "      <td>8.203688</td>\n",
       "      <td>4.829521</td>\n",
       "      <td>1.095424</td>\n",
       "      <td>1.259987</td>\n",
       "      <td>2.485996</td>\n",
       "      <td>1.979545</td>\n",
       "      <td>8.738301</td>\n",
       "      <td>17.658999</td>\n",
       "      <td>5.492759</td>\n",
       "      <td>6.607488</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2017</td>\n",
       "      <td>Courtney Lee</td>\n",
       "      <td>10.752884</td>\n",
       "      <td>2.895754</td>\n",
       "      <td>2.258178</td>\n",
       "      <td>0.957177</td>\n",
       "      <td>0.227242</td>\n",
       "      <td>0.971552</td>\n",
       "      <td>1.474474</td>\n",
       "      <td>3.921155</td>\n",
       "      <td>8.720009</td>\n",
       "      <td>1.436099</td>\n",
       "      <td>1.767534</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2017</td>\n",
       "      <td>Jeff Teague</td>\n",
       "      <td>14.697547</td>\n",
       "      <td>3.492407</td>\n",
       "      <td>6.985310</td>\n",
       "      <td>1.155002</td>\n",
       "      <td>0.336588</td>\n",
       "      <td>2.430367</td>\n",
       "      <td>1.238405</td>\n",
       "      <td>4.859224</td>\n",
       "      <td>10.933252</td>\n",
       "      <td>3.740694</td>\n",
       "      <td>4.626781</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2017</td>\n",
       "      <td>Dario Saric</td>\n",
       "      <td>15.974980</td>\n",
       "      <td>7.559007</td>\n",
       "      <td>2.897892</td>\n",
       "      <td>0.852812</td>\n",
       "      <td>0.538923</td>\n",
       "      <td>2.197371</td>\n",
       "      <td>1.494228</td>\n",
       "      <td>5.913596</td>\n",
       "      <td>13.826000</td>\n",
       "      <td>2.653560</td>\n",
       "      <td>3.464562</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2017</td>\n",
       "      <td>Gary Harris</td>\n",
       "      <td>14.273492</td>\n",
       "      <td>2.945392</td>\n",
       "      <td>2.729422</td>\n",
       "      <td>1.150623</td>\n",
       "      <td>0.142788</td>\n",
       "      <td>1.357865</td>\n",
       "      <td>1.785956</td>\n",
       "      <td>5.272619</td>\n",
       "      <td>11.116364</td>\n",
       "      <td>1.942298</td>\n",
       "      <td>2.602244</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2017</td>\n",
       "      <td>Spencer Dinwiddie</td>\n",
       "      <td>11.418371</td>\n",
       "      <td>3.922635</td>\n",
       "      <td>3.996381</td>\n",
       "      <td>0.886760</td>\n",
       "      <td>0.393057</td>\n",
       "      <td>1.532703</td>\n",
       "      <td>0.959279</td>\n",
       "      <td>3.933013</td>\n",
       "      <td>9.454569</td>\n",
       "      <td>2.593067</td>\n",
       "      <td>3.575013</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2017</td>\n",
       "      <td>Draymond Green</td>\n",
       "      <td>12.413613</td>\n",
       "      <td>8.208755</td>\n",
       "      <td>6.293799</td>\n",
       "      <td>1.529725</td>\n",
       "      <td>1.190713</td>\n",
       "      <td>2.071312</td>\n",
       "      <td>1.228567</td>\n",
       "      <td>4.364071</td>\n",
       "      <td>10.053166</td>\n",
       "      <td>2.456904</td>\n",
       "      <td>3.420478</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2017</td>\n",
       "      <td>P.J. Tucker</td>\n",
       "      <td>6.071491</td>\n",
       "      <td>5.391444</td>\n",
       "      <td>0.748964</td>\n",
       "      <td>1.087687</td>\n",
       "      <td>0.142981</td>\n",
       "      <td>0.650510</td>\n",
       "      <td>0.756014</td>\n",
       "      <td>2.304978</td>\n",
       "      <td>5.416074</td>\n",
       "      <td>0.705521</td>\n",
       "      <td>0.937180</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    season                    player     points   rebounds    assists  \\\n",
       "0     2017              LeBron James  24.943032   8.404722   8.170845   \n",
       "1     2017           Khris Middleton  13.992393   3.901478   2.844345   \n",
       "2     2017              Bradley Beal  20.602665   3.640051   3.421147   \n",
       "3     2017            Andrew Wiggins  20.511278   3.821239   2.183822   \n",
       "4     2017               CJ McCollum  20.360420   3.537566   3.537808   \n",
       "5     2017              Jrue Holiday  13.381516   3.484355   5.860924   \n",
       "6     2017        Karl-Anthony Towns  24.866613  11.656341   3.322843   \n",
       "7     2017         Russell Westbrook  28.696488  10.150878  10.620148   \n",
       "8     2017               Paul George  20.501784   6.384050   3.355529   \n",
       "9     2017     Giannis Antetokounmpo  23.275464   9.356313   5.376734   \n",
       "10    2017              Kemba Walker  20.999461   3.812989   5.822505   \n",
       "11    2017             Anthony Davis  25.313597  10.627323   2.032894   \n",
       "13    2017                Taj Gibson   8.682143   5.955375   0.939951   \n",
       "14    2017             DeMar DeRozan  24.191230   4.748690   3.828381   \n",
       "15    2017           Josh Richardson  10.904956   3.004024   2.499555   \n",
       "16    2017               Will Barton  12.358402   3.823879   2.964711   \n",
       "17    2017            Damian Lillard  25.356903   4.736356   6.409089   \n",
       "19    2017           Harrison Barnes  16.595919   4.942816   1.624621   \n",
       "20    2017            Andre Drummond  15.057725  12.748314   1.662575   \n",
       "21    2017            Thaddeus Young  11.236097   6.631301   2.053927   \n",
       "22    2017              Lou Williams  16.078587   2.051214   2.862504   \n",
       "23    2017             E'Twaun Moore   9.284709   2.738713   2.048276   \n",
       "24    2017                Joe Ingles  10.040861   3.973186   3.058129   \n",
       "25    2017              Jamal Murray  14.328483   3.819008   3.198023   \n",
       "26    2017            Victor Oladipo  15.977114   4.701369   3.217625   \n",
       "27    2017              James Harden  28.859641   7.848828   9.517825   \n",
       "28    2017          Robert Covington  13.643676   6.163541   2.043629   \n",
       "29    2017         LaMarcus Aldridge  17.198492   7.349330   2.262703   \n",
       "30    2017                Kyle Lowry  20.032290   4.507720   6.953607   \n",
       "31    2017             Klay Thompson  19.509312   3.709403   2.333715   \n",
       "32    2017           Carmelo Anthony  17.755981   5.570041   2.381638   \n",
       "33    2017              Steven Adams  10.533648   7.376657   1.261320   \n",
       "34    2017          Bojan Bogdanovic  12.532639   3.420704   1.762804   \n",
       "35    2017             Dwight Howard  13.170162  10.758102   1.648883   \n",
       "36    2017     Taurean Waller-Prince  11.323259   4.540606   1.980291   \n",
       "37    2017  Kentavious Caldwell-Pope  14.540540   3.669115   2.599157   \n",
       "38    2017              Nikola Jokic  18.416138   9.277181   4.840636   \n",
       "40    2017               Otto Porter  14.340340   6.049906   2.131802   \n",
       "41    2017            DeAndre Jordan  12.960170  12.058012   1.883292   \n",
       "42    2017                Marc Gasol  18.818532   7.036024   4.442984   \n",
       "44    2017              Goran Dragic  17.335579   3.367418   5.764307   \n",
       "46    2017           Wilson Chandler  15.557086   6.187838   2.474640   \n",
       "47    2017              Kevin Durant  24.948906   8.203688   4.829521   \n",
       "48    2017              Courtney Lee  10.752884   2.895754   2.258178   \n",
       "49    2017               Jeff Teague  14.697547   3.492407   6.985310   \n",
       "50    2017               Dario Saric  15.974980   7.559007   2.897892   \n",
       "51    2017               Gary Harris  14.273492   2.945392   2.729422   \n",
       "52    2017         Spencer Dinwiddie  11.418371   3.922635   3.996381   \n",
       "53    2017            Draymond Green  12.413613   8.208755   6.293799   \n",
       "54    2017               P.J. Tucker   6.071491   5.391444   0.748964   \n",
       "\n",
       "      steals    blocks  turnovers  threes_made       FGM        FGA       FTM  \\\n",
       "0   1.345292  0.612607   3.552995     1.647424  9.330926  18.462954  4.633756   \n",
       "1   1.227558  0.166228   1.818488     1.536074  4.960662  10.999172  2.534996   \n",
       "2   1.077844  0.303437   2.034305     2.646208  7.402198  16.075688  3.152061   \n",
       "3   0.951058  0.449024   2.170531     1.230865  7.529388  16.321960  4.221636   \n",
       "4   0.920871  0.399520   2.156241     2.248571  7.565362  16.386628  2.981125   \n",
       "5   1.326976  0.524537   2.249917     1.430401  5.137229  11.470059  1.676657   \n",
       "6   0.888906  1.328844   2.640501     1.251075  9.765563  18.414395  4.084412   \n",
       "7   1.909999  0.370554   4.366154     2.378485  9.433284  21.710369  7.451435   \n",
       "8   1.493419  0.386995   2.448160     2.441891  7.033615  15.889551  3.992662   \n",
       "9   1.473798  1.590362   2.786507     0.983095  8.368180  16.729118  5.556009   \n",
       "10  1.278816  0.317090   2.199115     2.615111  7.284535  17.013541  3.815280   \n",
       "11  1.265319  2.012647   2.087559     0.681795  9.435100  18.755478  5.761603   \n",
       "13  0.434538  0.881380   1.067072     0.037532  3.722588   7.666564  1.199435   \n",
       "14  1.008460  0.246408   2.406721     0.708833  8.578866  19.036792  6.324665   \n",
       "15  0.983135  0.584819   1.014945     1.391632  4.086767   9.687004  1.339790   \n",
       "16  0.745993  0.365664   1.421671     1.405115  4.363999  10.055718  2.225289   \n",
       "17  1.007520  0.284603   2.815054     2.803194  8.443648  19.327523  5.666413   \n",
       "19  0.690560  0.272593   1.244671     1.091115  6.408246  13.889094  2.688312   \n",
       "20  1.307551  1.216320   1.833514     0.207336  6.292370  11.908289  2.265648   \n",
       "21  1.280051  0.414142   1.301011     0.594727  4.833767   9.837656  0.973835   \n",
       "22  0.903204  0.162483   1.916404     1.950792  4.916362  11.469807  4.295072   \n",
       "23  0.779008  0.394348   0.925065     1.191112  3.629148   8.189048  0.835300   \n",
       "24  1.195888  0.176177   1.470644     1.626858  3.620115   8.329471  1.173772   \n",
       "25  0.887886  0.426608   1.781454     1.669870  5.274415  12.158814  2.109783   \n",
       "26  1.282743  0.389234   1.886925     1.742683  6.020298  13.625961  2.193836   \n",
       "27  1.635248  0.497128   4.724416     3.157945  8.680771  19.541687  8.340154   \n",
       "28  1.598626  0.752208   1.719987     2.093504  4.619150  11.243173  2.311873   \n",
       "29  0.642360  1.039687   1.575999     0.337631  6.866074  14.650599  3.128713   \n",
       "30  1.447896  0.242395   2.742269     2.816599  6.330473  14.500622  4.554745   \n",
       "31  0.796243  0.490013   1.652738     3.034884  7.196175  15.748390  2.082078   \n",
       "32  0.651183  0.425801   1.740153     1.658484  6.417771  14.676589  3.261954   \n",
       "33  0.792250  0.951233   1.499807     0.254676  4.177206   7.660152  1.924560   \n",
       "34  0.441215  0.087729   1.455896     1.686495  4.396828  10.060259  2.052488   \n",
       "35  0.870599  1.344265   2.136865     0.195451  5.054831   9.009701  2.865048   \n",
       "36  0.950724  0.595580   1.318302     1.086335  4.025514   9.691003  2.185897   \n",
       "37  1.164309  0.220517   1.184635     1.987730  5.171095  12.249063  2.210619   \n",
       "38  1.049376  0.762631   2.239560     0.916680  7.261116  13.326444  2.977225   \n",
       "40  1.327278  0.453350   1.007581     1.932909  5.279730  10.861828  1.847971   \n",
       "41  0.675399  1.582387   1.704084     0.299466  4.913910   7.828407  2.832884   \n",
       "42  0.930100  1.222528   2.163817     1.183217  6.824474  14.548894  3.986368   \n",
       "44  1.092807  0.169216   2.586461     1.551977  6.136221  13.286098  3.511160   \n",
       "46  0.828538  0.482355   1.693621     1.691298  5.924904  13.276394  2.015980   \n",
       "47  1.095424  1.259987   2.485996     1.979545  8.738301  17.658999  5.492759   \n",
       "48  0.957177  0.227242   0.971552     1.474474  3.921155   8.720009  1.436099   \n",
       "49  1.155002  0.336588   2.430367     1.238405  4.859224  10.933252  3.740694   \n",
       "50  0.852812  0.538923   2.197371     1.494228  5.913596  13.826000  2.653560   \n",
       "51  1.150623  0.142788   1.357865     1.785956  5.272619  11.116364  1.942298   \n",
       "52  0.886760  0.393057   1.532703     0.959279  3.933013   9.454569  2.593067   \n",
       "53  1.529725  1.190713   2.071312     1.228567  4.364071  10.053166  2.456904   \n",
       "54  1.087687  0.142981   0.650510     0.756014  2.304978   5.416074  0.705521   \n",
       "\n",
       "          FTA  min_rank  \n",
       "0    6.224230         1  \n",
       "1    3.081503         2  \n",
       "2    4.025243         3  \n",
       "3    5.603928         4  \n",
       "4    3.728018         5  \n",
       "5    2.166110         6  \n",
       "6    5.175839         7  \n",
       "7    9.344026         8  \n",
       "8    4.947319         9  \n",
       "9    7.458701        10  \n",
       "10   4.772578        11  \n",
       "11   7.463336        12  \n",
       "13   1.674445        14  \n",
       "14   7.901577        15  \n",
       "15   1.857738        16  \n",
       "16   2.947561        17  \n",
       "17   6.854037        18  \n",
       "19   3.476882        20  \n",
       "20   4.347235        21  \n",
       "21   1.388632        22  \n",
       "22   5.308780        23  \n",
       "23   1.116561        24  \n",
       "24   1.507410        25  \n",
       "25   2.569342        26  \n",
       "26   2.829740        27  \n",
       "27  10.261739        28  \n",
       "28   2.944490        29  \n",
       "29   3.969890        30  \n",
       "30   5.753392        31  \n",
       "31   2.565557        32  \n",
       "32   4.094391        33  \n",
       "33   3.001265        34  \n",
       "34   2.519891        35  \n",
       "35   4.586556        36  \n",
       "36   2.775790        37  \n",
       "37   2.875808        38  \n",
       "38   3.759076        39  \n",
       "40   2.439107        41  \n",
       "41   5.088167        42  \n",
       "42   5.186892        43  \n",
       "44   4.646967        45  \n",
       "46   2.616904        47  \n",
       "47   6.607488        48  \n",
       "48   1.767534        49  \n",
       "49   4.626781        50  \n",
       "50   3.464562        51  \n",
       "51   2.602244        52  \n",
       "52   3.575013        53  \n",
       "53   3.420478        54  \n",
       "54   0.937180        55  "
      ]
     },
     "execution_count": 1214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_ranker[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_ranker = rank_2017.value.sort_values(by='value_tot',ascending=False).reset_index(drop=True).reset_index()\n",
    "actual_ranker['rank'] = actual_ranker['index']+1\n",
    "actual_ranker.drop('index',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1177,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_predictions = pd.merge(prediction_ranker2,rank_2017.value,how='inner',left_on='player',right_on='player')\n",
    "compare_predictions = compare_predictions.sort_values(by='value_tot_y',ascending=False).reset_index(drop=True).reset_index()\n",
    "compare_predictions['rank'] = compare_predictions['index']+1\n",
    "compare_predictions.drop('index',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1178,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_preds = compare_predictions[['player','rank','predicted_rank','value_tot_x','value_tot_y']][0:200]\n",
    "\n",
    "yahoo_ranks = pd.read_csv('../Yahoo 2017 Ranks.csv', encoding = \"ISO-8859-1\", engine='python')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1179,
   "metadata": {},
   "outputs": [],
   "source": [
    "yahoo_ranks['PLAYER']=yahoo_ranks['PLAYER'].str.replace('','')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>player</th>\n",
       "      <th>value_tot</th>\n",
       "      <th>value_points</th>\n",
       "      <th>value_rebounds</th>\n",
       "      <th>value_assists</th>\n",
       "      <th>value_blocks</th>\n",
       "      <th>value_steals</th>\n",
       "      <th>value_turnovers</th>\n",
       "      <th>value_threes</th>\n",
       "      <th>value_fg</th>\n",
       "      <th>value_ft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2017</td>\n",
       "      <td>Anthony Davis</td>\n",
       "      <td>13.069292</td>\n",
       "      <td>2.728406</td>\n",
       "      <td>2.327843</td>\n",
       "      <td>-0.323373</td>\n",
       "      <td>4.382346</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>-0.642579</td>\n",
       "      <td>-0.719758</td>\n",
       "      <td>2.572502</td>\n",
       "      <td>1.340136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>2017</td>\n",
       "      <td>Stephen Curry</td>\n",
       "      <td>10.977767</td>\n",
       "      <td>2.415188</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>1.610250</td>\n",
       "      <td>-0.769567</td>\n",
       "      <td>1.647478</td>\n",
       "      <td>-1.635937</td>\n",
       "      <td>3.343394</td>\n",
       "      <td>1.073741</td>\n",
       "      <td>3.291282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2017</td>\n",
       "      <td>Kevin Durant</td>\n",
       "      <td>10.555627</td>\n",
       "      <td>2.415188</td>\n",
       "      <td>0.660945</td>\n",
       "      <td>1.254056</td>\n",
       "      <td>2.665042</td>\n",
       "      <td>-0.545910</td>\n",
       "      <td>-1.635937</td>\n",
       "      <td>1.369863</td>\n",
       "      <td>1.809299</td>\n",
       "      <td>2.563082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2017</td>\n",
       "      <td>James Harden</td>\n",
       "      <td>10.522310</td>\n",
       "      <td>3.152171</td>\n",
       "      <td>0.118234</td>\n",
       "      <td>2.984140</td>\n",
       "      <td>0.303748</td>\n",
       "      <td>2.134898</td>\n",
       "      <td>-3.374314</td>\n",
       "      <td>2.762944</td>\n",
       "      <td>-0.589500</td>\n",
       "      <td>3.029989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2017</td>\n",
       "      <td>Karl-Anthony Towns</td>\n",
       "      <td>9.046572</td>\n",
       "      <td>1.475533</td>\n",
       "      <td>2.793024</td>\n",
       "      <td>-0.272488</td>\n",
       "      <td>1.806390</td>\n",
       "      <td>-0.302200</td>\n",
       "      <td>-0.270069</td>\n",
       "      <td>0.208962</td>\n",
       "      <td>2.213129</td>\n",
       "      <td>1.394291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>LeBron James</td>\n",
       "      <td>8.050018</td>\n",
       "      <td>2.617858</td>\n",
       "      <td>1.358716</td>\n",
       "      <td>3.136795</td>\n",
       "      <td>0.733074</td>\n",
       "      <td>1.160059</td>\n",
       "      <td>-3.125975</td>\n",
       "      <td>0.557232</td>\n",
       "      <td>2.935558</td>\n",
       "      <td>-1.323300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>Giannis Antetokounmpo</td>\n",
       "      <td>7.982516</td>\n",
       "      <td>2.507311</td>\n",
       "      <td>1.901427</td>\n",
       "      <td>0.948747</td>\n",
       "      <td>1.806390</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>-1.635937</td>\n",
       "      <td>-0.835849</td>\n",
       "      <td>2.328774</td>\n",
       "      <td>-0.442116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2017</td>\n",
       "      <td>Damian Lillard</td>\n",
       "      <td>7.758411</td>\n",
       "      <td>2.507311</td>\n",
       "      <td>-0.230652</td>\n",
       "      <td>1.864674</td>\n",
       "      <td>-0.340241</td>\n",
       "      <td>0.428929</td>\n",
       "      <td>-1.387598</td>\n",
       "      <td>2.066403</td>\n",
       "      <td>-0.920536</td>\n",
       "      <td>3.770119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2017</td>\n",
       "      <td>Chris Paul</td>\n",
       "      <td>7.259998</td>\n",
       "      <td>0.978069</td>\n",
       "      <td>0.118234</td>\n",
       "      <td>2.526177</td>\n",
       "      <td>-0.769567</td>\n",
       "      <td>1.891188</td>\n",
       "      <td>-0.642579</td>\n",
       "      <td>1.369863</td>\n",
       "      <td>-0.176916</td>\n",
       "      <td>1.965529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2017</td>\n",
       "      <td>Jimmy Butler</td>\n",
       "      <td>7.194467</td>\n",
       "      <td>1.641355</td>\n",
       "      <td>0.079468</td>\n",
       "      <td>0.999632</td>\n",
       "      <td>-0.340241</td>\n",
       "      <td>2.622318</td>\n",
       "      <td>-0.145900</td>\n",
       "      <td>-0.139308</td>\n",
       "      <td>0.324360</td>\n",
       "      <td>2.152782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2017</td>\n",
       "      <td>Victor Oladipo</td>\n",
       "      <td>6.742591</td>\n",
       "      <td>1.807176</td>\n",
       "      <td>0.040703</td>\n",
       "      <td>0.694323</td>\n",
       "      <td>0.518411</td>\n",
       "      <td>3.597157</td>\n",
       "      <td>-1.511767</td>\n",
       "      <td>0.905503</td>\n",
       "      <td>0.389094</td>\n",
       "      <td>0.301991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>2017</td>\n",
       "      <td>DeMarcus Cousins</td>\n",
       "      <td>6.513379</td>\n",
       "      <td>2.194092</td>\n",
       "      <td>3.025615</td>\n",
       "      <td>1.254056</td>\n",
       "      <td>2.235716</td>\n",
       "      <td>1.647478</td>\n",
       "      <td>-4.119333</td>\n",
       "      <td>1.021593</td>\n",
       "      <td>0.301785</td>\n",
       "      <td>-1.047624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2017</td>\n",
       "      <td>Nikola Jokic</td>\n",
       "      <td>6.424866</td>\n",
       "      <td>0.959645</td>\n",
       "      <td>2.172783</td>\n",
       "      <td>1.610250</td>\n",
       "      <td>0.518411</td>\n",
       "      <td>0.672639</td>\n",
       "      <td>-1.387598</td>\n",
       "      <td>0.208962</td>\n",
       "      <td>0.838766</td>\n",
       "      <td>0.831007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>2017</td>\n",
       "      <td>Kyrie Irving</td>\n",
       "      <td>6.159878</td>\n",
       "      <td>2.046696</td>\n",
       "      <td>-0.502008</td>\n",
       "      <td>1.101402</td>\n",
       "      <td>-0.554904</td>\n",
       "      <td>0.428929</td>\n",
       "      <td>-0.766749</td>\n",
       "      <td>1.718133</td>\n",
       "      <td>0.968233</td>\n",
       "      <td>1.720144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>2017</td>\n",
       "      <td>Andre Ingram</td>\n",
       "      <td>5.581832</td>\n",
       "      <td>-0.237954</td>\n",
       "      <td>-0.812129</td>\n",
       "      <td>0.287245</td>\n",
       "      <td>2.021053</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>0.226610</td>\n",
       "      <td>1.369863</td>\n",
       "      <td>0.116338</td>\n",
       "      <td>1.207037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2017</td>\n",
       "      <td>LaMarcus Aldridge</td>\n",
       "      <td>5.370052</td>\n",
       "      <td>1.807176</td>\n",
       "      <td>1.319951</td>\n",
       "      <td>-0.476027</td>\n",
       "      <td>1.377064</td>\n",
       "      <td>-0.789620</td>\n",
       "      <td>0.226610</td>\n",
       "      <td>-1.068029</td>\n",
       "      <td>1.620860</td>\n",
       "      <td>1.352068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>2017</td>\n",
       "      <td>MarShon Brooks</td>\n",
       "      <td>5.131062</td>\n",
       "      <td>1.254438</td>\n",
       "      <td>-0.812129</td>\n",
       "      <td>0.338130</td>\n",
       "      <td>-0.340241</td>\n",
       "      <td>1.647478</td>\n",
       "      <td>-0.766749</td>\n",
       "      <td>1.602043</td>\n",
       "      <td>1.009007</td>\n",
       "      <td>1.199083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017</td>\n",
       "      <td>Paul George</td>\n",
       "      <td>5.126899</td>\n",
       "      <td>1.586081</td>\n",
       "      <td>0.234529</td>\n",
       "      <td>0.185475</td>\n",
       "      <td>-0.125578</td>\n",
       "      <td>2.622318</td>\n",
       "      <td>-1.263428</td>\n",
       "      <td>2.066403</td>\n",
       "      <td>-1.086400</td>\n",
       "      <td>0.907499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>2017</td>\n",
       "      <td>Kristaps Porzingis</td>\n",
       "      <td>4.816889</td>\n",
       "      <td>1.733478</td>\n",
       "      <td>0.583415</td>\n",
       "      <td>-0.883106</td>\n",
       "      <td>3.953020</td>\n",
       "      <td>-0.302200</td>\n",
       "      <td>-0.270069</td>\n",
       "      <td>0.673322</td>\n",
       "      <td>-0.888515</td>\n",
       "      <td>0.217545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017</td>\n",
       "      <td>Jrue Holiday</td>\n",
       "      <td>4.397228</td>\n",
       "      <td>1.051768</td>\n",
       "      <td>-0.230652</td>\n",
       "      <td>1.559365</td>\n",
       "      <td>0.518411</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>-1.139258</td>\n",
       "      <td>0.208962</td>\n",
       "      <td>0.875856</td>\n",
       "      <td>0.149007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>Khris Middleton</td>\n",
       "      <td>4.231094</td>\n",
       "      <td>1.254438</td>\n",
       "      <td>0.040703</td>\n",
       "      <td>0.541669</td>\n",
       "      <td>-0.554904</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>-0.766749</td>\n",
       "      <td>0.557232</td>\n",
       "      <td>0.034790</td>\n",
       "      <td>1.720144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>2017</td>\n",
       "      <td>Nikola Vucevic</td>\n",
       "      <td>4.156660</td>\n",
       "      <td>0.591153</td>\n",
       "      <td>1.591307</td>\n",
       "      <td>0.236360</td>\n",
       "      <td>1.162400</td>\n",
       "      <td>0.185219</td>\n",
       "      <td>-0.270069</td>\n",
       "      <td>-0.255398</td>\n",
       "      <td>0.356381</td>\n",
       "      <td>0.559307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2017</td>\n",
       "      <td>Kyle Lowry</td>\n",
       "      <td>4.141570</td>\n",
       "      <td>0.535879</td>\n",
       "      <td>0.195764</td>\n",
       "      <td>2.017329</td>\n",
       "      <td>-0.769567</td>\n",
       "      <td>0.428929</td>\n",
       "      <td>-0.766749</td>\n",
       "      <td>2.066403</td>\n",
       "      <td>-0.765502</td>\n",
       "      <td>1.199083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2017</td>\n",
       "      <td>Otto Porter</td>\n",
       "      <td>4.136911</td>\n",
       "      <td>0.259510</td>\n",
       "      <td>0.505884</td>\n",
       "      <td>-0.476027</td>\n",
       "      <td>-0.125578</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>0.847459</td>\n",
       "      <td>0.557232</td>\n",
       "      <td>0.888985</td>\n",
       "      <td>0.275676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>2017</td>\n",
       "      <td>Kawhi Leonard</td>\n",
       "      <td>4.001655</td>\n",
       "      <td>0.535879</td>\n",
       "      <td>-0.153122</td>\n",
       "      <td>-0.323373</td>\n",
       "      <td>0.947737</td>\n",
       "      <td>2.622318</td>\n",
       "      <td>-0.145900</td>\n",
       "      <td>-0.139308</td>\n",
       "      <td>0.190517</td>\n",
       "      <td>0.466907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>2017</td>\n",
       "      <td>Kevin Love</td>\n",
       "      <td>3.988737</td>\n",
       "      <td>0.793824</td>\n",
       "      <td>1.630072</td>\n",
       "      <td>-0.628682</td>\n",
       "      <td>-0.340241</td>\n",
       "      <td>-0.545910</td>\n",
       "      <td>0.226610</td>\n",
       "      <td>1.137683</td>\n",
       "      <td>-0.085231</td>\n",
       "      <td>1.800614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2017</td>\n",
       "      <td>Andre Drummond</td>\n",
       "      <td>3.805188</td>\n",
       "      <td>0.314784</td>\n",
       "      <td>4.227332</td>\n",
       "      <td>0.032821</td>\n",
       "      <td>2.235716</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>-1.139258</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>1.440481</td>\n",
       "      <td>-3.178068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017</td>\n",
       "      <td>Russell Westbrook</td>\n",
       "      <td>3.763264</td>\n",
       "      <td>2.230942</td>\n",
       "      <td>1.940192</td>\n",
       "      <td>3.747412</td>\n",
       "      <td>-0.554904</td>\n",
       "      <td>2.134898</td>\n",
       "      <td>-3.870994</td>\n",
       "      <td>-0.139308</td>\n",
       "      <td>-0.520390</td>\n",
       "      <td>-1.204585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2017</td>\n",
       "      <td>Kemba Walker</td>\n",
       "      <td>3.725170</td>\n",
       "      <td>1.622930</td>\n",
       "      <td>-0.773363</td>\n",
       "      <td>1.355826</td>\n",
       "      <td>-0.554904</td>\n",
       "      <td>0.428929</td>\n",
       "      <td>-0.642579</td>\n",
       "      <td>1.834223</td>\n",
       "      <td>-0.897960</td>\n",
       "      <td>1.352068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2017</td>\n",
       "      <td>Eric Bledsoe</td>\n",
       "      <td>3.653643</td>\n",
       "      <td>0.830673</td>\n",
       "      <td>-0.463243</td>\n",
       "      <td>1.101402</td>\n",
       "      <td>0.089085</td>\n",
       "      <td>2.622318</td>\n",
       "      <td>-1.511767</td>\n",
       "      <td>0.441142</td>\n",
       "      <td>0.360757</td>\n",
       "      <td>0.183276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>2017</td>\n",
       "      <td>Darrun Hilliard</td>\n",
       "      <td>-8.567256</td>\n",
       "      <td>-2.246234</td>\n",
       "      <td>-1.781256</td>\n",
       "      <td>-1.086645</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.008169</td>\n",
       "      <td>1.716648</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.468564</td>\n",
       "      <td>0.038246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>2017</td>\n",
       "      <td>Tim Quarterman</td>\n",
       "      <td>-8.645561</td>\n",
       "      <td>-2.209385</td>\n",
       "      <td>-1.587430</td>\n",
       "      <td>-1.341069</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>1.219968</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.307768</td>\n",
       "      <td>0.563284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>2017</td>\n",
       "      <td>Demetrius Jackson</td>\n",
       "      <td>-8.660268</td>\n",
       "      <td>-2.319932</td>\n",
       "      <td>-1.626195</td>\n",
       "      <td>-1.290185</td>\n",
       "      <td>-0.984230</td>\n",
       "      <td>-1.520749</td>\n",
       "      <td>1.095798</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.482386</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2017</td>\n",
       "      <td>Markel Brown</td>\n",
       "      <td>-8.715761</td>\n",
       "      <td>-2.209385</td>\n",
       "      <td>-1.471135</td>\n",
       "      <td>-1.239300</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>1.468308</td>\n",
       "      <td>-1.184119</td>\n",
       "      <td>-0.629359</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>2017</td>\n",
       "      <td>Josh Smith</td>\n",
       "      <td>-8.748490</td>\n",
       "      <td>-2.319932</td>\n",
       "      <td>-1.471135</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.569694</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>2017</td>\n",
       "      <td>Erik McCree</td>\n",
       "      <td>-8.773341</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.858786</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-1.520749</td>\n",
       "      <td>1.716648</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.436543</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>2017</td>\n",
       "      <td>Xavier Munford</td>\n",
       "      <td>-8.789856</td>\n",
       "      <td>-2.356782</td>\n",
       "      <td>-1.897551</td>\n",
       "      <td>-1.137530</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-1.764459</td>\n",
       "      <td>1.716648</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.496208</td>\n",
       "      <td>-0.122692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>2017</td>\n",
       "      <td>Tyler Lydon</td>\n",
       "      <td>-8.811713</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.975081</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>2017</td>\n",
       "      <td>Trey McKinney-Jones</td>\n",
       "      <td>-8.811713</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.975081</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>2017</td>\n",
       "      <td>Xavier Rathan-Mayes</td>\n",
       "      <td>-8.814577</td>\n",
       "      <td>-1.380278</td>\n",
       "      <td>-1.587430</td>\n",
       "      <td>0.338130</td>\n",
       "      <td>0.089085</td>\n",
       "      <td>0.672639</td>\n",
       "      <td>-0.642579</td>\n",
       "      <td>-1.300209</td>\n",
       "      <td>-2.811382</td>\n",
       "      <td>-2.192553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>2017</td>\n",
       "      <td>Matt Williams</td>\n",
       "      <td>-8.833537</td>\n",
       "      <td>-2.135687</td>\n",
       "      <td>-1.858786</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>1.716648</td>\n",
       "      <td>-1.184119</td>\n",
       "      <td>-0.427098</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>2017</td>\n",
       "      <td>Cole Aldrich</td>\n",
       "      <td>-8.856290</td>\n",
       "      <td>-2.338357</td>\n",
       "      <td>-1.703725</td>\n",
       "      <td>-1.442839</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.008169</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.234282</td>\n",
       "      <td>-0.486792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>2017</td>\n",
       "      <td>Nicolas Brussino</td>\n",
       "      <td>-8.938136</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.664960</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.436543</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>2017</td>\n",
       "      <td>PJ Dozier</td>\n",
       "      <td>-8.985381</td>\n",
       "      <td>-2.264659</td>\n",
       "      <td>-1.781256</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>1.468308</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>0.069110</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>2017</td>\n",
       "      <td>Omer Asik</td>\n",
       "      <td>-9.030298</td>\n",
       "      <td>-2.209385</td>\n",
       "      <td>-0.967189</td>\n",
       "      <td>-1.442839</td>\n",
       "      <td>-0.984230</td>\n",
       "      <td>-2.008169</td>\n",
       "      <td>1.592478</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.018199</td>\n",
       "      <td>-1.460376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>2017</td>\n",
       "      <td>London Perrantes</td>\n",
       "      <td>-9.069214</td>\n",
       "      <td>-2.356782</td>\n",
       "      <td>-1.858786</td>\n",
       "      <td>-1.290185</td>\n",
       "      <td>-0.984230</td>\n",
       "      <td>-2.008169</td>\n",
       "      <td>1.964987</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.597338</td>\n",
       "      <td>-0.406323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>2017</td>\n",
       "      <td>Jacob Pullen</td>\n",
       "      <td>-9.101093</td>\n",
       "      <td>-2.319932</td>\n",
       "      <td>-1.975081</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>1.716648</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.045843</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>2017</td>\n",
       "      <td>Charles Cooke</td>\n",
       "      <td>-9.142223</td>\n",
       "      <td>-2.356782</td>\n",
       "      <td>-1.897551</td>\n",
       "      <td>-1.442839</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.008169</td>\n",
       "      <td>1.964987</td>\n",
       "      <td>-1.416299</td>\n",
       "      <td>-0.583516</td>\n",
       "      <td>-0.203161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>2017</td>\n",
       "      <td>Nate Wolters</td>\n",
       "      <td>-9.152010</td>\n",
       "      <td>-2.375206</td>\n",
       "      <td>-1.820021</td>\n",
       "      <td>-1.391954</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.670825</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>2017</td>\n",
       "      <td>Derrick Williams</td>\n",
       "      <td>-9.237618</td>\n",
       "      <td>-2.264659</td>\n",
       "      <td>-1.781256</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.803976</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>2017</td>\n",
       "      <td>Josh McRoberts</td>\n",
       "      <td>-9.248257</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.975081</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.436543</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>2017</td>\n",
       "      <td>Nick Collison</td>\n",
       "      <td>-9.288480</td>\n",
       "      <td>-2.061988</td>\n",
       "      <td>-1.471135</td>\n",
       "      <td>-1.341069</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>1.468308</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>0.560941</td>\n",
       "      <td>-1.460376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>2017</td>\n",
       "      <td>Chris Boucher</td>\n",
       "      <td>-9.297149</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.587430</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.873086</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>2017</td>\n",
       "      <td>Kyle Singler</td>\n",
       "      <td>-9.322633</td>\n",
       "      <td>-2.098837</td>\n",
       "      <td>-1.664960</td>\n",
       "      <td>-1.391954</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.008169</td>\n",
       "      <td>1.716648</td>\n",
       "      <td>-1.300209</td>\n",
       "      <td>-0.440920</td>\n",
       "      <td>-0.935338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>2017</td>\n",
       "      <td>Vander Blue</td>\n",
       "      <td>-9.478457</td>\n",
       "      <td>-2.338357</td>\n",
       "      <td>-1.897551</td>\n",
       "      <td>-1.188415</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-1.764459</td>\n",
       "      <td>1.344138</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.496208</td>\n",
       "      <td>-0.406323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>2017</td>\n",
       "      <td>Aaron Jackson</td>\n",
       "      <td>-9.982955</td>\n",
       "      <td>-0.974937</td>\n",
       "      <td>-0.812129</td>\n",
       "      <td>-0.984876</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>0.847459</td>\n",
       "      <td>-0.371488</td>\n",
       "      <td>-2.204598</td>\n",
       "      <td>-2.031614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>2017</td>\n",
       "      <td>Luis Montero</td>\n",
       "      <td>-10.102304</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.587430</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>0.847459</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.436543</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>2017</td>\n",
       "      <td>Chinanu Onuaku</td>\n",
       "      <td>-10.337018</td>\n",
       "      <td>-1.711921</td>\n",
       "      <td>-0.424478</td>\n",
       "      <td>-0.984876</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>-1.635937</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.596646</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>2017</td>\n",
       "      <td>Mindaugas Kuzminskas</td>\n",
       "      <td>-10.557886</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.975081</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-1.746172</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>2017</td>\n",
       "      <td>Scotty Hopson</td>\n",
       "      <td>-12.265018</td>\n",
       "      <td>-2.264659</td>\n",
       "      <td>-1.975081</td>\n",
       "      <td>-0.984876</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>0.847459</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.873086</td>\n",
       "      <td>-2.031614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     season                 player  value_tot  value_points  value_rebounds  \\\n",
       "11     2017          Anthony Davis  13.069292      2.728406        2.327843   \n",
       "161    2017          Stephen Curry  10.977767      2.415188        0.001938   \n",
       "47     2017           Kevin Durant  10.555627      2.415188        0.660945   \n",
       "27     2017           James Harden  10.522310      3.152171        0.118234   \n",
       "6      2017     Karl-Anthony Towns   9.046572      1.475533        2.793024   \n",
       "0      2017           LeBron James   8.050018      2.617858        1.358716   \n",
       "9      2017  Giannis Antetokounmpo   7.982516      2.507311        1.901427   \n",
       "17     2017         Damian Lillard   7.758411      2.507311       -0.230652   \n",
       "120    2017             Chris Paul   7.259998      0.978069        0.118234   \n",
       "68     2017           Jimmy Butler   7.194467      1.641355        0.079468   \n",
       "26     2017         Victor Oladipo   6.742591      1.807176        0.040703   \n",
       "137    2017       DeMarcus Cousins   6.513379      2.194092        3.025615   \n",
       "38     2017           Nikola Jokic   6.424866      0.959645        2.172783   \n",
       "109    2017           Kyrie Irving   6.159878      2.046696       -0.502008   \n",
       "473    2017           Andre Ingram   5.581832     -0.237954       -0.812129   \n",
       "29     2017      LaMarcus Aldridge   5.370052      1.807176        1.319951   \n",
       "418    2017         MarShon Brooks   5.131062      1.254438       -0.812129   \n",
       "8      2017            Paul George   5.126899      1.586081        0.234529   \n",
       "171    2017     Kristaps Porzingis   4.816889      1.733478        0.583415   \n",
       "5      2017           Jrue Holiday   4.397228      1.051768       -0.230652   \n",
       "1      2017        Khris Middleton   4.231094      1.254438        0.040703   \n",
       "147    2017         Nikola Vucevic   4.156660      0.591153        1.591307   \n",
       "30     2017             Kyle Lowry   4.141570      0.535879        0.195764   \n",
       "40     2017            Otto Porter   4.136911      0.259510        0.505884   \n",
       "413    2017          Kawhi Leonard   4.001655      0.535879       -0.153122   \n",
       "155    2017             Kevin Love   3.988737      0.793824        1.630072   \n",
       "20     2017         Andre Drummond   3.805188      0.314784        4.227332   \n",
       "7      2017      Russell Westbrook   3.763264      2.230942        1.940192   \n",
       "10     2017           Kemba Walker   3.725170      1.622930       -0.773363   \n",
       "61     2017           Eric Bledsoe   3.653643      0.830673       -0.463243   \n",
       "..      ...                    ...        ...           ...             ...   \n",
       "456    2017        Darrun Hilliard  -8.567256     -2.246234       -1.781256   \n",
       "513    2017         Tim Quarterman  -8.645561     -2.209385       -1.587430   \n",
       "475    2017      Demetrius Jackson  -8.660268     -2.319932       -1.626195   \n",
       "497    2017           Markel Brown  -8.715761     -2.209385       -1.471135   \n",
       "514    2017             Josh Smith  -8.748490     -2.319932       -1.471135   \n",
       "521    2017            Erik McCree  -8.773341     -2.448905       -1.858786   \n",
       "506    2017         Xavier Munford  -8.789856     -2.356782       -1.897551   \n",
       "536    2017            Tyler Lydon  -8.811713     -2.448905       -1.975081   \n",
       "539    2017    Trey McKinney-Jones  -8.811713     -2.448905       -1.975081   \n",
       "447    2017    Xavier Rathan-Mayes  -8.814577     -1.380278       -1.587430   \n",
       "515    2017          Matt Williams  -8.833537     -2.135687       -1.858786   \n",
       "483    2017           Cole Aldrich  -8.856290     -2.338357       -1.703725   \n",
       "516    2017       Nicolas Brussino  -8.938136     -2.448905       -1.664960   \n",
       "533    2017              PJ Dozier  -8.985381     -2.264659       -1.781256   \n",
       "443    2017              Omer Asik  -9.030298     -2.209385       -0.967189   \n",
       "472    2017       London Perrantes  -9.069214     -2.356782       -1.858786   \n",
       "526    2017           Jacob Pullen  -9.101093     -2.319932       -1.975081   \n",
       "491    2017          Charles Cooke  -9.142223     -2.356782       -1.897551   \n",
       "508    2017           Nate Wolters  -9.152010     -2.375206       -1.820021   \n",
       "517    2017       Derrick Williams  -9.237618     -2.264659       -1.781256   \n",
       "527    2017         Josh McRoberts  -9.248257     -2.448905       -1.975081   \n",
       "466    2017          Nick Collison  -9.288480     -2.061988       -1.471135   \n",
       "538    2017          Chris Boucher  -9.297149     -2.448905       -1.587430   \n",
       "478    2017           Kyle Singler  -9.322633     -2.098837       -1.664960   \n",
       "484    2017            Vander Blue  -9.478457     -2.338357       -1.897551   \n",
       "493    2017          Aaron Jackson  -9.982955     -0.974937       -0.812129   \n",
       "522    2017           Luis Montero -10.102304     -2.448905       -1.587430   \n",
       "505    2017         Chinanu Onuaku -10.337018     -1.711921       -0.424478   \n",
       "534    2017   Mindaugas Kuzminskas -10.557886     -2.448905       -1.975081   \n",
       "520    2017          Scotty Hopson -12.265018     -2.264659       -1.975081   \n",
       "\n",
       "     value_assists  value_blocks  value_steals  value_turnovers  value_threes  \\\n",
       "11       -0.323373      4.382346      1.403769        -0.642579     -0.719758   \n",
       "161       1.610250     -0.769567      1.647478        -1.635937      3.343394   \n",
       "47        1.254056      2.665042     -0.545910        -1.635937      1.369863   \n",
       "27        2.984140      0.303748      2.134898        -3.374314      2.762944   \n",
       "6        -0.272488      1.806390     -0.302200        -0.270069      0.208962   \n",
       "0         3.136795      0.733074      1.160059        -3.125975      0.557232   \n",
       "9         0.948747      1.806390      1.403769        -1.635937     -0.835849   \n",
       "17        1.864674     -0.340241      0.428929        -1.387598      2.066403   \n",
       "120       2.526177     -0.769567      1.891188        -0.642579      1.369863   \n",
       "68        0.999632     -0.340241      2.622318        -0.145900     -0.139308   \n",
       "26        0.694323      0.518411      3.597157        -1.511767      0.905503   \n",
       "137       1.254056      2.235716      1.647478        -4.119333      1.021593   \n",
       "38        1.610250      0.518411      0.672639        -1.387598      0.208962   \n",
       "109       1.101402     -0.554904      0.428929        -0.766749      1.718133   \n",
       "473       0.287245      2.021053      1.403769         0.226610      1.369863   \n",
       "29       -0.476027      1.377064     -0.789620         0.226610     -1.068029   \n",
       "418       0.338130     -0.340241      1.647478        -0.766749      1.602043   \n",
       "8         0.185475     -0.125578      2.622318        -1.263428      2.066403   \n",
       "171      -0.883106      3.953020     -0.302200        -0.270069      0.673322   \n",
       "5         1.559365      0.518411      1.403769        -1.139258      0.208962   \n",
       "1         0.541669     -0.554904      1.403769        -0.766749      0.557232   \n",
       "147       0.236360      1.162400      0.185219        -0.270069     -0.255398   \n",
       "30        2.017329     -0.769567      0.428929        -0.766749      2.066403   \n",
       "40       -0.476027     -0.125578      1.403769         0.847459      0.557232   \n",
       "413      -0.323373      0.947737      2.622318        -0.145900     -0.139308   \n",
       "155      -0.628682     -0.340241     -0.545910         0.226610      1.137683   \n",
       "20        0.032821      2.235716      1.403769        -1.139258     -1.532389   \n",
       "7         3.747412     -0.554904      2.134898        -3.870994     -0.139308   \n",
       "10        1.355826     -0.554904      0.428929        -0.642579      1.834223   \n",
       "61        1.101402      0.089085      2.622318        -1.511767      0.441142   \n",
       "..             ...           ...           ...              ...           ...   \n",
       "456      -1.086645     -1.198893     -2.008169         1.716648     -1.532389   \n",
       "513      -1.341069     -1.198893     -2.251879         1.219968     -1.532389   \n",
       "475      -1.290185     -0.984230     -1.520749         1.095798     -1.532389   \n",
       "497      -1.239300     -1.198893     -2.251879         1.468308     -1.184119   \n",
       "514      -1.493724     -1.198893     -2.251879         2.089157     -1.532389   \n",
       "521      -1.493724     -1.198893     -1.520749         1.716648     -1.532389   \n",
       "506      -1.137530     -1.198893     -1.764459         1.716648     -1.532389   \n",
       "536      -1.493724     -1.198893     -2.251879         2.089157     -1.532389   \n",
       "539      -1.493724     -1.198893     -2.251879         2.089157     -1.532389   \n",
       "447       0.338130      0.089085      0.672639        -0.642579     -1.300209   \n",
       "515      -1.493724     -1.198893     -2.251879         1.716648     -1.184119   \n",
       "483      -1.442839     -1.198893     -2.008169         2.089157     -1.532389   \n",
       "516      -1.493724     -1.198893     -2.251879         2.089157     -1.532389   \n",
       "533      -1.493724     -1.198893     -2.251879         1.468308     -1.532389   \n",
       "443      -1.442839     -0.984230     -2.008169         1.592478     -1.532389   \n",
       "472      -1.290185     -0.984230     -2.008169         1.964987     -1.532389   \n",
       "526      -1.493724     -1.198893     -2.251879         1.716648     -1.532389   \n",
       "491      -1.442839     -1.198893     -2.008169         1.964987     -1.416299   \n",
       "508      -1.391954     -1.198893     -2.251879         2.089157     -1.532389   \n",
       "517      -1.493724     -1.198893     -2.251879         2.089157     -1.532389   \n",
       "527      -1.493724     -1.198893     -2.251879         2.089157     -1.532389   \n",
       "466      -1.341069     -1.198893     -2.251879         1.468308     -1.532389   \n",
       "538      -1.493724     -1.198893     -2.251879         2.089157     -1.532389   \n",
       "478      -1.391954     -1.198893     -2.008169         1.716648     -1.300209   \n",
       "484      -1.188415     -1.198893     -1.764459         1.344138     -1.532389   \n",
       "493      -0.984876     -1.198893     -2.251879         0.847459     -0.371488   \n",
       "522      -1.493724     -1.198893     -2.251879         0.847459     -1.532389   \n",
       "505      -0.984876     -1.198893     -2.251879        -1.635937     -1.532389   \n",
       "534      -1.493724     -1.198893     -2.251879         2.089157     -1.532389   \n",
       "520      -0.984876     -1.198893     -2.251879         0.847459     -1.532389   \n",
       "\n",
       "     value_fg  value_ft  \n",
       "11   2.572502  1.340136  \n",
       "161  1.073741  3.291282  \n",
       "47   1.809299  2.563082  \n",
       "27  -0.589500  3.029989  \n",
       "6    2.213129  1.394291  \n",
       "0    2.935558 -1.323300  \n",
       "9    2.328774 -0.442116  \n",
       "17  -0.920536  3.770119  \n",
       "120 -0.176916  1.965529  \n",
       "68   0.324360  2.152782  \n",
       "26   0.389094  0.301991  \n",
       "137  0.301785 -1.047624  \n",
       "38   0.838766  0.831007  \n",
       "109  0.968233  1.720144  \n",
       "473  0.116338  1.207037  \n",
       "29   1.620860  1.352068  \n",
       "418  1.009007  1.199083  \n",
       "8   -1.086400  0.907499  \n",
       "171 -0.888515  0.217545  \n",
       "5    0.875856  0.149007  \n",
       "1    0.034790  1.720144  \n",
       "147  0.356381  0.559307  \n",
       "30  -0.765502  1.199083  \n",
       "40   0.888985  0.275676  \n",
       "413  0.190517  0.466907  \n",
       "155 -0.085231  1.800614  \n",
       "20   1.440481 -3.178068  \n",
       "7   -0.520390 -1.204585  \n",
       "10  -0.897960  1.352068  \n",
       "61   0.360757  0.183276  \n",
       "..        ...       ...  \n",
       "456 -0.468564  0.038246  \n",
       "513 -0.307768  0.563284  \n",
       "475 -0.482386  0.000000  \n",
       "497 -0.629359  0.000000  \n",
       "514 -0.569694  0.000000  \n",
       "521 -0.436543  0.000000  \n",
       "506 -0.496208 -0.122692  \n",
       "536  0.000000  0.000000  \n",
       "539  0.000000  0.000000  \n",
       "447 -2.811382 -2.192553  \n",
       "515 -0.427098  0.000000  \n",
       "483 -0.234282 -0.486792  \n",
       "516 -0.436543  0.000000  \n",
       "533  0.069110  0.000000  \n",
       "443 -0.018199 -1.460376  \n",
       "472 -0.597338 -0.406323  \n",
       "526 -0.045843  0.000000  \n",
       "491 -0.583516 -0.203161  \n",
       "508 -0.670825  0.000000  \n",
       "517 -0.803976  0.000000  \n",
       "527 -0.436543  0.000000  \n",
       "466  0.560941 -1.460376  \n",
       "538 -0.873086  0.000000  \n",
       "478 -0.440920 -0.935338  \n",
       "484 -0.496208 -0.406323  \n",
       "493 -2.204598 -2.031614  \n",
       "522 -0.436543  0.000000  \n",
       "505 -0.596646  0.000000  \n",
       "534 -1.746172  0.000000  \n",
       "520 -0.873086 -2.031614  \n",
       "\n",
       "[540 rows x 12 columns]"
      ]
     },
     "execution_count": 842,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_2017.value.sort_values(by='value_tot',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Combined Rank</th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>Andy Behrens</th>\n",
       "      <th>Dahlton Del Don</th>\n",
       "      <th>Yahoo Staff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Kevin Durant</td>\n",
       "      <td>GSW</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Russell Westbrook</td>\n",
       "      <td>OKC</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>James Harden</td>\n",
       "      <td>HOU</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Stephen Curry</td>\n",
       "      <td>GSW</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Giannis Antetokounmpo</td>\n",
       "      <td>MIL</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Combined Rank                 PLAYER  TEAM  Andy Behrens  Dahlton Del Don  \\\n",
       "0              1           Kevin Durant  GSW            1.0              1.0   \n",
       "1              2      Russell Westbrook  OKC            2.0              5.0   \n",
       "2              3           James Harden  HOU            6.0              2.0   \n",
       "3              4          Stephen Curry  GSW            3.0              6.0   \n",
       "4              5  Giannis Antetokounmpo  MIL            9.0              3.0   \n",
       "\n",
       "   Yahoo Staff  \n",
       "0          5.0  \n",
       "1          1.0  \n",
       "2          3.0  \n",
       "3          4.0  \n",
       "4          2.0  "
      ]
     },
     "execution_count": 1180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yahoo_ranks['PLAYER']=yahoo_ranks['PLAYER'].str.replace('','')\n",
    "yahoo_ranks['PLAYER']=yahoo_ranks['PLAYER'].str.replace(' Jr.','')\n",
    "yahoo_ranks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>rank</th>\n",
       "      <th>predicted_rank</th>\n",
       "      <th>value_tot_x</th>\n",
       "      <th>value_tot_y</th>\n",
       "      <th>Combined Rank</th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>Andy Behrens</th>\n",
       "      <th>Dahlton Del Don</th>\n",
       "      <th>Yahoo Staff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anthony Davis</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9.616821</td>\n",
       "      <td>13.069292</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Anthony Davis</td>\n",
       "      <td>NOR</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stephen Curry</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9.832003</td>\n",
       "      <td>10.977767</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Stephen Curry</td>\n",
       "      <td>GSW</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kevin Durant</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9.939877</td>\n",
       "      <td>10.555627</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Kevin Durant</td>\n",
       "      <td>GSW</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>James Harden</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9.789783</td>\n",
       "      <td>10.522310</td>\n",
       "      <td>3.0</td>\n",
       "      <td>James Harden</td>\n",
       "      <td>HOU</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Karl-Anthony Towns</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>9.198967</td>\n",
       "      <td>9.046572</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Karl-Anthony Towns</td>\n",
       "      <td>MIN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LeBron James</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>7.601414</td>\n",
       "      <td>8.050018</td>\n",
       "      <td>9.0</td>\n",
       "      <td>LeBron James</td>\n",
       "      <td>LAL</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Giannis Antetokounmpo</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8.567877</td>\n",
       "      <td>7.982516</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Giannis Antetokounmpo</td>\n",
       "      <td>MIL</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Damian Lillard</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>5.473368</td>\n",
       "      <td>7.758411</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Damian Lillard</td>\n",
       "      <td>POR</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chris Paul</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>6.999847</td>\n",
       "      <td>7.259998</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Chris Paul</td>\n",
       "      <td>HOU</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jimmy Butler</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>6.252649</td>\n",
       "      <td>7.194467</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Jimmy Butler</td>\n",
       "      <td>PHI</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Victor Oladipo</td>\n",
       "      <td>11</td>\n",
       "      <td>48</td>\n",
       "      <td>1.779802</td>\n",
       "      <td>6.742591</td>\n",
       "      <td>52.0</td>\n",
       "      <td>Victor Oladipo</td>\n",
       "      <td>IND</td>\n",
       "      <td>45.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DeMarcus Cousins</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>5.235591</td>\n",
       "      <td>6.513379</td>\n",
       "      <td>15.0</td>\n",
       "      <td>DeMarcus Cousins</td>\n",
       "      <td>GSW</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Nikola Jokic</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>6.566469</td>\n",
       "      <td>6.424866</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Nikola Jokic</td>\n",
       "      <td>DEN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Kyrie Irving</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>5.428442</td>\n",
       "      <td>6.159878</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Kyrie Irving</td>\n",
       "      <td>BOS</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LaMarcus Aldridge</td>\n",
       "      <td>15</td>\n",
       "      <td>49</td>\n",
       "      <td>1.775638</td>\n",
       "      <td>5.370052</td>\n",
       "      <td>49.0</td>\n",
       "      <td>LaMarcus Aldridge</td>\n",
       "      <td>SAS</td>\n",
       "      <td>51.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Paul George</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>4.812927</td>\n",
       "      <td>5.126899</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Paul George</td>\n",
       "      <td>OKC</td>\n",
       "      <td>28.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kristaps Porzingis</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>5.134614</td>\n",
       "      <td>4.816889</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Kristaps Porzingis</td>\n",
       "      <td>NYK</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Jrue Holiday</td>\n",
       "      <td>18</td>\n",
       "      <td>47</td>\n",
       "      <td>1.818257</td>\n",
       "      <td>4.397228</td>\n",
       "      <td>43.0</td>\n",
       "      <td>Jrue Holiday</td>\n",
       "      <td>NOR</td>\n",
       "      <td>39.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Khris Middleton</td>\n",
       "      <td>19</td>\n",
       "      <td>65</td>\n",
       "      <td>0.821016</td>\n",
       "      <td>4.231094</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Khris Middleton</td>\n",
       "      <td>MIL</td>\n",
       "      <td>50.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Nikola Vucevic</td>\n",
       "      <td>20</td>\n",
       "      <td>35</td>\n",
       "      <td>2.802864</td>\n",
       "      <td>4.156660</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Nikola Vucevic</td>\n",
       "      <td>ORL</td>\n",
       "      <td>54.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Kyle Lowry</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>5.164371</td>\n",
       "      <td>4.141570</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Kyle Lowry</td>\n",
       "      <td>TOR</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Otto Porter</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "      <td>4.061504</td>\n",
       "      <td>4.136911</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Otto Porter</td>\n",
       "      <td>WAS</td>\n",
       "      <td>56.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Kevin Love</td>\n",
       "      <td>23</td>\n",
       "      <td>37</td>\n",
       "      <td>2.582592</td>\n",
       "      <td>3.988737</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Kevin Love</td>\n",
       "      <td>CLE</td>\n",
       "      <td>32.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Andre Drummond</td>\n",
       "      <td>24</td>\n",
       "      <td>40</td>\n",
       "      <td>2.509121</td>\n",
       "      <td>3.805188</td>\n",
       "      <td>54.0</td>\n",
       "      <td>Andre Drummond</td>\n",
       "      <td>DET</td>\n",
       "      <td>58.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Russell Westbrook</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>10.065838</td>\n",
       "      <td>3.763264</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Russell Westbrook</td>\n",
       "      <td>OKC</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Kemba Walker</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>4.245364</td>\n",
       "      <td>3.725170</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Kemba Walker</td>\n",
       "      <td>CHA</td>\n",
       "      <td>19.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Eric Bledsoe</td>\n",
       "      <td>27</td>\n",
       "      <td>36</td>\n",
       "      <td>2.633253</td>\n",
       "      <td>3.653643</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Eric Bledsoe</td>\n",
       "      <td>MIL</td>\n",
       "      <td>24.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Joel Embiid</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>5.180684</td>\n",
       "      <td>3.553557</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Joel Embiid</td>\n",
       "      <td>PHI</td>\n",
       "      <td>26.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Rudy Gobert</td>\n",
       "      <td>29</td>\n",
       "      <td>13</td>\n",
       "      <td>5.808387</td>\n",
       "      <td>3.474873</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Rudy Gobert</td>\n",
       "      <td>UTH</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Draymond Green</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>5.060514</td>\n",
       "      <td>3.435896</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Draymond Green</td>\n",
       "      <td>GSW</td>\n",
       "      <td>34.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Robert Covington</td>\n",
       "      <td>31</td>\n",
       "      <td>30</td>\n",
       "      <td>3.256315</td>\n",
       "      <td>3.186625</td>\n",
       "      <td>69.0</td>\n",
       "      <td>Robert Covington</td>\n",
       "      <td>MIN</td>\n",
       "      <td>128.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Gary Harris</td>\n",
       "      <td>32</td>\n",
       "      <td>63</td>\n",
       "      <td>0.838795</td>\n",
       "      <td>3.185140</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Gary Harris</td>\n",
       "      <td>DEN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Klay Thompson</td>\n",
       "      <td>33</td>\n",
       "      <td>31</td>\n",
       "      <td>3.218040</td>\n",
       "      <td>3.065733</td>\n",
       "      <td>33.0</td>\n",
       "      <td>Klay Thompson</td>\n",
       "      <td>GSW</td>\n",
       "      <td>43.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Clint Capela</td>\n",
       "      <td>34</td>\n",
       "      <td>119</td>\n",
       "      <td>-0.766625</td>\n",
       "      <td>3.035892</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Clint Capela</td>\n",
       "      <td>HOU</td>\n",
       "      <td>62.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Nikola Mirotic</td>\n",
       "      <td>35</td>\n",
       "      <td>99</td>\n",
       "      <td>-0.244538</td>\n",
       "      <td>2.974891</td>\n",
       "      <td>107.0</td>\n",
       "      <td>Nikola Mirotic</td>\n",
       "      <td>NOR</td>\n",
       "      <td>100.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Bradley Beal</td>\n",
       "      <td>36</td>\n",
       "      <td>29</td>\n",
       "      <td>3.271973</td>\n",
       "      <td>2.870454</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Bradley Beal</td>\n",
       "      <td>WAS</td>\n",
       "      <td>25.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Lou Williams</td>\n",
       "      <td>37</td>\n",
       "      <td>102</td>\n",
       "      <td>-0.301974</td>\n",
       "      <td>2.819207</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Lou Williams</td>\n",
       "      <td>LAC</td>\n",
       "      <td>55.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Hassan Whiteside</td>\n",
       "      <td>38</td>\n",
       "      <td>28</td>\n",
       "      <td>3.661737</td>\n",
       "      <td>2.622560</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Hassan Whiteside</td>\n",
       "      <td>MIA</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Devin Booker</td>\n",
       "      <td>39</td>\n",
       "      <td>57</td>\n",
       "      <td>1.043956</td>\n",
       "      <td>2.577359</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Devin Booker</td>\n",
       "      <td>PHO</td>\n",
       "      <td>41.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>DeMar DeRozan</td>\n",
       "      <td>40</td>\n",
       "      <td>51</td>\n",
       "      <td>1.595688</td>\n",
       "      <td>2.527442</td>\n",
       "      <td>35.0</td>\n",
       "      <td>DeMar DeRozan</td>\n",
       "      <td>SAS</td>\n",
       "      <td>47.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Tyreke Evans</td>\n",
       "      <td>41</td>\n",
       "      <td>75</td>\n",
       "      <td>0.377656</td>\n",
       "      <td>2.285132</td>\n",
       "      <td>162.0</td>\n",
       "      <td>Tyreke Evans</td>\n",
       "      <td>IND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.0</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Al Horford</td>\n",
       "      <td>42</td>\n",
       "      <td>27</td>\n",
       "      <td>3.701909</td>\n",
       "      <td>2.277502</td>\n",
       "      <td>42.0</td>\n",
       "      <td>Al Horford</td>\n",
       "      <td>BOS</td>\n",
       "      <td>49.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Marc Gasol</td>\n",
       "      <td>43</td>\n",
       "      <td>23</td>\n",
       "      <td>4.458690</td>\n",
       "      <td>2.243344</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Marc Gasol</td>\n",
       "      <td>MEM</td>\n",
       "      <td>29.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Darren Collison</td>\n",
       "      <td>44</td>\n",
       "      <td>114</td>\n",
       "      <td>-0.569191</td>\n",
       "      <td>2.143866</td>\n",
       "      <td>96.0</td>\n",
       "      <td>Darren Collison</td>\n",
       "      <td>IND</td>\n",
       "      <td>93.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Enes Kanter</td>\n",
       "      <td>45</td>\n",
       "      <td>61</td>\n",
       "      <td>0.902668</td>\n",
       "      <td>2.017416</td>\n",
       "      <td>101.0</td>\n",
       "      <td>Enes Kanter</td>\n",
       "      <td>NYK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>158.0</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Blake Griffin</td>\n",
       "      <td>46</td>\n",
       "      <td>41</td>\n",
       "      <td>2.356755</td>\n",
       "      <td>1.924843</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Blake Griffin</td>\n",
       "      <td>DET</td>\n",
       "      <td>30.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>CJ McCollum</td>\n",
       "      <td>47</td>\n",
       "      <td>38</td>\n",
       "      <td>2.534642</td>\n",
       "      <td>1.905093</td>\n",
       "      <td>24.0</td>\n",
       "      <td>CJ McCollum</td>\n",
       "      <td>POR</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Josh Richardson</td>\n",
       "      <td>48</td>\n",
       "      <td>116</td>\n",
       "      <td>-0.618384</td>\n",
       "      <td>1.804696</td>\n",
       "      <td>129.0</td>\n",
       "      <td>Josh Richardson</td>\n",
       "      <td>MIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107.0</td>\n",
       "      <td>186.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Tobias Harris</td>\n",
       "      <td>49</td>\n",
       "      <td>33</td>\n",
       "      <td>3.107275</td>\n",
       "      <td>1.788597</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Tobias Harris</td>\n",
       "      <td>LAC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Jeff Teague</td>\n",
       "      <td>50</td>\n",
       "      <td>46</td>\n",
       "      <td>1.852899</td>\n",
       "      <td>1.777921</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Jeff Teague</td>\n",
       "      <td>MIN</td>\n",
       "      <td>33.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   player  rank  predicted_rank  value_tot_x  value_tot_y  \\\n",
       "0           Anthony Davis     1               5     9.616821    13.069292   \n",
       "1           Stephen Curry     2               3     9.832003    10.977767   \n",
       "2            Kevin Durant     3               2     9.939877    10.555627   \n",
       "3            James Harden     4               4     9.789783    10.522310   \n",
       "4      Karl-Anthony Towns     5               6     9.198967     9.046572   \n",
       "5            LeBron James     6               8     7.601414     8.050018   \n",
       "6   Giannis Antetokounmpo     7               7     8.567877     7.982516   \n",
       "7          Damian Lillard     8              14     5.473368     7.758411   \n",
       "8              Chris Paul     9               9     6.999847     7.259998   \n",
       "9            Jimmy Butler    10              11     6.252649     7.194467   \n",
       "10         Victor Oladipo    11              48     1.779802     6.742591   \n",
       "11       DeMarcus Cousins    12              17     5.235591     6.513379   \n",
       "12           Nikola Jokic    13              10     6.566469     6.424866   \n",
       "13           Kyrie Irving    14              15     5.428442     6.159878   \n",
       "14      LaMarcus Aldridge    15              49     1.775638     5.370052   \n",
       "15            Paul George    16              22     4.812927     5.126899   \n",
       "16     Kristaps Porzingis    17              20     5.134614     4.816889   \n",
       "17           Jrue Holiday    18              47     1.818257     4.397228   \n",
       "18        Khris Middleton    19              65     0.821016     4.231094   \n",
       "19         Nikola Vucevic    20              35     2.802864     4.156660   \n",
       "20             Kyle Lowry    21              19     5.164371     4.141570   \n",
       "21            Otto Porter    22              25     4.061504     4.136911   \n",
       "22             Kevin Love    23              37     2.582592     3.988737   \n",
       "23         Andre Drummond    24              40     2.509121     3.805188   \n",
       "24      Russell Westbrook    25               1    10.065838     3.763264   \n",
       "25           Kemba Walker    26              24     4.245364     3.725170   \n",
       "26           Eric Bledsoe    27              36     2.633253     3.653643   \n",
       "27            Joel Embiid    28              18     5.180684     3.553557   \n",
       "28            Rudy Gobert    29              13     5.808387     3.474873   \n",
       "29         Draymond Green    30              21     5.060514     3.435896   \n",
       "30       Robert Covington    31              30     3.256315     3.186625   \n",
       "31            Gary Harris    32              63     0.838795     3.185140   \n",
       "32          Klay Thompson    33              31     3.218040     3.065733   \n",
       "33           Clint Capela    34             119    -0.766625     3.035892   \n",
       "34         Nikola Mirotic    35              99    -0.244538     2.974891   \n",
       "35           Bradley Beal    36              29     3.271973     2.870454   \n",
       "36           Lou Williams    37             102    -0.301974     2.819207   \n",
       "37       Hassan Whiteside    38              28     3.661737     2.622560   \n",
       "38           Devin Booker    39              57     1.043956     2.577359   \n",
       "39          DeMar DeRozan    40              51     1.595688     2.527442   \n",
       "40           Tyreke Evans    41              75     0.377656     2.285132   \n",
       "41             Al Horford    42              27     3.701909     2.277502   \n",
       "42             Marc Gasol    43              23     4.458690     2.243344   \n",
       "43        Darren Collison    44             114    -0.569191     2.143866   \n",
       "44            Enes Kanter    45              61     0.902668     2.017416   \n",
       "45          Blake Griffin    46              41     2.356755     1.924843   \n",
       "46            CJ McCollum    47              38     2.534642     1.905093   \n",
       "47        Josh Richardson    48             116    -0.618384     1.804696   \n",
       "48          Tobias Harris    49              33     3.107275     1.788597   \n",
       "49            Jeff Teague    50              46     1.852899     1.777921   \n",
       "\n",
       "    Combined Rank                 PLAYER  TEAM  Andy Behrens  Dahlton Del Don  \\\n",
       "0             7.0          Anthony Davis  NOR            4.0              8.0   \n",
       "1             4.0          Stephen Curry  GSW            3.0              6.0   \n",
       "2             1.0           Kevin Durant  GSW            1.0              1.0   \n",
       "3             3.0           James Harden  HOU            6.0              2.0   \n",
       "4             6.0     Karl-Anthony Towns  MIN            7.0              4.0   \n",
       "5             9.0           LeBron James  LAL            8.0             13.0   \n",
       "6             5.0  Giannis Antetokounmpo  MIL            9.0              3.0   \n",
       "7            17.0         Damian Lillard  POR           18.0             14.0   \n",
       "8            12.0             Chris Paul  HOU           13.0             10.0   \n",
       "9            16.0           Jimmy Butler  PHI           17.0             12.0   \n",
       "10           52.0         Victor Oladipo  IND           45.0             41.0   \n",
       "11           15.0       DeMarcus Cousins  GSW           14.0             17.0   \n",
       "12           10.0           Nikola Jokic  DEN           11.0              9.0   \n",
       "13           13.0           Kyrie Irving  BOS           15.0             11.0   \n",
       "14           49.0      LaMarcus Aldridge  SAS           51.0             49.0   \n",
       "15           18.0            Paul George  OKC           28.0             19.0   \n",
       "16           20.0     Kristaps Porzingis  NYK           22.0             20.0   \n",
       "17           43.0           Jrue Holiday  NOR           39.0             46.0   \n",
       "18           40.0        Khris Middleton  MIL           50.0             43.0   \n",
       "19           48.0         Nikola Vucevic  ORL           54.0             40.0   \n",
       "20           22.0             Kyle Lowry  TOR           21.0             22.0   \n",
       "21           41.0            Otto Porter  WAS           56.0             35.0   \n",
       "22           34.0             Kevin Love  CLE           32.0             37.0   \n",
       "23           54.0         Andre Drummond  DET           58.0             65.0   \n",
       "24            2.0      Russell Westbrook  OKC            2.0              5.0   \n",
       "25           21.0           Kemba Walker  CHA           19.0             26.0   \n",
       "26           29.0           Eric Bledsoe  MIL           24.0             34.0   \n",
       "27           27.0            Joel Embiid  PHI           26.0             25.0   \n",
       "28           14.0            Rudy Gobert  UTH           12.0             18.0   \n",
       "29           26.0         Draymond Green  GSW           34.0             24.0   \n",
       "30           69.0       Robert Covington  MIN          128.0             53.0   \n",
       "31           80.0            Gary Harris  DEN            NaN             47.0   \n",
       "32           33.0          Klay Thompson  GSW           43.0             31.0   \n",
       "33           60.0           Clint Capela  HOU           62.0             68.0   \n",
       "34          107.0         Nikola Mirotic  NOR          100.0             88.0   \n",
       "35           28.0           Bradley Beal  WAS           25.0             28.0   \n",
       "36           63.0           Lou Williams  LAC           55.0             73.0   \n",
       "37           19.0       Hassan Whiteside  MIA           16.0             23.0   \n",
       "38           51.0           Devin Booker  PHO           41.0             60.0   \n",
       "39           35.0          DeMar DeRozan  SAS           47.0             32.0   \n",
       "40          162.0           Tyreke Evans  IND            NaN            180.0   \n",
       "41           42.0             Al Horford  BOS           49.0             38.0   \n",
       "42           31.0             Marc Gasol  MEM           29.0             27.0   \n",
       "43           96.0        Darren Collison  IND           93.0             80.0   \n",
       "44          101.0            Enes Kanter  NYK            NaN            158.0   \n",
       "45           30.0          Blake Griffin  DET           30.0             33.0   \n",
       "46           24.0            CJ McCollum  POR           20.0             30.0   \n",
       "47          129.0        Josh Richardson  MIA            NaN            107.0   \n",
       "48           68.0          Tobias Harris  LAC            NaN             52.0   \n",
       "49           45.0            Jeff Teague  MIN           33.0             66.0   \n",
       "\n",
       "    Yahoo Staff  \n",
       "0           7.0  \n",
       "1           4.0  \n",
       "2           5.0  \n",
       "3           3.0  \n",
       "4           6.0  \n",
       "5          10.0  \n",
       "6           2.0  \n",
       "7          18.0  \n",
       "8          16.0  \n",
       "9          20.0  \n",
       "10         69.0  \n",
       "11         14.0  \n",
       "12         11.0  \n",
       "13         15.0  \n",
       "14         49.0  \n",
       "15         12.0  \n",
       "16         19.0  \n",
       "17         50.0  \n",
       "18         36.0  \n",
       "19         54.0  \n",
       "20         24.0  \n",
       "21         40.0  \n",
       "22         39.0  \n",
       "23         55.0  \n",
       "24          1.0  \n",
       "25         22.0  \n",
       "26         29.0  \n",
       "27         31.0  \n",
       "28         13.0  \n",
       "29         17.0  \n",
       "30         63.0  \n",
       "31        101.0  \n",
       "32         28.0  \n",
       "33         70.0  \n",
       "34        149.0  \n",
       "35         33.0  \n",
       "36         77.0  \n",
       "37         21.0  \n",
       "38         53.0  \n",
       "39         30.0  \n",
       "40        135.0  \n",
       "41         48.0  \n",
       "42         35.0  \n",
       "43         96.0  \n",
       "44         79.0  \n",
       "45         26.0  \n",
       "46         23.0  \n",
       "47        186.0  \n",
       "48         61.0  \n",
       "49         41.0  "
      ]
     },
     "execution_count": 1182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ranks = pd.merge(rank_preds,yahoo_ranks,how='left',left_on='player',right_on='PLAYER')\n",
    "\n",
    "all_ranks[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1206,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = all_ranks.copy()[['player']]\n",
    "l2 = all_ranks.copy().sort_values(by='predicted_rank',ascending=True).reset_index()['player']\n",
    "l3 = all_ranks.copy().sort_values(by='Combined Rank',ascending=True).reset_index()['player']\n",
    "l4 = all_ranks.copy().sort_values(by='Yahoo Staff',ascending=True).reset_index()['player']\n",
    "l5 = all_ranks.copy().sort_values(by='Andy Behrens',ascending=True).reset_index()['player']\n",
    "l6 = all_ranks.copy().sort_values(by='Dahlton Del Don',ascending=True).reset_index()['player']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Anthony Davis'],\n",
       "       ['Stephen Curry'],\n",
       "       ['Kevin Durant']], dtype=object)"
      ]
     },
     "execution_count": 1184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(l1.copy()[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(l1,l2,n=150):\n",
    "    weights = []\n",
    "    for i in range(1,n+1):\n",
    "        a = np.array(l1.copy()[0:i])\n",
    "        b = 0.0\n",
    "        for x in range(0,i):\n",
    "            if l2.copy().loc[x] in a:\n",
    "                b+=1.0\n",
    "        weights.append(b/i)\n",
    "    return np.mean(weights)\n",
    "\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my prediction first 100: 0.7462726976385661\n",
      "yahoo combined first 100: 0.7340696091076896\n",
      "yahoo staff first 100: 0.7138117029656793\n",
      "Andy Behrens first 100: 0.7122762102222214\n",
      "Dahlton Del Don first 100: 0.7420632541011389\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "print('my prediction first {}: {}'.format(n,evaluate(l1.copy(),l2.copy(),n)))\n",
    "print('yahoo combined first {}: {}'.format(n,evaluate(l1.copy(),l3.copy(),n)))\n",
    "print('yahoo staff first {}: {}'.format(n,evaluate(l1.copy(),l4.copy(),n)))\n",
    "print('Andy Behrens first {}: {}'.format(n,evaluate(l1.copy(),l5.copy(),n)))\n",
    "print('Dahlton Del Don first {}: {}'.format(n,evaluate(l1.copy(),l6.copy(),n)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>rank</th>\n",
       "      <th>predicted_rank</th>\n",
       "      <th>value_tot_x</th>\n",
       "      <th>value_tot_y</th>\n",
       "      <th>Combined Rank</th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>Andy Behrens</th>\n",
       "      <th>Dahlton Del Don</th>\n",
       "      <th>Yahoo Staff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anthony Davis</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9.616821</td>\n",
       "      <td>13.069292</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Anthony Davis</td>\n",
       "      <td>NOR</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stephen Curry</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9.832003</td>\n",
       "      <td>10.977767</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Stephen Curry</td>\n",
       "      <td>GSW</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kevin Durant</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9.939877</td>\n",
       "      <td>10.555627</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Kevin Durant</td>\n",
       "      <td>GSW</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>James Harden</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9.789783</td>\n",
       "      <td>10.522310</td>\n",
       "      <td>3.0</td>\n",
       "      <td>James Harden</td>\n",
       "      <td>HOU</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Karl-Anthony Towns</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>9.198967</td>\n",
       "      <td>9.046572</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Karl-Anthony Towns</td>\n",
       "      <td>MIN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LeBron James</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>7.601414</td>\n",
       "      <td>8.050018</td>\n",
       "      <td>9.0</td>\n",
       "      <td>LeBron James</td>\n",
       "      <td>LAL</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Giannis Antetokounmpo</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8.567877</td>\n",
       "      <td>7.982516</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Giannis Antetokounmpo</td>\n",
       "      <td>MIL</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Damian Lillard</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>5.473368</td>\n",
       "      <td>7.758411</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Damian Lillard</td>\n",
       "      <td>POR</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chris Paul</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>6.999847</td>\n",
       "      <td>7.259998</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Chris Paul</td>\n",
       "      <td>HOU</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jimmy Butler</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>6.252649</td>\n",
       "      <td>7.194467</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Jimmy Butler</td>\n",
       "      <td>PHI</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Victor Oladipo</td>\n",
       "      <td>11</td>\n",
       "      <td>48</td>\n",
       "      <td>1.779802</td>\n",
       "      <td>6.742591</td>\n",
       "      <td>52.0</td>\n",
       "      <td>Victor Oladipo</td>\n",
       "      <td>IND</td>\n",
       "      <td>45.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DeMarcus Cousins</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>5.235591</td>\n",
       "      <td>6.513379</td>\n",
       "      <td>15.0</td>\n",
       "      <td>DeMarcus Cousins</td>\n",
       "      <td>GSW</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Nikola Jokic</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>6.566469</td>\n",
       "      <td>6.424866</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Nikola Jokic</td>\n",
       "      <td>DEN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Kyrie Irving</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>5.428442</td>\n",
       "      <td>6.159878</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Kyrie Irving</td>\n",
       "      <td>BOS</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LaMarcus Aldridge</td>\n",
       "      <td>15</td>\n",
       "      <td>49</td>\n",
       "      <td>1.775638</td>\n",
       "      <td>5.370052</td>\n",
       "      <td>49.0</td>\n",
       "      <td>LaMarcus Aldridge</td>\n",
       "      <td>SAS</td>\n",
       "      <td>51.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Paul George</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>4.812927</td>\n",
       "      <td>5.126899</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Paul George</td>\n",
       "      <td>OKC</td>\n",
       "      <td>28.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kristaps Porzingis</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "      <td>5.134614</td>\n",
       "      <td>4.816889</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Kristaps Porzingis</td>\n",
       "      <td>NYK</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Jrue Holiday</td>\n",
       "      <td>18</td>\n",
       "      <td>47</td>\n",
       "      <td>1.818257</td>\n",
       "      <td>4.397228</td>\n",
       "      <td>43.0</td>\n",
       "      <td>Jrue Holiday</td>\n",
       "      <td>NOR</td>\n",
       "      <td>39.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Khris Middleton</td>\n",
       "      <td>19</td>\n",
       "      <td>65</td>\n",
       "      <td>0.821016</td>\n",
       "      <td>4.231094</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Khris Middleton</td>\n",
       "      <td>MIL</td>\n",
       "      <td>50.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Nikola Vucevic</td>\n",
       "      <td>20</td>\n",
       "      <td>35</td>\n",
       "      <td>2.802864</td>\n",
       "      <td>4.156660</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Nikola Vucevic</td>\n",
       "      <td>ORL</td>\n",
       "      <td>54.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Kyle Lowry</td>\n",
       "      <td>21</td>\n",
       "      <td>19</td>\n",
       "      <td>5.164371</td>\n",
       "      <td>4.141570</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Kyle Lowry</td>\n",
       "      <td>TOR</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Otto Porter</td>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "      <td>4.061504</td>\n",
       "      <td>4.136911</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Otto Porter</td>\n",
       "      <td>WAS</td>\n",
       "      <td>56.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Kevin Love</td>\n",
       "      <td>23</td>\n",
       "      <td>37</td>\n",
       "      <td>2.582592</td>\n",
       "      <td>3.988737</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Kevin Love</td>\n",
       "      <td>CLE</td>\n",
       "      <td>32.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Andre Drummond</td>\n",
       "      <td>24</td>\n",
       "      <td>40</td>\n",
       "      <td>2.509121</td>\n",
       "      <td>3.805188</td>\n",
       "      <td>54.0</td>\n",
       "      <td>Andre Drummond</td>\n",
       "      <td>DET</td>\n",
       "      <td>58.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Russell Westbrook</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>10.065838</td>\n",
       "      <td>3.763264</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Russell Westbrook</td>\n",
       "      <td>OKC</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Kemba Walker</td>\n",
       "      <td>26</td>\n",
       "      <td>24</td>\n",
       "      <td>4.245364</td>\n",
       "      <td>3.725170</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Kemba Walker</td>\n",
       "      <td>CHA</td>\n",
       "      <td>19.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Eric Bledsoe</td>\n",
       "      <td>27</td>\n",
       "      <td>36</td>\n",
       "      <td>2.633253</td>\n",
       "      <td>3.653643</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Eric Bledsoe</td>\n",
       "      <td>MIL</td>\n",
       "      <td>24.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Joel Embiid</td>\n",
       "      <td>28</td>\n",
       "      <td>18</td>\n",
       "      <td>5.180684</td>\n",
       "      <td>3.553557</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Joel Embiid</td>\n",
       "      <td>PHI</td>\n",
       "      <td>26.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Rudy Gobert</td>\n",
       "      <td>29</td>\n",
       "      <td>13</td>\n",
       "      <td>5.808387</td>\n",
       "      <td>3.474873</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Rudy Gobert</td>\n",
       "      <td>UTH</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Draymond Green</td>\n",
       "      <td>30</td>\n",
       "      <td>21</td>\n",
       "      <td>5.060514</td>\n",
       "      <td>3.435896</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Draymond Green</td>\n",
       "      <td>GSW</td>\n",
       "      <td>34.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Robin Lopez</td>\n",
       "      <td>171</td>\n",
       "      <td>95</td>\n",
       "      <td>-0.081828</td>\n",
       "      <td>-2.513065</td>\n",
       "      <td>109.0</td>\n",
       "      <td>Robin Lopez</td>\n",
       "      <td>CHI</td>\n",
       "      <td>89.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Jae Crowder</td>\n",
       "      <td>172</td>\n",
       "      <td>87</td>\n",
       "      <td>0.087582</td>\n",
       "      <td>-2.515449</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Jae Crowder</td>\n",
       "      <td>UTH</td>\n",
       "      <td>91.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Cory Joseph</td>\n",
       "      <td>173</td>\n",
       "      <td>160</td>\n",
       "      <td>-1.888611</td>\n",
       "      <td>-2.520356</td>\n",
       "      <td>184.0</td>\n",
       "      <td>Cory Joseph</td>\n",
       "      <td>IND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Maurice Harkless</td>\n",
       "      <td>174</td>\n",
       "      <td>104</td>\n",
       "      <td>-0.363484</td>\n",
       "      <td>-2.539700</td>\n",
       "      <td>157.0</td>\n",
       "      <td>Maurice Harkless</td>\n",
       "      <td>POR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132.0</td>\n",
       "      <td>162.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Dejounte Murray</td>\n",
       "      <td>175</td>\n",
       "      <td>278</td>\n",
       "      <td>-4.669061</td>\n",
       "      <td>-2.547384</td>\n",
       "      <td>214.0</td>\n",
       "      <td>Dejounte Murray</td>\n",
       "      <td>SAS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>188.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Shabazz Napier</td>\n",
       "      <td>176</td>\n",
       "      <td>287</td>\n",
       "      <td>-5.093488</td>\n",
       "      <td>-2.598822</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Andre Roberson</td>\n",
       "      <td>177</td>\n",
       "      <td>123</td>\n",
       "      <td>-0.861630</td>\n",
       "      <td>-2.627905</td>\n",
       "      <td>169.0</td>\n",
       "      <td>Andre Roberson</td>\n",
       "      <td>OKC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>141.0</td>\n",
       "      <td>170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Tyus Jones</td>\n",
       "      <td>178</td>\n",
       "      <td>215</td>\n",
       "      <td>-3.175982</td>\n",
       "      <td>-2.636447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>James Ennis</td>\n",
       "      <td>179</td>\n",
       "      <td>201</td>\n",
       "      <td>-2.780075</td>\n",
       "      <td>-2.650949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Luc Mbah a Moute</td>\n",
       "      <td>180</td>\n",
       "      <td>295</td>\n",
       "      <td>-5.558334</td>\n",
       "      <td>-2.652474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Tyson Chandler</td>\n",
       "      <td>181</td>\n",
       "      <td>139</td>\n",
       "      <td>-1.332593</td>\n",
       "      <td>-2.690522</td>\n",
       "      <td>178.0</td>\n",
       "      <td>Tyson Chandler</td>\n",
       "      <td>LAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>152.0</td>\n",
       "      <td>217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Marcus Smart</td>\n",
       "      <td>182</td>\n",
       "      <td>77</td>\n",
       "      <td>0.337518</td>\n",
       "      <td>-2.697004</td>\n",
       "      <td>94.0</td>\n",
       "      <td>Marcus Smart</td>\n",
       "      <td>BOS</td>\n",
       "      <td>87.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Andre Iguodala</td>\n",
       "      <td>183</td>\n",
       "      <td>106</td>\n",
       "      <td>-0.403033</td>\n",
       "      <td>-2.702815</td>\n",
       "      <td>164.0</td>\n",
       "      <td>Andre Iguodala</td>\n",
       "      <td>GSW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136.0</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Quinn Cook</td>\n",
       "      <td>184</td>\n",
       "      <td>276</td>\n",
       "      <td>-4.614812</td>\n",
       "      <td>-2.743507</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Wesley Johnson</td>\n",
       "      <td>185</td>\n",
       "      <td>240</td>\n",
       "      <td>-3.720472</td>\n",
       "      <td>-2.752677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Jonathon Simmons</td>\n",
       "      <td>186</td>\n",
       "      <td>186</td>\n",
       "      <td>-2.612875</td>\n",
       "      <td>-2.779381</td>\n",
       "      <td>203.0</td>\n",
       "      <td>Jonathon Simmons</td>\n",
       "      <td>ORL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Dwyane Wade</td>\n",
       "      <td>187</td>\n",
       "      <td>124</td>\n",
       "      <td>-0.889848</td>\n",
       "      <td>-2.796991</td>\n",
       "      <td>87.0</td>\n",
       "      <td>Dwyane Wade</td>\n",
       "      <td>MIA</td>\n",
       "      <td>63.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Frank Kaminsky</td>\n",
       "      <td>188</td>\n",
       "      <td>145</td>\n",
       "      <td>-1.453069</td>\n",
       "      <td>-2.797919</td>\n",
       "      <td>124.0</td>\n",
       "      <td>Frank Kaminsky</td>\n",
       "      <td>CHA</td>\n",
       "      <td>102.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Stanley Johnson</td>\n",
       "      <td>189</td>\n",
       "      <td>144</td>\n",
       "      <td>-1.389577</td>\n",
       "      <td>-2.873479</td>\n",
       "      <td>175.0</td>\n",
       "      <td>Stanley Johnson</td>\n",
       "      <td>DET</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>Garrett Temple</td>\n",
       "      <td>190</td>\n",
       "      <td>162</td>\n",
       "      <td>-1.913843</td>\n",
       "      <td>-2.876957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Justise Winslow</td>\n",
       "      <td>191</td>\n",
       "      <td>227</td>\n",
       "      <td>-3.396730</td>\n",
       "      <td>-2.938563</td>\n",
       "      <td>139.0</td>\n",
       "      <td>Justise Winslow</td>\n",
       "      <td>MIA</td>\n",
       "      <td>115.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Nemanja Bjelica</td>\n",
       "      <td>192</td>\n",
       "      <td>252</td>\n",
       "      <td>-3.980338</td>\n",
       "      <td>-2.956512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>J.R. Smith</td>\n",
       "      <td>193</td>\n",
       "      <td>130</td>\n",
       "      <td>-1.091000</td>\n",
       "      <td>-2.958959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Tony Snell</td>\n",
       "      <td>194</td>\n",
       "      <td>185</td>\n",
       "      <td>-2.526121</td>\n",
       "      <td>-2.963949</td>\n",
       "      <td>204.0</td>\n",
       "      <td>Tony Snell</td>\n",
       "      <td>MIL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>198.0</td>\n",
       "      <td>181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>C.J. Miles</td>\n",
       "      <td>195</td>\n",
       "      <td>149</td>\n",
       "      <td>-1.527586</td>\n",
       "      <td>-3.001869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Ed Davis</td>\n",
       "      <td>196</td>\n",
       "      <td>255</td>\n",
       "      <td>-4.063884</td>\n",
       "      <td>-3.006733</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Jerian Grant</td>\n",
       "      <td>197</td>\n",
       "      <td>192</td>\n",
       "      <td>-2.679175</td>\n",
       "      <td>-3.018571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Richaun Holmes</td>\n",
       "      <td>198</td>\n",
       "      <td>88</td>\n",
       "      <td>0.080998</td>\n",
       "      <td>-3.068791</td>\n",
       "      <td>177.0</td>\n",
       "      <td>Richaun Holmes</td>\n",
       "      <td>PHO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>159.0</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Avery Bradley</td>\n",
       "      <td>199</td>\n",
       "      <td>66</td>\n",
       "      <td>0.819506</td>\n",
       "      <td>-3.112203</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Avery Bradley</td>\n",
       "      <td>LAC</td>\n",
       "      <td>73.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Jerami Grant</td>\n",
       "      <td>200</td>\n",
       "      <td>181</td>\n",
       "      <td>-2.465293</td>\n",
       "      <td>-3.142402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    player  rank  predicted_rank  value_tot_x  value_tot_y  \\\n",
       "0            Anthony Davis     1               5     9.616821    13.069292   \n",
       "1            Stephen Curry     2               3     9.832003    10.977767   \n",
       "2             Kevin Durant     3               2     9.939877    10.555627   \n",
       "3             James Harden     4               4     9.789783    10.522310   \n",
       "4       Karl-Anthony Towns     5               6     9.198967     9.046572   \n",
       "5             LeBron James     6               8     7.601414     8.050018   \n",
       "6    Giannis Antetokounmpo     7               7     8.567877     7.982516   \n",
       "7           Damian Lillard     8              14     5.473368     7.758411   \n",
       "8               Chris Paul     9               9     6.999847     7.259998   \n",
       "9             Jimmy Butler    10              11     6.252649     7.194467   \n",
       "10          Victor Oladipo    11              48     1.779802     6.742591   \n",
       "11        DeMarcus Cousins    12              17     5.235591     6.513379   \n",
       "12            Nikola Jokic    13              10     6.566469     6.424866   \n",
       "13            Kyrie Irving    14              15     5.428442     6.159878   \n",
       "14       LaMarcus Aldridge    15              49     1.775638     5.370052   \n",
       "15             Paul George    16              22     4.812927     5.126899   \n",
       "16      Kristaps Porzingis    17              20     5.134614     4.816889   \n",
       "17            Jrue Holiday    18              47     1.818257     4.397228   \n",
       "18         Khris Middleton    19              65     0.821016     4.231094   \n",
       "19          Nikola Vucevic    20              35     2.802864     4.156660   \n",
       "20              Kyle Lowry    21              19     5.164371     4.141570   \n",
       "21             Otto Porter    22              25     4.061504     4.136911   \n",
       "22              Kevin Love    23              37     2.582592     3.988737   \n",
       "23          Andre Drummond    24              40     2.509121     3.805188   \n",
       "24       Russell Westbrook    25               1    10.065838     3.763264   \n",
       "25            Kemba Walker    26              24     4.245364     3.725170   \n",
       "26            Eric Bledsoe    27              36     2.633253     3.653643   \n",
       "27             Joel Embiid    28              18     5.180684     3.553557   \n",
       "28             Rudy Gobert    29              13     5.808387     3.474873   \n",
       "29          Draymond Green    30              21     5.060514     3.435896   \n",
       "..                     ...   ...             ...          ...          ...   \n",
       "170            Robin Lopez   171              95    -0.081828    -2.513065   \n",
       "171            Jae Crowder   172              87     0.087582    -2.515449   \n",
       "172            Cory Joseph   173             160    -1.888611    -2.520356   \n",
       "173       Maurice Harkless   174             104    -0.363484    -2.539700   \n",
       "174        Dejounte Murray   175             278    -4.669061    -2.547384   \n",
       "175         Shabazz Napier   176             287    -5.093488    -2.598822   \n",
       "176         Andre Roberson   177             123    -0.861630    -2.627905   \n",
       "177             Tyus Jones   178             215    -3.175982    -2.636447   \n",
       "178            James Ennis   179             201    -2.780075    -2.650949   \n",
       "179       Luc Mbah a Moute   180             295    -5.558334    -2.652474   \n",
       "180         Tyson Chandler   181             139    -1.332593    -2.690522   \n",
       "181           Marcus Smart   182              77     0.337518    -2.697004   \n",
       "182         Andre Iguodala   183             106    -0.403033    -2.702815   \n",
       "183             Quinn Cook   184             276    -4.614812    -2.743507   \n",
       "184         Wesley Johnson   185             240    -3.720472    -2.752677   \n",
       "185       Jonathon Simmons   186             186    -2.612875    -2.779381   \n",
       "186            Dwyane Wade   187             124    -0.889848    -2.796991   \n",
       "187         Frank Kaminsky   188             145    -1.453069    -2.797919   \n",
       "188        Stanley Johnson   189             144    -1.389577    -2.873479   \n",
       "189         Garrett Temple   190             162    -1.913843    -2.876957   \n",
       "190        Justise Winslow   191             227    -3.396730    -2.938563   \n",
       "191        Nemanja Bjelica   192             252    -3.980338    -2.956512   \n",
       "192             J.R. Smith   193             130    -1.091000    -2.958959   \n",
       "193             Tony Snell   194             185    -2.526121    -2.963949   \n",
       "194             C.J. Miles   195             149    -1.527586    -3.001869   \n",
       "195               Ed Davis   196             255    -4.063884    -3.006733   \n",
       "196           Jerian Grant   197             192    -2.679175    -3.018571   \n",
       "197         Richaun Holmes   198              88     0.080998    -3.068791   \n",
       "198          Avery Bradley   199              66     0.819506    -3.112203   \n",
       "199           Jerami Grant   200             181    -2.465293    -3.142402   \n",
       "\n",
       "     Combined Rank                 PLAYER  TEAM  Andy Behrens  \\\n",
       "0              7.0          Anthony Davis  NOR            4.0   \n",
       "1              4.0          Stephen Curry  GSW            3.0   \n",
       "2              1.0           Kevin Durant  GSW            1.0   \n",
       "3              3.0           James Harden  HOU            6.0   \n",
       "4              6.0     Karl-Anthony Towns  MIN            7.0   \n",
       "5              9.0           LeBron James  LAL            8.0   \n",
       "6              5.0  Giannis Antetokounmpo  MIL            9.0   \n",
       "7             17.0         Damian Lillard  POR           18.0   \n",
       "8             12.0             Chris Paul  HOU           13.0   \n",
       "9             16.0           Jimmy Butler  PHI           17.0   \n",
       "10            52.0         Victor Oladipo  IND           45.0   \n",
       "11            15.0       DeMarcus Cousins  GSW           14.0   \n",
       "12            10.0           Nikola Jokic  DEN           11.0   \n",
       "13            13.0           Kyrie Irving  BOS           15.0   \n",
       "14            49.0      LaMarcus Aldridge  SAS           51.0   \n",
       "15            18.0            Paul George  OKC           28.0   \n",
       "16            20.0     Kristaps Porzingis  NYK           22.0   \n",
       "17            43.0           Jrue Holiday  NOR           39.0   \n",
       "18            40.0        Khris Middleton  MIL           50.0   \n",
       "19            48.0         Nikola Vucevic  ORL           54.0   \n",
       "20            22.0             Kyle Lowry  TOR           21.0   \n",
       "21            41.0            Otto Porter  WAS           56.0   \n",
       "22            34.0             Kevin Love  CLE           32.0   \n",
       "23            54.0         Andre Drummond  DET           58.0   \n",
       "24             2.0      Russell Westbrook  OKC            2.0   \n",
       "25            21.0           Kemba Walker  CHA           19.0   \n",
       "26            29.0           Eric Bledsoe  MIL           24.0   \n",
       "27            27.0            Joel Embiid  PHI           26.0   \n",
       "28            14.0            Rudy Gobert  UTH           12.0   \n",
       "29            26.0         Draymond Green  GSW           34.0   \n",
       "..             ...                    ...   ...           ...   \n",
       "170          109.0            Robin Lopez  CHI           89.0   \n",
       "171           78.0            Jae Crowder  UTH           91.0   \n",
       "172          184.0            Cory Joseph  IND            NaN   \n",
       "173          157.0       Maurice Harkless  POR            NaN   \n",
       "174          214.0        Dejounte Murray  SAS            NaN   \n",
       "175            NaN                    NaN   NaN           NaN   \n",
       "176          169.0         Andre Roberson  OKC            NaN   \n",
       "177            NaN                    NaN   NaN           NaN   \n",
       "178            NaN                    NaN   NaN           NaN   \n",
       "179            NaN                    NaN   NaN           NaN   \n",
       "180          178.0         Tyson Chandler  LAL            NaN   \n",
       "181           94.0           Marcus Smart  BOS           87.0   \n",
       "182          164.0         Andre Iguodala  GSW            NaN   \n",
       "183            NaN                    NaN   NaN           NaN   \n",
       "184            NaN                    NaN   NaN           NaN   \n",
       "185          203.0       Jonathon Simmons  ORL            NaN   \n",
       "186           87.0            Dwyane Wade  MIA           63.0   \n",
       "187          124.0         Frank Kaminsky  CHA          102.0   \n",
       "188          175.0        Stanley Johnson  DET            NaN   \n",
       "189            NaN                    NaN   NaN           NaN   \n",
       "190          139.0        Justise Winslow  MIA          115.0   \n",
       "191            NaN                    NaN   NaN           NaN   \n",
       "192            NaN                    NaN   NaN           NaN   \n",
       "193          204.0             Tony Snell  MIL            NaN   \n",
       "194            NaN                    NaN   NaN           NaN   \n",
       "195            NaN                    NaN   NaN           NaN   \n",
       "196            NaN                    NaN   NaN           NaN   \n",
       "197          177.0         Richaun Holmes  PHO            NaN   \n",
       "198           65.0          Avery Bradley  LAC           73.0   \n",
       "199            NaN                    NaN   NaN           NaN   \n",
       "\n",
       "     Dahlton Del Don  Yahoo Staff  \n",
       "0                8.0          7.0  \n",
       "1                6.0          4.0  \n",
       "2                1.0          5.0  \n",
       "3                2.0          3.0  \n",
       "4                4.0          6.0  \n",
       "5               13.0         10.0  \n",
       "6                3.0          2.0  \n",
       "7               14.0         18.0  \n",
       "8               10.0         16.0  \n",
       "9               12.0         20.0  \n",
       "10              41.0         69.0  \n",
       "11              17.0         14.0  \n",
       "12               9.0         11.0  \n",
       "13              11.0         15.0  \n",
       "14              49.0         49.0  \n",
       "15              19.0         12.0  \n",
       "16              20.0         19.0  \n",
       "17              46.0         50.0  \n",
       "18              43.0         36.0  \n",
       "19              40.0         54.0  \n",
       "20              22.0         24.0  \n",
       "21              35.0         40.0  \n",
       "22              37.0         39.0  \n",
       "23              65.0         55.0  \n",
       "24               5.0          1.0  \n",
       "25              26.0         22.0  \n",
       "26              34.0         29.0  \n",
       "27              25.0         31.0  \n",
       "28              18.0         13.0  \n",
       "29              24.0         17.0  \n",
       "..               ...          ...  \n",
       "170            131.0        126.0  \n",
       "171             97.0         58.0  \n",
       "172              NaN        156.0  \n",
       "173            132.0        162.0  \n",
       "174              NaN        188.0  \n",
       "175              NaN          NaN  \n",
       "176            141.0        170.0  \n",
       "177              NaN          NaN  \n",
       "178              NaN          NaN  \n",
       "179              NaN          NaN  \n",
       "180            152.0        217.0  \n",
       "181             86.0         95.0  \n",
       "182            136.0        177.0  \n",
       "183              NaN          NaN  \n",
       "184              NaN          NaN  \n",
       "185              NaN        180.0  \n",
       "186            101.0         98.0  \n",
       "187            161.0        111.0  \n",
       "188            150.0          NaN  \n",
       "189              NaN          NaN  \n",
       "190            145.0        150.0  \n",
       "191              NaN          NaN  \n",
       "192              NaN          NaN  \n",
       "193            198.0        181.0  \n",
       "194              NaN          NaN  \n",
       "195              NaN          NaN  \n",
       "196              NaN          NaN  \n",
       "197            159.0        151.0  \n",
       "198             57.0         80.0  \n",
       "199              NaN          NaN  \n",
       "\n",
       "[200 rows x 11 columns]"
      ]
     },
     "execution_count": 1242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          Russell Westbrook\n",
       "1               Kevin Durant\n",
       "2              Stephen Curry\n",
       "3               James Harden\n",
       "4              Anthony Davis\n",
       "5         Karl-Anthony Towns\n",
       "6      Giannis Antetokounmpo\n",
       "7               LeBron James\n",
       "8                 Chris Paul\n",
       "9               Nikola Jokic\n",
       "10              Jimmy Butler\n",
       "11              Myles Turner\n",
       "12               Rudy Gobert\n",
       "13            Damian Lillard\n",
       "14              Kyrie Irving\n",
       "15                 John Wall\n",
       "16          DeMarcus Cousins\n",
       "17               Joel Embiid\n",
       "18                Kyle Lowry\n",
       "19        Kristaps Porzingis\n",
       "20            Draymond Green\n",
       "21               Paul George\n",
       "22                Marc Gasol\n",
       "23              Kemba Walker\n",
       "24               Otto Porter\n",
       "25                Al Horford\n",
       "26          Hassan Whiteside\n",
       "27              Bradley Beal\n",
       "28          Robert Covington\n",
       "29             Klay Thompson\n",
       "               ...          \n",
       "170               Tyus Jones\n",
       "171             Delon Wright\n",
       "172              Kelly Oubre\n",
       "173               David West\n",
       "174          Justise Winslow\n",
       "175               J.J. Barea\n",
       "176         Anthony Tolliver\n",
       "177           Wesley Johnson\n",
       "178               Jeff Green\n",
       "179               Trey Lyles\n",
       "180            Mario Hezonja\n",
       "181         Denzel Valentine\n",
       "182               Joe Harris\n",
       "183          Nemanja Bjelica\n",
       "184             Terry Rozier\n",
       "185                 Ed Davis\n",
       "186            D.J. Augustin\n",
       "187             Kosta Koufos\n",
       "188              Buddy Hield\n",
       "189            Pascal Siakam\n",
       "190               Trey Burke\n",
       "191               Quinn Cook\n",
       "192         Domantas Sabonis\n",
       "193          Dejounte Murray\n",
       "194             Jakob Poeltl\n",
       "195            Fred VanVleet\n",
       "196           Shabazz Napier\n",
       "197             Gerald Green\n",
       "198         Luc Mbah a Moute\n",
       "199         Tomas Satoransky\n",
       "Name: player, Length: 200, dtype: object"
      ]
     },
     "execution_count": 1203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7483000472698519"
      ]
     },
     "execution_count": 1192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(l1,l3,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1038,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>rank</th>\n",
       "      <th>predicted_rank</th>\n",
       "      <th>value_tot_x</th>\n",
       "      <th>value_tot_y</th>\n",
       "      <th>Combined Rank</th>\n",
       "      <th>PLAYER</th>\n",
       "      <th>TEAM</th>\n",
       "      <th>Andy Behrens</th>\n",
       "      <th>Dahlton Del Don</th>\n",
       "      <th>Yahoo Staff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anthony Davis</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9.806667</td>\n",
       "      <td>13.069292</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Anthony Davis</td>\n",
       "      <td>NOR</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stephen Curry</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9.812032</td>\n",
       "      <td>10.977767</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Stephen Curry</td>\n",
       "      <td>GSW</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kevin Durant</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10.070235</td>\n",
       "      <td>10.555627</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Kevin Durant</td>\n",
       "      <td>GSW</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>James Harden</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9.622534</td>\n",
       "      <td>10.522310</td>\n",
       "      <td>3.0</td>\n",
       "      <td>James Harden</td>\n",
       "      <td>HOU</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Karl-Anthony Towns</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>9.131304</td>\n",
       "      <td>9.046572</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Karl-Anthony Towns</td>\n",
       "      <td>MIN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LeBron James</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>7.362802</td>\n",
       "      <td>8.050018</td>\n",
       "      <td>9.0</td>\n",
       "      <td>LeBron James</td>\n",
       "      <td>LAL</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Giannis Antetokounmpo</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>8.520065</td>\n",
       "      <td>7.982516</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Giannis Antetokounmpo</td>\n",
       "      <td>MIL</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Damian Lillard</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>5.331345</td>\n",
       "      <td>7.758411</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Damian Lillard</td>\n",
       "      <td>POR</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chris Paul</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>7.402694</td>\n",
       "      <td>7.259998</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Chris Paul</td>\n",
       "      <td>HOU</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jimmy Butler</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>6.343362</td>\n",
       "      <td>7.194467</td>\n",
       "      <td>16.0</td>\n",
       "      <td>Jimmy Butler</td>\n",
       "      <td>PHI</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Victor Oladipo</td>\n",
       "      <td>11</td>\n",
       "      <td>53</td>\n",
       "      <td>1.251168</td>\n",
       "      <td>6.742591</td>\n",
       "      <td>52.0</td>\n",
       "      <td>Victor Oladipo</td>\n",
       "      <td>IND</td>\n",
       "      <td>45.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DeMarcus Cousins</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>5.225028</td>\n",
       "      <td>6.513379</td>\n",
       "      <td>15.0</td>\n",
       "      <td>DeMarcus Cousins</td>\n",
       "      <td>GSW</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Nikola Jokic</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>6.485715</td>\n",
       "      <td>6.424866</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Nikola Jokic</td>\n",
       "      <td>DEN</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Kyrie Irving</td>\n",
       "      <td>14</td>\n",
       "      <td>21</td>\n",
       "      <td>4.838035</td>\n",
       "      <td>6.159878</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Kyrie Irving</td>\n",
       "      <td>BOS</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LaMarcus Aldridge</td>\n",
       "      <td>15</td>\n",
       "      <td>50</td>\n",
       "      <td>1.475079</td>\n",
       "      <td>5.370052</td>\n",
       "      <td>49.0</td>\n",
       "      <td>LaMarcus Aldridge</td>\n",
       "      <td>SAS</td>\n",
       "      <td>51.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Paul George</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>5.100138</td>\n",
       "      <td>5.126899</td>\n",
       "      <td>18.0</td>\n",
       "      <td>Paul George</td>\n",
       "      <td>OKC</td>\n",
       "      <td>28.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kristaps Porzingis</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>4.823553</td>\n",
       "      <td>4.816889</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Kristaps Porzingis</td>\n",
       "      <td>NYK</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Jrue Holiday</td>\n",
       "      <td>18</td>\n",
       "      <td>46</td>\n",
       "      <td>1.854057</td>\n",
       "      <td>4.397228</td>\n",
       "      <td>43.0</td>\n",
       "      <td>Jrue Holiday</td>\n",
       "      <td>NOR</td>\n",
       "      <td>39.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Khris Middleton</td>\n",
       "      <td>19</td>\n",
       "      <td>58</td>\n",
       "      <td>0.999538</td>\n",
       "      <td>4.231094</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Khris Middleton</td>\n",
       "      <td>MIL</td>\n",
       "      <td>50.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Nikola Vucevic</td>\n",
       "      <td>20</td>\n",
       "      <td>41</td>\n",
       "      <td>2.543841</td>\n",
       "      <td>4.156660</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Nikola Vucevic</td>\n",
       "      <td>ORL</td>\n",
       "      <td>54.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Kyle Lowry</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>5.420132</td>\n",
       "      <td>4.141570</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Kyle Lowry</td>\n",
       "      <td>TOR</td>\n",
       "      <td>21.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Otto Porter</td>\n",
       "      <td>22</td>\n",
       "      <td>24</td>\n",
       "      <td>4.202257</td>\n",
       "      <td>4.136911</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Otto Porter</td>\n",
       "      <td>WAS</td>\n",
       "      <td>56.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Kevin Love</td>\n",
       "      <td>23</td>\n",
       "      <td>39</td>\n",
       "      <td>2.640084</td>\n",
       "      <td>3.988737</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Kevin Love</td>\n",
       "      <td>CLE</td>\n",
       "      <td>32.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Andre Drummond</td>\n",
       "      <td>24</td>\n",
       "      <td>40</td>\n",
       "      <td>2.625226</td>\n",
       "      <td>3.805188</td>\n",
       "      <td>54.0</td>\n",
       "      <td>Andre Drummond</td>\n",
       "      <td>DET</td>\n",
       "      <td>58.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Russell Westbrook</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>9.847682</td>\n",
       "      <td>3.763264</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Russell Westbrook</td>\n",
       "      <td>OKC</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Kemba Walker</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>4.100614</td>\n",
       "      <td>3.725170</td>\n",
       "      <td>21.0</td>\n",
       "      <td>Kemba Walker</td>\n",
       "      <td>CHA</td>\n",
       "      <td>19.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Eric Bledsoe</td>\n",
       "      <td>27</td>\n",
       "      <td>37</td>\n",
       "      <td>2.725121</td>\n",
       "      <td>3.653643</td>\n",
       "      <td>29.0</td>\n",
       "      <td>Eric Bledsoe</td>\n",
       "      <td>MIL</td>\n",
       "      <td>24.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Joel Embiid</td>\n",
       "      <td>28</td>\n",
       "      <td>20</td>\n",
       "      <td>4.928110</td>\n",
       "      <td>3.553557</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Joel Embiid</td>\n",
       "      <td>PHI</td>\n",
       "      <td>26.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Rudy Gobert</td>\n",
       "      <td>29</td>\n",
       "      <td>12</td>\n",
       "      <td>5.865661</td>\n",
       "      <td>3.474873</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Rudy Gobert</td>\n",
       "      <td>UTH</td>\n",
       "      <td>12.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Draymond Green</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>5.086017</td>\n",
       "      <td>3.435896</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Draymond Green</td>\n",
       "      <td>GSW</td>\n",
       "      <td>34.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Robin Lopez</td>\n",
       "      <td>171</td>\n",
       "      <td>106</td>\n",
       "      <td>-0.304118</td>\n",
       "      <td>-2.513065</td>\n",
       "      <td>109.0</td>\n",
       "      <td>Robin Lopez</td>\n",
       "      <td>CHI</td>\n",
       "      <td>89.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Jae Crowder</td>\n",
       "      <td>172</td>\n",
       "      <td>87</td>\n",
       "      <td>0.067868</td>\n",
       "      <td>-2.515449</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Jae Crowder</td>\n",
       "      <td>UTH</td>\n",
       "      <td>91.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Cory Joseph</td>\n",
       "      <td>173</td>\n",
       "      <td>176</td>\n",
       "      <td>-2.331650</td>\n",
       "      <td>-2.520356</td>\n",
       "      <td>184.0</td>\n",
       "      <td>Cory Joseph</td>\n",
       "      <td>IND</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Maurice Harkless</td>\n",
       "      <td>174</td>\n",
       "      <td>104</td>\n",
       "      <td>-0.238651</td>\n",
       "      <td>-2.539700</td>\n",
       "      <td>157.0</td>\n",
       "      <td>Maurice Harkless</td>\n",
       "      <td>POR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>132.0</td>\n",
       "      <td>162.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Dejounte Murray</td>\n",
       "      <td>175</td>\n",
       "      <td>282</td>\n",
       "      <td>-4.951308</td>\n",
       "      <td>-2.547384</td>\n",
       "      <td>214.0</td>\n",
       "      <td>Dejounte Murray</td>\n",
       "      <td>SAS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>188.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Shabazz Napier</td>\n",
       "      <td>176</td>\n",
       "      <td>290</td>\n",
       "      <td>-5.246493</td>\n",
       "      <td>-2.598822</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Andre Roberson</td>\n",
       "      <td>177</td>\n",
       "      <td>124</td>\n",
       "      <td>-0.786739</td>\n",
       "      <td>-2.627905</td>\n",
       "      <td>169.0</td>\n",
       "      <td>Andre Roberson</td>\n",
       "      <td>OKC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>141.0</td>\n",
       "      <td>170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Tyus Jones</td>\n",
       "      <td>178</td>\n",
       "      <td>200</td>\n",
       "      <td>-2.871145</td>\n",
       "      <td>-2.636447</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>James Ennis</td>\n",
       "      <td>179</td>\n",
       "      <td>195</td>\n",
       "      <td>-2.734089</td>\n",
       "      <td>-2.650949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Luc Mbah a Moute</td>\n",
       "      <td>180</td>\n",
       "      <td>292</td>\n",
       "      <td>-5.308009</td>\n",
       "      <td>-2.652474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Tyson Chandler</td>\n",
       "      <td>181</td>\n",
       "      <td>121</td>\n",
       "      <td>-0.751155</td>\n",
       "      <td>-2.690522</td>\n",
       "      <td>178.0</td>\n",
       "      <td>Tyson Chandler</td>\n",
       "      <td>LAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>152.0</td>\n",
       "      <td>217.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Marcus Smart</td>\n",
       "      <td>182</td>\n",
       "      <td>77</td>\n",
       "      <td>0.320233</td>\n",
       "      <td>-2.697004</td>\n",
       "      <td>94.0</td>\n",
       "      <td>Marcus Smart</td>\n",
       "      <td>BOS</td>\n",
       "      <td>87.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Andre Iguodala</td>\n",
       "      <td>183</td>\n",
       "      <td>103</td>\n",
       "      <td>-0.212835</td>\n",
       "      <td>-2.702815</td>\n",
       "      <td>164.0</td>\n",
       "      <td>Andre Iguodala</td>\n",
       "      <td>GSW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136.0</td>\n",
       "      <td>177.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Quinn Cook</td>\n",
       "      <td>184</td>\n",
       "      <td>272</td>\n",
       "      <td>-4.458241</td>\n",
       "      <td>-2.743507</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Wesley Johnson</td>\n",
       "      <td>185</td>\n",
       "      <td>231</td>\n",
       "      <td>-3.476305</td>\n",
       "      <td>-2.752677</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Jonathon Simmons</td>\n",
       "      <td>186</td>\n",
       "      <td>197</td>\n",
       "      <td>-2.779420</td>\n",
       "      <td>-2.779381</td>\n",
       "      <td>203.0</td>\n",
       "      <td>Jonathon Simmons</td>\n",
       "      <td>ORL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Dwyane Wade</td>\n",
       "      <td>187</td>\n",
       "      <td>126</td>\n",
       "      <td>-0.822268</td>\n",
       "      <td>-2.796991</td>\n",
       "      <td>87.0</td>\n",
       "      <td>Dwyane Wade</td>\n",
       "      <td>MIA</td>\n",
       "      <td>63.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Frank Kaminsky</td>\n",
       "      <td>188</td>\n",
       "      <td>151</td>\n",
       "      <td>-1.567235</td>\n",
       "      <td>-2.797919</td>\n",
       "      <td>124.0</td>\n",
       "      <td>Frank Kaminsky</td>\n",
       "      <td>CHA</td>\n",
       "      <td>102.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>111.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Stanley Johnson</td>\n",
       "      <td>189</td>\n",
       "      <td>142</td>\n",
       "      <td>-1.356105</td>\n",
       "      <td>-2.873479</td>\n",
       "      <td>175.0</td>\n",
       "      <td>Stanley Johnson</td>\n",
       "      <td>DET</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>Garrett Temple</td>\n",
       "      <td>190</td>\n",
       "      <td>172</td>\n",
       "      <td>-2.251288</td>\n",
       "      <td>-2.876957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Justise Winslow</td>\n",
       "      <td>191</td>\n",
       "      <td>233</td>\n",
       "      <td>-3.491598</td>\n",
       "      <td>-2.938563</td>\n",
       "      <td>139.0</td>\n",
       "      <td>Justise Winslow</td>\n",
       "      <td>MIA</td>\n",
       "      <td>115.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Nemanja Bjelica</td>\n",
       "      <td>192</td>\n",
       "      <td>252</td>\n",
       "      <td>-3.966048</td>\n",
       "      <td>-2.956512</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>J.R. Smith</td>\n",
       "      <td>193</td>\n",
       "      <td>138</td>\n",
       "      <td>-1.256952</td>\n",
       "      <td>-2.958959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Tony Snell</td>\n",
       "      <td>194</td>\n",
       "      <td>186</td>\n",
       "      <td>-2.528710</td>\n",
       "      <td>-2.963949</td>\n",
       "      <td>204.0</td>\n",
       "      <td>Tony Snell</td>\n",
       "      <td>MIL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>198.0</td>\n",
       "      <td>181.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>C.J. Miles</td>\n",
       "      <td>195</td>\n",
       "      <td>135</td>\n",
       "      <td>-1.194247</td>\n",
       "      <td>-3.001869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Ed Davis</td>\n",
       "      <td>196</td>\n",
       "      <td>240</td>\n",
       "      <td>-3.636499</td>\n",
       "      <td>-3.006733</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Jerian Grant</td>\n",
       "      <td>197</td>\n",
       "      <td>209</td>\n",
       "      <td>-3.025787</td>\n",
       "      <td>-3.018571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Richaun Holmes</td>\n",
       "      <td>198</td>\n",
       "      <td>101</td>\n",
       "      <td>-0.177594</td>\n",
       "      <td>-3.068791</td>\n",
       "      <td>177.0</td>\n",
       "      <td>Richaun Holmes</td>\n",
       "      <td>PHO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>159.0</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Avery Bradley</td>\n",
       "      <td>199</td>\n",
       "      <td>65</td>\n",
       "      <td>0.846834</td>\n",
       "      <td>-3.112203</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Avery Bradley</td>\n",
       "      <td>LAC</td>\n",
       "      <td>73.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Jerami Grant</td>\n",
       "      <td>200</td>\n",
       "      <td>171</td>\n",
       "      <td>-2.237334</td>\n",
       "      <td>-3.142402</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    player  rank  predicted_rank  value_tot_x  value_tot_y  \\\n",
       "0            Anthony Davis     1               4     9.806667    13.069292   \n",
       "1            Stephen Curry     2               3     9.812032    10.977767   \n",
       "2             Kevin Durant     3               1    10.070235    10.555627   \n",
       "3             James Harden     4               5     9.622534    10.522310   \n",
       "4       Karl-Anthony Towns     5               6     9.131304     9.046572   \n",
       "5             LeBron James     6               9     7.362802     8.050018   \n",
       "6    Giannis Antetokounmpo     7               7     8.520065     7.982516   \n",
       "7           Damian Lillard     8              15     5.331345     7.758411   \n",
       "8               Chris Paul     9               8     7.402694     7.259998   \n",
       "9             Jimmy Butler    10              11     6.343362     7.194467   \n",
       "10          Victor Oladipo    11              53     1.251168     6.742591   \n",
       "11        DeMarcus Cousins    12              16     5.225028     6.513379   \n",
       "12            Nikola Jokic    13              10     6.485715     6.424866   \n",
       "13            Kyrie Irving    14              21     4.838035     6.159878   \n",
       "14       LaMarcus Aldridge    15              50     1.475079     5.370052   \n",
       "15             Paul George    16              18     5.100138     5.126899   \n",
       "16      Kristaps Porzingis    17              22     4.823553     4.816889   \n",
       "17            Jrue Holiday    18              46     1.854057     4.397228   \n",
       "18         Khris Middleton    19              58     0.999538     4.231094   \n",
       "19          Nikola Vucevic    20              41     2.543841     4.156660   \n",
       "20              Kyle Lowry    21              14     5.420132     4.141570   \n",
       "21             Otto Porter    22              24     4.202257     4.136911   \n",
       "22              Kevin Love    23              39     2.640084     3.988737   \n",
       "23          Andre Drummond    24              40     2.625226     3.805188   \n",
       "24       Russell Westbrook    25               2     9.847682     3.763264   \n",
       "25            Kemba Walker    26              25     4.100614     3.725170   \n",
       "26            Eric Bledsoe    27              37     2.725121     3.653643   \n",
       "27             Joel Embiid    28              20     4.928110     3.553557   \n",
       "28             Rudy Gobert    29              12     5.865661     3.474873   \n",
       "29          Draymond Green    30              19     5.086017     3.435896   \n",
       "..                     ...   ...             ...          ...          ...   \n",
       "170            Robin Lopez   171             106    -0.304118    -2.513065   \n",
       "171            Jae Crowder   172              87     0.067868    -2.515449   \n",
       "172            Cory Joseph   173             176    -2.331650    -2.520356   \n",
       "173       Maurice Harkless   174             104    -0.238651    -2.539700   \n",
       "174        Dejounte Murray   175             282    -4.951308    -2.547384   \n",
       "175         Shabazz Napier   176             290    -5.246493    -2.598822   \n",
       "176         Andre Roberson   177             124    -0.786739    -2.627905   \n",
       "177             Tyus Jones   178             200    -2.871145    -2.636447   \n",
       "178            James Ennis   179             195    -2.734089    -2.650949   \n",
       "179       Luc Mbah a Moute   180             292    -5.308009    -2.652474   \n",
       "180         Tyson Chandler   181             121    -0.751155    -2.690522   \n",
       "181           Marcus Smart   182              77     0.320233    -2.697004   \n",
       "182         Andre Iguodala   183             103    -0.212835    -2.702815   \n",
       "183             Quinn Cook   184             272    -4.458241    -2.743507   \n",
       "184         Wesley Johnson   185             231    -3.476305    -2.752677   \n",
       "185       Jonathon Simmons   186             197    -2.779420    -2.779381   \n",
       "186            Dwyane Wade   187             126    -0.822268    -2.796991   \n",
       "187         Frank Kaminsky   188             151    -1.567235    -2.797919   \n",
       "188        Stanley Johnson   189             142    -1.356105    -2.873479   \n",
       "189         Garrett Temple   190             172    -2.251288    -2.876957   \n",
       "190        Justise Winslow   191             233    -3.491598    -2.938563   \n",
       "191        Nemanja Bjelica   192             252    -3.966048    -2.956512   \n",
       "192             J.R. Smith   193             138    -1.256952    -2.958959   \n",
       "193             Tony Snell   194             186    -2.528710    -2.963949   \n",
       "194             C.J. Miles   195             135    -1.194247    -3.001869   \n",
       "195               Ed Davis   196             240    -3.636499    -3.006733   \n",
       "196           Jerian Grant   197             209    -3.025787    -3.018571   \n",
       "197         Richaun Holmes   198             101    -0.177594    -3.068791   \n",
       "198          Avery Bradley   199              65     0.846834    -3.112203   \n",
       "199           Jerami Grant   200             171    -2.237334    -3.142402   \n",
       "\n",
       "     Combined Rank                 PLAYER  TEAM  Andy Behrens  \\\n",
       "0              7.0          Anthony Davis  NOR            4.0   \n",
       "1              4.0          Stephen Curry  GSW            3.0   \n",
       "2              1.0           Kevin Durant  GSW            1.0   \n",
       "3              3.0           James Harden  HOU            6.0   \n",
       "4              6.0     Karl-Anthony Towns  MIN            7.0   \n",
       "5              9.0           LeBron James  LAL            8.0   \n",
       "6              5.0  Giannis Antetokounmpo  MIL            9.0   \n",
       "7             17.0         Damian Lillard  POR           18.0   \n",
       "8             12.0             Chris Paul  HOU           13.0   \n",
       "9             16.0           Jimmy Butler  PHI           17.0   \n",
       "10            52.0         Victor Oladipo  IND           45.0   \n",
       "11            15.0       DeMarcus Cousins  GSW           14.0   \n",
       "12            10.0           Nikola Jokic  DEN           11.0   \n",
       "13            13.0           Kyrie Irving  BOS           15.0   \n",
       "14            49.0      LaMarcus Aldridge  SAS           51.0   \n",
       "15            18.0            Paul George  OKC           28.0   \n",
       "16            20.0     Kristaps Porzingis  NYK           22.0   \n",
       "17            43.0           Jrue Holiday  NOR           39.0   \n",
       "18            40.0        Khris Middleton  MIL           50.0   \n",
       "19            48.0         Nikola Vucevic  ORL           54.0   \n",
       "20            22.0             Kyle Lowry  TOR           21.0   \n",
       "21            41.0            Otto Porter  WAS           56.0   \n",
       "22            34.0             Kevin Love  CLE           32.0   \n",
       "23            54.0         Andre Drummond  DET           58.0   \n",
       "24             2.0      Russell Westbrook  OKC            2.0   \n",
       "25            21.0           Kemba Walker  CHA           19.0   \n",
       "26            29.0           Eric Bledsoe  MIL           24.0   \n",
       "27            27.0            Joel Embiid  PHI           26.0   \n",
       "28            14.0            Rudy Gobert  UTH           12.0   \n",
       "29            26.0         Draymond Green  GSW           34.0   \n",
       "..             ...                    ...   ...           ...   \n",
       "170          109.0            Robin Lopez  CHI           89.0   \n",
       "171           78.0            Jae Crowder  UTH           91.0   \n",
       "172          184.0            Cory Joseph  IND            NaN   \n",
       "173          157.0       Maurice Harkless  POR            NaN   \n",
       "174          214.0        Dejounte Murray  SAS            NaN   \n",
       "175            NaN                    NaN   NaN           NaN   \n",
       "176          169.0         Andre Roberson  OKC            NaN   \n",
       "177            NaN                    NaN   NaN           NaN   \n",
       "178            NaN                    NaN   NaN           NaN   \n",
       "179            NaN                    NaN   NaN           NaN   \n",
       "180          178.0         Tyson Chandler  LAL            NaN   \n",
       "181           94.0           Marcus Smart  BOS           87.0   \n",
       "182          164.0         Andre Iguodala  GSW            NaN   \n",
       "183            NaN                    NaN   NaN           NaN   \n",
       "184            NaN                    NaN   NaN           NaN   \n",
       "185          203.0       Jonathon Simmons  ORL            NaN   \n",
       "186           87.0            Dwyane Wade  MIA           63.0   \n",
       "187          124.0         Frank Kaminsky  CHA          102.0   \n",
       "188          175.0        Stanley Johnson  DET            NaN   \n",
       "189            NaN                    NaN   NaN           NaN   \n",
       "190          139.0        Justise Winslow  MIA          115.0   \n",
       "191            NaN                    NaN   NaN           NaN   \n",
       "192            NaN                    NaN   NaN           NaN   \n",
       "193          204.0             Tony Snell  MIL            NaN   \n",
       "194            NaN                    NaN   NaN           NaN   \n",
       "195            NaN                    NaN   NaN           NaN   \n",
       "196            NaN                    NaN   NaN           NaN   \n",
       "197          177.0         Richaun Holmes  PHO            NaN   \n",
       "198           65.0          Avery Bradley  LAC           73.0   \n",
       "199            NaN                    NaN   NaN           NaN   \n",
       "\n",
       "     Dahlton Del Don  Yahoo Staff  \n",
       "0                8.0          7.0  \n",
       "1                6.0          4.0  \n",
       "2                1.0          5.0  \n",
       "3                2.0          3.0  \n",
       "4                4.0          6.0  \n",
       "5               13.0         10.0  \n",
       "6                3.0          2.0  \n",
       "7               14.0         18.0  \n",
       "8               10.0         16.0  \n",
       "9               12.0         20.0  \n",
       "10              41.0         69.0  \n",
       "11              17.0         14.0  \n",
       "12               9.0         11.0  \n",
       "13              11.0         15.0  \n",
       "14              49.0         49.0  \n",
       "15              19.0         12.0  \n",
       "16              20.0         19.0  \n",
       "17              46.0         50.0  \n",
       "18              43.0         36.0  \n",
       "19              40.0         54.0  \n",
       "20              22.0         24.0  \n",
       "21              35.0         40.0  \n",
       "22              37.0         39.0  \n",
       "23              65.0         55.0  \n",
       "24               5.0          1.0  \n",
       "25              26.0         22.0  \n",
       "26              34.0         29.0  \n",
       "27              25.0         31.0  \n",
       "28              18.0         13.0  \n",
       "29              24.0         17.0  \n",
       "..               ...          ...  \n",
       "170            131.0        126.0  \n",
       "171             97.0         58.0  \n",
       "172              NaN        156.0  \n",
       "173            132.0        162.0  \n",
       "174              NaN        188.0  \n",
       "175              NaN          NaN  \n",
       "176            141.0        170.0  \n",
       "177              NaN          NaN  \n",
       "178              NaN          NaN  \n",
       "179              NaN          NaN  \n",
       "180            152.0        217.0  \n",
       "181             86.0         95.0  \n",
       "182            136.0        177.0  \n",
       "183              NaN          NaN  \n",
       "184              NaN          NaN  \n",
       "185              NaN        180.0  \n",
       "186            101.0         98.0  \n",
       "187            161.0        111.0  \n",
       "188            150.0          NaN  \n",
       "189              NaN          NaN  \n",
       "190            145.0        150.0  \n",
       "191              NaN          NaN  \n",
       "192              NaN          NaN  \n",
       "193            198.0        181.0  \n",
       "194              NaN          NaN  \n",
       "195              NaN          NaN  \n",
       "196              NaN          NaN  \n",
       "197            159.0        151.0  \n",
       "198             57.0         80.0  \n",
       "199              NaN          NaN  \n",
       "\n",
       "[200 rows x 11 columns]"
      ]
     },
     "execution_count": 1038,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1276,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['player']=='Stephen Curry']['age']\n",
    "df[df['player']=='Stephen Curry']['points']\n",
    "\n",
    "df['points'] = df['points'].astype(float)\n",
    "df['age'] = df['age'].astype(float)\n",
    "df['season'] = df['season'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>player</th>\n",
       "      <th>position</th>\n",
       "      <th>age</th>\n",
       "      <th>team</th>\n",
       "      <th>gamesPlayed</th>\n",
       "      <th>gamesStarted</th>\n",
       "      <th>minutes</th>\n",
       "      <th>points</th>\n",
       "      <th>rebounds</th>\n",
       "      <th>...</th>\n",
       "      <th>steals</th>\n",
       "      <th>blocks</th>\n",
       "      <th>turnovers</th>\n",
       "      <th>threes_made</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>starter</th>\n",
       "      <th>min_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2008</td>\n",
       "      <td>Ryan Gomes</td>\n",
       "      <td>SF</td>\n",
       "      <td>26.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>82</td>\n",
       "      <td>76</td>\n",
       "      <td>31.9</td>\n",
       "      <td>13.3</td>\n",
       "      <td>4.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>11.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2008</td>\n",
       "      <td>Randy Foye</td>\n",
       "      <td>SG</td>\n",
       "      <td>25.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>70</td>\n",
       "      <td>61</td>\n",
       "      <td>35.6</td>\n",
       "      <td>16.3</td>\n",
       "      <td>3.1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>5.7</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2008</td>\n",
       "      <td>Mike Miller</td>\n",
       "      <td>SF</td>\n",
       "      <td>28.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>73</td>\n",
       "      <td>47</td>\n",
       "      <td>32.3</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2008</td>\n",
       "      <td>Sebastian Telfair</td>\n",
       "      <td>PG</td>\n",
       "      <td>23.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>75</td>\n",
       "      <td>43</td>\n",
       "      <td>27.9</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>2008</td>\n",
       "      <td>Kevin Love</td>\n",
       "      <td>C</td>\n",
       "      <td>20.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>81</td>\n",
       "      <td>37</td>\n",
       "      <td>25.3</td>\n",
       "      <td>11.1</td>\n",
       "      <td>9.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>8.5</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>2008</td>\n",
       "      <td>Al Jefferson</td>\n",
       "      <td>C</td>\n",
       "      <td>24.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>36.7</td>\n",
       "      <td>23.1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>19.5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>2008</td>\n",
       "      <td>Craig Smith</td>\n",
       "      <td>PF</td>\n",
       "      <td>25.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>74</td>\n",
       "      <td>31</td>\n",
       "      <td>19.7</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>2008</td>\n",
       "      <td>Rodney Carney</td>\n",
       "      <td>SG</td>\n",
       "      <td>24.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>67</td>\n",
       "      <td>6</td>\n",
       "      <td>17.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>2008</td>\n",
       "      <td>Brian Cardinal</td>\n",
       "      <td>PF</td>\n",
       "      <td>31.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>14.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>2008</td>\n",
       "      <td>Kevin Ollie</td>\n",
       "      <td>PG</td>\n",
       "      <td>36.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>50</td>\n",
       "      <td>21</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>2008</td>\n",
       "      <td>Rashad McCants</td>\n",
       "      <td>SG</td>\n",
       "      <td>24.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>58</td>\n",
       "      <td>3</td>\n",
       "      <td>19.4</td>\n",
       "      <td>9.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>2008</td>\n",
       "      <td>Jason Collins</td>\n",
       "      <td>C</td>\n",
       "      <td>30.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>31</td>\n",
       "      <td>22</td>\n",
       "      <td>13.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>2008</td>\n",
       "      <td>Corey Brewer</td>\n",
       "      <td>SF</td>\n",
       "      <td>22.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>20.5</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>2008</td>\n",
       "      <td>Mark Madsen</td>\n",
       "      <td>C</td>\n",
       "      <td>33.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>2009</td>\n",
       "      <td>Corey Brewer</td>\n",
       "      <td>SG</td>\n",
       "      <td>23.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>30.3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>2009</td>\n",
       "      <td>Al Jefferson</td>\n",
       "      <td>C</td>\n",
       "      <td>25.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>76</td>\n",
       "      <td>76</td>\n",
       "      <td>32.4</td>\n",
       "      <td>17.1</td>\n",
       "      <td>9.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>14.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>2009</td>\n",
       "      <td>Jonny Flynn</td>\n",
       "      <td>PG</td>\n",
       "      <td>20.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>28.9</td>\n",
       "      <td>13.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>11.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>2009</td>\n",
       "      <td>Ryan Gomes</td>\n",
       "      <td>SF</td>\n",
       "      <td>27.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>76</td>\n",
       "      <td>64</td>\n",
       "      <td>29.1</td>\n",
       "      <td>10.9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>9.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>2009</td>\n",
       "      <td>Ramon Sessions</td>\n",
       "      <td>PG</td>\n",
       "      <td>23.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>21.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>2009</td>\n",
       "      <td>Kevin Love</td>\n",
       "      <td>PF</td>\n",
       "      <td>21.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>60</td>\n",
       "      <td>22</td>\n",
       "      <td>28.6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>4.9</td>\n",
       "      <td>10.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>2009</td>\n",
       "      <td>Damien Wilkins</td>\n",
       "      <td>SF</td>\n",
       "      <td>30.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>80</td>\n",
       "      <td>31</td>\n",
       "      <td>19.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>2009</td>\n",
       "      <td>Wayne Ellington</td>\n",
       "      <td>SG</td>\n",
       "      <td>22.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>18.2</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>2009</td>\n",
       "      <td>Ryan Hollins</td>\n",
       "      <td>C</td>\n",
       "      <td>25.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>73</td>\n",
       "      <td>27</td>\n",
       "      <td>16.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705</th>\n",
       "      <td>2009</td>\n",
       "      <td>Sasha Pavlovic</td>\n",
       "      <td>SF</td>\n",
       "      <td>26.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>71</td>\n",
       "      <td>0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>2009</td>\n",
       "      <td>Darko Milicic</td>\n",
       "      <td>C</td>\n",
       "      <td>24.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>32</td>\n",
       "      <td>18</td>\n",
       "      <td>25.6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>2009</td>\n",
       "      <td>Oleksiy Pecherov</td>\n",
       "      <td>C</td>\n",
       "      <td>24.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>44</td>\n",
       "      <td>5</td>\n",
       "      <td>10.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>2009</td>\n",
       "      <td>Nathan Jawai</td>\n",
       "      <td>C</td>\n",
       "      <td>23.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>10.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>2009</td>\n",
       "      <td>Brian Cardinal</td>\n",
       "      <td>PF</td>\n",
       "      <td>32.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "      <td>363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>2010</td>\n",
       "      <td>Kevin Love</td>\n",
       "      <td>PF</td>\n",
       "      <td>22.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>35.8</td>\n",
       "      <td>20.2</td>\n",
       "      <td>15.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>6.6</td>\n",
       "      <td>14.1</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6.8</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>951</th>\n",
       "      <td>2010</td>\n",
       "      <td>Michael Beasley</td>\n",
       "      <td>SF</td>\n",
       "      <td>22.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>32.3</td>\n",
       "      <td>19.2</td>\n",
       "      <td>5.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>7.7</td>\n",
       "      <td>17.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3676</th>\n",
       "      <td>2015</td>\n",
       "      <td>Nikola Pekovic</td>\n",
       "      <td>C</td>\n",
       "      <td>30.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3733</th>\n",
       "      <td>2016</td>\n",
       "      <td>Andrew Wiggins</td>\n",
       "      <td>SF</td>\n",
       "      <td>21.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>37.2</td>\n",
       "      <td>23.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>8.6</td>\n",
       "      <td>19.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3734</th>\n",
       "      <td>2016</td>\n",
       "      <td>Karl-Anthony Towns</td>\n",
       "      <td>C</td>\n",
       "      <td>21.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>37.0</td>\n",
       "      <td>25.1</td>\n",
       "      <td>12.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>9.8</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3752</th>\n",
       "      <td>2016</td>\n",
       "      <td>Gorgui Dieng</td>\n",
       "      <td>PF</td>\n",
       "      <td>27.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>32.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3774</th>\n",
       "      <td>2016</td>\n",
       "      <td>Ricky Rubio</td>\n",
       "      <td>PG</td>\n",
       "      <td>26.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>32.9</td>\n",
       "      <td>11.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3873</th>\n",
       "      <td>2016</td>\n",
       "      <td>Zach LaVine</td>\n",
       "      <td>SG</td>\n",
       "      <td>21.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>37.2</td>\n",
       "      <td>18.9</td>\n",
       "      <td>3.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>15.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3912</th>\n",
       "      <td>2016</td>\n",
       "      <td>Shabazz Muhammad</td>\n",
       "      <td>SF</td>\n",
       "      <td>24.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>19.4</td>\n",
       "      <td>9.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3943</th>\n",
       "      <td>2016</td>\n",
       "      <td>Kris Dunn</td>\n",
       "      <td>PG</td>\n",
       "      <td>22.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>78</td>\n",
       "      <td>7</td>\n",
       "      <td>17.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3969</th>\n",
       "      <td>2016</td>\n",
       "      <td>Nemanja Bjelica</td>\n",
       "      <td>PF</td>\n",
       "      <td>28.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>18.3</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4002</th>\n",
       "      <td>2016</td>\n",
       "      <td>Brandon Rush</td>\n",
       "      <td>SG</td>\n",
       "      <td>31.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>47</td>\n",
       "      <td>33</td>\n",
       "      <td>21.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4037</th>\n",
       "      <td>2016</td>\n",
       "      <td>Tyus Jones</td>\n",
       "      <td>PG</td>\n",
       "      <td>20.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4075</th>\n",
       "      <td>2016</td>\n",
       "      <td>Cole Aldrich</td>\n",
       "      <td>C</td>\n",
       "      <td>28.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4155</th>\n",
       "      <td>2016</td>\n",
       "      <td>Adreian Payne</td>\n",
       "      <td>PF</td>\n",
       "      <td>25.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4187</th>\n",
       "      <td>2016</td>\n",
       "      <td>Jordan Hill</td>\n",
       "      <td>C</td>\n",
       "      <td>29.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4213</th>\n",
       "      <td>2016</td>\n",
       "      <td>John Lucas III</td>\n",
       "      <td>PG</td>\n",
       "      <td>34.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4222</th>\n",
       "      <td>2017</td>\n",
       "      <td>Andrew Wiggins</td>\n",
       "      <td>SF</td>\n",
       "      <td>22.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>36.3</td>\n",
       "      <td>17.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>6.9</td>\n",
       "      <td>15.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4225</th>\n",
       "      <td>2017</td>\n",
       "      <td>Karl-Anthony Towns</td>\n",
       "      <td>C</td>\n",
       "      <td>22.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>35.6</td>\n",
       "      <td>21.3</td>\n",
       "      <td>12.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>7.8</td>\n",
       "      <td>14.3</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4232</th>\n",
       "      <td>2017</td>\n",
       "      <td>Taj Gibson</td>\n",
       "      <td>PF</td>\n",
       "      <td>32.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>33.2</td>\n",
       "      <td>12.2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268</th>\n",
       "      <td>2017</td>\n",
       "      <td>Jeff Teague</td>\n",
       "      <td>PG</td>\n",
       "      <td>29.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>33.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>11.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4287</th>\n",
       "      <td>2017</td>\n",
       "      <td>Jimmy Butler</td>\n",
       "      <td>SG</td>\n",
       "      <td>28.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>36.7</td>\n",
       "      <td>22.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>7.4</td>\n",
       "      <td>15.6</td>\n",
       "      <td>6.2</td>\n",
       "      <td>7.2</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4373</th>\n",
       "      <td>2017</td>\n",
       "      <td>Jamal Crawford</td>\n",
       "      <td>SG</td>\n",
       "      <td>37.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>20.7</td>\n",
       "      <td>10.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4408</th>\n",
       "      <td>2017</td>\n",
       "      <td>Tyus Jones</td>\n",
       "      <td>PG</td>\n",
       "      <td>21.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>82</td>\n",
       "      <td>11</td>\n",
       "      <td>17.9</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4425</th>\n",
       "      <td>2017</td>\n",
       "      <td>Nemanja Bjelica</td>\n",
       "      <td>PF</td>\n",
       "      <td>29.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>67</td>\n",
       "      <td>21</td>\n",
       "      <td>20.5</td>\n",
       "      <td>6.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4434</th>\n",
       "      <td>2017</td>\n",
       "      <td>Gorgui Dieng</td>\n",
       "      <td>C</td>\n",
       "      <td>28.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>16.9</td>\n",
       "      <td>5.9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.4</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4605</th>\n",
       "      <td>2017</td>\n",
       "      <td>Shabazz Muhammad</td>\n",
       "      <td>SF</td>\n",
       "      <td>25.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>9.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4627</th>\n",
       "      <td>2017</td>\n",
       "      <td>Marcus Georges-Hunt</td>\n",
       "      <td>SG</td>\n",
       "      <td>23.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4639</th>\n",
       "      <td>2017</td>\n",
       "      <td>Aaron Brooks</td>\n",
       "      <td>PG</td>\n",
       "      <td>33.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4702</th>\n",
       "      <td>2017</td>\n",
       "      <td>Cole Aldrich</td>\n",
       "      <td>C</td>\n",
       "      <td>29.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4750</th>\n",
       "      <td>2017</td>\n",
       "      <td>Anthony Brown</td>\n",
       "      <td>SF</td>\n",
       "      <td>25.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4751</th>\n",
       "      <td>2017</td>\n",
       "      <td>Justin Patton</td>\n",
       "      <td>C</td>\n",
       "      <td>20.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     season               player position   age team gamesPlayed gamesStarted  \\\n",
       "45     2008           Ryan Gomes       SF  26.0  MIN          82           76   \n",
       "61     2008           Randy Foye       SG  25.0  MIN          70           61   \n",
       "76     2008          Mike Miller       SF  28.0  MIN          73           47   \n",
       "106    2008    Sebastian Telfair       PG  23.0  MIN          75           43   \n",
       "113    2008           Kevin Love        C  20.0  MIN          81           37   \n",
       "145    2008         Al Jefferson        C  24.0  MIN          50           50   \n",
       "190    2008          Craig Smith       PF  25.0  MIN          74           31   \n",
       "220    2008        Rodney Carney       SG  24.0  MIN          67            6   \n",
       "256    2008       Brian Cardinal       PF  31.0  MIN          64            4   \n",
       "269    2008          Kevin Ollie       PG  36.0  MIN          50           21   \n",
       "310    2008       Rashad McCants       SG  24.0  MIN          58            3   \n",
       "330    2008        Jason Collins        C  30.0  MIN          31           22   \n",
       "347    2008         Corey Brewer       SF  22.0  MIN          15            8   \n",
       "395    2008          Mark Madsen        C  33.0  MIN          19            1   \n",
       "501    2009         Corey Brewer       SG  23.0  MIN          82           82   \n",
       "506    2009         Al Jefferson        C  25.0  MIN          76           76   \n",
       "521    2009          Jonny Flynn       PG  20.0  MIN          81           81   \n",
       "541    2009           Ryan Gomes       SF  27.0  MIN          76           64   \n",
       "597    2009       Ramon Sessions       PG  23.0  MIN          82            1   \n",
       "600    2009           Kevin Love       PF  21.0  MIN          60           22   \n",
       "624    2009       Damien Wilkins       SF  30.0  MIN          80           31   \n",
       "652    2009      Wayne Ellington       SG  22.0  MIN          76            1   \n",
       "664    2009         Ryan Hollins        C  25.0  MIN          73           27   \n",
       "705    2009       Sasha Pavlovic       SF  26.0  MIN          71            0   \n",
       "754    2009        Darko Milicic        C  24.0  MIN          32           18   \n",
       "777    2009     Oleksiy Pecherov        C  24.0  MIN          44            5   \n",
       "780    2009         Nathan Jawai        C  23.0  MIN          39            2   \n",
       "806    2009       Brian Cardinal       PF  32.0  MIN          29            0   \n",
       "922    2010           Kevin Love       PF  22.0  MIN          73           73   \n",
       "951    2010      Michael Beasley       SF  22.0  MIN          73           73   \n",
       "...     ...                  ...      ...   ...  ...         ...          ...   \n",
       "3676   2015       Nikola Pekovic        C  30.0  MIN          12            3   \n",
       "3733   2016       Andrew Wiggins       SF  21.0  MIN          82           82   \n",
       "3734   2016   Karl-Anthony Towns        C  21.0  MIN          82           82   \n",
       "3752   2016         Gorgui Dieng       PF  27.0  MIN          82           82   \n",
       "3774   2016          Ricky Rubio       PG  26.0  MIN          75           75   \n",
       "3873   2016          Zach LaVine       SG  21.0  MIN          47           47   \n",
       "3912   2016     Shabazz Muhammad       SF  24.0  MIN          78            1   \n",
       "3943   2016            Kris Dunn       PG  22.0  MIN          78            7   \n",
       "3969   2016      Nemanja Bjelica       PF  28.0  MIN          65            1   \n",
       "4002   2016         Brandon Rush       SG  31.0  MIN          47           33   \n",
       "4037   2016           Tyus Jones       PG  20.0  MIN          60            0   \n",
       "4075   2016         Cole Aldrich        C  28.0  MIN          62            0   \n",
       "4155   2016        Adreian Payne       PF  25.0  MIN          18            0   \n",
       "4187   2016          Jordan Hill        C  29.0  MIN           7            0   \n",
       "4213   2016       John Lucas III       PG  34.0  MIN           5            0   \n",
       "4222   2017       Andrew Wiggins       SF  22.0  MIN          82           82   \n",
       "4225   2017   Karl-Anthony Towns        C  22.0  MIN          82           82   \n",
       "4232   2017           Taj Gibson       PF  32.0  MIN          82           82   \n",
       "4268   2017          Jeff Teague       PG  29.0  MIN          70           70   \n",
       "4287   2017         Jimmy Butler       SG  28.0  MIN          59           59   \n",
       "4373   2017       Jamal Crawford       SG  37.0  MIN          80            0   \n",
       "4408   2017           Tyus Jones       PG  21.0  MIN          82           11   \n",
       "4425   2017      Nemanja Bjelica       PF  29.0  MIN          67           21   \n",
       "4434   2017         Gorgui Dieng        C  28.0  MIN          79            0   \n",
       "4605   2017     Shabazz Muhammad       SF  25.0  MIN          32            2   \n",
       "4627   2017  Marcus Georges-Hunt       SG  23.0  MIN          42            0   \n",
       "4639   2017         Aaron Brooks       PG  33.0  MIN          32            1   \n",
       "4702   2017         Cole Aldrich        C  29.0  MIN          21            0   \n",
       "4750   2017        Anthony Brown       SF  25.0  MIN           1            0   \n",
       "4751   2017        Justin Patton        C  20.0  MIN           1            0   \n",
       "\n",
       "     minutes  points rebounds   ...    steals blocks turnovers threes_made  \\\n",
       "45      31.9    13.3      4.8   ...       0.8    0.3       1.6         1.3   \n",
       "61      35.6    16.3      3.1   ...       1.0    0.4       2.1         1.6   \n",
       "76      32.3     9.9      6.6   ...       0.4    0.4       2.0         1.2   \n",
       "106     27.9     9.8      1.7   ...       1.0    0.2       1.9         1.0   \n",
       "113     25.3    11.1      9.1   ...       0.4    0.6       1.5         0.0   \n",
       "145     36.7    23.1     11.0   ...       0.8    1.7       1.8         0.0   \n",
       "190     19.7    10.1      3.8   ...       0.4    0.3       1.4         0.0   \n",
       "220     17.9     7.2      1.9   ...       0.7    0.4       0.6         1.2   \n",
       "256     14.2     3.0      2.2   ...       0.6    0.2       0.8         0.5   \n",
       "269     17.0     4.0      1.5   ...       0.4    0.1       0.7         0.0   \n",
       "310     19.4     9.1      1.9   ...       0.8    0.2       1.3         1.1   \n",
       "330     13.6     1.8      2.3   ...       0.3    0.4       0.4         0.0   \n",
       "347     20.5     6.2      3.3   ...       1.0    0.2       0.9         0.3   \n",
       "395      6.1     0.3      0.9   ...       0.1    0.1       0.2         0.0   \n",
       "501     30.3    13.0      3.4   ...       1.4    0.4       2.0         1.0   \n",
       "506     32.4    17.1      9.3   ...       0.8    1.3       1.8         0.0   \n",
       "521     28.9    13.5      2.4   ...       1.0    0.0       2.9         1.0   \n",
       "541     29.1    10.9      4.6   ...       0.8    0.2       1.3         1.0   \n",
       "597     21.1     8.2      2.6   ...       0.7    0.1       1.7         0.0   \n",
       "600     28.6    14.0     11.0   ...       0.7    0.4       2.0         0.6   \n",
       "624     19.8     5.6      3.1   ...       0.8    0.3       1.0         0.2   \n",
       "652     18.2     6.6      2.1   ...       0.3    0.1       1.0         0.8   \n",
       "664     16.8     6.1      2.8   ...       0.3    0.5       1.3         0.0   \n",
       "705     12.4     3.7      1.6   ...       0.3    0.1       0.7         0.5   \n",
       "754     25.6     8.3      5.5   ...       0.8    1.4       1.4         0.0   \n",
       "777     10.2     4.5      2.8   ...       0.2    0.3       0.7         0.3   \n",
       "780     10.6     3.2      2.7   ...       0.3    0.2       0.7         0.0   \n",
       "806      9.2     1.7      1.0   ...       0.3    0.1       0.2         0.1   \n",
       "922     35.8    20.2     15.2   ...       0.6    0.4       2.1         1.2   \n",
       "951     32.3    19.2      5.6   ...       0.7    0.7       2.7         0.8   \n",
       "...      ...     ...      ...   ...       ...    ...       ...         ...   \n",
       "3676    13.0     4.5      1.8   ...       0.1    0.0       0.8         0.0   \n",
       "3733    37.2    23.6      4.0   ...       1.0    0.4       2.3         1.3   \n",
       "3734    37.0    25.1     12.3   ...       0.7    1.3       2.6         1.2   \n",
       "3752    32.4    10.0      7.9   ...       1.1    1.2       1.3         0.2   \n",
       "3774    32.9    11.1      4.1   ...       1.7    0.1       2.6         0.8   \n",
       "3873    37.2    18.9      3.4   ...       0.9    0.2       1.8         2.6   \n",
       "3912    19.4     9.9      2.8   ...       0.3    0.1       0.7         0.6   \n",
       "3943    17.1     3.8      2.1   ...       1.0    0.5       1.1         0.3   \n",
       "3969    18.3     6.2      3.8   ...       0.6    0.3       0.9         0.9   \n",
       "4002    21.9     4.2      2.1   ...       0.5    0.5       0.6         0.9   \n",
       "4037    12.9     3.5      1.1   ...       0.8    0.1       0.6         0.4   \n",
       "4075     8.6     1.7      2.5   ...       0.4    0.4       0.3         0.0   \n",
       "4155     7.5     3.5      1.8   ...       0.4    0.4       0.4         0.2   \n",
       "4187     6.7     1.7      2.0   ...       0.1    0.0       0.6         0.0   \n",
       "4213     2.2     0.4      0.0   ...       0.4    0.0       0.0         0.0   \n",
       "4222    36.3    17.7      4.4   ...       1.1    0.6       1.7         1.4   \n",
       "4225    35.6    21.3     12.3   ...       0.8    1.4       1.9         1.5   \n",
       "4232    33.2    12.2      7.1   ...       0.8    0.7       1.1         0.1   \n",
       "4268    33.0    14.2      3.0   ...       1.5    0.3       2.5         1.2   \n",
       "4287    36.7    22.2      5.3   ...       2.0    0.4       1.8         1.2   \n",
       "4373    20.7    10.3      1.2   ...       0.5    0.1       1.2         1.3   \n",
       "4408    17.9     5.1      1.6   ...       1.2    0.1       0.7         0.5   \n",
       "4425    20.5     6.8      4.1   ...       0.7    0.2       0.8         1.1   \n",
       "4434    16.9     5.9      4.6   ...       0.6    0.5       0.7         0.2   \n",
       "4605     9.4     3.8      1.4   ...       0.2    0.1       0.2         0.1   \n",
       "4627     5.3     1.4      0.4   ...       0.1    0.0       0.1         0.1   \n",
       "4639     5.9     2.3      0.5   ...       0.2    0.0       0.3         0.3   \n",
       "4702     2.3     0.6      0.7   ...       0.1    0.0       0.0         0.0   \n",
       "4750     4.0     3.0      0.0   ...       0.0    0.0       0.0         1.0   \n",
       "4751     4.0     2.0      0.0   ...       1.0    0.0       0.0         0.0   \n",
       "\n",
       "      FGM   FGA  FTM  FTA starter min_rank  \n",
       "45    5.1  11.9  1.8  2.2       1       46  \n",
       "61    5.7  14.0  3.3  3.9       1       62  \n",
       "76    3.6   7.5  1.5  2.0       1       77  \n",
       "106   3.6   9.3  1.7  2.1       0      107  \n",
       "113   3.9   8.5  3.3  4.1       0      114  \n",
       "145   9.7  19.5  3.7  5.0       1      146  \n",
       "190   3.9   6.9  2.3  3.4       0      191  \n",
       "220   2.6   6.3  0.7  1.0       0      221  \n",
       "256   1.0   2.6  0.5  0.5       0      257  \n",
       "269   1.2   3.0  1.6  1.9       0      270  \n",
       "310   3.1   8.6  1.8  2.4       0      311  \n",
       "330   0.7   2.3  0.4  0.9       1      331  \n",
       "347   2.5   6.0  0.9  1.3       0      348  \n",
       "395   0.2   0.7  0.0  0.2       0      396  \n",
       "501   5.0  11.6  2.0  3.1       1       58  \n",
       "506   7.4  14.8  2.4  3.5       1       63  \n",
       "521   4.9  11.8  2.8  3.3       1       78  \n",
       "541   4.3   9.6  1.4  1.7       1       98  \n",
       "597   3.1   6.8  2.0  2.8       0      154  \n",
       "600   4.9  10.8  3.8  4.6       0      157  \n",
       "624   2.1   4.8  1.3  1.6       0      181  \n",
       "652   2.5   5.9  0.8  0.9       0      209  \n",
       "664   2.3   4.2  1.5  2.2       0      221  \n",
       "705   1.5   4.2  0.1  0.4       0      262  \n",
       "754   3.8   7.8  0.6  1.2       0      311  \n",
       "777   1.8   4.3  0.7  0.7       0      334  \n",
       "780   1.3   2.8  0.7  1.0       0      337  \n",
       "806   0.5   1.2  0.6  0.6       0      363  \n",
       "922   6.6  14.1  5.8  6.8       1       37  \n",
       "951   7.7  17.1  3.0  4.0       1       66  \n",
       "...   ...   ...  ...  ...     ...      ...  \n",
       "3676  1.6   4.2  1.3  1.7       0      420  \n",
       "3733  8.6  19.1  5.0  6.6       1        1  \n",
       "3734  9.8  18.0  4.3  5.2       1        2  \n",
       "3752  4.0   8.1  1.7  2.0       1       20  \n",
       "3774  3.5   8.7  3.4  3.8       1       42  \n",
       "3873  6.9  15.1  2.5  3.0       1      141  \n",
       "3912  3.7   7.7  1.9  2.4       0      180  \n",
       "3943  1.5   4.0  0.5  0.8       0      211  \n",
       "3969  2.3   5.5  0.7  0.9       0      237  \n",
       "4002  1.5   4.0  0.3  0.4       1      270  \n",
       "4037  1.3   3.0  0.6  0.7       0      305  \n",
       "4075  0.7   1.4  0.2  0.4       0      343  \n",
       "4155  1.3   3.0  0.8  1.1       0      423  \n",
       "4187  0.7   1.9  0.3  0.3       0      455  \n",
       "4213  0.2   0.8  0.0  0.0       0      481  \n",
       "4222  6.9  15.9  2.5  3.8       1        4  \n",
       "4225  7.8  14.3  4.2  4.9       1        7  \n",
       "4232  5.2   9.0  1.7  2.3       1       14  \n",
       "4268  5.1  11.3  2.9  3.4       1       50  \n",
       "4287  7.4  15.6  6.2  7.2       1       69  \n",
       "4373  3.9   9.3  1.3  1.4       0      155  \n",
       "4408  1.8   4.0  0.9  1.0       0      190  \n",
       "4425  2.6   5.5  0.5  0.7       0      207  \n",
       "4434  2.4   4.9  1.0  1.3       0      216  \n",
       "4605  1.5   3.8  0.7  1.0       0      387  \n",
       "4627  0.5   1.1  0.3  0.5       0      409  \n",
       "4639  0.9   2.2  0.3  0.3       0      421  \n",
       "4702  0.2   0.7  0.1  0.3       0      484  \n",
       "4750  1.0   1.0  0.0  0.0       0      532  \n",
       "4751  1.0   2.0  0.0  0.0       0      533  \n",
       "\n",
       "[159 rows x 21 columns]"
      ]
     },
     "execution_count": 1264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['team']=='MIN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a55b2f048>"
      ]
     },
     "execution_count": 1268,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df[df['player']=='Stephen Curry']['age'],df[df['player']=='Stephen Curry']['points'], color = 'blue',label = 'Steph Curry')\n",
    "plt.plot(df[df['player']=='Kevin Durant']['age'],df[df['player']=='Kevin Durant']['points'], color = 'gold',label = 'Kevin Durant')\n",
    "plt.plot(df[df['player']=='Karl-Anthony Towns']['age'],df[df['player']=='Karl-Anthony Towns']['points'], color = 'green',label = 'Karl Towns')\n",
    "plt.plot(df[df['player']=='James Harden']['age'],df[df['player']=='James Harden']['points'], color = 'red',label = 'James Harden')\n",
    "plt.plot(df[df['player']=='Anthony Davis']['age'],df[df['player']=='Anthony Davis']['points'], color = 'purple',label = 'Anthony Davis')\n",
    "\n",
    "plt.title('Points Career trajectory')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Points')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>player</th>\n",
       "      <th>position</th>\n",
       "      <th>age</th>\n",
       "      <th>team</th>\n",
       "      <th>gamesPlayed</th>\n",
       "      <th>gamesStarted</th>\n",
       "      <th>minutes</th>\n",
       "      <th>points</th>\n",
       "      <th>rebounds</th>\n",
       "      <th>...</th>\n",
       "      <th>steals</th>\n",
       "      <th>blocks</th>\n",
       "      <th>turnovers</th>\n",
       "      <th>threes_made</th>\n",
       "      <th>FGM</th>\n",
       "      <th>FGA</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>starter</th>\n",
       "      <th>min_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4219</th>\n",
       "      <td>2017</td>\n",
       "      <td>LeBron James</td>\n",
       "      <td>PF</td>\n",
       "      <td>33.0</td>\n",
       "      <td>CLE</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>36.9</td>\n",
       "      <td>27.5</td>\n",
       "      <td>8.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>10.5</td>\n",
       "      <td>19.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4232</th>\n",
       "      <td>2017</td>\n",
       "      <td>Taj Gibson</td>\n",
       "      <td>PF</td>\n",
       "      <td>32.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>33.2</td>\n",
       "      <td>12.2</td>\n",
       "      <td>7.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4241</th>\n",
       "      <td>2017</td>\n",
       "      <td>Lou Williams</td>\n",
       "      <td>SG</td>\n",
       "      <td>31.0</td>\n",
       "      <td>LAC</td>\n",
       "      <td>79</td>\n",
       "      <td>19</td>\n",
       "      <td>32.8</td>\n",
       "      <td>22.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>16.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4248</th>\n",
       "      <td>2017</td>\n",
       "      <td>LaMarcus Aldridge</td>\n",
       "      <td>C</td>\n",
       "      <td>32.0</td>\n",
       "      <td>SAS</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>33.5</td>\n",
       "      <td>23.1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>9.2</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4249</th>\n",
       "      <td>2017</td>\n",
       "      <td>Kyle Lowry</td>\n",
       "      <td>PG</td>\n",
       "      <td>31.0</td>\n",
       "      <td>TOR</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>32.2</td>\n",
       "      <td>16.2</td>\n",
       "      <td>5.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>12.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4251</th>\n",
       "      <td>2017</td>\n",
       "      <td>Carmelo Anthony</td>\n",
       "      <td>PF</td>\n",
       "      <td>33.0</td>\n",
       "      <td>OKC</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>32.1</td>\n",
       "      <td>16.2</td>\n",
       "      <td>5.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4254</th>\n",
       "      <td>2017</td>\n",
       "      <td>Dwight Howard</td>\n",
       "      <td>C</td>\n",
       "      <td>32.0</td>\n",
       "      <td>CHA</td>\n",
       "      <td>81</td>\n",
       "      <td>81</td>\n",
       "      <td>30.4</td>\n",
       "      <td>16.6</td>\n",
       "      <td>12.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>11.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>7.2</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4261</th>\n",
       "      <td>2017</td>\n",
       "      <td>Marc Gasol</td>\n",
       "      <td>C</td>\n",
       "      <td>33.0</td>\n",
       "      <td>MEM</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>33.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>8.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>5.9</td>\n",
       "      <td>14.2</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4263</th>\n",
       "      <td>2017</td>\n",
       "      <td>Goran Dragic</td>\n",
       "      <td>PG</td>\n",
       "      <td>31.0</td>\n",
       "      <td>MIA</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>31.7</td>\n",
       "      <td>17.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>14.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4267</th>\n",
       "      <td>2017</td>\n",
       "      <td>Courtney Lee</td>\n",
       "      <td>SG</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NYK</td>\n",
       "      <td>76</td>\n",
       "      <td>69</td>\n",
       "      <td>30.4</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4273</th>\n",
       "      <td>2017</td>\n",
       "      <td>P.J. Tucker</td>\n",
       "      <td>PF</td>\n",
       "      <td>32.0</td>\n",
       "      <td>HOU</td>\n",
       "      <td>82</td>\n",
       "      <td>34</td>\n",
       "      <td>27.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4275</th>\n",
       "      <td>2017</td>\n",
       "      <td>Al Horford</td>\n",
       "      <td>C</td>\n",
       "      <td>31.0</td>\n",
       "      <td>BOS</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>31.6</td>\n",
       "      <td>12.9</td>\n",
       "      <td>7.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>10.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4276</th>\n",
       "      <td>2017</td>\n",
       "      <td>Trevor Ariza</td>\n",
       "      <td>SF</td>\n",
       "      <td>32.0</td>\n",
       "      <td>HOU</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>33.9</td>\n",
       "      <td>11.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4279</th>\n",
       "      <td>2017</td>\n",
       "      <td>J.R. Smith</td>\n",
       "      <td>SG</td>\n",
       "      <td>32.0</td>\n",
       "      <td>CLE</td>\n",
       "      <td>80</td>\n",
       "      <td>61</td>\n",
       "      <td>28.1</td>\n",
       "      <td>8.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4285</th>\n",
       "      <td>2017</td>\n",
       "      <td>DeMarre Carroll</td>\n",
       "      <td>SF</td>\n",
       "      <td>31.0</td>\n",
       "      <td>BRK</td>\n",
       "      <td>73</td>\n",
       "      <td>73</td>\n",
       "      <td>29.9</td>\n",
       "      <td>13.5</td>\n",
       "      <td>6.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>10.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4292</th>\n",
       "      <td>2017</td>\n",
       "      <td>Wesley Matthews</td>\n",
       "      <td>SF</td>\n",
       "      <td>31.0</td>\n",
       "      <td>DAL</td>\n",
       "      <td>63</td>\n",
       "      <td>62</td>\n",
       "      <td>33.8</td>\n",
       "      <td>12.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>11.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4293</th>\n",
       "      <td>2017</td>\n",
       "      <td>J.J. Redick</td>\n",
       "      <td>SG</td>\n",
       "      <td>33.0</td>\n",
       "      <td>PHI</td>\n",
       "      <td>70</td>\n",
       "      <td>70</td>\n",
       "      <td>30.2</td>\n",
       "      <td>17.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.8</td>\n",
       "      <td>12.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4299</th>\n",
       "      <td>2017</td>\n",
       "      <td>Marcin Gortat</td>\n",
       "      <td>C</td>\n",
       "      <td>33.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>82</td>\n",
       "      <td>82</td>\n",
       "      <td>25.3</td>\n",
       "      <td>8.4</td>\n",
       "      <td>7.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>6.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4317</th>\n",
       "      <td>2017</td>\n",
       "      <td>Marvin Williams</td>\n",
       "      <td>PF</td>\n",
       "      <td>31.0</td>\n",
       "      <td>CHA</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>25.7</td>\n",
       "      <td>9.5</td>\n",
       "      <td>4.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.3</td>\n",
       "      <td>7.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4332</th>\n",
       "      <td>2017</td>\n",
       "      <td>Dirk Nowitzki</td>\n",
       "      <td>C</td>\n",
       "      <td>39.0</td>\n",
       "      <td>DAL</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>24.7</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4339</th>\n",
       "      <td>2017</td>\n",
       "      <td>Chris Paul</td>\n",
       "      <td>PG</td>\n",
       "      <td>32.0</td>\n",
       "      <td>HOU</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>31.8</td>\n",
       "      <td>18.6</td>\n",
       "      <td>5.4</td>\n",
       "      <td>...</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.3</td>\n",
       "      <td>13.8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4344</th>\n",
       "      <td>2017</td>\n",
       "      <td>Jeff Green</td>\n",
       "      <td>PF</td>\n",
       "      <td>31.0</td>\n",
       "      <td>CLE</td>\n",
       "      <td>78</td>\n",
       "      <td>13</td>\n",
       "      <td>23.4</td>\n",
       "      <td>10.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>7.9</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4347</th>\n",
       "      <td>2017</td>\n",
       "      <td>Pau Gasol</td>\n",
       "      <td>C</td>\n",
       "      <td>37.0</td>\n",
       "      <td>SAS</td>\n",
       "      <td>77</td>\n",
       "      <td>63</td>\n",
       "      <td>23.5</td>\n",
       "      <td>10.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.7</td>\n",
       "      <td>8.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>1</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4354</th>\n",
       "      <td>2017</td>\n",
       "      <td>Anthony Tolliver</td>\n",
       "      <td>PF</td>\n",
       "      <td>32.0</td>\n",
       "      <td>DET</td>\n",
       "      <td>79</td>\n",
       "      <td>14</td>\n",
       "      <td>22.2</td>\n",
       "      <td>8.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4362</th>\n",
       "      <td>2017</td>\n",
       "      <td>Rajon Rondo</td>\n",
       "      <td>PG</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NOP</td>\n",
       "      <td>65</td>\n",
       "      <td>63</td>\n",
       "      <td>26.2</td>\n",
       "      <td>8.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4373</th>\n",
       "      <td>2017</td>\n",
       "      <td>Jamal Crawford</td>\n",
       "      <td>SG</td>\n",
       "      <td>37.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>20.7</td>\n",
       "      <td>10.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>9.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4382</th>\n",
       "      <td>2017</td>\n",
       "      <td>Andre Iguodala</td>\n",
       "      <td>SF</td>\n",
       "      <td>34.0</td>\n",
       "      <td>GSW</td>\n",
       "      <td>64</td>\n",
       "      <td>7</td>\n",
       "      <td>25.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4384</th>\n",
       "      <td>2017</td>\n",
       "      <td>Garrett Temple</td>\n",
       "      <td>SG</td>\n",
       "      <td>31.0</td>\n",
       "      <td>SAC</td>\n",
       "      <td>65</td>\n",
       "      <td>35</td>\n",
       "      <td>24.8</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4386</th>\n",
       "      <td>2017</td>\n",
       "      <td>J.J. Barea</td>\n",
       "      <td>PG</td>\n",
       "      <td>33.0</td>\n",
       "      <td>DAL</td>\n",
       "      <td>69</td>\n",
       "      <td>10</td>\n",
       "      <td>23.2</td>\n",
       "      <td>11.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4387</th>\n",
       "      <td>2017</td>\n",
       "      <td>Kyle Korver</td>\n",
       "      <td>SG</td>\n",
       "      <td>36.0</td>\n",
       "      <td>CLE</td>\n",
       "      <td>73</td>\n",
       "      <td>4</td>\n",
       "      <td>21.6</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4513</th>\n",
       "      <td>2017</td>\n",
       "      <td>Thabo Sefolosha</td>\n",
       "      <td>SF</td>\n",
       "      <td>33.0</td>\n",
       "      <td>UTA</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>21.2</td>\n",
       "      <td>8.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4514</th>\n",
       "      <td>2017</td>\n",
       "      <td>Devin Harris</td>\n",
       "      <td>PG</td>\n",
       "      <td>34.0</td>\n",
       "      <td>DAL</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>19.7</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4521</th>\n",
       "      <td>2017</td>\n",
       "      <td>Nene Hilario</td>\n",
       "      <td>C</td>\n",
       "      <td>35.0</td>\n",
       "      <td>HOU</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>14.6</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4527</th>\n",
       "      <td>2017</td>\n",
       "      <td>Salah Mejri</td>\n",
       "      <td>C</td>\n",
       "      <td>31.0</td>\n",
       "      <td>DAL</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4532</th>\n",
       "      <td>2017</td>\n",
       "      <td>Joe Johnson</td>\n",
       "      <td>SF</td>\n",
       "      <td>36.0</td>\n",
       "      <td>UTA</td>\n",
       "      <td>55</td>\n",
       "      <td>4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4533</th>\n",
       "      <td>2017</td>\n",
       "      <td>Corey Brewer</td>\n",
       "      <td>SF</td>\n",
       "      <td>31.0</td>\n",
       "      <td>LAL</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>12.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4536</th>\n",
       "      <td>2017</td>\n",
       "      <td>Jared Dudley</td>\n",
       "      <td>PF</td>\n",
       "      <td>32.0</td>\n",
       "      <td>PHO</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0</td>\n",
       "      <td>318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4537</th>\n",
       "      <td>2017</td>\n",
       "      <td>Arron Afflalo</td>\n",
       "      <td>SG</td>\n",
       "      <td>32.0</td>\n",
       "      <td>ORL</td>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "      <td>12.9</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4557</th>\n",
       "      <td>2017</td>\n",
       "      <td>Channing Frye</td>\n",
       "      <td>C</td>\n",
       "      <td>34.0</td>\n",
       "      <td>CLE</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4568</th>\n",
       "      <td>2017</td>\n",
       "      <td>Al Jefferson</td>\n",
       "      <td>C</td>\n",
       "      <td>33.0</td>\n",
       "      <td>IND</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>13.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4593</th>\n",
       "      <td>2017</td>\n",
       "      <td>Timofey Mozgov</td>\n",
       "      <td>C</td>\n",
       "      <td>31.0</td>\n",
       "      <td>BRK</td>\n",
       "      <td>31</td>\n",
       "      <td>13</td>\n",
       "      <td>11.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4594</th>\n",
       "      <td>2017</td>\n",
       "      <td>Emeka Okafor</td>\n",
       "      <td>C</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NOP</td>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "      <td>13.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4609</th>\n",
       "      <td>2017</td>\n",
       "      <td>Jason Smith</td>\n",
       "      <td>C</td>\n",
       "      <td>31.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>33</td>\n",
       "      <td>2</td>\n",
       "      <td>8.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4615</th>\n",
       "      <td>2017</td>\n",
       "      <td>Tony Allen</td>\n",
       "      <td>SF</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NOP</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>12.4</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4626</th>\n",
       "      <td>2017</td>\n",
       "      <td>Ramon Sessions</td>\n",
       "      <td>PG</td>\n",
       "      <td>31.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>0</td>\n",
       "      <td>408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4628</th>\n",
       "      <td>2017</td>\n",
       "      <td>Andrew Bogut</td>\n",
       "      <td>C</td>\n",
       "      <td>33.0</td>\n",
       "      <td>LAL</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4639</th>\n",
       "      <td>2017</td>\n",
       "      <td>Aaron Brooks</td>\n",
       "      <td>PG</td>\n",
       "      <td>33.0</td>\n",
       "      <td>MIN</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4647</th>\n",
       "      <td>2017</td>\n",
       "      <td>Richard Jefferson</td>\n",
       "      <td>SF</td>\n",
       "      <td>37.0</td>\n",
       "      <td>DEN</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4651</th>\n",
       "      <td>2017</td>\n",
       "      <td>Mirza Teletovic</td>\n",
       "      <td>PF</td>\n",
       "      <td>32.0</td>\n",
       "      <td>MIL</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>7.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4652</th>\n",
       "      <td>2017</td>\n",
       "      <td>Damien Wilkins</td>\n",
       "      <td>SF</td>\n",
       "      <td>38.0</td>\n",
       "      <td>IND</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.7</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4662</th>\n",
       "      <td>2017</td>\n",
       "      <td>Omer Asik</td>\n",
       "      <td>C</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NOP</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4667</th>\n",
       "      <td>2017</td>\n",
       "      <td>Bobby Brown</td>\n",
       "      <td>PG</td>\n",
       "      <td>33.0</td>\n",
       "      <td>HOU</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4685</th>\n",
       "      <td>2017</td>\n",
       "      <td>Nick Collison</td>\n",
       "      <td>PF</td>\n",
       "      <td>37.0</td>\n",
       "      <td>OKC</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4688</th>\n",
       "      <td>2017</td>\n",
       "      <td>Udonis Haslem</td>\n",
       "      <td>C</td>\n",
       "      <td>37.0</td>\n",
       "      <td>MIA</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4692</th>\n",
       "      <td>2017</td>\n",
       "      <td>Andre Ingram</td>\n",
       "      <td>SG</td>\n",
       "      <td>32.0</td>\n",
       "      <td>LAL</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4707</th>\n",
       "      <td>2017</td>\n",
       "      <td>Joakim Noah</td>\n",
       "      <td>C</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NYK</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "      <td>489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4712</th>\n",
       "      <td>2017</td>\n",
       "      <td>Aaron Jackson</td>\n",
       "      <td>PG</td>\n",
       "      <td>31.0</td>\n",
       "      <td>HOU</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4729</th>\n",
       "      <td>2017</td>\n",
       "      <td>Kendrick Perkins</td>\n",
       "      <td>C</td>\n",
       "      <td>33.0</td>\n",
       "      <td>CLE</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4731</th>\n",
       "      <td>2017</td>\n",
       "      <td>Luol Deng</td>\n",
       "      <td>SF</td>\n",
       "      <td>32.0</td>\n",
       "      <td>LAL</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4733</th>\n",
       "      <td>2017</td>\n",
       "      <td>Josh Smith</td>\n",
       "      <td>PF</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NOP</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      season             player position   age team gamesPlayed gamesStarted  \\\n",
       "4219    2017       LeBron James       PF  33.0  CLE          82           82   \n",
       "4232    2017         Taj Gibson       PF  32.0  MIN          82           82   \n",
       "4241    2017       Lou Williams       SG  31.0  LAC          79           19   \n",
       "4248    2017  LaMarcus Aldridge        C  32.0  SAS          75           75   \n",
       "4249    2017         Kyle Lowry       PG  31.0  TOR          78           78   \n",
       "4251    2017    Carmelo Anthony       PF  33.0  OKC          78           78   \n",
       "4254    2017      Dwight Howard        C  32.0  CHA          81           81   \n",
       "4261    2017         Marc Gasol        C  33.0  MEM          73           73   \n",
       "4263    2017       Goran Dragic       PG  31.0  MIA          75           75   \n",
       "4267    2017       Courtney Lee       SG  32.0  NYK          76           69   \n",
       "4273    2017        P.J. Tucker       PF  32.0  HOU          82           34   \n",
       "4275    2017         Al Horford        C  31.0  BOS          72           72   \n",
       "4276    2017       Trevor Ariza       SF  32.0  HOU          67           67   \n",
       "4279    2017         J.R. Smith       SG  32.0  CLE          80           61   \n",
       "4285    2017    DeMarre Carroll       SF  31.0  BRK          73           73   \n",
       "4292    2017    Wesley Matthews       SF  31.0  DAL          63           62   \n",
       "4293    2017        J.J. Redick       SG  33.0  PHI          70           70   \n",
       "4299    2017      Marcin Gortat        C  33.0  WAS          82           82   \n",
       "4317    2017    Marvin Williams       PF  31.0  CHA          78           78   \n",
       "4332    2017      Dirk Nowitzki        C  39.0  DAL          77           77   \n",
       "4339    2017         Chris Paul       PG  32.0  HOU          58           58   \n",
       "4344    2017         Jeff Green       PF  31.0  CLE          78           13   \n",
       "4347    2017          Pau Gasol        C  37.0  SAS          77           63   \n",
       "4354    2017   Anthony Tolliver       PF  32.0  DET          79           14   \n",
       "4362    2017        Rajon Rondo       PG  31.0  NOP          65           63   \n",
       "4373    2017     Jamal Crawford       SG  37.0  MIN          80            0   \n",
       "4382    2017     Andre Iguodala       SF  34.0  GSW          64            7   \n",
       "4384    2017     Garrett Temple       SG  31.0  SAC          65           35   \n",
       "4386    2017         J.J. Barea       PG  33.0  DAL          69           10   \n",
       "4387    2017        Kyle Korver       SG  36.0  CLE          73            4   \n",
       "...      ...                ...      ...   ...  ...         ...          ...   \n",
       "4513    2017    Thabo Sefolosha       SF  33.0  UTA          38            6   \n",
       "4514    2017       Devin Harris       PG  34.0  DAL          71            1   \n",
       "4521    2017       Nene Hilario        C  35.0  HOU          52            4   \n",
       "4527    2017        Salah Mejri        C  31.0  DAL          61            1   \n",
       "4532    2017        Joe Johnson       SF  36.0  UTA          55            4   \n",
       "4533    2017       Corey Brewer       SF  31.0  LAL          54            2   \n",
       "4536    2017       Jared Dudley       PF  32.0  PHO          48            0   \n",
       "4537    2017      Arron Afflalo       SG  32.0  ORL          53            3   \n",
       "4557    2017      Channing Frye        C  34.0  CLE          53            1   \n",
       "4568    2017       Al Jefferson        C  33.0  IND          36            1   \n",
       "4593    2017     Timofey Mozgov        C  31.0  BRK          31           13   \n",
       "4594    2017       Emeka Okafor        C  35.0  NOP          26           19   \n",
       "4609    2017        Jason Smith        C  31.0  WAS          33            2   \n",
       "4615    2017         Tony Allen       SF  36.0  NOP          22            0   \n",
       "4626    2017     Ramon Sessions       PG  31.0  WAS          28            3   \n",
       "4628    2017       Andrew Bogut        C  33.0  LAL          23            5   \n",
       "4639    2017       Aaron Brooks       PG  33.0  MIN          32            1   \n",
       "4647    2017  Richard Jefferson       SF  37.0  DEN          20            0   \n",
       "4651    2017    Mirza Teletovic       PF  32.0  MIL          10            0   \n",
       "4652    2017     Damien Wilkins       SF  38.0  IND          19            1   \n",
       "4662    2017          Omer Asik        C  31.0  NOP          18            0   \n",
       "4667    2017        Bobby Brown       PG  33.0  HOU          20            0   \n",
       "4685    2017      Nick Collison       PF  37.0  OKC          15            0   \n",
       "4688    2017      Udonis Haslem        C  37.0  MIA          14            0   \n",
       "4692    2017       Andre Ingram       SG  32.0  LAL           2            0   \n",
       "4707    2017        Joakim Noah        C  32.0  NYK           7            0   \n",
       "4712    2017      Aaron Jackson       PG  31.0  HOU           1            0   \n",
       "4729    2017   Kendrick Perkins        C  33.0  CLE           1            0   \n",
       "4731    2017          Luol Deng       SF  32.0  LAL           1            1   \n",
       "4733    2017         Josh Smith       PF  32.0  NOP           3            0   \n",
       "\n",
       "     minutes  points rebounds   ...    steals blocks turnovers threes_made  \\\n",
       "4219    36.9    27.5      8.6   ...       1.4    0.9       4.2         1.8   \n",
       "4232    33.2    12.2      7.1   ...       0.8    0.7       1.1         0.1   \n",
       "4241    32.8    22.6      2.5   ...       1.1    0.2       3.0         2.4   \n",
       "4248    33.5    23.1      8.5   ...       0.6    1.2       1.5         0.4   \n",
       "4249    32.2    16.2      5.6   ...       1.1    0.2       2.3         3.1   \n",
       "4251    32.1    16.2      5.8   ...       0.6    0.6       1.3         2.2   \n",
       "4254    30.4    16.6     12.5   ...       0.6    1.6       2.6         0.0   \n",
       "4261    33.0    17.2      8.1   ...       0.7    1.4       2.7         1.5   \n",
       "4263    31.7    17.3      4.1   ...       0.8    0.2       2.2         1.5   \n",
       "4267    30.4    12.0      2.9   ...       1.1    0.2       1.1         1.5   \n",
       "4273    27.8     6.1      5.6   ...       1.0    0.3       0.9         1.4   \n",
       "4275    31.6    12.9      7.4   ...       0.6    1.1       1.8         1.3   \n",
       "4276    33.9    11.7      4.4   ...       1.5    0.2       0.8         2.5   \n",
       "4279    28.1     8.3      2.9   ...       0.9    0.1       1.0         1.8   \n",
       "4285    29.9    13.5      6.6   ...       0.8    0.4       1.4         2.0   \n",
       "4292    33.8    12.7      3.1   ...       1.2    0.3       1.3         2.4   \n",
       "4293    30.2    17.1      2.5   ...       0.5    0.1       1.5         2.8   \n",
       "4299    25.3     8.4      7.6   ...       0.5    0.7       1.2         0.0   \n",
       "4317    25.7     9.5      4.7   ...       0.7    0.5       0.8         1.6   \n",
       "4332    24.7    12.0      5.7   ...       0.6    0.6       0.7         1.8   \n",
       "4339    31.8    18.6      5.4   ...       1.7    0.2       2.2         2.5   \n",
       "4344    23.4    10.8      3.2   ...       0.5    0.4       1.0         0.7   \n",
       "4347    23.5    10.1      8.0   ...       0.3    1.0       1.4         0.6   \n",
       "4354    22.2     8.9      3.1   ...       0.4    0.3       0.7         2.0   \n",
       "4362    26.2     8.3      4.0   ...       1.1    0.2       2.3         0.8   \n",
       "4373    20.7    10.3      1.2   ...       0.5    0.1       1.2         1.3   \n",
       "4382    25.3     6.0      3.8   ...       0.8    0.6       1.0         0.5   \n",
       "4384    24.8     8.4      2.3   ...       0.9    0.4       1.2         1.4   \n",
       "4386    23.2    11.6      2.9   ...       0.5    0.0       2.1         1.7   \n",
       "4387    21.6     9.2      2.3   ...       0.4    0.4       0.8         2.2   \n",
       "...      ...     ...      ...   ...       ...    ...       ...         ...   \n",
       "4513    21.2     8.2      4.2   ...       1.4    0.3       0.8         0.8   \n",
       "4514    19.7     8.5      1.9   ...       0.8    0.2       1.1         1.0   \n",
       "4521    14.6     6.5      3.4   ...       0.5    0.3       0.7         0.0   \n",
       "4527    12.0     3.5      4.0   ...       0.4    1.1       0.6         0.0   \n",
       "4532    22.0     7.3      3.3   ...       0.4    0.2       1.0         0.7   \n",
       "4533    12.9     3.7      1.7   ...       0.8    0.1       0.7         0.1   \n",
       "4536    14.3     3.2      2.0   ...       0.5    0.2       0.6         0.6   \n",
       "4537    12.9     3.4      1.2   ...       0.1    0.2       0.4         0.5   \n",
       "4557    16.7     4.8      2.5   ...       0.4    0.3       0.4         0.7   \n",
       "4568    13.4     7.0      4.0   ...       0.4    0.6       0.6         0.0   \n",
       "4593    11.6     4.2      3.2   ...       0.2    0.4       1.1         0.1   \n",
       "4594    13.6     4.4      4.6   ...       0.3    1.0       0.5         0.0   \n",
       "4609     8.6     3.4      1.6   ...       0.1    0.4       0.5         0.1   \n",
       "4615    12.4     4.7      2.1   ...       0.5    0.1       0.9         0.2   \n",
       "4626    15.0     5.9      1.3   ...       0.5    0.1       1.0         0.4   \n",
       "4628     9.4     1.6      3.4   ...       0.2    0.6       0.8         0.0   \n",
       "4639     5.9     2.3      0.5   ...       0.2    0.0       0.3         0.3   \n",
       "4647     8.2     1.5      0.9   ...       0.1    0.1       0.3         0.1   \n",
       "4651    15.9     7.1      2.3   ...       0.4    0.1       0.7         2.1   \n",
       "4652     8.0     1.7      0.8   ...       0.1    0.1       0.3         0.2   \n",
       "4662    15.3     1.3      2.6   ...       0.1    0.1       0.4         0.0   \n",
       "4667     5.8     2.5      0.4   ...       0.2    0.0       0.5         0.6   \n",
       "4685     5.0     2.1      1.3   ...       0.0    0.0       0.5         0.0   \n",
       "4688     5.1     0.6      0.7   ...       0.0    0.1       0.1         0.1   \n",
       "4692    32.0    12.0      3.0   ...       1.5    1.5       1.5         2.5   \n",
       "4707     5.7     1.7      2.0   ...       0.3    0.3       0.6         0.0   \n",
       "4712    35.0     8.0      3.0   ...       0.0    0.0       1.0         1.0   \n",
       "4729    15.0     3.0      1.0   ...       1.0    0.0       1.0         0.0   \n",
       "4731    13.0     2.0      0.0   ...       1.0    0.0       1.0         0.0   \n",
       "4733     4.0     0.7      1.3   ...       0.0    0.0       0.0         0.0   \n",
       "\n",
       "       FGM   FGA  FTM  FTA starter min_rank  \n",
       "4219  10.5  19.3  4.7  6.5       1        1  \n",
       "4232   5.2   9.0  1.7  2.3       1       14  \n",
       "4241   7.4  16.9  5.5  6.2       0       23  \n",
       "4248   9.2  18.0  4.5  5.3       1       30  \n",
       "4249   5.2  12.1  2.9  3.3       1       31  \n",
       "4251   6.1  15.0  1.9  2.5       1       33  \n",
       "4254   6.2  11.2  4.1  7.2       1       36  \n",
       "4261   5.9  14.2  3.8  4.6       1       43  \n",
       "4263   6.5  14.3  2.9  3.6       1       45  \n",
       "4267   4.5   9.9  1.5  1.6       1       49  \n",
       "4273   2.1   5.4  0.5  0.7       0       55  \n",
       "4275   5.1  10.5  1.3  1.7       1       57  \n",
       "4276   4.0   9.7  1.1  1.3       1       58  \n",
       "4279   3.0   7.4  0.5  0.7       1       61  \n",
       "4285   4.5  10.8  2.6  3.4       1       67  \n",
       "4292   4.5  11.1  1.3  1.6       1       74  \n",
       "4293   5.8  12.6  2.8  3.1       1       75  \n",
       "4299   3.5   6.8  1.3  2.0       1       81  \n",
       "4317   3.3   7.2  1.3  1.6       1       99  \n",
       "4332   4.5   9.8  1.3  1.4       1      114  \n",
       "4339   6.3  13.8  3.5  3.8       1      121  \n",
       "4344   3.8   7.9  2.6  3.0       0      126  \n",
       "4347   3.7   8.1  2.1  2.7       1      129  \n",
       "4354   2.8   6.0  1.3  1.7       0      136  \n",
       "4362   3.6   7.6  0.4  0.7       1      144  \n",
       "4373   3.9   9.3  1.3  1.4       0      155  \n",
       "4382   2.3   5.0  0.9  1.4       0      164  \n",
       "4384   3.1   7.3  0.9  1.2       0      166  \n",
       "4386   4.4  10.0  1.2  1.5       0      168  \n",
       "4387   3.0   6.6  0.9  1.0       0      169  \n",
       "...    ...   ...  ...  ...     ...      ...  \n",
       "4513   3.1   6.3  1.2  1.4       0      295  \n",
       "4514   2.7   6.5  2.1  2.5       0      296  \n",
       "4521   2.6   4.6  1.3  2.1       0      303  \n",
       "4527   1.4   2.2  0.6  1.1       0      309  \n",
       "4532   3.0   7.1  0.6  0.8       0      314  \n",
       "4533   1.4   3.2  0.6  0.9       0      315  \n",
       "4536   1.0   2.5  0.6  0.7       0      318  \n",
       "4537   1.2   3.1  0.4  0.5       0      319  \n",
       "4557   1.9   3.8  0.3  0.3       0      339  \n",
       "4568   3.1   5.8  0.8  1.0       0      350  \n",
       "4593   1.7   3.0  0.7  1.0       0      375  \n",
       "4594   1.8   3.7  0.7  0.8       1      376  \n",
       "4609   1.4   3.5  0.6  0.6       0      391  \n",
       "4615   2.0   4.1  0.5  1.0       0      397  \n",
       "4626   1.7   4.3  2.1  2.8       0      408  \n",
       "4628   0.7   1.1  0.1  0.1       0      410  \n",
       "4639   0.9   2.2  0.3  0.3       0      421  \n",
       "4647   0.6   1.4  0.2  0.4       0      429  \n",
       "4651   2.5   5.7  0.0  0.0       0      433  \n",
       "4652   0.7   2.1  0.2  0.2       0      434  \n",
       "4662   0.5   1.1  0.3  0.9       0      444  \n",
       "4667   1.0   2.9  0.1  0.1       0      449  \n",
       "4685   0.9   1.3  0.3  0.9       0      467  \n",
       "4688   0.2   1.1  0.1  0.1       0      470  \n",
       "4692   4.0   8.5  1.5  1.5       0      474  \n",
       "4707   0.7   1.4  0.3  0.6       0      489  \n",
       "4712   3.0   9.0  1.0  2.0       0      494  \n",
       "4729   1.0   2.0  1.0  2.0       0      511  \n",
       "4731   1.0   2.0  0.0  0.0       1      513  \n",
       "4733   0.3   1.3  0.0  0.0       0      515  \n",
       "\n",
       "[84 rows x 21 columns]"
      ]
     },
     "execution_count": 1277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['season']==2017) & (df['age']>30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a55fc3b70>"
      ]
     },
     "execution_count": 1295,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzsnXl4Tccbxz+TPRKRTUIttYdmR0SQ2JfaqtaWUq2lC4pqUaXVTWm19lLU0lZpa6u2flpKRCy1C5XYYi8iCUEiZJnfH3NzG0TcLDf3Rs7nec6Te+6ZmfPee5n3zDsz31dIKdHQ0NDQKLlYmNoADQ0NDQ3TojkCDQ0NjRKO5gg0NDQ0SjiaI9DQ0NAo4WiOQENDQ6OEozkCDQ0NjRKO5gg0jIoQYpwQYqGp7XhcEUL8Twjxoqnt0CjeCG0fgYYhCCHOAJ5ABpAMrAeGSSlvFeI9JgI1pJQv5LN+LeAToDlgDZwFlgAzpJQZhWRmoSGEkEBNKeVJE9sxkQJ87xrFH21EoJEXOkkpHYG6QBAw3sT26BFCVAf+Bs4DvlLKMkAPoD5QOh/tWRaibVZFWa+oKS52auSClFI7tOORB3AGaJXt/HPgN93rJ4B1QCJwEhiUrdxE4Hvd6yqABF4EzgHxwLu6a+2Au0AacAs4pHu/PxAL3AROA30eYt/3wO+P+Aw/A5eBJCAC8M52bQkwFzXSSQZaAbbAVJ2tV4B5gH22Oh2Bg8B1YAfgd9/3NQaIAu4AVvfZEqH7LpJ1n7cX0Ay4oKt3GfgOcAF+A64C13SvK2ZrJxwYmO38ZSBaV/YP4Mls17yBjbrf6QowLpfv/VG/6Urdd34D9UCQArhlK1NPZ7O1qf/taocB/79NbYB2FI+DbI4AqAT8A3ykO98KfAXYAQG6DqCl7tpEHnQECwB7wF/XSda5v6zu3EHX0Xjpzstn77zvs+8y8NIjPsPLqNGBLTAdOJjt2hKUg2iMGinb6cqsA1x19X4FPtWVrwvEAcGAJcq5nQFss31fB3Xflf1D7JGokEzWeTMgHZiis9EecAO6AaV0NvwMrM1WJxydIwC66DrtOoCVroPeobtWGrgEjNJ9ttJAcE7fu4G/aZrufhY6O9cDr2WrPw2YZep/t9ph4P9vUxugHcXj0HVst1BPv2d1nYS9rqPLAEpnK/spsET3Wt/J8J8jyP5Euxt47v6yunMH3f26PawzzVY2DWiXh8/jrLOljO58CfBttusC9bRePdt7IcBp3eu56BxhtuvHgKbZvq+XH2FDTo7gLmCXS50A4Fq28+yO4H/AgGzXLFBP6k8CzwMHHtLm/d+7Ib9pxH1t9AK2615bohxzA1P/u9UOww5tjkAjL3SRUjpLKZ+UUr4upbyNCiEkSilvZit3FqiQSzuXs71OARxzKiSlTEZ1MK8Cl4QQvwshaj+kzQTUiCFHhBCWQojJQohTQogbqI4awD1bsfPZXpdFPYXvE0JcF0JcBzbo3gfVuY7Kuqa7Xgn1feTUnqFclVKmZrO7lBDiayHEWZ3dEYDzQ+YwngRmZLMnEeXQKuhsO2WgDYb8pvd/tl+Ap4QQ1YDWQJKUcreB99MwMZoj0Cgo/wKuQojsE7KVgYv5aOuBJWxSyj+klK1RnXwMKqyUE5tQI4eH0Rt4BhX7L4ManYDqKHO6fzxwGxWKctYdZaSaLAfVEX6S7ZqzlLKUlHJ5bp/HAO6vMwrwQoVxnICwHOzO4jzwyn022Uspd+iuVTfwnob8pvfU0Tmvn4A+QF/U/IZGMUFzBBoFQkp5HjVR+qkQwk4I4QcMAJblo7krQBUhhAWAEMJTCNFZCOGAmku4hQpZ5MT7QCMhxOdCiHK6+jWEEN8LIZxRMfE7qJFDKWDSIz5XJsrpTBNCeOjaqyCEaKsrsgB4VQgRLBQOQogO93Wehnzeao8oUxrlkK4LIVx1n/NhzAPeEUJ46+wtI4Toobv2G1BOCDFCCGErhCgthAjOZof+ey/Ab/otanK/M2oiWaOYoDkCjcLgedQT9r/AGuB9KeXGfLTzs+5vghBiP+rf5yhdu4lAU+D1nCpKKU+hYvhVgH+EEEnAKmAvasXRt6jwxkXgKLDLAHvGoCZfd+nCMptQT+dIKfcCg4DZqBU6J1GdYF6YCCzVhXJ6PqTMdNRcTLzO5g0Pa0xKuQY10bxCZ+8R4GndtZuokE0nVGjuBGq/BTz4vUM+flMp5XYgE9gvpTyTW1kN80LbUKahUYwRQkQAC6WU35raFgAhxGbgBymltpu8GKFtBNHQKKYIIUqhQkunTW0LgBAiCLWs9hlT26KRN7TQkIZGMUQ3b3EZtd4/0sTmIIRYigqdjbhvtZFGMUALDWloaGiUcLQRgYaGhkYJp1jMEbi7u8sqVaqY2gwNDQ2NYsW+ffvipZRlH1WuWDiCKlWqsHfvXlOboaGhoVGsEEKcNaScFhrS0NDQKOFojkBDQ0OjhKM5Ag0NDY0STrGYI9DQ0Ch60tLSuHDhAqmpqY8urGFS7OzsqFixItbW1vmqrzkCDQ2NHLlw4QKlS5emSpUqCJGT2KmGOSClJCEhgQsXLlC1atV8taGFhjQ0NHIkNTUVNzc3zQmYOUII3NzcCjRy0xyBhobGQ9GcQPGgoL+T0RyBTsd8txDikBDiHyHEB7r3qwoh/hZCnBBC/CiEsDGWDSWCfftg4kRTW6GhoVGMMeaI4A7QQkrpj8qz2k4I0RCllz5NSlkTpeM+wIg2PP6sXw8ffAAb8yP/r6Fh3lhaWhIQEIC3tzf+/v58+eWXZGZmArB3717eeOONHOstWbKEoUOH5tr2kiVLsLCwICoqSv+ej48PZ86cKZDNAwcO5OjRowBMmpRr/iMAHB0fzNT677//0r179wLZkReM5gik4pbu1Fp3SKAFsFL3/lKgi7FsKBG8/TbUqAFDhsCdO6a2RkOjULG3t+fgwYP8888/bNy4kfXr1/PBBx8AUL9+fWbOnPlAnfT0dIPbr1ixIp988kmh2QuwcOFCnnrqKcAwR5ATTzzxBCtXrnx0wULCqHMEuoThB4E4YCMqefZ1KWXWL3WBhyQ5F0IMFkLsFULsvXr1qjHNLN7Y2cGcOXDiBEydamprNDSMhoeHB/Pnz2f27NlIKQkPD6djx44ATJw4kcGDB9OmTRv69et3T73ff/+dkJAQ4uPjH2izY8eO/PPPPxw7duyBa8uXL8fX1xcfHx/GjBkDwE8//cSbb74JwIwZM6hWTWUaPXXqFE2aNAGgWbNm7N27l7Fjx3L79m0CAgLo06cP8+bNIyAggICAAKpWrUrz5s3vuV98fDwhISH8/vvvnDlzBh8fnwJ+Y4Zj1OWjUsoMIECXM3YNUCenYg+pOx+YD1C/fn2Ta2VnpmeSlpKGrZOtqU15kDZtoHt3+Phj6N0b8rmETEPjYYwYAQcPFm6bAQEwfXre6lSrVo3MzEzi4uIeuLZv3z4iIyOxt7dnyZIlAKxZs4Yvv/yS9evX4+Li8kAdCwsLRo8ezaRJk1i6dKn+/X///ZcxY8awb98+XFxcaNOmDWvXriUsLIzPP/8cgG3btuHm5sbFixeJjIwkNDT0nrYnT57M7NmzOZjti3v11VdJS0ujRYsWeocCcOXKFTp37szHH39M69atCxyeyitFsmpISnkdCAcaAs5CiCwHVBGVE9WsOfXnKb7y/ooZ1WaQdC7J1ObkzLRpYGkJw4eb2hINDaPysBwqnTt3xt7eXn++ZcsWpkyZwu+//56jE8iid+/e7Nq1i9On/0v0tmfPHpo1a0bZsmWxsrKiT58+REREUK5cOW7dusXNmzc5f/48vXv3JiIigm3btj3gCB7G8OHDadGiBZ06dQLUxr2WLVvy2Wef0bp1a4PaKGyMNiIQQpQF0qSU14UQ9kAr1ETxFqA7sAJ4EfjFWDYUlOtnr/Pnm38SvToa1xquZNzNYHWf1by45UUsrMxs5W3Fimr10Ntvw7p10LmzqS3SeIzI65O7sYiNjcXS0hIPDw+io6Pvuebg4HDPebVq1YiNjeX48ePUr1//oW1aWVkxatQopkyZon8vt4RdISEhLF68GC8vL0JDQ1m0aBE7d+7kiy++eKT9S5Ys4ezZs8yePfue+9erV48//viDpk2bPrINY2DM3qw8sEUIEQXsATZKKX8DxgBvCiFOAm7AN0a0IV+kp6az9aOtzKkzh5MbTtJiUgteO/IaHed15FzkObZ+tNXUJubM8OHg7Q1vvAEpKaa2RkOjULl69SqvvvoqQ4cONWjd/JNPPsnq1avp168f//zzT65l+/fvz6ZNm8iajwwODmbr1q3Ex8eTkZHB8uXL9Z10WFgYU6dOJSwsjMDAQLZs2YKtrS1lypR5oF1ra2vS0tIAFbqaOnUq33//PRYW/3W9QggWLVpETEwMkydPNvj7KEyMNiKQUkYBgTm8Hws0MNZ9C8rx346zYfgGrsVe46keT9FmahvKVFY/sG9vX079eYptH2+jaouqVGlaxbTG3o+1tZo4btYMJk1ScwYaGsWYrMnWtLQ0rKys6Nu37z2x9Ufh5eXFsmXL6NGjB7/++ivVq1fPsZyNjQ1vvPEGw3Wh1fLly/Ppp5/SvHlzpJS0b9+eZ555BoDQ0FDOnz9PWFgYlpaWVKpUidq1a+fY7uDBg/Hz86Nu3brY2NiQmJionySuX78+CxcuBNQy2RUrVtCpUyecnJxo3769wZ+xMCgWOYvr168vjZ2YJvFUIhuGb+DE7ydwr+PO07OeplrLag+Uu3vrLl/X/Zr02+m8cvAVSrmVMqpd+aJfP/jxR4iKAi8vU1ujUUyJjo6mTp2c1ndomCM5/V5CiH1SyofHxXSYWaC76ElLSWPzhM189dRXnN16ltZTW/PqoVdzdAIANo42dF/RnVtXbrFuwLpcY4km4/PPwd4ehg4Fc7RPQ0PDrCixjkBKSfTqaObUmcO2j7fh3dOboceH0mhUIyytLXOtW75ueVpNacWxX46xd64ZptD09FRhoU2b4OefTW2NhoaGmVMiHUH8sXi+b/s9P3X7CTtnO/pH9OfZ756ldPnSBrfRcERDaravyR9v/sGVqCtGtDafvPYaBAbCyJFw86aprdHQ0DBjSpQjuHPzDhvHbGSu71wu7r5Iu5ntGLxvME+GPpnntoQQPLP4Gexd7Fn53ErSUtKMYHEBsLSEuXPh0iVNlE5DQyNXSoQjkFJyePlh5tSew47PduDX149hx4cRPCy4QPsBHDwcePa7Z4mPiWfDiA2FaHEhERwMAwfCjBlw+LCprdHQ0DBTHntHEHckjqXNl7K692ocyzsyYOcAnvnmGRw8HB5d2QCqtapG4zGN2b9gP//8nPtaZZPw6afg7Ayvv65NHGtoaOTIY+0IIj6OYF7APOIOx9Hx644M/HsgFRtWLPT7NP+wORWCK/DroF+5fvZ6obdfINzcYMoUiIyEb781tTUaGnlCCEHfvn315+np6ZQtW1YvNmdMNmzYQIMGDahduzYBAQH06tWLc+fOAfDee++xadOmfLU7ceJEpuYgEJldejq7oN66deuMvtHssXYEzlWdqTuoLkOPD6Xe4HpYWBrn41paW9JteTeQsLr3ajLTM41yn3zz0ksQEqLkJ65dM7U1GhoG4+DgwJEjR7h9+zYAGzdupEKFHAWLC5UjR44wbNgwli5dSkxMDAcPHqRPnz56MbgPP/yQVq1aFeo9HyY93blzZ8aOHVuo97qfx9oR+PXxo+PcjkWy6culqgsd5nXg/I7zhH8QbvT75QkLC/jqK0hIgHffNbU1Ghp54umnn+b3338HlDT0888/r7+2e/duGjVqRGBgII0aNdLLSS9ZsoSuXbvSrl07atasyejRo/V1sieCWblyJf3793/gnlOmTGHcuHH3bNDq3LkzYWFhgJKkyOq0q1Spwvvvv0/dunXx9fUlJiYGgMTERLp06YKfnx8NGza8JwHOoUOHaNGiBTVr1mTBggUAD5WeNiTJTkExqgx1ScP3eV9iN8ay7RMlQVG1uRnJQQcEqA1ms2bByy9DLiJcGhr3M2LEiHvklAuDgIAAphugZvfcc8/x4Ycf0rFjR6Kionj55ZfZtm0bALVr1yYiIgIrKys2bdrEuHHjWLVqFQAHDx7kwIED2Nra4uXlxbBhw6hUqZJBtv3zzz+89dZbBn8Wd3d39u/fz1dffcXUqVNZuHAh77//PoGBgaxdu5bNmzfTr18//XcYFRXFrl27SE5OJjAwkA4dOhh8L2PwWI8ITMHTs57GrZYba15YQ0q8mQm/ffih2mz2+uuQkWFqazQ0DMLPz48zZ86wfPnyBzR4kpKS6NGjBz4+PowcOfIecbmWLVtSpkwZ7OzseOqppzh79my+7p+QkEBAQAC1atXKMbYP0LVrVwDq1aunDx9FRkbq5zdatGhBQkICSUlKxv6ZZ57B3t4ed3d3mjdvzu7du/NlW2GhjQgKGRsHG7ot78Y3Db/hl5d/4blfnjNIKbFIKFMGvvgC+vSBBQvg1VdNbZFGMcGQJ3dj0rlzZ9566y3Cw8NJSEjQvz9hwgSaN2/OmjVrOHPmDM2aNdNfs7X9L4mUpaWlPoVl9v+PqampOd7P29ub/fv34+/vj5ubGwcPHmTq1KncunUrx/JZ98p+n5zkZ7LufX+fYOo+QhsRGIHygeVp9Vkrjv96nN2zTevpH+D556F5cxg3DrQUoBrFhJdffpn33nsPX1/fe95PSkrSTx5nZSV7FJ6enkRHR5OZmcmaNWtyLDN69Gg++eSTe3IepORR2j0sLIxly5YBahWQu7s7Tk5OAPzyyy+kpqaSkJBAeHg4QUFBeWq7sNEcgZEIfiOYmh1qsvGtjVw+dNnU5vyHEDB7tpKd0OVh1TAPzC6UaEZUrFhRLxGdndGjR/POO+/QuHFjMgwMd06ePJmOHTvSokULypcvn2MZX19fZsyYQb9+/ahduzaNGzcmOjqa3r17G2zzxIkT2bt3L35+fowdO/aeVJgNGjSgQ4cONGzYkAkTJvDEE08Y3K4x0GSojUjy1WTm+c/D1smWwfsGY+NgY2qT/mPs2P/2FzRubGprSjTxMfFs/XArMWtiGHp8KGUqPZjgxBRoMtTFC02G2kxxKOtA1++7knA8gQ3DzUyCYsIEqFRJTRzrYpoaRUvC8QRWv7Car7y/4ti6YwQPDzavhwWNEoM2WWxkqraoSpN3mhA5KZJqravh0+vBdcImwcFBaRB17apCRSNGmNqiEkPCiQQiPorg8LLDWNlZETIqhEZvN8KhbOHInmho5BXNERQBzSY248zmM/w2+DcqNKiAS1WXAreZlpJG3JE4Lh+6TEp8Cs5VnHGt7opLdRfsXe0NW4XQpQs8/TS89x707AkFjFNmpGWQdDaJxFOJXDt1DUsbSwL6BxRI2O9xIvFkIhEfRxD1fRSWNpY0HNmQxqMbF5rulYZGftEcQRFgaW1J1x+68nXA16x6fhUvbXvpkclvspBScuPCDa5EXeHKIXVcPnSZxBOJyMyc53dsy9jiWsNV7xhcqrvoXztVcEJY6JyEEGqDmbc3jBoFy5c/0p67yXe5duqavrPX/z2ZSNK5JGTGvTYdXXmU7iu6Y+dsZ9DnfRy5FnuNiI8iOPTdISytLQkeHkzj0Y1x9HR8dGUNjSJAcwRFhEtVFzrO78iq51YR/n44LSe1fKBMemo6V49e5fKhy/pO/0rUFW4n3taXca7qTDn/cvg854Onvyfl/Mvh4OnA9TPX7+mYr526xqX9l4heHX2P9pGlrSUu1VzudRLd3sHlh1k499uIZbtWpMSnPNBW4qlEEk8mknwl+R6b7V3tcanuQsXgivj29r3H6ZxYf4L1Q9azsOFCnl/3PG613Iz3BZsh105fI+LjCA4tVQ6gwbAGNBnTBMdymgPQMC+0VUNFzLqB6ziw6AA9fu6BjYPNf51+1BXiY+L1T9TWpazx8PXA089T3+F7+nli62T7iDvcS2Z6Jknnk+7pzLN37mnJ2RPqSGwcbbl76+49bThVdHpgZKEPQ7nY53r/sxFn+anbT2SmZ9L9x+5Ub1M9T/YXR66fuU7EJxEcWnIIYSmo90o9moxtkqcMeOaAtmqoeFGQVUOaIyhi7ibfZUH9BcTHxOvfc6rkpDp6//86fZfqLkZTS81CSklyXLJyDmu2kvjFIlJDWuDSs7W+s3eu6oy1vXWB7nP9zHWWd17O1X+u0ubLNgS/EWzynZTG4PrZ62z7ZBsHFx9EWAjqDq5Lk7FNcKrgZGrT8oWpHUFCQgItW6qR8+XLl7G0tKRs2bKAEpuzsSncFVYvvPAC27dvp0yZMlhaWvLVV18RHBxscP3x48fj7u7OCBMtvCiII9BCQ0WMjYMNz//2PCc3nMTDWz3x27vm/lRtLIQQOHo64ujpSOXGfeH0Wlg7EWqdgk4ToHrZQrmPcxVnBuwYwJq+a/hjxB/EHY6j/Zz2WNk+Hv/8ks4lsW3SNg4sOoAQ/40AnCoWTwdgLmRJO4DanOXo6JgnIbj8MG3aNLp06cL69et57bXX2L9/v0H10gu4BDs9PR0rK9P9f9CWc5gA1+quNBjSgCrNqpjMCeTIN9/A8OHw44/g5aVUSmNjC6VpG0cbeq7qSej4UA58c4DvWn1HclzyoyuaMTcu3OD3139nZo2ZHFh0gLoD6zLs5DDaz26vOQEj89lnn+Hj44OPjw+zZs0C4OTJk/j4+DBgwAC8vb15+umnSU1N5dixYzRo0EBfNzo6+p7znAgLC+PkyZMAzJs3j6CgIPz9/enRo4c+N8ILL7zAqFGjaN68OePGjbun/ty5c+nQoQOpqamcOHGCtm3bUq9ePcLCwjh+/Pgj6xc1j8cjmUbh4OwMX36pEthMmQLz5sF338GLL6o8BlULJqstLAQtPmqBh48Hv/T/hQVBC3hu3XOU8y9XSB+gaLhx8QaRn0ayf8F+pJQEvhxI6LhQylQ2jx3BxuDkyZMPFVzLL46OjtSoUSPP9Xbv3s2yZcvYvXs3GRkZNGjQgKZNm1KqVCmOHTvG8uXL8fX1pWvXrqxdu5bnnnsOOzs7jhw5go+PD4sXL+all17K9R6//vqrXteoR48evKoTaBw7dixLlizhtddeA+DUqVP89ddfWFhYMH78eEAJ9G3dupU1a9ZgY2PD4MGDWbhwIdWrV2f79u0MHTqUP//884H6pkQbEWg8SPnyMH26Gg289hp8/z3UqgWDBoFOYrcg+PTy4aXIl8jMyGRRo0VEr45+dCUz4Oa/N1k/bD0zq81k39f78H/Rn2EnhtFxXsfH2gmYG9u2baNbt26UKlWK0qVL06VLFyIjIwGoUaOGvgPPLgk9YMAAFi9eTHp6Oj///PM9yW2yM3LkSAICAli8eLE+YUxUVBShoaH4+vqyYsWKe6Sue/TocU8nvnjxYjZv3szPP/+MjY0N169fZ9euXXTr1o2AgACGDBnCv//++9D6pkIbEWg8nCeegJkzlTjd5Mkwfz4sXapSX777LlSunP+m6z3BoD2D+PHZH/mp2080+7AZYePDzHIS+ealm0ROjmTf1/vITM8koH8Aoe+GFsrGwOJCfp7cjUVuC1weJj3do0cPJk2aROPGjQkJCcHZ2TnH+llzBNnp168f//vf//Dx8WHhwoXs2rVLf83B4d7NgL6+vhw8eJCLFy/y5JNPIqXE3d39oUl97q9vKkzvijTMnwoV1MazU6fUqGDJEqhRQ40Wzp/Pd7Oly5emf3h//Pr6Ef5eOCt7rSQtJe2BcrduQXx8Dg0YmVuXb7Fh5AZmVpvJnjl78O3jy7Djw+i8sHOJcgLmRlhYGGvWrOH27dvcunWLX375hdDQ0FzrlCpVihYtWjB06NBHhoXuJzk5mXLlypGWlsYPP/yQa9n69eszZ84cOnXqxOXLl3FxcaF8+fJ6uevMzEwOHTqUp/sXBZoj0DCcihVhzhw4eRIGDFCTyzVqwJAhcOFCvpq0srOiy9IutPqsFUdXHmVRk0UknU+6p8yiRerW/frBrl1g7BXPt67c4o9RfzCj2gx2z9qNz3M+DD02lGe+eQaXapoDMDUNGjTg+eefJygoiIYNG/Laa689kKcgJ/r06YO1tbV+SaqhfPjhhzRo0IDWrVvz1FNPPbJ806ZNmTx5Mh06dCAxMZEVK1Ywb948/P398fb25rfffsvT/YsCbR+BRv45exYmTVI9tYUFDB6s5K11iULyyon1J1j1/Cqs7K3otaYXlUJUftnoaKWL9913Ko1CQIASTe3dW2nnFRbJccls/3w7e+bsIeNOBn4v+BE2IQzXGq6Fd5NihKn3ERQ2kydP5s6dO7z//vumNsUoaBvKNEzLmTPwyScqZGRp+Z9DyIeI3dWjV1neeTk3zt+g4/yOBLwYoL928yYsWwZz50JUFDg5qVHCa6+BAQ9qDyUlPkU5gNl7SE9Nx7e3L2ETwkqcJMb9PE6OoFOnTpw/f57Nmzfj6vp4OnbNEWiYB6dPw8cfqwlla2u1J+HTT5W4XR5ISUhhZc+VnN58mpBRIbSa0uqeXdZSwo4dyiH8/DPcvQtNm6pRQpcuYOiG05T4FHZ8sYPds3aTlpKmdwDuXu55svdx5XFyBCUBLTGNhnlQtaqaNzh+XOU5mDJFhY3ySCm3UvTZ0IegoUHs/GInyzsuJzXpvyTjQqikat9/r6YmJk9WUapevdRCpgkTcp/DTklI4a9xfzGj6gy2T9mOV2cvhhwdQtfvu2pOQKNEYrQRgRCiEvAtUA7IBOZLKWcIISYCg4CszOnjpJTrc2tLGxEUQzIzoXlzFcM5elTtTcgH++bvY/2Q9di52FHKvVSuZW/dgmvX1F8AR0dwdX1wHuHG+RvcTb6Ld09vmr7XlLJPFY6UxuOGNiIoXpir1lA6MEpKuV8IURrYJ4TYqLs2TUo51Yj31jA1FhawYAH4+cEbb6gYTj6oN7ge7nXc2Tt37z1y2jnhofubnKz2wp0+DbHnlCOoXl0NWGxsoHJoZYLfCMbD2yPX9jQ0SgpGcwRSykvAJd3rm0KIaCB/y0k0iie1asH778O4cbB2rQrg54MnQ5/kydAn81zvzh1YvVrNJSzZBrbHVPho2CDw8M6XKRoajyVFMkd5fQWQAAAgAElEQVQghKgCBAJ/694aKoSIEkIsEkJoC7MfZ956C/z91Uzu9etFemtbW3j+eYiIUBGqAQOUY2jQQG2H0DB/LC0tCQgIwNvbG39/f7788ksyM3MfGZqC69ev4+bmpt/1vHPnToQQXNDtr0lKSsLV1TVPtjs6Fl0CI6M7AiGEI7AKGCGlvAHMBaoDAagRwxcPqTdYCLFXCLH36tWrORXRKA5YW8PChXDlipKqMBG+vqrzv3gROnWCoUNh4kTjb07TKBj29vYcPHiQf/75h40bN7J+/Xo++OADU5v1AM7OzpQrV47oaKWbtWPHDgIDA9mxYwcAu3btIjg42Cx0hXLCqFYJIaxRTmCZlHI1gJTyipQyQ0qZCSwActSDlVLOl1LWl1LWz0pGoVFMqV8fRo5UWkVbt5rUFCcnWLVKySV98IFyCBkZJjVJw0A8PDyYP38+s2fPRkpJ+/btiYqKAiAwMJAPP/wQgAkTJrBw4UL69u3LL7/8oq/fp08f1q1bx5kzZwgNDaVu3brUrVtX31mHh4fTrFkzunfvTu3atenTp4/+CX/fvn00bdqUevXq0bZtWy5duvSAfY0bN9a3tWPHDkaOHHnPeaNGjQBYsGCBXta6W7dupKSkAHD69GlCQkIICgpiwoQJ97T9+eefExQUhJ+fn3E2xEkpjXIAArVqaPp975fP9noksOJRbdWrV09qFHNu3ZKyalUpa9aUMiXF1NbIzEwpR4+WEqTs2VPK1FRTW2R+HD169L+T4cOlbNq0cI/hwx9pg4ODwwPvOTs7y8uXL8tPP/1Uzp49WyYlJcn69evLNm3aSCmlbNasmYyJiZHh4eHymWeekVJKef36dVmlShWZlpYmk5OT5e3bt6WUUh4/flxm9S9btmyRTk5O8vz58zIjI0M2bNhQbtu2Td69e1eGhITIuLg4KaWUK1askC+99NIDdi1evFj/fkBAgLx9+7Zs3LixlFLKVq1ayb/++ktKKWV8fLy+zrvvvitnzpwppZSyU6dOcunSpVJKKWfPnq3/7H/88YccNGiQzMzMlBkZGbJDhw5y69atD9z/nt9LB7BXGtBfG3NE0BjoC7QQQhzUHe2Bz4QQh4UQUUBznTPQeNxxcFAjghMn4KOPTG0NQqhtDp9/Dj/9BB07qp3LGuaP1D2lh4aGEhERQWRkJB06dODWrVukpKRw5swZvLy8aNq0KSdPniQuLo7ly5fTrVs3rKysSEtLY9CgQfj6+tKjRw+OHj2qb7tBgwZUrFgRCwsLAgICOHPmDMeOHePIkSO0bt2agIAAPv74Y33sPztZI4LTp09TpUoV7OzskFJy69Yt9u3bp0+Gc+TIEb2s9bJly/Sy1tu3b9fLY/ft21ff7p9//smff/5JYGAgdevWJSYmhhMnThTqd2rMVUORqFHB/eS6Z0DjMaZVK+jfHz77DHr2VKJBJuatt6BsWTWR3LIl/P67Ote4j+nTTW0BALGxsVhaWuLh4YGLiwt79+6lWrVqtG7dmvj4eBYsWEC9evX05fv27cuyZctYsWIFi3SbG6dNm4anpyeHDh0iMzMTOzs7ffmcZKyllHh7e7Nz585cbatZsybXrl3j119/JSQkBFA5ERYvXkzVqlX1k7/9+/dn7dq1+Pv7s2TJEsLDw/Vt5CTDLqXknXfe4ZVXXsn7F2Yg5jlzofH48sUX4OYGAwdCAfO8FhYvvghr1sDhwxAaqnYpa5gfV69e5dVXX2Xo0KEIIbCxsaFSpUr89NNPNGzYkNDQUKZOnXqPJHX//v2ZrnNi3t5qzXBSUhLly5fHwsKC7777joxHTBJ5eXlx9epVvSNIS0u7JzlNdkJCQpgxY4beEYSEhDB9+nT9/ADAzZs3KV++PGlpaSxbtkz/fuPGjVmxYgXAPe+3bduWRYsW6TPEXbx4kbi4OMO+NAPRHIFG0eLqqnIb7NtnNk+ZoFYSbdwIly8r+YqH/D/XKGJu376tXz7aqlUr2rRpc89kaWhoKJ6enpQqVYrQ0FAuXLhwjyPw9PSkTp069+QgeP3111m6dCkNGzbk+PHjj0wOY2Njw8qVKxkzZgz+/v4EBAToJ4Hvp3Hjxpw/f5769dVm3pCQEGJjY+9xBB999BHBwcG0bt2a2rVr69+fMWMGc+bMISgoiKSk/6TY27RpQ+/evQkJCcHX15fu3btzs5DjmJronEbRI6XaXLZxo3oMr17d1BbpiYqCdu0gNVWFiXQPdiWSx0FiIiUlBV9fX/bv30+ZMo93OlFNdE6jeCGEWtRvZaUkq83oYcTPD7ZvV9GrVq3gf/8ztUUa+WXTpk3Url2bYcOGPfZOoKBojkDDNFSsqCaNN29WeQzMiKpVITISvLygc2eVA0Gj+NGqVSvOnTvHiBEjTG2K2aM5Ag3TMXiwmp19800VnDcjPD0hPByaNIEXXoCZM01tkYaG8dAcgYbpyFIoTUlRCqVmhpOTCg09+6zKsTN+vFlFsTQ0Cg3NEWiYFi8veO89JVOdTQ7AXLCzU6YNHKiycb76qiZJofH4oTkCDdMzerRShXv9dci2bM5csLRUm6LHjVN/e/ZUq4o0NB4XNEegYXqsrVWKy8uXVdJ7M0QINSKYNk1JWbdvDzdumNqqx5uEhAQCAgIICAigXLlyVKhQQX+efV1+XlmyZAlly5YlMDCQmjVr0rZt24fuCygpGDNDmYaG4QQFwYgR8OWXKolAWJipLcqRESPA3V2plzZvruYQPLREZ0bBzc2NgwcPAjBx4kQcHR156623CqXtXr16MXv2bAC2bNlC165d2bJlS7HfN5FftBGBhvnw4Ydq7eagQWYde3nhBTWdER0NjRrBIyRoNIxAlm5PeHg4TZs2pWfPntSqVYuxY8eybNkyGjRogK+vL6dOnXpkW82bN2fw4MHMnz8fgGbNmpG1gTU+Pp4qVaoAaiTRtWtX2rVrR82aNRk9erS+jQ0bNlC3bl38/f1p2bIlALt376ZRo0YEBgbSqFEjjh079sh2TIU2ItAwHxwc4OuvoU0bpVD6ySemtuihtG8Pf/2lUl82bgxDhsCkSVC6tKktMw4jNozg4OWDhdpmQLkAprcruMzIoUOHiI6OxtXVlWrVqjFw4EB2797NjBkzmDVrll5rKDfq1q3L119//chyBw8e5MCBA9ja2uLl5cWwYcOws7Nj0KBBREREULVqVRITEwGoXbs2ERERWFlZsWnTJsaNG8eqVase2k6lSpUK9kUUAG1EoGFetG6tVOA++wwOHTK1NbkSEqI0iYYOVRulvb2VLIVG0RIUFET58uWxtbWlevXqtGnTBgBfX1/OnDljUBuGSu20bNmSMmXKYGdnx1NPPcXZs2fZtWsXYWFhVK1aFQBXV1dAidv16NEDHx8fRo4ceY9QXU7tmBJtRKBhfnzxBaxfr9Zs7typpCjMlNKl1Waz559X5nbsCM89BzNmPF5zB4Xx5G4ssktHW1hY6M8tLCxIN1Dh9sCBA/r5ASsrK31u4dT7QpQPk6nOST56woQJNG/enDVr1nDmzBmaNWuWazumRBsRaJgfbm5KoXTv3mKzpTckBPbvV+kvV62COnVg6VJtA1pxYOvWrcyfP59BgwYBUKVKFfbt2wfAypUrH1k/JCSErVu3cvr0aQB9aCgpKYkKFSoAal7AnNEcgYZ50rOnerwePx5iY01tjUHY2qq9cQcPQu3aKgdP27ag6x80zIgff/yRgIAAatWqxaRJk1i1apV+RPDWW28xd+5cGjVqRHx8/CPbKlu2LPPnz6dr1674+/vTq1cvAEaPHs0777xD48aNH5nzwNRoMtQa5suFC/DUUxAcDH/+qRbzFxMyM2HePBgzRr3+6COlomHGUa4HeBxkqEsSmgy1xuNJxYoweTJs2qTiLMUICwu1UfroUWjRAkaNUuEjM5//1iihaI7ABEgpSUlJMbUZxYNXX1XrM4cNg7ffBgPWhZsTlSrBunWwYgWcOwf16impitu3TW2ZhsZ/aI7ABJw8eZIDBw7oVyZo5IKFBfzwgwq2T5sGNWqoFGLr1hUb9Tch1H6D6Gjo2xc+/RT8/WHrVlNbpqGh0ByBCXBzcyM9PZ2EhARTm1I8qFwZVq5UWeUnTlTpLZ95Ru1C/uQTs8tl8DBcXWHxYpWhMz0dmjVTKRmuXze1ZRolHc0RmAAXFxdsbGy4cuWKqU0pXlSoAO+/rxzC6tVKwnr8eBV/6dVLPWIXg8UPrVopX/bWW0pr76mn1McxRzIy4OrVYvG1ahQAzRGYACEEHh4eJCYmkpaWZmpzih9WVipbzMaNcOyYmj/YuFE9Yvv4wOzZZilnnR0HB/j8c9i9W20869YNevSAu3dNbdm9XLqk/K42eH280RyBifD09ERKydWrV01tSvGmVi2lWHrhAixapHrYYcPU6OGVV9SifjOmXj3YswfmD9pDh5X9WT770evWi4qMDIiLU68vXTLNqCBLXM4QsuSlAwIC8Pb2pnv37kZblFGlShWD9hgUFzRHYCIcHR1xcHDgcjGJb5s9pUopbejdu1XP2qsXfPcdBAYqidDvvjNbRVPrsycZuKY9/VmK9zvPcOe6eSwpunFD7YGoUAHu3Ckeo4JevXpx8OBB/vnnH2xsbPjxxx8fKGNqOQdzRHMEJsTT05ObN29qS0kLm/r1VfD94kW10ighAfr1U/sSRo82r53K8fHw9NMI4PjgqdS9u5PzLfqpHtjEZt28qSa4y5UDe3vTjQru5+rVq3Tr1o2goCCCgoLYvn37A2XS09NJTk7GxcUFgP79+/Pmm2/SvHlzxowZQ2JiIl26dMHPz4+GDRsSFRUFqLwHL7/8Ms2aNaNatWrMNEDipEuXLtSrVw9vb2+9lDWoh70xY8ZQr149WrVqxe7du/Xtrlu3DoCMjAzefvttgoKC8PPz0yugXrp0ibCwMAICAvDx8WHbtm0F/t5yoxjtc3z88PDwIDY2lri4OL3muUYh4uKiMskMHw6bN8PcuSqMNGOGEgTq2NG09t2+DZ07q7DW5s3UbBjCnI2CoQdGkfbmaKynTzWZaV98AU2bQvnyavnryVkbOLfnMrvsVEK5wqBcQDnaTW+X53rDhw9n5MiRNGnShHPnztG2bVuio6MBJR0RGRnJpUuXqFWrFp06ddLXO378OJs2bcLS0pJhw4YRGBjI2rVr2bx5M/369dMnwYmJiWHLli3cvHkTLy8vXnvtNaxz+dCLFi3C1dWV27dvExQURLdu3XBzcyM5OZlmzZoxZcoUnn32WcaPH8/GjRs5evQoL774Ip07d+abb76hTJky7Nmzhzt37tC4cWPatGnD6tWradu2Le+++y4ZGRlGf1jURgQmxNbWFmdnZ65cuWKwDK5GPhACWrb8bwmqn5+anTWlZnRmptpUsGsXLFsGISEIAd4LRzKLoVjP+EIJ75mAhAQ1316qlBoJgNJRsrAwj8nsTZs2MXToUAICAujcuTM3btzg5s2bwH+hocuXL+Pr68vnn3+ur9ejRw8sLS0BiIyMpG/fvgC0aNGChIQEknQLDDp06ICtrS3u7u54eHg8cnXfzJkz8ff3p2HDhpw/f54TJ04AYGNjQ7t2ytH5+vrStGlTrK2t75HH/vPPP/n2228JCAggODiYhIQETpw4QVBQEIsXL2bixIkcPnyY0kZOdKGNCExMuXLliImJ4caNG5QpU8bU5jz+VKigdItat4auXWHtWnj66aK34+231ahk2jRlh47mLQQfN51OzV3naDt8OKJyZbVnogj58ktITgZn5//eazejHYmJKqpWtaoSiDUVmZmZ7Ny5E/ssL5UDQgg6derErFmzGKvLg+3g4KC/ntODV5aUdF4kosPDw9m0aRM7d+6kVKlSNGvWTC9dbW1trW/zYfLYUkpmzZpF27ZtH2g7IiKC33//nb59+/L222/Tr1+/h9pRULQRgYlxd3fHwsJC21NQlLi4qOWmPj5qGeqGDUV7/5kzVW87fLgKXd3HxI8s6XpnOZcrBqlEB7t3F5lpiYlqINKjx4MhIBcX85graNOmjT7fMKAP6dxPZGQk1atXz/FaWFgYy5YtA1Rn7u7ujpOTU55tSUpKwsXFhVKlShETE8OuXbvyVL9t27bMnTtXv4z8+PHjJCcnc/bsWTw8PBg0aBADBgxg//79ebYtL2gjAhNjaWmJu7s7V69epUaNGlhYaL65SMhyBq1aQZcuKglxDk9lhc7atarzf/ZZFYjPgdBQaNK6FC33/8oRz4ZYdOyoQkjVqhndvGnT1CTxhAkPXhNCzRnExsK1a2oi2dikpKRQsWJF/fmbb77JzJkzGTJkCH5+fqSnpxMWFsa8efOA/+YIMjMzqVix4kPzAEycOJGXXnoJPz8/SpUqxdI8ihqmp6dja2tLu3btmDdvHn5+fnh5edGwYcM8tTNw4EDOnDlD3bp1kVJStmxZ1q5dS3h4OJ9//jnW1tY4Ojry7bff5qndPCOlNPujXr168nEmISFBhoeHy7i4OFObUvJISJAyIEBKW1sp//jDuPfatUtKe3spg4OlTE7OteiOHVKClPNHxUjp6iplrVpSxscb1byEBCmdnKTs3l2dHz169IEymZlSHjki5eHD6nVJJC4uTj7xxBOmNuMBcvq9gL3SgD5We/w0AzTJCRPi6qpkrmvXVrH4TZuMc59Tp6BTJ3jiCfj1VzUTmwshIWrqYuxiL5J/+EVNcnfpYtS9ENOnq70D77338DJZo4LUVDUqKGmsW7eO0NBQPv30U1ObUqhojsAM0CQncsfoy+fc3JQDqFlTddZ//VW47ev2CpCZqXIxly1rULUPPlAx++l7m8C330JkJLz4olH2GFy7plbVdu0Kvr65l3VxATs7088VmILOnTsTExNj1IlbU2A0RyCEqCSE2CKEiBZC/COEGK5731UIsVEIcUL318VYNhQnsiQn4rL29GsAkJaWxqFDh9izZw83btww3o3c3ZUDqFFDOYMtWwqn3dRU9SR/7pySzq5Vy+CqQUHKlKlTIaltTyVO9NNPoFsFU5jMmJHzaEDmuLpGjQpu3y6ZowJzJKffKS8Y5AiEEMOFEE5C8Y0QYr8Qos0jqqUDo6SUdYCGwBAhxFPAWOAvKWVN4C/deYknS3JCCw/9R2pqKgcOHODWrVtYW1tz4sQJ4+63KFtWOYNq1aBDBwgPL1h7mZlqR/OOHfD990rqIo988IGSqZ4+HZXm7PXXlUP46quC2ZaNrPa7dFF5ErKws7MjISEhx+/c1bXkjgrMDSklCQkJ2NnZ5bsNQ1cNvSylnCGEaAuUBV4CFgN/5mLcJeCS7vVNIUQ0UAF4BmimK7YUCAfG5Mf4xw1PT09iY2NJSUmh1CNiyI87ycnJHD58mPT0dPz8/Lh79y7R0dH8+++/VKhQwXg39vBQu5CbN1fOYP16tcU2P4wZAz//rFYHde+eryYCA9UCoy+/hDfeELjMmAHnzythvUqV1JChgMycqcRa7x8NVKxYkQsXLjxUGDE1VUW9UlMfOeWhYWTs7OzuWV2VZwyZUQaidH9nAM/qXh8wpK6ubBXgHOAEXL/v2rWH1BkM7AX2Vq5cueBT6sWA1NRUGR4eLmNjY01tiklJSkqSkZGRcvv27fLmzZtSSikzMzPlwYMH5bZt2+SdO3eMb8Tly1LWqSNlqVJSbt2a9/qzZ6tlP0OHFnh5zaFDqqnx43Vv3LolZf36yrbduwvU9vXrUjo7S9m5c97rpqerxUx+flJmZBTIDA0jQSGvGtonhPgTaA/8IYQoDRg0YyWEcARWASOklAYHeaWU86WU9aWU9csaOLlW3LG1tcXFxYW4uLgSKzmRmJjIoUOHsLKyIjAwUC9DLISgZs2aZGZmcqoo8hZ7eqqRQeXK0L69mqg1lHXr4I03lI7Q9OkqqF4A/PzUBq/p03UKoA4O8NtvavTSsSOcPp3vtmfNUqGh99/Pe11LS7XfICpKbcPQKL4Y6ggGoGL5QVLKFMAGFR7KFSGENcoJLJNSZuVguiKEKK+7Xh7QZkez4enpSWpqql73pCQRFxfHkSNHsLe3JzAw8AEJgVKlSlGpUiXi4uK4XhT5HcuVU86gYkW16icHlcsH2LMHnntOKaAuX656y0Lg/feV7MPULB06T0/43/8gLU05qsTEPLd544YKOXXqBHXr5s+u555Ti60+/FCbKyjOGOoINkop90sprwNIKROAablVEEpk4xsgWkr5ZbZL64AXda9fBLRniWxkSU6UtNVDFy9eJDo6GicnJwICArCxscmxXOXKlbGzs+PEiRNkFoVUc/nyagXRE09Au3Zq4vdhnD6tntDLlTNor0Be8PZWne6sWf8li6F2bfUoHhurJhLu3MlTm7Nnq1U/+RkNZGFlpbKFHjyoBkIaxZNcHYEQwk4I4Qq4CyFcdEs/XYUQVYAnHtF2Y6Av0EIIcVB3tAcmA62FECeA1rpzDR2WlpaULVuWuLi4ounoTIyUktOnT3Py5Enc3Nzw8/PDyurhaxgsLS2pXr06KSkpXLx4sWiMzHIG5csrZ5CTnkxioho1pKerJ3UPj0I347331JLNbIKaSo9i6VKIiID+/Q3eY3DzpprD7tBBZUkrCL17q1W3H3ygjQqKLblNIADDgdPAHSBW9/o0cAgYasgkRGEcj7vExP2UFMmJzMxMeezYMRkeHi5jYmJkZh4mVQ8fPiwjIiLk7du3jWjhfVy4IGWNGkqHYdcuGXM1RvZf219eTTgvZZMmSqZi2zajmtC3r1KpuHTpvgtTpqgZ5bFjDWpn0iRVvIBzzXoWL1btrVtXOO1pFA4YOFls6KqfYYaUM9ZR0hxBZmam3LFjhzx8+LCpTTEaGRkZ8siRIzI8PFyeOnUqT05ASilTUlJkRESEPHLkiJEsfAjnz0tZvbqUTk5yyar3pNWHVtJ9vK1c5ovMXLHC6Lc/flxKS0spR4y470JmppSvvab+S8+dm2sbN29K6eYm5dNPF55daWlSVqsmZb16JVeDyBwx1BEYNEcgpZwlhGgkhOgthOiXdRhhgKLBvZITd80hE0ghk56ezuHDh4mPj6datWpUq1ZNr9tuKPb29lSuXJn4+HgS8zFRmm8qVlRhInd3Xnx5BvtPt6H65Tv06QYd0pdy9vpZo96+Zk21R23uXPj332wXhFAbAjp0gCFD1KqihzBnjlp9VJC5gfuxsoJ334V9+0yb70cjfxi6s/g7YCrQBAjSHfWNaFeJJ0ty4mGbeYord+/e5dChQ1y/fh0vLy8qVaqU77YqVaqEvb09J0+eLNr5lEqVlDNwdcV38Xq227zKjLbTiTgbgfdX3sz8eyYZmRlGu/348ZCRAQ/onllZwYoVahda9+7Qqxf8+KOaENBx65ZaedS2LQQHF65dffuqpDXaXEExxJBhAxANCEPKGuMoaaGhLPbs2SP37dtnajMKjdu3b8u///5bRkREyPhCklTOmk85ffp0obSXJ86fl3LePBUXkVKeuXZGPv3905KJyOAFwfLwFeOF9gYNktLGRspz53K4eOWKlK++KqWHhwoV2dpK2bGjlIsWyZnvx0tQMtfGYMECdcvffzdO+xp5AwNDQ0Ia4LqFED8Db0glG1Hk1K9fX+7du9cUtzYp58+fJzY2lqCgoGIvOZGcnExUVBSZmZn4+PgUalrOo0ePkpCQQP369XNNX1gUSClZfmQ5wzcMJyk1ibFNxvJu6LvYWtk+unIeOHtWhYkGDFBhohzJyICdO2H1anWcPUs6lhx2bUrgh12VuFAhy3XcvQteXmrR1K5dBd5Lp1FAhBD7pJSPjN4Yuo/AHTgqhPhDCLEu6yiYiRqPwkO3BLG4C9ElJSXp0wn6+/sXem7m6tWrI4Tg5MmTGPJgY0yEEPT27U30kGh6+fTio4iPCPg6gMhzediZbABPPgkDB8I334AuD/qDWFpCkyZq19jp03w3Yh+TGYuX0yUYOlTNd4SEqPWohbRb28YGxo1T2TX/+KNQmtQoAgwdEeSouiWl3FroFuVASR0RAERFRZGSkkJwcHCeJ1TNgYSEBI4ePYqtrS1+fn4FUkjMjazRk7e3N+7u7ka5R3744+QfvPLbK5xNOsvr9V/n01af4mSb99y4OXHhglq/37cvLFiQe9mUFBW/9/NTGTqJjoY1a9RIYd8+VcjPTyUk6NpV5XPO57+3u3fVaOWJJ9T+u2L4z/axwdARgcmWhOblKKlzBFJKefnyZRkeHi6vXbtmalPyTJbte/fuNbpQXEZGhtyzZ4/cuXOnTE9PN+q98srNOzfliP+NkGKikBW+qCB/ifml0Np+4w21nPTkydzLffmlit3nuM3h9Gkpp01TeyGEUAVr1JBy9GiVXjMfinLz5qlmjJ39UyN3KIw5AiFEpJSyiRDiJpC9oFA+RBbOo80jKMkjgoyMDHbs2IGHhwdeXl6mNueRSCm5du0aly9f5urVqzg7O+Pt7Z3rbuHCIisEValSJaoVQaL3vPL3hb8Z+OtAjsQdoad3T2a2m4mno2eB2rx0SaVPeO45WLw45zIpKaqMt7cBydcuX1ayFatXK52l9HSVTGf7dpW8x0Du3lWjlUqVlF5fYY4KLl9WUhsbN6pFUmb4U5sN2ojgMSI6Olpu27bN7J50s3Pz5k158uRJuWPHDhkeHi4jIyPliRMnZEYR6xNHR0fLrVu3yuRHJIc3FXfS78iPt34sbT6ykS6TXeSi/YvyvJnuft58U0oLC7XZLCemTVNP53lW005MlHLOHFX566/zbNdXX6mqGzfmuWqOxMSo1VK2tmrgYmUl5fPPF07bjysU5qohnWfxB0J1pxFSyqh8u6k8UpJHBADXrl0jKiqKOnXq6CeQzYE7d+4QFxfHlStXSE5ORgiBq6srnp6euLm5YWFR9Cmx7969y549e3B0dMTPz89s51Vi4mMY/Otgtp3bRouqLZjfcT7VXavnq60rV9RT8bPPqhOBFeIAACAASURBVERo2bl9W12rXTuf2TelhOrVoU6dPO8Uu3NHjQqqVFFSSPn9KbZvV/PZ69aBra2SVHrzTViyBCZNggMHICAgf20/7hTqqiFdvuFlgIfuWCaEGFYwEzUMxdnZGRsbG7NYPZSRkcGVK1eIiopi165dxMbGYmFhQY0aNQgJCcHHx4eyZcuaxAkA2NjYULVqVa5fv27Wm/Fqu9cmvH848zrMY++/e/Gd68uXO7/M16onT0+1COiHH9QccHYWLFChlHzvIhZC5VX46y+1Gy0P2Nqq9MqRkSrKlBcyM9VcdqNGauHTtm0q98HZs2q5bM2a8Pbb4OIC77yTt7Y1csCQYQMQBThkO3dAl7WsKI6SHhqSUspTp07JrVu3Fk12rvvIzMyU165dkzExMXLbtm0yPDxc7ty5U8bGxpplCCYzM1Pu27dP7tixQ6bpNnuZMxeSLshOP3SSTET+78T/8tXG1atSOjpK2avXf+/dvi3lE09IGRZWQAM3b1YxnlWr8lw1y4bQUCmv3oqXc3bPkbfTHi4UePu2ikLVqqVuWbWqlLNmqaRsOfH556rcli15Nq1EQCFnKBNA9j3zGbr3NIoIU0hOpKSkcPr0af7++28OHTrE1atXKVu2LP7+/gQHB1O1alWz3OgmhKBGjRrcvXuXMw9dZG8+VHCqwMqeK6noVJGPIz7O16jA3V0lRfvpJzh8WL23cKHSIyqwplBoqHr0zkcaMjs7NSrY9vctQr9uz5D1Q3jlt1ce+IyJifDxx2p/xCuvgJOTUsc4flyNdhwccm5/yBC1J27sWE3WoiAY6ggWA38LISYKISYCu1BJZzSKCAcHBxwdHY0eHkpLS+PixYvs37+fPXv2cO7cOUqVKkWdOnUICQnBy8sLZ2dns429Z+Hk5ET58uW5ePEit/IY0jAFNpY2jGk8hu3ntxNxNiJfbYwaBY6OSuvnzh2YPFn14c2bF9A4KyslZvfbb2oVUR558eW72PbtTsyNvTxb+1m+PfQtM/6eAajNcMOHq4ygEyao3AhbtqgNaT17qlvnhr09TJwIf/+tpcssEIYMG3Teuy7wBipHQaCh9Qrj0EJDinPnzsnw8HCjhGPS09PlyZMn5datW2V4eLjcs2ePPHfunExNTS30exUVd+/eldu3b5f79+8v8MqcoiDlbor0/NxTtlzaMt9tvPeeCpW88or6u2lTIRn388+qwfDwPFXLyMyQvVf1lkxEErhQbt6SIbus6CItP7CUzV7eKC0tpbS2lvLFF6XMr+p6WpqUXl5S1qkjpRkvrDMJFEZoSJehbIQQYjZKcfQrKeUMKeUBYzsojQfx9FRrzgt7VHDz5k3279/PhQsX8PT0pF69etSvX59KlSpha1u4GjlFibW1NdWqVePGjRtmMdGeE3fv3uWnn36iWbNmPOHxBC/Xfpm/Tv/FzvM789XeyJFQpgx8/TU0bgwtWhSSoW3bKv2IPOSjlFIy6o9R/HD4Bz4Im0S5SwN4a5QF1xZ9S8aV2oSX7cVLb8YSG6tWAPn45M80Kyv45BM1Uf7tt/lro6TzqNDQUpTc9GHgaZQUtYaJsLGxwcXFhStXruQrjnw/mZmZnDlzhv3795Oeno6vry9eXl44OjoWgrXmgaenJ05OTsTGxpKWlmZqc/ScO3eO8ePHU7lyZXr16sW5c+dISUkhbn0cbvZufLLtk3y16+ysQkSg5gYKLYJXurTyKr/8YnAwfsr2KUz/ezrDg4czodlYxo6F/fvhxJHSjK68ljLOmeyq+gzOHgUP3XXtCkFB6jOnpha4uZJHbsMF4HC211bA/9u787goy/WP4597gEFwQxFNcQVFASEVtOMh7biU5pppmZm5r5UdtTLNn0dPZovlsdUt17TcTU3TSkPEckEUQcGVXFBU3FFQgev3x4xmKTuzAPf79ZoXMPPM83yFca55lvu6I3Oym1HQN31o6E8F1XIiOTlZ9uzZI6GhoXLw4EG5fft2ASW0P9evX5fQ0FA5dOiQTXOkp6fLxo0bpVOnTmIwGEQpJR06dJD169dLWlqaDBkyRIxGo7y17i1hArLnTN5akN+5Y6E209Onmw4P5WBWuDmRc4QJyIsrX5T0DNOgwvR006C2uxe+bTq6SQwTDdJ1adcCOXS3ebMp3ief5HtVRQYFMVXl39/4dSGwvbS0NNm2bZvExcXl6fkZGRly6tQpCQsLk/Dw8CI/L/JdR44ckdDQULl69arVt52UlCRTpkwRb29vAcTDw0PGjBnzwBwK8fHx4uDgIENeHyJl3y8rzy591upZs3T6tOkt4733slxsTdwaMUw0SJtv2sittKwvd/54+8fCBOTdre8WSMQnnzRNw3nlSoGsrtArqEKQDlwz364Dafd9fy0nGyiImy4Ef5XXlhMpKSmyd+9eCQ0Nlf3799tkTIKt3LlzR3777TeJiIiwyonjjIwM+f333+Xll18WZ2dnAaRZs2by7bffZnkCvk+fPuLi4iIj1o0QJiAx56w8J3N2goNFHnss04fD/giTEpNKSJPZTeT6revZri4jI0NeWvWSMAFZG7c23/EiIkzvauPG5XtVRUJOC0GW5whExEFEyphvpUXE8b7vrdJwTntQpUqVSE9P5+LFizlaXkRITEwkIiKC5ORkfHx8qF+/Pkaj0cJJ7YejoyPe3t4kJydz5i+T/RasGzduMHv2bIKCgmjatCmrVq2if//+7N+/n7CwMHr06JHlCfgxY8Zw69Yt0sPTKelUksnhky2WNU86dzZdq3n2wTmqos9F0/G7jtQoW4P1L66nlDH7c01KKWZ1mEVQ5SB6rupJ7IXYbJ+TlaAg02WnU6eaWm9oOWObPgBavri5ueHs7JyjK2Fu377NgQMHOHToEKVKlSIoKIjKlSvb/TgAS/Dw8MDNzY34+Hhu3LhRoOuOjY1l+PDhVKlShUGDBpGWlsb06dM5c+YMX375JQEBATlaj4+PD927d2ful3PpF9CPJTFLOHLxSIFmzZfOnU1f1637y91/XPmDNovaUMpYik0vbaKCa847lbo4ubC6+2pcnFzovKQzV1Kv5CvipEmmcRSTJuVrNcWKLgSFkFKKihUrcunSJW7fvp3pcklJSURERHDp0iW8vLx49NFHbT6Voy0ppfDx8cFgMLB//35SUlLytb47d+6wfPlyWrRogZ+fHzNnzqRjx46Eh4cTFRXFkCFDKF26dK7XO3bsWJKTk3GKcMLoYOT98L/PUm9D9eubZri5b/TWhRsXaLOoDSlpKWx8aSM13GrkerXVylZjxXMriL8Sz4srXyQ9Iz37J2WiTh3T7G0zZ8Lx43leTfGSk+NHtr7pcwQPSk5OltDQUDl16tQDj925c0diY2PvTQqTnFmjlmIqOTlZwsPDZceOHXkaMHft2jWZOnWqVK9eXQCpWbOmfPDBBwV64r1Lly7i5uYmg78fLI7/dZT4y/EFtu58e/11Uy/o69flWuo1CZ4VLCUmlZDwE+H5XvX03dOFCcjbP7+dr/UkJIi4uIj07JnvSIUaBdxrSLMzmbWcuHz5MhEREZw7d44aNWrQsGFDSmbWqKWYKlmyJIGBgdy5c4f9+/dnuVd1v8TERMaOHUv16tUZOXIkNWvWZO3atRw9epTRo0fj4eFRYBnHjRvHlStXcDvghkLxYfiHBbbufOvcGW7d4vbG9Ty77Fn2nt3L8ueWE1I9JN+rHhI8hEGNBvHB9g9YErMkz+upUsXUuuLbbyEqKt+xir6cVAtb3/QewcOdOnVKQkNDJTk5WdLS0u5dIrlz506bXCZZ2Fy+fFnCwsJk9+7dWY6jiI2Nlf79+4vRaBSllHTt2lV27Nhh8Xzt2rWTChUqSN9VfcX4rlFOXz1t8W3myJ07kl7OTV54o6YwAZm3d16Brv5W2i0JmRMiLpNcJPJMZJ7Xc+mSiJubSLt2BRiukEHvERR9dyep+eOPP9izZw8JCQl4enoSFBREmTL6oq7s3J1G8+bNm0RHR5N2X0M1ESE8PJzOnTvj6+vL4sWL6d+/P4cPH2bFihU89thjFs83btw4kpKSqHysMukZ6Xz8m30M7BcHB/7duxJLSv3Bhy3fp0+DPgW6fqODkZXPr8Td1Z1nlj7DhRt567h7d66CDRtME+NomdOFoBAzGo2UL1+epKQkMjIyCAwMpHbt2jg4ONg6WqFRvnx5/Pz8uH79OgcOHOD27dusXr2af/7znzRr1ozt27czfvx4Tp48yVdffUXt2rWtlq1p06a0atWKuZ/MpYd/D2bumcn5G+ettv3MTN42mc/dDjHyN3gzo6lFtlGpVCVWd1/N+RvneW75c9xJz1t7kFdfNR0m0m2qs6YLQSFXq1YtqlevTnBwMOXKlbN1nEKpQoUKeHl5cfnyZWbOnMnzzz/P+fPn+eKLLzh58iQTJ04s0OP/uTFu3DgSExPxSvAiNS2Vqb9PtUmOu2bvmc24X8fxkm93poQ6oXLRhC63gqsEM7vjbLae2MrITSPztA5XV1P/od9/f+CKV+1+OTl+ZOubPkegWUpSUpL897//FQ8PD+nQoYOEhobKxo0b7ab3UkZGhoSEhEi1atXk+aXPS6nJpeTizYs2ybLq4CoxTDTI04uelttpt0XathXx9hax8EjtkRtHChOQOZFz8vT8O3dMM575+xe/NtXocwSalrn4+Hhee+01qlevzvjx42ncuDGjRo3Cy8uLEiVKcOzYMcQOjiUopRg3bhynTp3C75IfybeT+WznZ1bPsfWPrfRY2YMmnk1Y/txynBycTFcPHTsGBw9adNsfPvkhT3o9ydD1Q9lxekeun+/oaBpcduAALFpkgYBFQU6qha1veo9AKyhRUVHSvXt3MRgM4uTkJH369JGYv3XTjI+Pl9DQUDl8+LBdTGiTkZEhwcHB4u3tLZ2/7SxuH7jJ1VTrXRW27+w+KfN+GfH9wleSbiT9+cDdJnSTJ1s8w8WbF8XrUy+p/HFlSbiWkOvnp6eLBAWJVK8uUojnWso19B6Bpj1o9+7d/Pjjj4waNYr4+HjmzZuHv7//X5apUaMGVatW5cyZM8THx9so6Z/u7hUcO3aMoJtBXEm9wpe7vrTKto9cPELbxW0p41yGTS9twt3V/c8HPT0hONgqc0SWdynPmhfWcO3WNZ5d+iypabmbdMBgME3defIkTJ9uoZCFmBIL7f4qpeYCHYDzIlLffN8EYCBw93qwsSKyIbt1BQcHS0REhEVyasXLrVu3SE1NpWzZslkuJyIcOXKEs2fP3jshb0sZGRk0aNCAO3fuUHNcTSLORPDH639Q0mi5wYKRZyNpu6gtgrC1z1b8PPweXGjSJNNkw2fOQOXKFsty16rYVXRd1pU+Dfowt9PcXPfMat3aNMDs2DEoDldYK6X2iEhwdstZco9gPtD2Iff/T0QamG/ZFgFNK0jOzs7ZFgEwfQqvU6cOFStWJD4+noSEBCuky5zBYOCdd94hLi6Ox9MfJ+lmEjP3zLTY9n6N/5V/zf8Xrk6ubO+3/eFFADJtQmcpz/o+y/81/z/m75vP57s+z/Xz338fkpLgk08sEK4Qs1ghEJEw4JKl1q9plqaUol69eri7u3P06FHOPqT1sjV169aNunXrsnzqclrUbMGU36bk+hBJTqyKXUXbxW2pXrY62/ttx8fdJ/OFH9KEztIm/GsCnep2YuSmkYzcNJJLKTl/m2ncGLp1MxWC87YfkmE3bHGO4FWl1H6l1FyllL7wXbNrSin8/PwoV64chw8f5rwN3z0cHBwYO3YsUVFRtHJqRWJyInP3zi3QbczaM4vnlj9HUOUgwvqG4VnGM+snKAWdOsHmzZCc/7mHc8KgDCzqsog+Dfrw6c5P8f7Mm49/+zjHRXHSJNO8xrpN9Z+sXQimA95AA+AskOkOmlJqkFIqQikVceFC3oaYa1pBMBgM+Pv7U6ZMGeLi4nI8IZAl9OjRg1q1arHm0zX8s+o/+XD7h9xOz1nTvKyICO+FvcfgHwbTtnZbfnn5F8q7lM/Zk81N6Pjpp3znyKnSzqX5utPX7Bu8j6ZVm/Lmz29S74t6LN6/mAzJyPK5detCv34wYwbYwbUAdsGqhUBEzolIuohkALOBJlksO0tEgkUk2FajOjXtLgcHBwICAihZsiQHDhzg8uXLNsnh5OTEmDFj2L1rN+1Kt+Pk1ZN8E/VNvtaZIRmM2DTCNGI48CW+7/49rk6uOV9Bs2amxj5WPDx0V0ClADb03MAvvUyF66XVL9F4dmO2xG/J8nn/+Q84OJi+alYuBEqp+y8r6ALEWHP7mpYfjo6OBAYG4uLiQkxMDFevXrVJjpdffpmqVauy8YuNBFUO4v3w90nLSMv+iQ9xO/02vVb34tOdn/Lvx/7NgmcWmAaL5YajI7RvDz/8AGl5y5FfrbxaETEogm+6fEPSzSRaLWxF+2/bE3P+4W8xnp4wfLhpgNn+/VYOa4csVgiUUt8BvwN1lVKnlVL9gY+UUtFKqf1AC2CEpbavaZbg5OREYGAgzs7OREdHc/36datncHZ25q233iJ8Wzhd3Ltw7PIxlsYszfV6bty+Qeclnfk2+lsmt5zM1DZTMag8viV07gyXLsFvv+Xt+QXAoAy8FPgSh149xEetP2L7ye08OuNRBqwdQMK1B6/6Gj3adAnpO+/YIKydsdg4goKkxxFo9iY1NZV9+/bdu77f1TUXh1IKQEpKCrVq1SIgMIDELomkZ6QTMywmx2/kl1Iu0f7b9uxK2MXMDjMZ0GhA/gJdvw4VKpjafdrJtZkXb17kvW3v8cWuL3A0ODKq6SjeCnmL0s5/Th/6/vswdixs2waPP27DsBZiD+MINK3IKlGiBIGBgYgIMTEx3LmTtzbJeeXi4sIbb7zBLz//QvfK3YlNimVV7KocPff0tdM0m9eMvWf3suK5FfkvAgClS0PLlqbzBHby4dLd1Z2pbaYS92ocnet1ZtK2SXh/5s1Xu7+619b69ddN4+CKe5tqXQg0LY9cXV2pX78+t27dIiYmhvT0vE+4nhdDhgyhfPny7JizAx93HyaFTcq2Ud6hpEOEzA3h1NVTbHxpI118uxRcICs1ocstr3JefNf1O3YO2Imvhy+vbHiF+tPr833c97i4COPHw/btpr2D4koXAk3Lh7Jly1KvXj2uXbtGXFycVTuWlipVihEjRrD+h/X0rNaTqHNRrD+yPtPldyfs5vF5j5OalsrWPlv5V81/FWygjh1NXy04R0F+NPFsQmjvUNa+sBaDMtBlaReaz29OwNM7ePFF07mCDz6wdUrb0IVA0/LJw8MDb29vkpKSOHbsmFW3/dprr1G2bFmiFkVR060m74a9+9Bi9MvxX2ixoAWljKUI7xtOw8oNCz6MFZvQ5ZVSio51OxI9NJoZ7Wdw5OIRHp/flDudu/PcizcZMwY++sjWKa1PFwJNKwCenp54enqSkJDA6dOnrbbdsmXL8tprr7F65Wp6e/dmV8Iufjn+y1+WWXZgGe0Wt8OrnBfb+22njnsdywXq3Bl27gQbt+PIjqPBkcHBgzk6/Cjjmo1jeewy/vnqHLp3N11N9LF9TA9tNboQaFoBUErh7e2Nu7s7x44dIykpyWrbfv3113F1deXQ0kN4lvZk0rY/eydM3z2dF1a8QBPPJmzts5UqpatYNoyVm9DlVyljKd5t+S5NPJswK3I633wjPP88vPkmTLXtrKBWpQuBphUQpRS+vr6ULl2a2NhYrl27ZpXtVqhQgaFDh7Ls22X09elL2Ikwwk6EMTF0IsM2DKO9T3t+6vUT5Vys0NrrbhM6Oz1PkJlhwcOITYple8JWFi+G556DUaPgf/+zdTLr0IVA0wqQg4MD9evXx2g0EhMTQ0pKilW2O2rUKIxGIye/P0nFkhV5ZskzTNg6gd6P9mbV86ty1zIiP+42ofvlF6s1oSsIz/s/T7kS5fhq91c4OsLixdC1K4wcCZ9+aut0lqcLgaYVMKPRSEBAACJCdHS0VcYYPPLIIwwcOJBvF3zLQN+BXE69zKimo5jbeW7uW0bklw2a0OWXi5ML/Rr2Y3Xcas5eP4uTE3z3HXTpAv/+N3ye+6kPChVdCDTNAu6OMUhNTSUmJoaMjKw7YhaEN998E6UUlzZcInpoNB8/9XHeW0bkhw2b0OXH4KDBpGWk8XXk1wA4OcGSJfDMM6a+RF9aZ3ZQm9CFQNMspGzZsvj6+lptjEG1atXo06cPc+fMpXxaDltIW8LdJnTr19usCV1e1HGvw1PeTzErcta9Jn5GIyxdatrJefVV+OorG4e0EF0INM2CPDw88PLy4sKFCxw/ftzi23v77bdJS0vjY1tf/9i5M1y8aNMmdHkxNHgop6+d5ofDP9y7z2iEZctM4+VeecU0j0FRowuBpllY1apVqVKlCqdPn7b43MdeXl707NmTGTNmMHv2bKv3QLqnTRvTO2ghOzzUwacDVctUZXrE9L/cbzTC8uXQoQMMHQozLTddtE3oQqBpFqaUonbt2vfmPrb0GINJkyYREBDAoEGD8PHxYc6cOdYvCHbYhC4nHA2ODGo0iJ+O/cSRi0f+8pizM6xYAe3awZAhMHu2jUJagC4EmmYF1hxjUK1aNXbs2MH69eupUKECAwYMoF69esybN8+6BcFOm9BlZ0CjATgaHJm558GP/c7OsHIlPP00DBoEc+bYIKAF6EKgaVZizTEGSinatWvHrl27WLduHeXKlaNfv374+voyf/580qxxEtfOm9BlpnLpynSp14W5e+eScufBv1GJErBqFbRtCwMHwty5NghZwHQh0DQrsvYYA6UUHTp0YPfu3axZs4YyZcrQt29ffH19WbhwoWULQiFoQpeZYY2HcTn1MssOLHvo4yVKwOrV8OSTMGAAzJ9v3XwFTRcCTbMyV1dX/P39rTrGQClFp06d2LNnD99//z2lSpWid+/e+Pn5sWjRIsvNpWBuQrd3wwamTZvGm2++yVk7b0gH8ESNJ/Ct4MtXEZlfL1qiBHz/PbRuDf36wYIFVgxY0ETE7m9BQUGiaUXNuXPnJDQ0VA4cOCAZGRlW3XZ6erqsWrVKAgMDBZC6devK4sWLJS0tLd/rvnjxoqxbt07GjBkjfYKCREAGggBiMBjE09NTIiIiCuBfYVmf7fhMmIBEJGSd9eZNkdatRZQSWbjQSuFyCIiQHLzH6j0CTbORihUrUqtWLS5cuEB8fLxVt20wGOjSpQt79+5lxYoVODk50bNnTwICAliyZEmO9xBEhEOHDjFv3jwGDBiAn58f7u7udOzYkSlTpnBAKS6WKcPERo1ISEggMjISBwcHmjVrxtKlSy38r8yflx99GVcn1wcuJf07FxfT0a8WLaB3b1i0yEoBC1JOqoWtb3qPQCuqMjIy5PDhwxIaGioJCQk2y5Geni7Lli0Tf39/AcTPz0+WLFki6enpf1kuJSVFtm3bJh988IF07NhR3N3dBfOn/XLlykn79u1l8uTJEhoaKjdu3DA96fXXRZydRa5fFxHTntDjjz8ugIwbN+6BbdiTgWsHisskF7mccjnbZW/cEGnRQsRgEPnxRyuEywFyuEdg8zf5nNx0IdCKsoyMDNm/f7+EhobKyZMnrX6Y6H7p6emydOlS8fPzE0D8/f3liy++kFGjRsk//vEPcXJyuvfG7+PjI3379pXZs2fLwYMHM39D37LF9FazcuW9u27duiX9+/cXQLp06SLXzUXC3kSeiRQmINN+n5aj5ZOTRd58817Ns7mcFgJlWta+BQcHS0REhK1jaJrFpKenExcXR1JSEpUqVcLHxweDwXZHbtPT01m+fDkTJ04kLi4OZ2dngoODCQkJISQkhKZNm+Lh4ZGzlaWlQcWKpstJ7zujKiJ89tlnjBw5kvr167NmzRpq1qxpmX9QPjSd05TLKZeJfSUWpZSt4+SKUmqPiARnu5wuBJpmH0SEEydOcOLECcqUKYO/vz9Go9GmmdLT0zl06BDe3t44OzvnfUW9esGPP0Jioqkp3X1++uknunfvjqOjI6tWraJZs2b5TF2wFkYtpPf3vdn88mZa1mpp6zi5ktNCoE8Wa5qdUEpRs2ZN/Pz8SE5OJjIykuvXr9s0k4ODA35+fvkrApBlE7qnnnqKnTt3Ur58eVq1asXXX3+dv20VsOf9n6e8S/lsTxoXZroQaJqd8fDwoEGDBgDs27ePCxcu2DhRAcimCZ2Pjw87d+6kZcuWDBw4kOHDh1tn9HMOlHAsQb8G/Vgdu5oz18/YOo5F6EKgaXaodOnSNGrUiFKlSnHw4EH++OMPCsNh3EzloAmdm5sbP/zwAyNHjuTzzz/n6aef5vLly1YO+nBDgoeQLun3Jq0panQh0DQ7ZTQaefTRR6lUqRInTpzg4MGDlhsBbA13m9DFxma6iKOjI5988glz585l69atNGnShLi4OCuGfDjv8t608W7DzD0zuZNuo9beFqQLgabZMYPBQN26dfHy8iIpKYl9+/aRmppq61h507kzfPghuLtnu2jfvn359ddfuXbtGo899hg//vijFQJmbVjjYZy5foZ1h9fZOkqB04VA0+ycUopq1apRv359UlJSiIyM5OrVq7aOlXuVK8Nbb0GlSjlaPCQkhN27d+Pl5UWHDh345JNPbHp4rH2d9lQrU61InjTWhUDTCgl3d3caNWqEo6MjUVFRJCYm2jqSxVWvXp3w8HC6dOnCG2+8Qd++fbl165ZNsjgYHBgcNJhfjv/C4YuHbZLBUnQh0LRCxNXVlYYNG1K2bFkOHTrE0aNHC/dJ5BwoWbIky5YtY8KECSxYsIAWLVrYrAj2b9QfR4MjMyKK1sTFuhBoWiHj5OREYGAgnp6eJCQkEB0dbTeXWlqKwWDgP//5D8uXLycqKorGjRsTGRlp9RyPlHqErr5dmbdvHjfv3LT69i1FFwJNK4TuzoPs4+PDlStXiIyM5ObNovPGlJlu3bqxfft2lFKEj8ZhbwAADs5JREFUhIQwePBgoqKirJphaPBQrqReYWmMfXdPzQ1dCDStEKtcuTKBgYGkpaURGRnJpUuXbB3J4ho0aMDu3bt58cUXWbhwIQ0aNCAkJIRFixZZ5Yqq5jWa4+fhl+WkNYWNxQqBUmquUuq8UirmvvvKK6V+VkodMX8tZ6nta1px4ebmRqNGjShRogTR0dGcPn26yJ83qFSpEnPmzCEhIYGpU6dy4cIFevXqRbVq1Rg9ejTHjx+32LaVUgwNHkrEmQh2J+y22HasyZJ7BPOBtn+7721gs4jUATabf9Y0LZ9KlChBw4YNqVChAseOHePw4cNFvhgAlC9fnhEjRhAXF8fPP/9M8+bN+eSTT6hduzbt2rVj3bp1FhmE1yuwFyWdShaZS0ktVghEJAz4+35qZ+BuH9oFwDOW2r6mFTd3G8RVr16dxMTEYlMMwHQyuXXr1qxcuZITJ04wfvx49u3bR6dOnfD29mby5MmcO3euwLZXtkRZegb05LuY77icYh9tMPLD2ucIKonIWQDz14qZLaiUGqSUilBKRRSJpluaZgVKKWrVqnWvGFh7Ckx74OnpyYQJEzhx4gQrVqzA29ubd955h2rVqvHiiy+ybdu2AimQQxsPJTUtlfn75uc/tI3Z7cliEZklIsEiEpzjCTA0TQOgZs2aVK5cmVOnTnH69Glbx7EJJycnunbtyubNm4mNjWXYsGFs2LCB5s2bExgYyFdffcW1a9fyvP4GjzSgadWmTI+YToZkFGBy67N2ITinlKoMYP563srb17RiQSlFnTp17p0zKMjDIoVRvXr1mDZtGgkJCXz99dcYjUZeeeUVPD09GTp0KNHR0Xla77DGwzhy6Qhb4rcUcGLrsnYhWAv0Nn/fG3h4c3JN0/JNKYWvr++9UcjF4dLS7JQsWZL+/fsTERHBzp076datG/PnzycwMJBp06blen3d/LpRwbVCoT9pbMnLR78DfgfqKqVOK6X6Ax8ATyqljgBPmn/WNM1CDAYD9evXx9XVlQMHDuTrUEhRopSiSZMmzJs3j4SEBLp27cqIESOYPHlyrtZzd9KaNXFrSLiWYKG0lmfJq4Z6iEhlEXESkaoiMkdELopIKxGpY/6qP6JomoU5OjoSGBiI0WgkOjq6WIxAzo3y5cuzZMkSevbsyTvvvMO4ceNydTJ5cPBgMiSD2ZGzLZjSsuz2ZLGmaQXHaDQSGBiIUor9+/fbrIOnvXJ0dGTBggUMGDCA9957j1GjRuW4GHiV86Jt7bbM2jOr0E5aowuBphUTLi4uBAQEkJaWxv79+7lzp3C+aVmKg4MDs2bNYvjw4fzvf/9j2LBhZGTk7GqgYY2HcTb5LGsPrbVwSsvQhUDTipHSpUvj7+9PSkoKMTExhXvqSwtQSjFt2jRGjx7NjBkz6NevX45+R0/XfpoaZWsUeP8ha136qwuBphUz5cqVw9fXl2vXrnHw4MEcf+otLpRSvP/++0ycOJEFCxbQs2fPbPee7k5asyV+C3FJ+Z9jOTU1lfHjx+Pl5cWmTZvyvb7s6EKgacWQh4cHderU4dKlS8WqFUVOKaUYP348U6ZMYenSpXTr1i3b8yr9G/XHyeCU70lrwsPDadiwIe+++y4vvPACQUFB+VpfTuhCoGnFVJUqVahRowbnzp0rlq0ocuKNN97giy++YO3atXTq1CnLK64qlqxIN79uzN83nxu3b+R6W1evXmXYsGE0a9aMlJQUNm7cyMKFC6lQoUJ+/gk5oguBphVjNWrUoEqVKpw6dYpTp07ZOo5deuWVV5gzZw4///wz7dq14/r165kuOzR4KFdvXc31SOO1a9fi7+/PzJkzGTFiBDExMbRp0ya/0XPM0Wpb0jTN7tyd6ez27dscP34co9FIpUqVbB3L7vTr1w8XFxd69erFU089xY8//oibm9sDyz1e/XEOv3qYOu51crTexMREhg8fzvLlywkICGDVqlU0adKkoONnS+8RaFoxd7cVhZubG4cOHeLixYu2jmSXevTowfLly9mzZw8tW7YkKSnpgWWUUjkqAiLC3Llz8fX1Ze3atbz33nvs2bPHJkUAdCHQNA1TKwp/f39KlizJwYMHuXr1qq0j2aUuXbqwZs0aYmNjadGiBYmJiblex9GjR2ndujX9+/cnICCAqKgoxo4di5OTkwUS54wuBJqmAabRtQEBARiNRmJiYrhxI/cnPIuDp59+mvXr13P8+HGeeOKJHF/rn5aWxkcffURAQAARERHMmDGD0NBQ6tata+HE2dOFQNO0e+62ojAYDERHR1tlMvjCqGXLlvz0008kJibSrFmzbK+6ioyMpEmTJowePZo2bdpw8OBBBg8ejMFgH2/B9pFC0zS7cX8riujoaN2KIhMhISFs3ryZq1ev0qxZMw4fPvzAMjdv3uStt96iSZMmnD17lhUrVrB69Wo8PT1tkDhzuhBomvaAUqVKUb9+fVJSUoiOjtatKDIRHBxMaGgot2/fpnnz5sTExNx7bMuWLQQGBjJlyhT69u3LwYMH6dq1K0opGyZ+OF0INE17KDc3N/z8/EhJSSElJcXWcexWYGAgYWFhODg48MQTT7B582b69+9Pq1atUEqxZcsWZs+eTbly5WwdNVN6HIGmaZmqUKECbm5uODrqt4qs1KtXj7CwMFq1akXr1q1xcHDg7bffZvz48bi4uNg6Xrb0X1fTtCzpIpAz3t7ehIWF8eGHHzJw4EAaNGhg60g5pv/CmqZpBaR69ep8+eWXto6Ra/ocgaZpWjGnC4GmaVoxpwuBpmlaMacLgaZpWjGnC4GmaVoxpwuBpmlaMacLgaZpWjGnC4GmaVoxp0TE1hmypZS6AJzI49MrAA9OJWR7Olfu6Fy5o3Pljr3mgvxlqyEiHtktVCgKQX4opSJEJNjWOf5O58odnSt3dK7csddcYJ1s+tCQpmlaMacLgaZpWjFXHArBLFsHyITOlTs6V+7oXLljr7nACtmK/DkCTdM0LWvFYY9A0zRNy4IuBJqmacVckSoESqlqSqlflVKxSqkDSqnX//b4G0opUUpVsJdcSqnXlFKHzPd/ZA+5lFINlFI7lFL7lFIRSqkmVs5VQim1SykVZc410Xx/LaXUTqXUEaXUUqWU0U5yLTb/DWOUUnOVUk72kOu+xz9XSiVbM1NWuZTJe0qpw+bX3nA7ydVKKRVpft2HK6VqWzPXffkclFJ7lVI/mH+2/OteRIrMDagMNDJ/Xxo4DPiZf64GbMI0MK2CPeQCWgC/AM7mxyraSa6fgKfN97cDQq2cSwGlzN87ATuBfwDLgBfM988AhtpJrnbmxxTwnb3kMv8cDHwDJFszUza/r77AQsBgfszar/vMch0GfM33DwPmW/t3Zt72SOBb4AfzzxZ/3RepPQIROSsikebvrwOxgKf54f8BbwFWPzueRa6hwAcicsv82Hk7ySVAGfNiZYEzVs4lInL3E6yT+SZAS2CF+f4FwDP2kEtENpgfE2AXUNUecimlHIApmF73VpfF33Eo8F8RyTAvZ+3XfWa5bPq6B1BKVQXaA1+bf1ZY4XVfpArB/ZRSNYGGwE6lVCcgQUSibBqKv+YCfIBm5t2+rUqpxnaS69/AFKXUKeBjYIwN8jgopfYB54GfgWPAFRFJMy9ymj+LvM1yicjO+x5zAnoBG+0k16vAWhE5a+082eTyBrqbDzv+qJSqYye5BgAblFKnMf0dP7B2LmAapsKdYf7ZHSu87otkIVBKlQJWYnpDSwPeAcbbNBR/zSUi1wBHoBym3dI3gWXmTwC2zjUUGCEi1YARwBxrZxKRdBFpgOnTdRPA92GLWTfVg7mUUvXve/grIExEttlBrubAc8Dn1s6STa76gDOQKqa2CbOBuXaSawTQTkSqAvOAqdbMpJTqAJwXkT333/2QRQv8dV/kCoH5U9lKYLGIrML06aMWEKWU+gPTHz5SKfWIjXOBqbqvMu+q7sL0KcDaJ7Iflqs3cPf75ZjeiG1CRK4AoZiKpZtSytH8UFVssOv+kFxtAZRS/wE8MB3ftZn7crUAagNHza97V6XUUTvI1RbT636l+aHVQKCNYt2f62ng0fv28JYC/7RynBCgk/nvtQTTIaFpWOF1X6QKgfnT9BwgVkSmAohItIhUFJGaIlIT04uwkYgk2jKX2feY/tgopXwAI1bsgJhFrjPAE+bvWwJHrJXJnMtDKeVm/t4FaI3p/MWvQDfzYr2BNXaQK04pNQBoA/S4e9zbDnLtEZFH7nvd3xQRq14Fk9nvi/te95heZ4ftIFcsUNb8/xDgSfN9ViMiY0Skqvnv9QKwRUR6YoXXvWP2ixQqIZiO7UWbj/8BjBWRDTbMBJnkwrRLPFcpFQPcBnqbTzjaOtdA4FPzp5BUYJAVM4HpaqYF5pOdBmCZiPyglDoILFFKTQL2Yv1DVpnlSsN0Ndrv5iN7q0Tkv7bOZcXtZyaz31c4sFgpNQJIxnRs3h5yDQRWKqUygMtAPyvnysxoLPy61y0mNE3TirkidWhI0zRNyz1dCDRN04o5XQg0TdOKOV0INE3TijldCDRN04o5XQg0LRtKqS7K1LW2nq2zaJol6EKgadnrAYRjGuSjaUWOLgSalgVzH6YQoD/mQqCUMiilvjL3sv9BKbVBKdXN/FiQuYHgHqXUJqVUZRvG17Qc0YVA07L2DLBRRA4Dl5RSjYBngZpAAKZRsU3hXt+mz4FuIhKEaeT4e7YIrWm5UdRaTGhaQeuBqfEXmBqB9cDUv365ua9QolLqV/PjdYH6wM/mVhMOgM1aQGtaTulCoGmZUEq5Y2qOVl8pJZje2AVTx8yHPgU4ICJNrRRR0wqEPjSkaZnrBiwUkRrmLp7VgHhMHWK7ms8VVAL+ZV7+EOChlLp3qEgp5W+L4JqWG7oQaFrmevDgp/+VQBVM7cxjgJmYZnW7KiK3MRWPD5VSUcA+rN/TXtNyTXcf1bQ8UEqVEpFk8+GjXUCINee40LSCpM8RaFre/GCe3MQIvKuLgFaY6T0CTdO0Yk6fI9A0TSvmdCHQNE0r5nQh0DRNK+Z0IdA0TSvmdCHQNE0r5v4fmGJZBXBx2fsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "players = ['Dirk Nowitzki','Manu Ginobili','Tony Parker','Dwyane Wade','Tim Duncan','LeBron James']\n",
    "colors = ['blue','black','silver','red','green','purple']\n",
    "\n",
    "for color,player in zip(colors,players):\n",
    "    plt.plot(df[df['player']==player]['age'],df[df['player']==player]['points'], color = color,label = player)\n",
    "    \n",
    "plt.title('Points Career trajectory')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Points')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LeBron James'], dtype=object)"
      ]
     },
     "execution_count": 1292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['season']==2012) &(df['team']=='MIA')][0:1]['player'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
