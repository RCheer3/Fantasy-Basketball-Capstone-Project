{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "import psycopg2 as pg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier,RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from Player_rank import Player_ranker\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nHere we're loading in all of the traditional Fantasy basketball stats into SQL, using window function to get a ranking by minutes\\n\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Here we're loading in all of the traditional Fantasy basketball stats into SQL, using window function to get a ranking by minutes\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"IF you have open connections run the following in the psql command prompt:\\n\\nSELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname = 'nba_capstone';\\n\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''IF you have open connections run the following in the psql command prompt:\n",
    "\n",
    "SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname = 'nba_capstone';\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pg2.connect(dbname = 'postgres',host='localhost')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.autocommit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Note for some reason you can not access the database if it is not all lowercase'''\n",
    "\n",
    "cur.execute('DROP DATABASE IF EXISTS nba_capstone;')  # Makes sure there is not already a class_example database and removes is if there is\n",
    "cur.execute('CREATE DATABASE nba_capstone;')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pg2.connect(dbname = 'nba_capstone',host='localhost')\n",
    "conn.autocommit = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "        CREATE TABLE NBA_stats (\n",
    "            Season integer, \n",
    "            Player varchar(50), \n",
    "            Pos varchar(10),\n",
    "            Age int,\n",
    "            Tm varchar(15),\n",
    "            G int,\n",
    "            GS int,\n",
    "            MP float,\n",
    "            FG float,\n",
    "            FGA float,\n",
    "            FG_Percentage float,\n",
    "            Threes_Made float,\n",
    "            Threes_Attempted float,\n",
    "            Three_Percentage float,\n",
    "            Twos_Made float,\n",
    "            Twos_Attempted float,\n",
    "            Twos_Percentage float,\n",
    "            eff_FG_Percentage float,\n",
    "            FTM float,\n",
    "            FTA float,\n",
    "            FT_Percentage float,\n",
    "            ORB float,\n",
    "            DRB float,\n",
    "            Rebounds float,\n",
    "            AST float,\n",
    "            STL float,\n",
    "            BLK float,\n",
    "            TOV float,\n",
    "            Fouls float,\n",
    "            Points float\n",
    "        );\n",
    "        '''\n",
    "\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# current_directory_path = os.getcwd()\n",
    "# current_directory_path\n",
    "\n",
    "query = '''\n",
    "        COPY NBA_stats \n",
    "        FROM '/Users/rcheer/Desktop/Galvanize/Capstone/Fantasy-Basketball-Capstone-Project/NBA stats.csv' \n",
    "        DELIMITER ',' \n",
    "        CSV HEADER;\n",
    "        '''\n",
    "\n",
    "\n",
    "\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "        CREATE TABLE nba_advanced (\n",
    "            Season integer, \n",
    "            Player varchar(50), \n",
    "            Pos varchar(10),\n",
    "            Age int,\n",
    "            Tm varchar(15),\n",
    "            G int,\n",
    "            total_MP float,\n",
    "            PER float,\n",
    "            True_Shooting float,\n",
    "            Three_Attempt_Rate float,\n",
    "            FT_rate float,\n",
    "            ORB_Percentage float,\n",
    "            DRB_Percentage float,\n",
    "            Rebound_Percentage float,\n",
    "            Assist_Percentage float,\n",
    "            Steal_Percentage float,\n",
    "            Block_Percentage float,\n",
    "            Turnover_Percentage float,\n",
    "            Usage_Percentage float,\n",
    "            Offensive_WinShares float,\n",
    "            Defensive_WinShares float,\n",
    "            WinShares float,\n",
    "            WinShares_Per48 float,\n",
    "            Offensive_BoxPlusMinus float,\n",
    "            Defensive_BoxPlusMinus float,\n",
    "            BoxPlusMinus float,\n",
    "            Value_overReplacement float\n",
    "        );\n",
    "        '''\n",
    "\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "        COPY nba_advanced \n",
    "        FROM '/Users/rcheer/Desktop/Galvanize/Capstone/Fantasy-Basketball-Capstone-Project/NBA Advanced.csv' \n",
    "        DELIMITER ',' \n",
    "        CSV HEADER;\n",
    "        '''\n",
    "\n",
    "\n",
    "\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "save for later\n",
    "d.points,d.rebounds,d.ast,d.stl,d.blk,d.tov,d.fg_percentage,d.FT_percentage\n",
    "'''\n",
    "\n",
    "\n",
    "query1 = '''\n",
    "            update nba_stats set Tm = 'NOP' where Tm = 'NOH';\n",
    "            update nba_advanced set Tm = 'NOP' where Tm = 'NOH';\n",
    "            update nba_stats set Tm = 'CHA' where Tm = 'CHO';\n",
    "            update nba_advanced set Tm = 'CHA' where Tm = 'CHO';\n",
    "            \n",
    "            DROP TABLE IF EXISTS players;\n",
    "            CREATE TABLE players AS\n",
    "            select season,player,max(G) as Games from NBA_stats where Tm!='TOT' group by season,player;\n",
    "            \n",
    "            DROP TABLE IF EXISTS y_predictions;\n",
    "            CREATE TABLE y_predictions AS\n",
    "            select d.season,d.player,d.pos,d.age,MAX(case when p.player is not null then d.Tm else NULL end) as StartingTeam,SUM(G) as Games,SUM(GS) as GS,\n",
    "            max(MP) as minutes\n",
    "            from NBA_stats d\n",
    "            left join players p\n",
    "                on d.season = p.season\n",
    "                and d.player = p.player\n",
    "                and d.G = p.Games\n",
    "            where d.Tm!='TOT'\n",
    "            group by d.season,d.player,d.pos,d.age;\n",
    "            \n",
    "            update y_predictions set StartingTeam = 'NOP' where startingTeam = 'NOH';\n",
    "            update y_predictions set StartingTeam = 'CHA' where startingTeam = 'CHO';\n",
    "            \n",
    "            DROP TABLE IF EXISTS rank_by_minutes;\n",
    "            CREATE TABLE rank_by_minutes AS\n",
    "            select y.*,n.points,n.rebounds,n.ast,n.stl,n.blk,n.tov,n.threes_made,n.fg,n.fga,n.ftm,n.fta,\n",
    "            case when cast(y.GS as float)/y.Games >0.6 then 1 else 0 end as starter,\n",
    "            row_number() over(partition by n.season order by MP*G desc) as min_rank from NBA_stats n\n",
    "            inner join y_predictions y\n",
    "                ON n.player = y.player\n",
    "                and n.season = y.season\n",
    "                and n.Tm=y.startingTeam;\n",
    "            \n",
    "            select * from rank_by_minutes        \n",
    "                \n",
    "        '''\n",
    "cur.execute(query1)\n",
    "data = cur.fetchall()\n",
    "df = pd.DataFrame(np.array(data))\n",
    "df.columns = ['season','player','position','age','team','gamesPlayed','gamesStarted','minutes'\n",
    "              ,'points','rebounds','assists','steals','blocks','turnovers','threes_made','FGM','FGA','FTM','FTA','starter','min_rank']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['min_rank']=pd.to_numeric(df['min_rank'])\n",
    "df['points']=pd.to_numeric(df['points'])\n",
    "df['rebounds']=pd.to_numeric(df['rebounds'])\n",
    "df['assists']=pd.to_numeric(df['assists'])\n",
    "df['steals']=pd.to_numeric(df['steals'])\n",
    "df['blocks']=pd.to_numeric(df['blocks'])\n",
    "df['turnovers']=pd.to_numeric(df['turnovers'])\n",
    "df['threes_made']=pd.to_numeric(df['threes_made'])\n",
    "df['FGM']=pd.to_numeric(df['FGM'])\n",
    "df['FGA']=pd.to_numeric(df['FGA'])\n",
    "df['FTM']=pd.to_numeric(df['FTM'])\n",
    "df['FTA']=pd.to_numeric(df['FTA'])\n",
    "df['gamesPlayed']=pd.to_numeric(df['gamesPlayed'])\n",
    "df['gamesStarted']=pd.to_numeric(df['gamesStarted'])\n",
    "df['minutes']=pd.to_numeric(df['minutes'])\n",
    "df['age']=pd.to_numeric(df['age'])\n",
    "df['season']=pd.to_numeric(df['season'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>mean_points</th>\n",
       "      <th>mean_rebounds</th>\n",
       "      <th>mean_assists</th>\n",
       "      <th>mean_steals</th>\n",
       "      <th>mean_blocks</th>\n",
       "      <th>mean_turnovers</th>\n",
       "      <th>mean_threes_made</th>\n",
       "      <th>mean_fgm</th>\n",
       "      <th>mean_fga</th>\n",
       "      <th>mean_ftm</th>\n",
       "      <th>mean_fta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>13.3005</td>\n",
       "      <td>5.1235</td>\n",
       "      <td>2.7870</td>\n",
       "      <td>0.9150</td>\n",
       "      <td>0.5690</td>\n",
       "      <td>1.7035</td>\n",
       "      <td>0.8780</td>\n",
       "      <td>4.9095</td>\n",
       "      <td>10.5850</td>\n",
       "      <td>2.5990</td>\n",
       "      <td>3.3115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009</td>\n",
       "      <td>12.9850</td>\n",
       "      <td>5.1080</td>\n",
       "      <td>2.8490</td>\n",
       "      <td>0.9120</td>\n",
       "      <td>0.5600</td>\n",
       "      <td>1.6965</td>\n",
       "      <td>0.8265</td>\n",
       "      <td>4.8530</td>\n",
       "      <td>10.4370</td>\n",
       "      <td>2.4600</td>\n",
       "      <td>3.1825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010</td>\n",
       "      <td>12.9225</td>\n",
       "      <td>5.0185</td>\n",
       "      <td>2.8135</td>\n",
       "      <td>0.9085</td>\n",
       "      <td>0.5685</td>\n",
       "      <td>1.6790</td>\n",
       "      <td>0.8380</td>\n",
       "      <td>4.7955</td>\n",
       "      <td>10.3525</td>\n",
       "      <td>2.4955</td>\n",
       "      <td>3.2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011</td>\n",
       "      <td>12.1830</td>\n",
       "      <td>4.8915</td>\n",
       "      <td>2.6840</td>\n",
       "      <td>0.9225</td>\n",
       "      <td>0.5725</td>\n",
       "      <td>1.6805</td>\n",
       "      <td>0.8030</td>\n",
       "      <td>4.5925</td>\n",
       "      <td>10.1180</td>\n",
       "      <td>2.1955</td>\n",
       "      <td>2.8590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012</td>\n",
       "      <td>12.5550</td>\n",
       "      <td>5.0520</td>\n",
       "      <td>2.8840</td>\n",
       "      <td>0.9585</td>\n",
       "      <td>0.6125</td>\n",
       "      <td>1.7410</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>4.7285</td>\n",
       "      <td>10.3275</td>\n",
       "      <td>2.2150</td>\n",
       "      <td>2.8920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013</td>\n",
       "      <td>13.0510</td>\n",
       "      <td>5.1265</td>\n",
       "      <td>2.8310</td>\n",
       "      <td>0.9505</td>\n",
       "      <td>0.5420</td>\n",
       "      <td>1.7375</td>\n",
       "      <td>0.9715</td>\n",
       "      <td>4.8545</td>\n",
       "      <td>10.5425</td>\n",
       "      <td>2.3790</td>\n",
       "      <td>3.1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014</td>\n",
       "      <td>12.3805</td>\n",
       "      <td>4.9890</td>\n",
       "      <td>2.7145</td>\n",
       "      <td>0.9230</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>1.6315</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>4.6260</td>\n",
       "      <td>10.1940</td>\n",
       "      <td>2.1725</td>\n",
       "      <td>2.8505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015</td>\n",
       "      <td>12.8715</td>\n",
       "      <td>5.1935</td>\n",
       "      <td>2.7720</td>\n",
       "      <td>0.9530</td>\n",
       "      <td>0.5900</td>\n",
       "      <td>1.6785</td>\n",
       "      <td>1.0530</td>\n",
       "      <td>4.7645</td>\n",
       "      <td>10.4595</td>\n",
       "      <td>2.2840</td>\n",
       "      <td>2.9900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2016</td>\n",
       "      <td>13.3550</td>\n",
       "      <td>5.0420</td>\n",
       "      <td>2.8950</td>\n",
       "      <td>0.9230</td>\n",
       "      <td>0.5340</td>\n",
       "      <td>1.6195</td>\n",
       "      <td>1.2170</td>\n",
       "      <td>4.8980</td>\n",
       "      <td>10.6355</td>\n",
       "      <td>2.3385</td>\n",
       "      <td>2.9850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2017</td>\n",
       "      <td>13.2915</td>\n",
       "      <td>5.0950</td>\n",
       "      <td>2.9355</td>\n",
       "      <td>0.9240</td>\n",
       "      <td>0.5585</td>\n",
       "      <td>1.6825</td>\n",
       "      <td>1.3200</td>\n",
       "      <td>4.9175</td>\n",
       "      <td>10.6135</td>\n",
       "      <td>2.1395</td>\n",
       "      <td>2.7465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season  mean_points  mean_rebounds  mean_assists  mean_steals  mean_blocks  \\\n",
       "0    2008      13.3005         5.1235        2.7870       0.9150       0.5690   \n",
       "1    2009      12.9850         5.1080        2.8490       0.9120       0.5600   \n",
       "2    2010      12.9225         5.0185        2.8135       0.9085       0.5685   \n",
       "3    2011      12.1830         4.8915        2.6840       0.9225       0.5725   \n",
       "4    2012      12.5550         5.0520        2.8840       0.9585       0.6125   \n",
       "5    2013      13.0510         5.1265        2.8310       0.9505       0.5420   \n",
       "6    2014      12.3805         4.9890        2.7145       0.9230       0.5390   \n",
       "7    2015      12.8715         5.1935        2.7720       0.9530       0.5900   \n",
       "8    2016      13.3550         5.0420        2.8950       0.9230       0.5340   \n",
       "9    2017      13.2915         5.0950        2.9355       0.9240       0.5585   \n",
       "\n",
       "   mean_turnovers  mean_threes_made  mean_fgm  mean_fga  mean_ftm  mean_fta  \n",
       "0          1.7035            0.8780    4.9095   10.5850    2.5990    3.3115  \n",
       "1          1.6965            0.8265    4.8530   10.4370    2.4600    3.1825  \n",
       "2          1.6790            0.8380    4.7955   10.3525    2.4955    3.2005  \n",
       "3          1.6805            0.8030    4.5925   10.1180    2.1955    2.8590  \n",
       "4          1.7410            0.8800    4.7285   10.3275    2.2150    2.8920  \n",
       "5          1.7375            0.9715    4.8545   10.5425    2.3790    3.1020  \n",
       "6          1.6315            0.9600    4.6260   10.1940    2.1725    2.8505  \n",
       "7          1.6785            1.0530    4.7645   10.4595    2.2840    2.9900  \n",
       "8          1.6195            1.2170    4.8980   10.6355    2.3385    2.9850  \n",
       "9          1.6825            1.3200    4.9175   10.6135    2.1395    2.7465  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = Player_ranker(df)\n",
    "test.get_category_dist()\n",
    "test.cat_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.assign_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_copy = test.value.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>player</th>\n",
       "      <th>value_tot</th>\n",
       "      <th>value_points</th>\n",
       "      <th>value_rebounds</th>\n",
       "      <th>value_assists</th>\n",
       "      <th>value_blocks</th>\n",
       "      <th>value_steals</th>\n",
       "      <th>value_turnovers</th>\n",
       "      <th>value_threes</th>\n",
       "      <th>value_fg</th>\n",
       "      <th>value_ft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>Andre Iguodala</td>\n",
       "      <td>1.569149</td>\n",
       "      <td>1.022902</td>\n",
       "      <td>0.233549</td>\n",
       "      <td>1.209232</td>\n",
       "      <td>-0.313073</td>\n",
       "      <td>1.720216</td>\n",
       "      <td>-1.392654</td>\n",
       "      <td>0.164932</td>\n",
       "      <td>0.201353</td>\n",
       "      <td>-1.277308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>Joe Johnson</td>\n",
       "      <td>2.248938</td>\n",
       "      <td>1.506499</td>\n",
       "      <td>-0.293101</td>\n",
       "      <td>1.449827</td>\n",
       "      <td>-0.683573</td>\n",
       "      <td>0.464584</td>\n",
       "      <td>-1.113145</td>\n",
       "      <td>1.381647</td>\n",
       "      <td>-1.036752</td>\n",
       "      <td>0.572951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>O.J. Mayo</td>\n",
       "      <td>0.491912</td>\n",
       "      <td>0.967102</td>\n",
       "      <td>-0.536170</td>\n",
       "      <td>0.198732</td>\n",
       "      <td>-0.683573</td>\n",
       "      <td>0.464584</td>\n",
       "      <td>-1.532409</td>\n",
       "      <td>1.246456</td>\n",
       "      <td>-0.633993</td>\n",
       "      <td>1.001183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008</td>\n",
       "      <td>Antawn Jamison</td>\n",
       "      <td>3.459954</td>\n",
       "      <td>1.655298</td>\n",
       "      <td>1.529918</td>\n",
       "      <td>-0.426816</td>\n",
       "      <td>-0.498323</td>\n",
       "      <td>0.715710</td>\n",
       "      <td>0.284401</td>\n",
       "      <td>0.705694</td>\n",
       "      <td>0.083254</td>\n",
       "      <td>-0.589183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>Raymond Felton</td>\n",
       "      <td>-0.135656</td>\n",
       "      <td>0.167306</td>\n",
       "      <td>-0.536170</td>\n",
       "      <td>1.882899</td>\n",
       "      <td>-0.313073</td>\n",
       "      <td>1.469090</td>\n",
       "      <td>-1.532409</td>\n",
       "      <td>-0.240639</td>\n",
       "      <td>-1.364914</td>\n",
       "      <td>0.332253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season          player  value_tot  value_points  value_rebounds  \\\n",
       "0    2008  Andre Iguodala   1.569149      1.022902        0.233549   \n",
       "1    2008     Joe Johnson   2.248938      1.506499       -0.293101   \n",
       "2    2008       O.J. Mayo   0.491912      0.967102       -0.536170   \n",
       "3    2008  Antawn Jamison   3.459954      1.655298        1.529918   \n",
       "4    2008  Raymond Felton  -0.135656      0.167306       -0.536170   \n",
       "\n",
       "   value_assists  value_blocks  value_steals  value_turnovers  value_threes  \\\n",
       "0       1.209232     -0.313073      1.720216        -1.392654      0.164932   \n",
       "1       1.449827     -0.683573      0.464584        -1.113145      1.381647   \n",
       "2       0.198732     -0.683573      0.464584        -1.532409      1.246456   \n",
       "3      -0.426816     -0.498323      0.715710         0.284401      0.705694   \n",
       "4       1.882899     -0.313073      1.469090        -1.532409     -0.240639   \n",
       "\n",
       "   value_fg  value_ft  \n",
       "0  0.201353 -1.277308  \n",
       "1 -1.036752  0.572951  \n",
       "2 -0.633993  1.001183  \n",
       "3  0.083254 -0.589183  \n",
       "4 -1.364914  0.332253  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy value data back into SQL\n",
    "engine = create_engine(\"postgresql://@localhost/nba_capstone\")\n",
    "\n",
    "value_copy.to_sql(name='value', con=engine, if_exists = 'replace', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "        DROP TABLE IF EXISTS player_value;\n",
    "        CREATE TABLE player_value AS\n",
    "        select ROW_NUMBER() OVER(PARTITION BY season ORDER BY value_tot DESC),* from value;\n",
    "        \n",
    "        DROP TABLE IF EXISTS value;\n",
    "        \n",
    "        select * from player_value;\n",
    "        \n",
    "        '''\n",
    "\n",
    "\n",
    "cur.execute(query)\n",
    "ranking_data = cur.fetchall()\n",
    "df_2 = pd.DataFrame(np.array(ranking_data))\n",
    "cols_value = ['playerrank']\n",
    "for item in (list(value_copy.columns)):\n",
    "    cols_value.append(item)\n",
    "cols_value\n",
    "df_2.columns=cols_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_2.columns:\n",
    "    if i!='player':\n",
    "        df_2[i]=pd.to_numeric(df_2[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_2.columns:\n",
    "    if i!='player':\n",
    "        df_2[i]=pd.to_numeric(df_2[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playerrank</th>\n",
       "      <th>season</th>\n",
       "      <th>player</th>\n",
       "      <th>value_tot</th>\n",
       "      <th>value_points</th>\n",
       "      <th>value_rebounds</th>\n",
       "      <th>value_assists</th>\n",
       "      <th>value_blocks</th>\n",
       "      <th>value_steals</th>\n",
       "      <th>value_turnovers</th>\n",
       "      <th>value_threes</th>\n",
       "      <th>value_fg</th>\n",
       "      <th>value_ft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2008</td>\n",
       "      <td>Chris Paul</td>\n",
       "      <td>10.649584</td>\n",
       "      <td>1.766898</td>\n",
       "      <td>0.152526</td>\n",
       "      <td>3.952019</td>\n",
       "      <td>-0.868823</td>\n",
       "      <td>4.733733</td>\n",
       "      <td>-1.811918</td>\n",
       "      <td>-0.105449</td>\n",
       "      <td>1.195183</td>\n",
       "      <td>1.635414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>LeBron James</td>\n",
       "      <td>8.708530</td>\n",
       "      <td>2.808492</td>\n",
       "      <td>1.003268</td>\n",
       "      <td>2.123494</td>\n",
       "      <td>0.983678</td>\n",
       "      <td>1.971343</td>\n",
       "      <td>-1.811918</td>\n",
       "      <td>0.976075</td>\n",
       "      <td>0.888138</td>\n",
       "      <td>-0.234041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2008</td>\n",
       "      <td>Dwyane Wade</td>\n",
       "      <td>8.419529</td>\n",
       "      <td>3.143291</td>\n",
       "      <td>-0.050032</td>\n",
       "      <td>2.267852</td>\n",
       "      <td>1.354178</td>\n",
       "      <td>3.226975</td>\n",
       "      <td>-2.370936</td>\n",
       "      <td>0.300123</td>\n",
       "      <td>1.126183</td>\n",
       "      <td>-0.578103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "      <td>Danny Granger</td>\n",
       "      <td>6.463654</td>\n",
       "      <td>2.324895</td>\n",
       "      <td>-0.009520</td>\n",
       "      <td>-0.041864</td>\n",
       "      <td>1.539428</td>\n",
       "      <td>0.213457</td>\n",
       "      <td>-1.113145</td>\n",
       "      <td>2.463170</td>\n",
       "      <td>-0.678128</td>\n",
       "      <td>1.765360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2008</td>\n",
       "      <td>Dirk Nowitzki</td>\n",
       "      <td>6.094625</td>\n",
       "      <td>2.343495</td>\n",
       "      <td>1.327360</td>\n",
       "      <td>-0.186221</td>\n",
       "      <td>0.427928</td>\n",
       "      <td>-0.288795</td>\n",
       "      <td>-0.274618</td>\n",
       "      <td>-0.105449</td>\n",
       "      <td>0.611555</td>\n",
       "      <td>2.239370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   playerrank  season         player  value_tot  value_points  value_rebounds  \\\n",
       "0           1    2008     Chris Paul  10.649584      1.766898        0.152526   \n",
       "1           2    2008   LeBron James   8.708530      2.808492        1.003268   \n",
       "2           3    2008    Dwyane Wade   8.419529      3.143291       -0.050032   \n",
       "3           4    2008  Danny Granger   6.463654      2.324895       -0.009520   \n",
       "4           5    2008  Dirk Nowitzki   6.094625      2.343495        1.327360   \n",
       "\n",
       "   value_assists  value_blocks  value_steals  value_turnovers  value_threes  \\\n",
       "0       3.952019     -0.868823      4.733733        -1.811918     -0.105449   \n",
       "1       2.123494      0.983678      1.971343        -1.811918      0.976075   \n",
       "2       2.267852      1.354178      3.226975        -2.370936      0.300123   \n",
       "3      -0.041864      1.539428      0.213457        -1.113145      2.463170   \n",
       "4      -0.186221      0.427928     -0.288795        -0.274618     -0.105449   \n",
       "\n",
       "   value_fg  value_ft  \n",
       "0  1.195183  1.635414  \n",
       "1  0.888138 -0.234041  \n",
       "2  1.126183 -0.578103  \n",
       "3 -0.678128  1.765360  \n",
       "4  0.611555  2.239370  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playerrank</th>\n",
       "      <th>season</th>\n",
       "      <th>player</th>\n",
       "      <th>value_tot</th>\n",
       "      <th>value_points</th>\n",
       "      <th>value_rebounds</th>\n",
       "      <th>value_assists</th>\n",
       "      <th>value_blocks</th>\n",
       "      <th>value_steals</th>\n",
       "      <th>value_turnovers</th>\n",
       "      <th>value_threes</th>\n",
       "      <th>value_fg</th>\n",
       "      <th>value_ft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4219</th>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>Anthony Davis</td>\n",
       "      <td>13.069292</td>\n",
       "      <td>2.728406</td>\n",
       "      <td>2.327843</td>\n",
       "      <td>-0.323373</td>\n",
       "      <td>4.382346</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>-0.642579</td>\n",
       "      <td>-0.719758</td>\n",
       "      <td>2.572502</td>\n",
       "      <td>1.340136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4220</th>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>Stephen Curry</td>\n",
       "      <td>10.977767</td>\n",
       "      <td>2.415188</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>1.610250</td>\n",
       "      <td>-0.769567</td>\n",
       "      <td>1.647478</td>\n",
       "      <td>-1.635937</td>\n",
       "      <td>3.343394</td>\n",
       "      <td>1.073741</td>\n",
       "      <td>3.291282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4221</th>\n",
       "      <td>3</td>\n",
       "      <td>2017</td>\n",
       "      <td>Kevin Durant</td>\n",
       "      <td>10.555627</td>\n",
       "      <td>2.415188</td>\n",
       "      <td>0.660945</td>\n",
       "      <td>1.254056</td>\n",
       "      <td>2.665042</td>\n",
       "      <td>-0.545910</td>\n",
       "      <td>-1.635937</td>\n",
       "      <td>1.369863</td>\n",
       "      <td>1.809299</td>\n",
       "      <td>2.563082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4222</th>\n",
       "      <td>4</td>\n",
       "      <td>2017</td>\n",
       "      <td>James Harden</td>\n",
       "      <td>10.522310</td>\n",
       "      <td>3.152171</td>\n",
       "      <td>0.118234</td>\n",
       "      <td>2.984140</td>\n",
       "      <td>0.303748</td>\n",
       "      <td>2.134898</td>\n",
       "      <td>-3.374314</td>\n",
       "      <td>2.762944</td>\n",
       "      <td>-0.589500</td>\n",
       "      <td>3.029989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4223</th>\n",
       "      <td>5</td>\n",
       "      <td>2017</td>\n",
       "      <td>Karl-Anthony Towns</td>\n",
       "      <td>9.046572</td>\n",
       "      <td>1.475533</td>\n",
       "      <td>2.793024</td>\n",
       "      <td>-0.272488</td>\n",
       "      <td>1.806390</td>\n",
       "      <td>-0.302200</td>\n",
       "      <td>-0.270069</td>\n",
       "      <td>0.208962</td>\n",
       "      <td>2.213129</td>\n",
       "      <td>1.394291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4224</th>\n",
       "      <td>6</td>\n",
       "      <td>2017</td>\n",
       "      <td>LeBron James</td>\n",
       "      <td>8.050018</td>\n",
       "      <td>2.617858</td>\n",
       "      <td>1.358716</td>\n",
       "      <td>3.136795</td>\n",
       "      <td>0.733074</td>\n",
       "      <td>1.160059</td>\n",
       "      <td>-3.125975</td>\n",
       "      <td>0.557232</td>\n",
       "      <td>2.935558</td>\n",
       "      <td>-1.323300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4225</th>\n",
       "      <td>7</td>\n",
       "      <td>2017</td>\n",
       "      <td>Giannis Antetokounmpo</td>\n",
       "      <td>7.982516</td>\n",
       "      <td>2.507311</td>\n",
       "      <td>1.901427</td>\n",
       "      <td>0.948747</td>\n",
       "      <td>1.806390</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>-1.635937</td>\n",
       "      <td>-0.835849</td>\n",
       "      <td>2.328774</td>\n",
       "      <td>-0.442116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4226</th>\n",
       "      <td>8</td>\n",
       "      <td>2017</td>\n",
       "      <td>Damian Lillard</td>\n",
       "      <td>7.758411</td>\n",
       "      <td>2.507311</td>\n",
       "      <td>-0.230652</td>\n",
       "      <td>1.864674</td>\n",
       "      <td>-0.340241</td>\n",
       "      <td>0.428929</td>\n",
       "      <td>-1.387598</td>\n",
       "      <td>2.066403</td>\n",
       "      <td>-0.920536</td>\n",
       "      <td>3.770119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4227</th>\n",
       "      <td>9</td>\n",
       "      <td>2017</td>\n",
       "      <td>Chris Paul</td>\n",
       "      <td>7.259998</td>\n",
       "      <td>0.978069</td>\n",
       "      <td>0.118234</td>\n",
       "      <td>2.526177</td>\n",
       "      <td>-0.769567</td>\n",
       "      <td>1.891188</td>\n",
       "      <td>-0.642579</td>\n",
       "      <td>1.369863</td>\n",
       "      <td>-0.176916</td>\n",
       "      <td>1.965529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4228</th>\n",
       "      <td>10</td>\n",
       "      <td>2017</td>\n",
       "      <td>Jimmy Butler</td>\n",
       "      <td>7.194467</td>\n",
       "      <td>1.641355</td>\n",
       "      <td>0.079468</td>\n",
       "      <td>0.999632</td>\n",
       "      <td>-0.340241</td>\n",
       "      <td>2.622318</td>\n",
       "      <td>-0.145900</td>\n",
       "      <td>-0.139308</td>\n",
       "      <td>0.324360</td>\n",
       "      <td>2.152782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4229</th>\n",
       "      <td>11</td>\n",
       "      <td>2017</td>\n",
       "      <td>Victor Oladipo</td>\n",
       "      <td>6.742591</td>\n",
       "      <td>1.807176</td>\n",
       "      <td>0.040703</td>\n",
       "      <td>0.694323</td>\n",
       "      <td>0.518411</td>\n",
       "      <td>3.597157</td>\n",
       "      <td>-1.511767</td>\n",
       "      <td>0.905503</td>\n",
       "      <td>0.389094</td>\n",
       "      <td>0.301991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4230</th>\n",
       "      <td>12</td>\n",
       "      <td>2017</td>\n",
       "      <td>DeMarcus Cousins</td>\n",
       "      <td>6.513379</td>\n",
       "      <td>2.194092</td>\n",
       "      <td>3.025615</td>\n",
       "      <td>1.254056</td>\n",
       "      <td>2.235716</td>\n",
       "      <td>1.647478</td>\n",
       "      <td>-4.119333</td>\n",
       "      <td>1.021593</td>\n",
       "      <td>0.301785</td>\n",
       "      <td>-1.047624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4231</th>\n",
       "      <td>13</td>\n",
       "      <td>2017</td>\n",
       "      <td>Nikola Jokic</td>\n",
       "      <td>6.424866</td>\n",
       "      <td>0.959645</td>\n",
       "      <td>2.172783</td>\n",
       "      <td>1.610250</td>\n",
       "      <td>0.518411</td>\n",
       "      <td>0.672639</td>\n",
       "      <td>-1.387598</td>\n",
       "      <td>0.208962</td>\n",
       "      <td>0.838766</td>\n",
       "      <td>0.831007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4232</th>\n",
       "      <td>14</td>\n",
       "      <td>2017</td>\n",
       "      <td>Kyrie Irving</td>\n",
       "      <td>6.159878</td>\n",
       "      <td>2.046696</td>\n",
       "      <td>-0.502008</td>\n",
       "      <td>1.101402</td>\n",
       "      <td>-0.554904</td>\n",
       "      <td>0.428929</td>\n",
       "      <td>-0.766749</td>\n",
       "      <td>1.718133</td>\n",
       "      <td>0.968233</td>\n",
       "      <td>1.720144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4233</th>\n",
       "      <td>15</td>\n",
       "      <td>2017</td>\n",
       "      <td>Andre Ingram</td>\n",
       "      <td>5.581832</td>\n",
       "      <td>-0.237954</td>\n",
       "      <td>-0.812129</td>\n",
       "      <td>0.287245</td>\n",
       "      <td>2.021053</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>0.226610</td>\n",
       "      <td>1.369863</td>\n",
       "      <td>0.116338</td>\n",
       "      <td>1.207037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4234</th>\n",
       "      <td>16</td>\n",
       "      <td>2017</td>\n",
       "      <td>LaMarcus Aldridge</td>\n",
       "      <td>5.370052</td>\n",
       "      <td>1.807176</td>\n",
       "      <td>1.319951</td>\n",
       "      <td>-0.476027</td>\n",
       "      <td>1.377064</td>\n",
       "      <td>-0.789620</td>\n",
       "      <td>0.226610</td>\n",
       "      <td>-1.068029</td>\n",
       "      <td>1.620860</td>\n",
       "      <td>1.352068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4235</th>\n",
       "      <td>17</td>\n",
       "      <td>2017</td>\n",
       "      <td>MarShon Brooks</td>\n",
       "      <td>5.131062</td>\n",
       "      <td>1.254438</td>\n",
       "      <td>-0.812129</td>\n",
       "      <td>0.338130</td>\n",
       "      <td>-0.340241</td>\n",
       "      <td>1.647478</td>\n",
       "      <td>-0.766749</td>\n",
       "      <td>1.602043</td>\n",
       "      <td>1.009007</td>\n",
       "      <td>1.199083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4236</th>\n",
       "      <td>18</td>\n",
       "      <td>2017</td>\n",
       "      <td>Paul George</td>\n",
       "      <td>5.126899</td>\n",
       "      <td>1.586081</td>\n",
       "      <td>0.234529</td>\n",
       "      <td>0.185475</td>\n",
       "      <td>-0.125578</td>\n",
       "      <td>2.622318</td>\n",
       "      <td>-1.263428</td>\n",
       "      <td>2.066403</td>\n",
       "      <td>-1.086400</td>\n",
       "      <td>0.907499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4237</th>\n",
       "      <td>19</td>\n",
       "      <td>2017</td>\n",
       "      <td>Kristaps Porzingis</td>\n",
       "      <td>4.816889</td>\n",
       "      <td>1.733478</td>\n",
       "      <td>0.583415</td>\n",
       "      <td>-0.883106</td>\n",
       "      <td>3.953020</td>\n",
       "      <td>-0.302200</td>\n",
       "      <td>-0.270069</td>\n",
       "      <td>0.673322</td>\n",
       "      <td>-0.888515</td>\n",
       "      <td>0.217545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4238</th>\n",
       "      <td>20</td>\n",
       "      <td>2017</td>\n",
       "      <td>Jrue Holiday</td>\n",
       "      <td>4.397228</td>\n",
       "      <td>1.051768</td>\n",
       "      <td>-0.230652</td>\n",
       "      <td>1.559365</td>\n",
       "      <td>0.518411</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>-1.139258</td>\n",
       "      <td>0.208962</td>\n",
       "      <td>0.875856</td>\n",
       "      <td>0.149007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4239</th>\n",
       "      <td>21</td>\n",
       "      <td>2017</td>\n",
       "      <td>Khris Middleton</td>\n",
       "      <td>4.231094</td>\n",
       "      <td>1.254438</td>\n",
       "      <td>0.040703</td>\n",
       "      <td>0.541669</td>\n",
       "      <td>-0.554904</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>-0.766749</td>\n",
       "      <td>0.557232</td>\n",
       "      <td>0.034790</td>\n",
       "      <td>1.720144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4240</th>\n",
       "      <td>22</td>\n",
       "      <td>2017</td>\n",
       "      <td>Nikola Vucevic</td>\n",
       "      <td>4.156660</td>\n",
       "      <td>0.591153</td>\n",
       "      <td>1.591307</td>\n",
       "      <td>0.236360</td>\n",
       "      <td>1.162400</td>\n",
       "      <td>0.185219</td>\n",
       "      <td>-0.270069</td>\n",
       "      <td>-0.255398</td>\n",
       "      <td>0.356381</td>\n",
       "      <td>0.559307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4241</th>\n",
       "      <td>23</td>\n",
       "      <td>2017</td>\n",
       "      <td>Kyle Lowry</td>\n",
       "      <td>4.141570</td>\n",
       "      <td>0.535879</td>\n",
       "      <td>0.195764</td>\n",
       "      <td>2.017329</td>\n",
       "      <td>-0.769567</td>\n",
       "      <td>0.428929</td>\n",
       "      <td>-0.766749</td>\n",
       "      <td>2.066403</td>\n",
       "      <td>-0.765502</td>\n",
       "      <td>1.199083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4242</th>\n",
       "      <td>24</td>\n",
       "      <td>2017</td>\n",
       "      <td>Otto Porter</td>\n",
       "      <td>4.136911</td>\n",
       "      <td>0.259510</td>\n",
       "      <td>0.505884</td>\n",
       "      <td>-0.476027</td>\n",
       "      <td>-0.125578</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>0.847459</td>\n",
       "      <td>0.557232</td>\n",
       "      <td>0.888985</td>\n",
       "      <td>0.275676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4243</th>\n",
       "      <td>25</td>\n",
       "      <td>2017</td>\n",
       "      <td>Kawhi Leonard</td>\n",
       "      <td>4.001655</td>\n",
       "      <td>0.535879</td>\n",
       "      <td>-0.153122</td>\n",
       "      <td>-0.323373</td>\n",
       "      <td>0.947737</td>\n",
       "      <td>2.622318</td>\n",
       "      <td>-0.145900</td>\n",
       "      <td>-0.139308</td>\n",
       "      <td>0.190517</td>\n",
       "      <td>0.466907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4244</th>\n",
       "      <td>26</td>\n",
       "      <td>2017</td>\n",
       "      <td>Kevin Love</td>\n",
       "      <td>3.988737</td>\n",
       "      <td>0.793824</td>\n",
       "      <td>1.630072</td>\n",
       "      <td>-0.628682</td>\n",
       "      <td>-0.340241</td>\n",
       "      <td>-0.545910</td>\n",
       "      <td>0.226610</td>\n",
       "      <td>1.137683</td>\n",
       "      <td>-0.085231</td>\n",
       "      <td>1.800614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4245</th>\n",
       "      <td>27</td>\n",
       "      <td>2017</td>\n",
       "      <td>Andre Drummond</td>\n",
       "      <td>3.805188</td>\n",
       "      <td>0.314784</td>\n",
       "      <td>4.227332</td>\n",
       "      <td>0.032821</td>\n",
       "      <td>2.235716</td>\n",
       "      <td>1.403769</td>\n",
       "      <td>-1.139258</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>1.440481</td>\n",
       "      <td>-3.178068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4246</th>\n",
       "      <td>28</td>\n",
       "      <td>2017</td>\n",
       "      <td>Russell Westbrook</td>\n",
       "      <td>3.763264</td>\n",
       "      <td>2.230942</td>\n",
       "      <td>1.940192</td>\n",
       "      <td>3.747412</td>\n",
       "      <td>-0.554904</td>\n",
       "      <td>2.134898</td>\n",
       "      <td>-3.870994</td>\n",
       "      <td>-0.139308</td>\n",
       "      <td>-0.520390</td>\n",
       "      <td>-1.204585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4247</th>\n",
       "      <td>29</td>\n",
       "      <td>2017</td>\n",
       "      <td>Kemba Walker</td>\n",
       "      <td>3.725170</td>\n",
       "      <td>1.622930</td>\n",
       "      <td>-0.773363</td>\n",
       "      <td>1.355826</td>\n",
       "      <td>-0.554904</td>\n",
       "      <td>0.428929</td>\n",
       "      <td>-0.642579</td>\n",
       "      <td>1.834223</td>\n",
       "      <td>-0.897960</td>\n",
       "      <td>1.352068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4248</th>\n",
       "      <td>30</td>\n",
       "      <td>2017</td>\n",
       "      <td>Eric Bledsoe</td>\n",
       "      <td>3.653643</td>\n",
       "      <td>0.830673</td>\n",
       "      <td>-0.463243</td>\n",
       "      <td>1.101402</td>\n",
       "      <td>0.089085</td>\n",
       "      <td>2.622318</td>\n",
       "      <td>-1.511767</td>\n",
       "      <td>0.441142</td>\n",
       "      <td>0.360757</td>\n",
       "      <td>0.183276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4729</th>\n",
       "      <td>511</td>\n",
       "      <td>2017</td>\n",
       "      <td>Darrun Hilliard</td>\n",
       "      <td>-8.567256</td>\n",
       "      <td>-2.246234</td>\n",
       "      <td>-1.781256</td>\n",
       "      <td>-1.086645</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.008169</td>\n",
       "      <td>1.716648</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.468564</td>\n",
       "      <td>0.038246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4730</th>\n",
       "      <td>512</td>\n",
       "      <td>2017</td>\n",
       "      <td>Tim Quarterman</td>\n",
       "      <td>-8.645561</td>\n",
       "      <td>-2.209385</td>\n",
       "      <td>-1.587430</td>\n",
       "      <td>-1.341069</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>1.219968</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.307768</td>\n",
       "      <td>0.563284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4731</th>\n",
       "      <td>513</td>\n",
       "      <td>2017</td>\n",
       "      <td>Demetrius Jackson</td>\n",
       "      <td>-8.660268</td>\n",
       "      <td>-2.319932</td>\n",
       "      <td>-1.626195</td>\n",
       "      <td>-1.290185</td>\n",
       "      <td>-0.984230</td>\n",
       "      <td>-1.520749</td>\n",
       "      <td>1.095798</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.482386</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4732</th>\n",
       "      <td>514</td>\n",
       "      <td>2017</td>\n",
       "      <td>Markel Brown</td>\n",
       "      <td>-8.715761</td>\n",
       "      <td>-2.209385</td>\n",
       "      <td>-1.471135</td>\n",
       "      <td>-1.239300</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>1.468308</td>\n",
       "      <td>-1.184119</td>\n",
       "      <td>-0.629359</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4733</th>\n",
       "      <td>515</td>\n",
       "      <td>2017</td>\n",
       "      <td>Josh Smith</td>\n",
       "      <td>-8.748490</td>\n",
       "      <td>-2.319932</td>\n",
       "      <td>-1.471135</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.569694</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4734</th>\n",
       "      <td>516</td>\n",
       "      <td>2017</td>\n",
       "      <td>Erik McCree</td>\n",
       "      <td>-8.773341</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.858786</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-1.520749</td>\n",
       "      <td>1.716648</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.436543</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4735</th>\n",
       "      <td>517</td>\n",
       "      <td>2017</td>\n",
       "      <td>Xavier Munford</td>\n",
       "      <td>-8.789856</td>\n",
       "      <td>-2.356782</td>\n",
       "      <td>-1.897551</td>\n",
       "      <td>-1.137530</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-1.764459</td>\n",
       "      <td>1.716648</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.496208</td>\n",
       "      <td>-0.122692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4736</th>\n",
       "      <td>518</td>\n",
       "      <td>2017</td>\n",
       "      <td>Tyler Lydon</td>\n",
       "      <td>-8.811713</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.975081</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4737</th>\n",
       "      <td>519</td>\n",
       "      <td>2017</td>\n",
       "      <td>Trey McKinney-Jones</td>\n",
       "      <td>-8.811713</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.975081</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4738</th>\n",
       "      <td>520</td>\n",
       "      <td>2017</td>\n",
       "      <td>Xavier Rathan-Mayes</td>\n",
       "      <td>-8.814577</td>\n",
       "      <td>-1.380278</td>\n",
       "      <td>-1.587430</td>\n",
       "      <td>0.338130</td>\n",
       "      <td>0.089085</td>\n",
       "      <td>0.672639</td>\n",
       "      <td>-0.642579</td>\n",
       "      <td>-1.300209</td>\n",
       "      <td>-2.811382</td>\n",
       "      <td>-2.192553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4739</th>\n",
       "      <td>521</td>\n",
       "      <td>2017</td>\n",
       "      <td>Matt Williams</td>\n",
       "      <td>-8.833537</td>\n",
       "      <td>-2.135687</td>\n",
       "      <td>-1.858786</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>1.716648</td>\n",
       "      <td>-1.184119</td>\n",
       "      <td>-0.427098</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4740</th>\n",
       "      <td>522</td>\n",
       "      <td>2017</td>\n",
       "      <td>Cole Aldrich</td>\n",
       "      <td>-8.856290</td>\n",
       "      <td>-2.338357</td>\n",
       "      <td>-1.703725</td>\n",
       "      <td>-1.442839</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.008169</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.234282</td>\n",
       "      <td>-0.486792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4741</th>\n",
       "      <td>523</td>\n",
       "      <td>2017</td>\n",
       "      <td>Nicolas Brussino</td>\n",
       "      <td>-8.938136</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.664960</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.436543</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4742</th>\n",
       "      <td>524</td>\n",
       "      <td>2017</td>\n",
       "      <td>PJ Dozier</td>\n",
       "      <td>-8.985381</td>\n",
       "      <td>-2.264659</td>\n",
       "      <td>-1.781256</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>1.468308</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>0.069110</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4743</th>\n",
       "      <td>525</td>\n",
       "      <td>2017</td>\n",
       "      <td>Omer Asik</td>\n",
       "      <td>-9.030298</td>\n",
       "      <td>-2.209385</td>\n",
       "      <td>-0.967189</td>\n",
       "      <td>-1.442839</td>\n",
       "      <td>-0.984230</td>\n",
       "      <td>-2.008169</td>\n",
       "      <td>1.592478</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.018199</td>\n",
       "      <td>-1.460376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4744</th>\n",
       "      <td>526</td>\n",
       "      <td>2017</td>\n",
       "      <td>London Perrantes</td>\n",
       "      <td>-9.069214</td>\n",
       "      <td>-2.356782</td>\n",
       "      <td>-1.858786</td>\n",
       "      <td>-1.290185</td>\n",
       "      <td>-0.984230</td>\n",
       "      <td>-2.008169</td>\n",
       "      <td>1.964987</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.597338</td>\n",
       "      <td>-0.406323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4745</th>\n",
       "      <td>527</td>\n",
       "      <td>2017</td>\n",
       "      <td>Jacob Pullen</td>\n",
       "      <td>-9.101093</td>\n",
       "      <td>-2.319932</td>\n",
       "      <td>-1.975081</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>1.716648</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.045843</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4746</th>\n",
       "      <td>528</td>\n",
       "      <td>2017</td>\n",
       "      <td>Charles Cooke</td>\n",
       "      <td>-9.142223</td>\n",
       "      <td>-2.356782</td>\n",
       "      <td>-1.897551</td>\n",
       "      <td>-1.442839</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.008169</td>\n",
       "      <td>1.964987</td>\n",
       "      <td>-1.416299</td>\n",
       "      <td>-0.583516</td>\n",
       "      <td>-0.203161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4747</th>\n",
       "      <td>529</td>\n",
       "      <td>2017</td>\n",
       "      <td>Nate Wolters</td>\n",
       "      <td>-9.152010</td>\n",
       "      <td>-2.375206</td>\n",
       "      <td>-1.820021</td>\n",
       "      <td>-1.391954</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.670825</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4748</th>\n",
       "      <td>530</td>\n",
       "      <td>2017</td>\n",
       "      <td>Derrick Williams</td>\n",
       "      <td>-9.237618</td>\n",
       "      <td>-2.264659</td>\n",
       "      <td>-1.781256</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.803976</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4749</th>\n",
       "      <td>531</td>\n",
       "      <td>2017</td>\n",
       "      <td>Josh McRoberts</td>\n",
       "      <td>-9.248257</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.975081</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.436543</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4750</th>\n",
       "      <td>532</td>\n",
       "      <td>2017</td>\n",
       "      <td>Nick Collison</td>\n",
       "      <td>-9.288480</td>\n",
       "      <td>-2.061988</td>\n",
       "      <td>-1.471135</td>\n",
       "      <td>-1.341069</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>1.468308</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>0.560941</td>\n",
       "      <td>-1.460376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4751</th>\n",
       "      <td>533</td>\n",
       "      <td>2017</td>\n",
       "      <td>Chris Boucher</td>\n",
       "      <td>-9.297149</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.587430</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.873086</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4752</th>\n",
       "      <td>534</td>\n",
       "      <td>2017</td>\n",
       "      <td>Kyle Singler</td>\n",
       "      <td>-9.322633</td>\n",
       "      <td>-2.098837</td>\n",
       "      <td>-1.664960</td>\n",
       "      <td>-1.391954</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.008169</td>\n",
       "      <td>1.716648</td>\n",
       "      <td>-1.300209</td>\n",
       "      <td>-0.440920</td>\n",
       "      <td>-0.935338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4753</th>\n",
       "      <td>535</td>\n",
       "      <td>2017</td>\n",
       "      <td>Vander Blue</td>\n",
       "      <td>-9.478457</td>\n",
       "      <td>-2.338357</td>\n",
       "      <td>-1.897551</td>\n",
       "      <td>-1.188415</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-1.764459</td>\n",
       "      <td>1.344138</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.496208</td>\n",
       "      <td>-0.406323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4754</th>\n",
       "      <td>536</td>\n",
       "      <td>2017</td>\n",
       "      <td>Aaron Jackson</td>\n",
       "      <td>-9.982955</td>\n",
       "      <td>-0.974937</td>\n",
       "      <td>-0.812129</td>\n",
       "      <td>-0.984876</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>0.847459</td>\n",
       "      <td>-0.371488</td>\n",
       "      <td>-2.204598</td>\n",
       "      <td>-2.031614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4755</th>\n",
       "      <td>537</td>\n",
       "      <td>2017</td>\n",
       "      <td>Luis Montero</td>\n",
       "      <td>-10.102304</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.587430</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>0.847459</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.436543</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4756</th>\n",
       "      <td>538</td>\n",
       "      <td>2017</td>\n",
       "      <td>Chinanu Onuaku</td>\n",
       "      <td>-10.337018</td>\n",
       "      <td>-1.711921</td>\n",
       "      <td>-0.424478</td>\n",
       "      <td>-0.984876</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>-1.635937</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.596646</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4757</th>\n",
       "      <td>539</td>\n",
       "      <td>2017</td>\n",
       "      <td>Mindaugas Kuzminskas</td>\n",
       "      <td>-10.557886</td>\n",
       "      <td>-2.448905</td>\n",
       "      <td>-1.975081</td>\n",
       "      <td>-1.493724</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>2.089157</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-1.746172</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4758</th>\n",
       "      <td>540</td>\n",
       "      <td>2017</td>\n",
       "      <td>Scotty Hopson</td>\n",
       "      <td>-12.265018</td>\n",
       "      <td>-2.264659</td>\n",
       "      <td>-1.975081</td>\n",
       "      <td>-0.984876</td>\n",
       "      <td>-1.198893</td>\n",
       "      <td>-2.251879</td>\n",
       "      <td>0.847459</td>\n",
       "      <td>-1.532389</td>\n",
       "      <td>-0.873086</td>\n",
       "      <td>-2.031614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      playerrank  season                 player  value_tot  value_points  \\\n",
       "4219           1    2017          Anthony Davis  13.069292      2.728406   \n",
       "4220           2    2017          Stephen Curry  10.977767      2.415188   \n",
       "4221           3    2017           Kevin Durant  10.555627      2.415188   \n",
       "4222           4    2017           James Harden  10.522310      3.152171   \n",
       "4223           5    2017     Karl-Anthony Towns   9.046572      1.475533   \n",
       "4224           6    2017           LeBron James   8.050018      2.617858   \n",
       "4225           7    2017  Giannis Antetokounmpo   7.982516      2.507311   \n",
       "4226           8    2017         Damian Lillard   7.758411      2.507311   \n",
       "4227           9    2017             Chris Paul   7.259998      0.978069   \n",
       "4228          10    2017           Jimmy Butler   7.194467      1.641355   \n",
       "4229          11    2017         Victor Oladipo   6.742591      1.807176   \n",
       "4230          12    2017       DeMarcus Cousins   6.513379      2.194092   \n",
       "4231          13    2017           Nikola Jokic   6.424866      0.959645   \n",
       "4232          14    2017           Kyrie Irving   6.159878      2.046696   \n",
       "4233          15    2017           Andre Ingram   5.581832     -0.237954   \n",
       "4234          16    2017      LaMarcus Aldridge   5.370052      1.807176   \n",
       "4235          17    2017         MarShon Brooks   5.131062      1.254438   \n",
       "4236          18    2017            Paul George   5.126899      1.586081   \n",
       "4237          19    2017     Kristaps Porzingis   4.816889      1.733478   \n",
       "4238          20    2017           Jrue Holiday   4.397228      1.051768   \n",
       "4239          21    2017        Khris Middleton   4.231094      1.254438   \n",
       "4240          22    2017         Nikola Vucevic   4.156660      0.591153   \n",
       "4241          23    2017             Kyle Lowry   4.141570      0.535879   \n",
       "4242          24    2017            Otto Porter   4.136911      0.259510   \n",
       "4243          25    2017          Kawhi Leonard   4.001655      0.535879   \n",
       "4244          26    2017             Kevin Love   3.988737      0.793824   \n",
       "4245          27    2017         Andre Drummond   3.805188      0.314784   \n",
       "4246          28    2017      Russell Westbrook   3.763264      2.230942   \n",
       "4247          29    2017           Kemba Walker   3.725170      1.622930   \n",
       "4248          30    2017           Eric Bledsoe   3.653643      0.830673   \n",
       "...          ...     ...                    ...        ...           ...   \n",
       "4729         511    2017        Darrun Hilliard  -8.567256     -2.246234   \n",
       "4730         512    2017         Tim Quarterman  -8.645561     -2.209385   \n",
       "4731         513    2017      Demetrius Jackson  -8.660268     -2.319932   \n",
       "4732         514    2017           Markel Brown  -8.715761     -2.209385   \n",
       "4733         515    2017             Josh Smith  -8.748490     -2.319932   \n",
       "4734         516    2017            Erik McCree  -8.773341     -2.448905   \n",
       "4735         517    2017         Xavier Munford  -8.789856     -2.356782   \n",
       "4736         518    2017            Tyler Lydon  -8.811713     -2.448905   \n",
       "4737         519    2017    Trey McKinney-Jones  -8.811713     -2.448905   \n",
       "4738         520    2017    Xavier Rathan-Mayes  -8.814577     -1.380278   \n",
       "4739         521    2017          Matt Williams  -8.833537     -2.135687   \n",
       "4740         522    2017           Cole Aldrich  -8.856290     -2.338357   \n",
       "4741         523    2017       Nicolas Brussino  -8.938136     -2.448905   \n",
       "4742         524    2017              PJ Dozier  -8.985381     -2.264659   \n",
       "4743         525    2017              Omer Asik  -9.030298     -2.209385   \n",
       "4744         526    2017       London Perrantes  -9.069214     -2.356782   \n",
       "4745         527    2017           Jacob Pullen  -9.101093     -2.319932   \n",
       "4746         528    2017          Charles Cooke  -9.142223     -2.356782   \n",
       "4747         529    2017           Nate Wolters  -9.152010     -2.375206   \n",
       "4748         530    2017       Derrick Williams  -9.237618     -2.264659   \n",
       "4749         531    2017         Josh McRoberts  -9.248257     -2.448905   \n",
       "4750         532    2017          Nick Collison  -9.288480     -2.061988   \n",
       "4751         533    2017          Chris Boucher  -9.297149     -2.448905   \n",
       "4752         534    2017           Kyle Singler  -9.322633     -2.098837   \n",
       "4753         535    2017            Vander Blue  -9.478457     -2.338357   \n",
       "4754         536    2017          Aaron Jackson  -9.982955     -0.974937   \n",
       "4755         537    2017           Luis Montero -10.102304     -2.448905   \n",
       "4756         538    2017         Chinanu Onuaku -10.337018     -1.711921   \n",
       "4757         539    2017   Mindaugas Kuzminskas -10.557886     -2.448905   \n",
       "4758         540    2017          Scotty Hopson -12.265018     -2.264659   \n",
       "\n",
       "      value_rebounds  value_assists  value_blocks  value_steals  \\\n",
       "4219        2.327843      -0.323373      4.382346      1.403769   \n",
       "4220        0.001938       1.610250     -0.769567      1.647478   \n",
       "4221        0.660945       1.254056      2.665042     -0.545910   \n",
       "4222        0.118234       2.984140      0.303748      2.134898   \n",
       "4223        2.793024      -0.272488      1.806390     -0.302200   \n",
       "4224        1.358716       3.136795      0.733074      1.160059   \n",
       "4225        1.901427       0.948747      1.806390      1.403769   \n",
       "4226       -0.230652       1.864674     -0.340241      0.428929   \n",
       "4227        0.118234       2.526177     -0.769567      1.891188   \n",
       "4228        0.079468       0.999632     -0.340241      2.622318   \n",
       "4229        0.040703       0.694323      0.518411      3.597157   \n",
       "4230        3.025615       1.254056      2.235716      1.647478   \n",
       "4231        2.172783       1.610250      0.518411      0.672639   \n",
       "4232       -0.502008       1.101402     -0.554904      0.428929   \n",
       "4233       -0.812129       0.287245      2.021053      1.403769   \n",
       "4234        1.319951      -0.476027      1.377064     -0.789620   \n",
       "4235       -0.812129       0.338130     -0.340241      1.647478   \n",
       "4236        0.234529       0.185475     -0.125578      2.622318   \n",
       "4237        0.583415      -0.883106      3.953020     -0.302200   \n",
       "4238       -0.230652       1.559365      0.518411      1.403769   \n",
       "4239        0.040703       0.541669     -0.554904      1.403769   \n",
       "4240        1.591307       0.236360      1.162400      0.185219   \n",
       "4241        0.195764       2.017329     -0.769567      0.428929   \n",
       "4242        0.505884      -0.476027     -0.125578      1.403769   \n",
       "4243       -0.153122      -0.323373      0.947737      2.622318   \n",
       "4244        1.630072      -0.628682     -0.340241     -0.545910   \n",
       "4245        4.227332       0.032821      2.235716      1.403769   \n",
       "4246        1.940192       3.747412     -0.554904      2.134898   \n",
       "4247       -0.773363       1.355826     -0.554904      0.428929   \n",
       "4248       -0.463243       1.101402      0.089085      2.622318   \n",
       "...              ...            ...           ...           ...   \n",
       "4729       -1.781256      -1.086645     -1.198893     -2.008169   \n",
       "4730       -1.587430      -1.341069     -1.198893     -2.251879   \n",
       "4731       -1.626195      -1.290185     -0.984230     -1.520749   \n",
       "4732       -1.471135      -1.239300     -1.198893     -2.251879   \n",
       "4733       -1.471135      -1.493724     -1.198893     -2.251879   \n",
       "4734       -1.858786      -1.493724     -1.198893     -1.520749   \n",
       "4735       -1.897551      -1.137530     -1.198893     -1.764459   \n",
       "4736       -1.975081      -1.493724     -1.198893     -2.251879   \n",
       "4737       -1.975081      -1.493724     -1.198893     -2.251879   \n",
       "4738       -1.587430       0.338130      0.089085      0.672639   \n",
       "4739       -1.858786      -1.493724     -1.198893     -2.251879   \n",
       "4740       -1.703725      -1.442839     -1.198893     -2.008169   \n",
       "4741       -1.664960      -1.493724     -1.198893     -2.251879   \n",
       "4742       -1.781256      -1.493724     -1.198893     -2.251879   \n",
       "4743       -0.967189      -1.442839     -0.984230     -2.008169   \n",
       "4744       -1.858786      -1.290185     -0.984230     -2.008169   \n",
       "4745       -1.975081      -1.493724     -1.198893     -2.251879   \n",
       "4746       -1.897551      -1.442839     -1.198893     -2.008169   \n",
       "4747       -1.820021      -1.391954     -1.198893     -2.251879   \n",
       "4748       -1.781256      -1.493724     -1.198893     -2.251879   \n",
       "4749       -1.975081      -1.493724     -1.198893     -2.251879   \n",
       "4750       -1.471135      -1.341069     -1.198893     -2.251879   \n",
       "4751       -1.587430      -1.493724     -1.198893     -2.251879   \n",
       "4752       -1.664960      -1.391954     -1.198893     -2.008169   \n",
       "4753       -1.897551      -1.188415     -1.198893     -1.764459   \n",
       "4754       -0.812129      -0.984876     -1.198893     -2.251879   \n",
       "4755       -1.587430      -1.493724     -1.198893     -2.251879   \n",
       "4756       -0.424478      -0.984876     -1.198893     -2.251879   \n",
       "4757       -1.975081      -1.493724     -1.198893     -2.251879   \n",
       "4758       -1.975081      -0.984876     -1.198893     -2.251879   \n",
       "\n",
       "      value_turnovers  value_threes  value_fg  value_ft  \n",
       "4219        -0.642579     -0.719758  2.572502  1.340136  \n",
       "4220        -1.635937      3.343394  1.073741  3.291282  \n",
       "4221        -1.635937      1.369863  1.809299  2.563082  \n",
       "4222        -3.374314      2.762944 -0.589500  3.029989  \n",
       "4223        -0.270069      0.208962  2.213129  1.394291  \n",
       "4224        -3.125975      0.557232  2.935558 -1.323300  \n",
       "4225        -1.635937     -0.835849  2.328774 -0.442116  \n",
       "4226        -1.387598      2.066403 -0.920536  3.770119  \n",
       "4227        -0.642579      1.369863 -0.176916  1.965529  \n",
       "4228        -0.145900     -0.139308  0.324360  2.152782  \n",
       "4229        -1.511767      0.905503  0.389094  0.301991  \n",
       "4230        -4.119333      1.021593  0.301785 -1.047624  \n",
       "4231        -1.387598      0.208962  0.838766  0.831007  \n",
       "4232        -0.766749      1.718133  0.968233  1.720144  \n",
       "4233         0.226610      1.369863  0.116338  1.207037  \n",
       "4234         0.226610     -1.068029  1.620860  1.352068  \n",
       "4235        -0.766749      1.602043  1.009007  1.199083  \n",
       "4236        -1.263428      2.066403 -1.086400  0.907499  \n",
       "4237        -0.270069      0.673322 -0.888515  0.217545  \n",
       "4238        -1.139258      0.208962  0.875856  0.149007  \n",
       "4239        -0.766749      0.557232  0.034790  1.720144  \n",
       "4240        -0.270069     -0.255398  0.356381  0.559307  \n",
       "4241        -0.766749      2.066403 -0.765502  1.199083  \n",
       "4242         0.847459      0.557232  0.888985  0.275676  \n",
       "4243        -0.145900     -0.139308  0.190517  0.466907  \n",
       "4244         0.226610      1.137683 -0.085231  1.800614  \n",
       "4245        -1.139258     -1.532389  1.440481 -3.178068  \n",
       "4246        -3.870994     -0.139308 -0.520390 -1.204585  \n",
       "4247        -0.642579      1.834223 -0.897960  1.352068  \n",
       "4248        -1.511767      0.441142  0.360757  0.183276  \n",
       "...               ...           ...       ...       ...  \n",
       "4729         1.716648     -1.532389 -0.468564  0.038246  \n",
       "4730         1.219968     -1.532389 -0.307768  0.563284  \n",
       "4731         1.095798     -1.532389 -0.482386  0.000000  \n",
       "4732         1.468308     -1.184119 -0.629359  0.000000  \n",
       "4733         2.089157     -1.532389 -0.569694  0.000000  \n",
       "4734         1.716648     -1.532389 -0.436543  0.000000  \n",
       "4735         1.716648     -1.532389 -0.496208 -0.122692  \n",
       "4736         2.089157     -1.532389  0.000000  0.000000  \n",
       "4737         2.089157     -1.532389  0.000000  0.000000  \n",
       "4738        -0.642579     -1.300209 -2.811382 -2.192553  \n",
       "4739         1.716648     -1.184119 -0.427098  0.000000  \n",
       "4740         2.089157     -1.532389 -0.234282 -0.486792  \n",
       "4741         2.089157     -1.532389 -0.436543  0.000000  \n",
       "4742         1.468308     -1.532389  0.069110  0.000000  \n",
       "4743         1.592478     -1.532389 -0.018199 -1.460376  \n",
       "4744         1.964987     -1.532389 -0.597338 -0.406323  \n",
       "4745         1.716648     -1.532389 -0.045843  0.000000  \n",
       "4746         1.964987     -1.416299 -0.583516 -0.203161  \n",
       "4747         2.089157     -1.532389 -0.670825  0.000000  \n",
       "4748         2.089157     -1.532389 -0.803976  0.000000  \n",
       "4749         2.089157     -1.532389 -0.436543  0.000000  \n",
       "4750         1.468308     -1.532389  0.560941 -1.460376  \n",
       "4751         2.089157     -1.532389 -0.873086  0.000000  \n",
       "4752         1.716648     -1.300209 -0.440920 -0.935338  \n",
       "4753         1.344138     -1.532389 -0.496208 -0.406323  \n",
       "4754         0.847459     -0.371488 -2.204598 -2.031614  \n",
       "4755         0.847459     -1.532389 -0.436543  0.000000  \n",
       "4756        -1.635937     -1.532389 -0.596646  0.000000  \n",
       "4757         2.089157     -1.532389 -1.746172  0.000000  \n",
       "4758         0.847459     -1.532389 -0.873086 -2.031614  \n",
       "\n",
       "[540 rows x 13 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2[df_2['season']==2017].sort_values(by='playerrank', ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Creating all teammate based changes\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "query = '''\n",
    "        DROP TABLE IF EXISTS adv_top10min;\n",
    "        CREATE TEMPORARY TABLE adv_top10min as \n",
    "        select a.*,usage_percentage*total_MP/G as usage_withMins,row_number() over(partition by a.season,tm order by usage_percentage*total_MP/G desc) as usage_rank\n",
    "        from(select *,row_number() over(partition by season,tm order by total_MP desc) as min_rank from nba_advanced) a\n",
    "        inner join y_predictions y\n",
    "                ON a.player = y.player\n",
    "                and a.season = y.season\n",
    "                and a.Tm=y.startingTeam\n",
    "        where min_rank<=10;\n",
    "        \n",
    "        DROP TABLE IF EXISTS Change_Teams;\n",
    "        CREATE TABLE Change_Teams AS\n",
    "        select na.tm as old_team,na2.tm as new_team,na2.player,na2.pos,p.season,na.usage_withMins,\n",
    "        n.points,n.rebounds,n.ast,n.threes_made,na.usage_rank \n",
    "        from player_value p\n",
    "        inner join adv_top10min na\n",
    "            on p.player = na.player\n",
    "            and p.season = na.season+1\n",
    "        inner join adv_top10min na2\n",
    "            on na2.player = na.player\n",
    "            and na2.season = p.season\n",
    "            and na2.tm != na.tm\n",
    "        inner join rank_by_minutes n\n",
    "            ON N.player = na.player\n",
    "            and n.season = na.season;\n",
    "        \n",
    "        \n",
    "        \n",
    "        DROP TABLE IF EXISTS incoming_by_team;\n",
    "        CREATE TABLE incoming_by_team AS\n",
    "        select new_team,season,SUM(case when usage_withmins >1000 then 1 else 0 end) as high_usageplayer_added,\n",
    "        SUM(usage_withmins) as usagemin_added, MAX(usage_withmins) as max_usageadded,\n",
    "        SUM(points) as points_added, MAX(points) as max_pointsadded,SUM(rebounds) as rebounds_added,\n",
    "        MAX(rebounds) as max_reboundsadded, SUM(ast) as ast_added, MAX(ast) as max_astadded,\n",
    "        SUM(threes_made) as threes_added, MAX(threes_made) as max_threesadded \n",
    "        from change_teams\n",
    "        group by new_team,season;\n",
    "        \n",
    "        DROP TABLE IF EXISTS outgoing_by_team;\n",
    "        CREATE TABLE outgoing_by_team AS\n",
    "        select old_team,season,SUM(case when usage_withmins >1000 then 1 else 0 end) as high_usageplayer_dropped,\n",
    "        SUM(usage_withmins) as usagemin_dropped, MAX(usage_withmins) as max_usagedropped,\n",
    "        SUM(points) as points_dropped, MAX(points) as max_pointsdropped,SUM(rebounds) as rebounds_dropped,\n",
    "        MAX(rebounds) as max_reboundsdropped, SUM(ast) as ast_dropped, MAX(ast) as max_astdropped,\n",
    "        SUM(threes_made) as threes_dropped, MAX(threes_made) as max_threesdropped\n",
    "        from change_teams\n",
    "        group by old_team,season;\n",
    "        \n",
    "        DROP TABLE IF EXISTS Team_Changes;\n",
    "        CREATE TABLE Team_Changes AS\n",
    "        select c.new_team as team, c.season,c.high_usageplayer_added,o.usagemin_dropped-c.usagemin_added as usagemin_opened,\n",
    "        c.max_usageadded,o.high_usageplayer_dropped,o.max_usagedropped,\n",
    "        o.points_dropped-c.points_added as points_opened,max_pointsdropped,max_pointsadded,\n",
    "        o.rebounds_dropped-c.rebounds_added as rebounds_opened,max_reboundsdropped,max_reboundsadded,\n",
    "        o.ast_dropped-c.ast_added as ast_opened,max_astdropped,max_astadded,\n",
    "        o.threes_dropped-c.threes_added as threes_opened,max_threesdropped,max_threesadded\n",
    "        from incoming_by_team c\n",
    "        inner join outgoing_by_team o\n",
    "            ON o.old_team = c.new_team\n",
    "            and o.season = c.season;\n",
    "            \n",
    "        DROP TABLE IF EXISTS Team_maxes;\n",
    "        CREATE TABLE Team_maxes AS\n",
    "        select R.season,R.startingTeam,MAX(R2.points) as pts, max(r2.rebounds) as reb, max(r2.ast) as ast,\n",
    "        MAX(R2.Tov) as TO,MAX(r2.FGA) as shot_attempts, cast(NULL as float) as max_usage \n",
    "        from rank_by_minutes R\n",
    "        inner join rank_by_minutes R2\n",
    "            ON R2.startingTeam = R.startingTeam\n",
    "            and R2.season+1 = R.season\n",
    "        group by R.season,R.startingTeam;\n",
    "        \n",
    "        \n",
    "        update Team_maxes T\n",
    "        set max_usage = usage\n",
    "        from\n",
    "        (select T.season,T.startingTeam,T.pts,t.reb,t.ast,t.TO,MAX(a.usage_percentage) as usage from Team_maxes T\n",
    "        inner join adv_top10min a\n",
    "            ON a.season+1 = t.season\n",
    "            and a.tm = t.startingteam\n",
    "        group by T.season,T.startingTeam,T.pts,t.reb,t.ast,t.TO) A\n",
    "        WHERE A.season = T.season and  A.startingTeam = T.startingTeam;\n",
    "        \n",
    "        \n",
    "        \n",
    "        '''\n",
    "\n",
    "\n",
    "cur.execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Get player based data\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "query = '''\n",
    "        DROP TABLE IF EXISTS player_stats;\n",
    "        CREATE TABLE player_stats AS\n",
    "        select r.*,r2.starter as starter_ly,r3.points-r2.points as change_points_ly,r2.points as points_ly\n",
    "        ,r3.rebounds-r2.rebounds as change_reb_ly, r2.rebounds as rebounds_ly,\n",
    "        r3.ast-r2.ast as change_ast_ly, r2.ast as ast_ly,r3.stl-r2.stl as change_stl_ly,r2.stl as stl_ly,\n",
    "        r3.blk-r2.blk as change_blk_ly, r2.blk as blk_ly,r3.tov-r2.tov as change_tov_ly,r2.tov as tov_ly,\n",
    "        r2.threes_made as threes_ly,r3.threes_made-r2.threes_made as change_threes\n",
    "        from rank_by_minutes r\n",
    "        left join rank_by_minutes r2\n",
    "            on r.player = r2.player\n",
    "            and r.season = r2.season+1\n",
    "        left join rank_by_minutes r3\n",
    "            ON r3.player = r2.player\n",
    "            and r3.season+1 = r2.season;\n",
    "        \n",
    "        DROP TABLE IF EXISTS player_advstats;\n",
    "        CREATE TABLE player_advstats AS\n",
    "        select y.player,y.season,y.startingteam,a.per as per_ly, a2.per-a.per as change_per,a.three_attempt_rate as threeAR_ly,\n",
    "        a2.three_attempt_rate-a.three_attempt_rate as change_3AR, a.rebound_percentage as reb_perc_ly, a2.rebound_percentage-a.rebound_percentage as change_reb_perc\n",
    "        ,a.assist_percentage as ast_perc_ly, a2.assist_percentage-a.assist_percentage as change_assist_perc\n",
    "        ,a.steal_percentage as stl_perc_ly, a2.steal_percentage-a.steal_percentage as change_stl_perc_ly\n",
    "        ,a.block_percentage as blk_perc_ly, a2.block_percentage-a.block_percentage as change_blk_perc_ly\n",
    "        ,a.turnover_percentage as TO_perc_ly, a2.turnover_percentage-a.turnover_percentage as change_turnover_perc_ly,\n",
    "        rank() over(partition by y.season,y.startingTeam order by a.usage_percentage) as usagerank,\n",
    "        rank() over(partition by y.season,a.tm order by a.usage_percentage) as usagerank_ly,\n",
    "        a.offensive_winshares,\n",
    "        a.defensive_winshares,a.winshares,a.winshares_per48,a.offensive_boxplusminus,a.defensive_boxplusminus,\n",
    "        a.boxplusminus,a.value_overreplacement        \n",
    "        from y_predictions y\n",
    "        left join nba_advanced a\n",
    "            ON a.player = y.player\n",
    "            and a.season+1 = y.season\n",
    "        left join nba_advanced a2\n",
    "            ON a2.player = a.player\n",
    "            and a2.season+1 = a.season;\n",
    "    \n",
    "        \n",
    "        DROP TABLE IF EXISTS player_careerstats;\n",
    "        CREATE TABLE player_careerstats AS\n",
    "        select r.player,r.season,SUM(case when r2.player is not null then 1 else 0 end) as YearsPro, avg(r2.points) as career_points\n",
    "        ,avg(r2.rebounds) as career_rebounds,avg(r2.ast) as career_ast, avg(r2.stl) as career_stl, avg(r2.blk) as career_blk\n",
    "        ,avg(r2.tov) as career_TO, avg(r2.threes_made) as career_threesmade,avg(r2.ftm) as career_ftm,avg(r2.fta) as career_fta\n",
    "        ,avg(r2.fga) as career_fga, avg(r2.fg) as career_fgm\n",
    "        from rank_by_minutes r\n",
    "        inner join rank_by_minutes r2\n",
    "            ON r.player = r2.player\n",
    "            and r.season > r2.season\n",
    "        group by r.player,r.season;\n",
    "       \n",
    "        '''\n",
    "\n",
    "\n",
    "cur.execute(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    " query= '''\n",
    "        \n",
    "        DROP TABLE IF EXISTS points_pred;\n",
    "        CREATE TABLE points_pred(\n",
    "        season int, --these come from player_stats\n",
    "        player varchar(50),\n",
    "        Age int,\n",
    "        team varchar(50),\n",
    "        points float, -- these come from player_stats\n",
    "        points_ly float,\n",
    "        change_points_ly float,\n",
    "        starter_change int,\n",
    "        C_PF int,\n",
    "        PG int,\n",
    "        SG_SF int,\n",
    "        \n",
    "         -- these come from team_changes\n",
    "        high_usageplayer_added int,\n",
    "        usagemin_opened float,\n",
    "        maxusage_added float,\n",
    "        high_usageplayer_dropped int,\n",
    "        points_opened float,\n",
    "        max_pointsdropped float,\n",
    "        max_pointsadded float,\n",
    "        \n",
    "        three_ar_ly float, -- from player_advstats\n",
    "        change_3ar float,\n",
    "        per_ly float,\n",
    "        change_per float,\n",
    "        usagerank float,\n",
    "        usagerank_ly float,\n",
    "        offensive_winshares float,\n",
    "        offensive_boxplusminus float,\n",
    "        boxplusminus float,\n",
    "        value_overreplacement float,\n",
    "        \n",
    "        career_points float,\n",
    "        yearspro int\n",
    "        );\n",
    "        \n",
    "        INSERT INTO points_pred(season,player,age,team,points,points_ly,change_points_ly,starter_change,C_PF,PG,SG_SF)\n",
    "        SELECT season,player,age,startingteam,points,points_ly,change_points_ly,starter-starter_ly,\n",
    "        case when pos in ('C','PF') then 1 else 0 end,case when pos='PG' then 1 else 0 end,case when pos in('SG','SF') then 1 else 0 end from player_stats;\n",
    "        \n",
    "        update points_pred pp\n",
    "        set high_usageplayer_added = tc.high_usageplayer_added,usagemin_opened=tc.usagemin_opened,\n",
    "        maxusage_added=tc.max_usageadded,high_usageplayer_dropped=tc.high_usageplayer_dropped,points_opened=tc.points_opened,\n",
    "        max_pointsdropped=tc.max_pointsdropped,max_pointsadded=tc.max_pointsadded\n",
    "        from team_changes tc\n",
    "        where tc.team = pp.team and pp.season=tc.season;\n",
    "        \n",
    "        update points_pred pp\n",
    "        set three_ar_ly = pa.threear_ly,change_3ar=pa.change_3ar,per_ly=pa.per_ly,change_per=pa.change_per,\n",
    "        usagerank=pa.usagerank,usagerank_ly=pa.usagerank_ly,offensive_winshares=pa.offensive_winshares,\n",
    "        offensive_boxplusminus=pa.offensive_boxplusminus,boxplusminus=pa.boxplusminus,value_overreplacement=pa.value_overreplacement\n",
    "        from player_advstats pa\n",
    "        where pp.player = pa.player and pp.season = pa.season and pp.team = pa.startingteam;\n",
    "        \n",
    "        update points_pred pp\n",
    "        set career_points = pc.career_points, yearspro = pc.yearspro\n",
    "        from player_careerstats pc\n",
    "        where pp.player = pc.player and pp.season = pc.season;\n",
    "        \n",
    "        \n",
    "        select * from points_pred where season>2009\n",
    "        '''\n",
    "\n",
    "\n",
    "cur.execute(query)\n",
    "data = cur.fetchall()\n",
    "points_df = pd.DataFrame(np.array(data))\n",
    "points_df.columns = ['season','player','age','team','points','points_ly','change_points_ly','starter_change','C_PF','PG','SG_SF','high_usageplayer_added','usagemin_opened','maxusage_added','high_usageplayer_dropped','points_opened','max_pointsdropped',\n",
    "                    'max_pointsadded','three_ar_ly','change_3ar','per_ly','change_per','usagerank','usagerank_ly','offensive_winshares','offensive_boxplusminus','boxplusminus','value_overreplacement','career_points','yearspro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rookies = points_df[points_df['points_ly'].isna()]\n",
    "rookies.sort_values(by='points',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "players = points_df[points_df['points_ly'].notna()]\n",
    "for i in players.columns:\n",
    "    if i not in(['player','team']):\n",
    "        players[i]=pd.to_numeric(players[i])\n",
    "players = players.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = players[players['season']!=2017]['points']\n",
    "X = players[players['season']!=2017].drop(['points','player','season','team'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import GradientBoostingRegressor,RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function connection.close>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cur.close()\n",
    "conn.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression error: 0.7706184121337402\n",
      "GradientBoost error: 0.7695143834691159\n",
      "RandomForest error: 0.7068402746139153\n"
     ]
    }
   ],
   "source": [
    "r2_lr = np.mean(cross_val_score(LinearRegression(),X_train,y_train,cv=10,n_jobs=-1))\n",
    "print('Linear Regression error: {}'.format(r2_lr))\n",
    "\n",
    "r2_gb = np.mean(cross_val_score(GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.5),X_train,y_train,cv=5,n_jobs=-1))\n",
    "print('GradientBoost error: {}'.format(r2_gb))\n",
    "\n",
    "r2_rf = np.mean(cross_val_score(RandomForestRegressor(n_estimators=1000,max_depth = 3,max_features=0.5),X_train,y_train,cv=5,n_jobs=-1))\n",
    "print('RandomForest error: {}'.format(r2_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7495924120019375, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7476594944544669, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7943399658158287, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7190431458804185, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7222216933630867, total=   0.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7627053638805009, total=   0.6s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7502206778411044, total=   0.6s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000, score=0.8045909017875303, total=   0.6s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7293798119305249, total=   0.6s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7300588658432952, total=   0.6s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7724619977012069, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7526974885743176, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000, score=0.810172956048633, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7464345262995764, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7359319991432365, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000, score=0.7714118315177116, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000, score=0.7484088434769929, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000, score=0.809351530051144, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000, score=0.7396221339062757, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.3, n_estimators=2000, score=0.7360800496568037, total=   1.0s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7782412972206614, total=   0.7s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7534142959553877, total=   0.7s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000, score=0.8076397951828361, total=   0.7s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7526210846094401, total=   0.8s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=1000, score=0.739283943797602, total=   0.8s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000, score=0.7718861303857902, total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000, score=0.7502934336936846, total=   1.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000, score=0.8069350259476348, total=   1.3s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000, score=0.7376255382516397, total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=3, max_features=0.5, n_estimators=2000, score=0.737654204563374, total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7626771339183323, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7465049831143591, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000, score=0.8018587343434184, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7303094382099727, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7286900382983863, total=   0.5s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7601056582996399, total=   1.0s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7428013575185071, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000, score=0.8003830497626752, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7290513105397022, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7293391964796927, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7770393060223986, total=   1.0s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7515317599698752, total=   1.0s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000, score=0.8057791616339796, total=   1.2s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7403035333377772, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7380020790437171, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7661440685290489, total=   1.7s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7396205227844399, total=   1.7s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000, score=0.802302081648347, total=   1.7s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7295044347022633, total=   1.8s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7316890912641884, total=   1.8s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7715801807194493, total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7457471806092637, total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000, score=0.8033399817639613, total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000, score=0.744422152544153, total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7393631477275849, total=   1.4s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7603685317760063, total=   2.7s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7374521750249801, total=   2.7s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7991477867900119, total=   2.8s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7310660946972016, total=   2.7s\n",
      "[CV] learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=5, max_features=0.5, n_estimators=2000, score=0.73103055543112, total=   2.7s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7562111426304283, total=   0.9s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7480430230577373, total=   0.8s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7967011623928267, total=   0.8s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7257278038368107, total=   0.8s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7256501733403956, total=   0.8s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7461836284262331, total=   1.5s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7426505957356664, total=   1.5s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7943318467730048, total=   1.5s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7163064966131981, total=   1.5s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7268958591275507, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7642667464108575, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7472279720786172, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000, score=0.8051508686829824, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000, score=0.730024428630686, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7321632082347167, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7570609920410137, total=   3.2s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7422406018737014, total=   3.1s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000, score=0.8025975188997343, total=   3.1s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7321555092651384, total=   3.1s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7271797914893012, total=   3.1s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7624550271802718, total=   2.8s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7422698693042158, total=   2.8s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000, score=0.80269818476494, total=   2.6s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7366475381642718, total=   2.7s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7304025880552752, total=   2.6s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7579714310310804, total=   5.0s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7381936611530922, total=   5.0s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7997123433740743, total=   4.9s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000, score=0.729932346775635, total=   4.9s\n",
      "[CV] learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=7, max_features=0.5, n_estimators=2000, score=0.721586215979279, total=   4.9s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000, score=0.737095505582872, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7391002109576411, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7821762588610093, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7153281788280829, total=   1.8s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7123294115378661, total=   1.6s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7394600909167903, total=   3.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7397868483744654, total=   3.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7868843929850418, total=   3.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7230768853387237, total=   3.1s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7163275204374132, total=   3.1s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7546220342493819, total=   3.9s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7452179324783312, total=   3.9s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7971776444927601, total=   3.9s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7299268435231488, total=   3.9s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=1000, score=0.721997645297602, total=   3.8s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7537602466103849, total=   6.7s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7453613935960759, total=   6.9s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7963422967116403, total=   7.3s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000, score=0.731775920024456, total=   7.0s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7192168588867147, total=   7.3s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7521194216181062, total=   6.8s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000, score=0.73591294700449, total=   6.6s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000, score=0.8000873197537989, total=   6.5s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7281733634094683, total=   6.7s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7275044178926261, total=   6.4s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7545468244722808, total=  11.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7373252340416532, total=  11.3s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000, score=0.8003975458072936, total=  11.2s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7251717171625662, total=  11.6s\n",
      "[CV] learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.01, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7249564186650879, total=  11.5s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000, score=0.752286846835078, total=   0.3s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7344522867350258, total=   0.3s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000, score=0.8002626878951357, total=   0.3s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000, score=0.703864233587904, total=   0.3s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7235337227035721, total=   0.3s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7393922487573352, total=   0.6s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7125520140158332, total=   0.6s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000, score=0.79302259406663, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7073971620006783, total=   0.6s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7119012948136328, total=   0.6s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7559099138338337, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7319007998160488, total=   0.4s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7992056979535583, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7203937644737937, total=   0.4s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=1000, score=0.721137441584053, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000, score=0.7385908644620797, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000, score=0.7092442173441982, total=   0.9s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000, score=0.7851112072120722, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000, score=0.6894879510843741, total=   0.9s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.3, n_estimators=2000, score=0.7074554670306207, total=   0.9s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7466439072911673, total=   0.7s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7257824680827822, total=   0.7s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000, score=0.8005423190440591, total=   0.7s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7147742701837227, total=   0.7s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7219265556585865, total=   0.7s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000, score=0.729322513231452, total=   1.4s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000, score=0.7082251376147489, total=   1.4s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000, score=0.786368296727049, total=   1.4s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000, score=0.6927225064421316, total=   1.4s\n",
      "[CV] learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=3, max_features=0.5, n_estimators=2000, score=0.7021674528402333, total=   1.4s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000, score=0.735987099698128, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7163199673523517, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7837932451898368, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7048473971269863, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7286024372293955, total=   0.5s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7434888704202895, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7199128185929571, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7876007854609404, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000, score=0.6945420460139555, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7055204482159698, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7510237368472615, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7303682814183251, total=   0.9s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7875888975676699, total=   0.9s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7086265574189083, total=   0.9s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7244035036909662, total=   0.9s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7393223717485395, total=   1.8s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7229888788680818, total=   1.8s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7914514342873987, total=   1.9s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7119477121686841, total=   1.8s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7131420118957748, total=   1.8s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7483604041973191, total=   1.4s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000, score=0.722014021511503, total=   1.4s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7873754260611263, total=   1.5s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7146158970835647, total=   1.4s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7223065561849062, total=   1.4s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7445193304153469, total=   2.9s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7268449941649757, total=   2.9s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7910472172522893, total=   2.8s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7076979390667831, total=   2.9s\n",
      "[CV] learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7155123783998669, total=   3.1s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7508683171448276, total=   0.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7369347684284189, total=   0.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7868665407329936, total=   0.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7051506815535404, total=   0.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7168202672140183, total=   0.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7403865965978269, total=   1.5s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7394960864825679, total=   1.5s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7866143604997458, total=   1.5s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000, score=0.70787989008121, total=   1.5s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.1, n_estimators=2000, score=0.708104263057199, total=   1.5s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7527646705276453, total=   1.6s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7306964803031681, total=   1.6s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7968111012770279, total=   1.6s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7207640091874379, total=   1.6s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7215776096779543, total=   1.6s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7532871973495969, total=   2.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7300993993125191, total=   2.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7962722790974893, total=   2.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7249697944914697, total=   2.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7245997112925274, total=   2.8s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7450880758859164, total=   2.4s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7219047273998561, total=   2.4s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7968425632753985, total=   2.5s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7228328199892681, total=   2.5s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7210661583696008, total=   2.5s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7490806201728469, total=   4.3s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7251426220404611, total=   4.4s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7987682411300973, total=   4.4s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7209759908921514, total=   4.6s\n",
      "[CV] learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7279667359080849, total=   4.7s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7177709865279249, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7284447966563368, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7781155952166244, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7134790895649794, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7022702697577334, total=   1.0s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7278511082439557, total=   1.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7282186855102353, total=   1.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000, score=0.771979995001921, total=   1.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7168075035305853, total=   1.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7107626870256414, total=   1.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7485030109277822, total=   2.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7434980023515272, total=   2.0s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7896427314684267, total=   2.0s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7194799449885727, total=   2.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7233966325426893, total=   2.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7397012993381731, total=   2.2s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7369431862597071, total=   2.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7890744709242321, total=   2.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7174973044650194, total=   2.1s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7198864632305905, total=   2.2s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7494867760789095, total=   3.3s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7325835434169372, total=   3.4s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7991469983980578, total=   3.3s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7226740586690906, total=   3.4s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7216717811919983, total=   3.4s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7487770435984751, total=   3.5s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7330375830969063, total=   3.5s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7975796905296982, total=   3.4s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7222503677852579, total=   3.4s\n",
      "[CV] learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.05, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7095453234854497, total=   3.5s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7400927184551788, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7051763260749899, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000, score=0.7863782256378044, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000, score=0.6903610883360561, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=1000, score=0.709880163506944, total=   0.3s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7238648057886273, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000, score=0.7015505815972904, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000, score=0.771189774211563, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000, score=0.6774645909887353, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.1, n_estimators=2000, score=0.6983061932376536, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7346831372833165, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000, score=0.6977042165981303, total=   0.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7876122507583366, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000, score=0.690826704359533, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=1000, score=0.7044378218776257, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000, score=0.7191456328307622, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000, score=0.6950523653128976, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000, score=0.770112856119971, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000, score=0.6671644457002963, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.3, n_estimators=2000, score=0.6967486575476491, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7239935260934496, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000, score=0.6968332954089733, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7912071424581322, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000, score=0.6787669355629476, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=1000, score=0.7036425895595, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000, score=0.7107280285375973, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000, score=0.6906934320836046, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000, score=0.7684853436032557, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000, score=0.6733068186415727, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=3, max_features=0.5, n_estimators=2000, score=0.6881659954174325, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000, score=0.73062496919834, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7112315806878475, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7889885476586568, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000, score=0.6938845522487078, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=1000, score=0.7078837587072513, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7355003080703729, total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7127437181038732, total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7818553463982422, total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000, score=0.6858339349017537, total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.1, n_estimators=2000, score=0.7021546186806401, total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7417695496650021, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7099484489978046, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7923173090695046, total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000, score=0.6985217244130694, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=1000, score=0.7017796878802254, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7366849469695127, total=   1.8s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000, score=0.710631893814357, total=   1.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000, score=0.7701324326286275, total=   1.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000, score=0.6971844661677287, total=   1.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.3, n_estimators=2000, score=0.710067350050307, total=   1.8s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7378688585097068, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000, score=0.723908544033475, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7861375811253967, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7083898379004534, total=   1.5s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=1000, score=0.7020346355186942, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7436745379932068, total=   3.0s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000, score=0.721390374669193, total=   3.1s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7899364619877614, total=   2.9s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7023376993387401, total=   2.8s\n",
      "[CV] learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=5, max_features=0.5, n_estimators=2000, score=0.7078778010172415, total=   2.9s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7332085221187111, total=   0.8s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7260121075747383, total=   0.8s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7757299189069455, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7071261929320487, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=1000, score=0.7061625505249256, total=   0.8s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7394025958553498, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7376728682711406, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7813160199839769, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000, score=0.699058564582554, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.1, n_estimators=2000, score=0.7095696708273942, total=   0.9s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7501109680043165, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7320737587546198, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7871169906244867, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7234201757710497, total=   1.4s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=1000, score=0.7194652481909605, total=   1.5s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7418655595748486, total=   1.5s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7244626202046608, total=   1.5s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7834005945928676, total=   1.5s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7241832829411852, total=   1.5s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.3, n_estimators=2000, score=0.7227272210830801, total=   1.5s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7453695426305416, total=   2.2s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7308966989776801, total=   2.3s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7894149280812881, total=   2.2s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7252913188700597, total=   2.2s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=1000, score=0.7107156873553534, total=   2.3s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7499877423621176, total=   2.3s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7295974357531997, total=   2.4s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000, score=0.8033482037577244, total=   2.4s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000, score=0.708724944503413, total=   2.4s\n",
      "[CV] learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=7, max_features=0.5, n_estimators=2000, score=0.7096245120460201, total=   2.3s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7245899828276123, total=   0.5s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000, score=0.7213787716744793, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000, score=0.771114043249621, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000, score=0.6951395793983591, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=1000, score=0.6866123757502176, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7083380746262937, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7218458017159783, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000, score=0.7729539221198265, total=   0.6s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000, score=0.6786220787087511, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.1, n_estimators=2000, score=0.6924059206715347, total=   0.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7461429399331911, total=   1.0s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7335854835740997, total=   1.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7882061664132022, total=   1.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000, score=0.715496985489933, total=   1.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=1000, score=0.7125187406617058, total=   1.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7351299096149566, total=   1.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7332982267329171, total=   1.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7847242825214382, total=   1.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7182262515857962, total=   1.2s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.3, n_estimators=2000, score=0.7061579918019316, total=   1.1s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7342673085994973, total=   1.8s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7324242118013593, total=   1.8s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7848016999949579, total=   1.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7116218347626846, total=   1.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=1000, score=0.7100725360014587, total=   1.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7420754701332148, total=   1.8s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7149834059138893, total=   1.8s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7906294839563833, total=   1.7s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7086771799125724, total=   1.8s\n",
      "[CV] learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000 \n",
      "[CV]  learning_rate=0.1, max_depth=10, max_features=0.5, n_estimators=2000, score=0.7012909195205025, total=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed: 11.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'learning_rate': [0.01, 0.05, 0.1], 'n_estimators': [1000, 2000], 'max_depth': [3, 5, 7, 10], 'max_features': [0.1, 0.3, 0.5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'learning_rate':[0.01,0.05,0.1], 'n_estimators':[1000,2000],'max_depth':[3,5,7,10],'max_features':[0.1,0.3,0.5]}\n",
    "\n",
    "clf = GridSearchCV(GradientBoostingRegressor(), parameters, cv=5,verbose=3)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.01, loss='ls', max_depth=3, max_features=0.5,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=1000, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model, Input\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.stats as scs\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=16,input_dim= 26,activation='relu'))\n",
    "#model.add(Dense(units=8, activation='relu'))\n",
    "#model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(units=8, activation='relu'))\n",
    "#model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(units=4, activation='relu'))\n",
    "#model.add(Dropout(rate=0.25))\n",
    "model.add(Dense(units=1,activation='linear'))\n",
    "model.compile(loss='mse', optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "1883/1883 [==============================] - 0s 242us/step - loss: 416.2584\n",
      "Epoch 2/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 209.1091\n",
      "Epoch 3/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 165.5059\n",
      "Epoch 4/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 139.0482\n",
      "Epoch 5/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 130.5637\n",
      "Epoch 6/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 127.7999\n",
      "Epoch 7/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 122.4804\n",
      "Epoch 8/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 112.3718\n",
      "Epoch 9/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 108.7543\n",
      "Epoch 10/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 99.5249\n",
      "Epoch 11/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 87.9469\n",
      "Epoch 12/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 80.6404\n",
      "Epoch 13/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 79.1041\n",
      "Epoch 14/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 75.4520\n",
      "Epoch 15/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 73.9179\n",
      "Epoch 16/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 66.9681\n",
      "Epoch 17/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 64.8751\n",
      "Epoch 18/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 61.9715\n",
      "Epoch 19/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 59.2301\n",
      "Epoch 20/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 57.9251\n",
      "Epoch 21/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 53.7750\n",
      "Epoch 22/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 54.8898\n",
      "Epoch 23/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 51.6061\n",
      "Epoch 24/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 50.7308\n",
      "Epoch 25/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 49.9111\n",
      "Epoch 26/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 45.1340\n",
      "Epoch 27/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 43.6889\n",
      "Epoch 28/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 43.3193\n",
      "Epoch 29/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 40.4162\n",
      "Epoch 30/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 39.6851\n",
      "Epoch 31/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 39.1624\n",
      "Epoch 32/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 39.9786\n",
      "Epoch 33/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 40.6373\n",
      "Epoch 34/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 39.5659\n",
      "Epoch 35/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 38.3132\n",
      "Epoch 36/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 36.7418\n",
      "Epoch 37/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 37.0447\n",
      "Epoch 38/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 36.9522\n",
      "Epoch 39/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 37.5016\n",
      "Epoch 40/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 36.1982\n",
      "Epoch 41/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 35.7108\n",
      "Epoch 42/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 34.8462\n",
      "Epoch 43/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 35.3763\n",
      "Epoch 44/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 37.0695\n",
      "Epoch 45/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 34.8651\n",
      "Epoch 46/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 37.3951\n",
      "Epoch 47/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 32.4107\n",
      "Epoch 48/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 33.5408\n",
      "Epoch 49/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 33.6562\n",
      "Epoch 50/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 32.8563\n",
      "Epoch 51/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 30.4339\n",
      "Epoch 52/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 32.6144\n",
      "Epoch 53/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 31.0616\n",
      "Epoch 54/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 32.5074\n",
      "Epoch 55/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 28.2591\n",
      "Epoch 56/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 28.6740\n",
      "Epoch 57/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 28.1219\n",
      "Epoch 58/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 28.4771\n",
      "Epoch 59/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 29.8842\n",
      "Epoch 60/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 24.6296\n",
      "Epoch 61/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 26.2551\n",
      "Epoch 62/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 25.6514\n",
      "Epoch 63/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 24.4705\n",
      "Epoch 64/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 25.0336\n",
      "Epoch 65/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 21.8220\n",
      "Epoch 66/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 22.6757\n",
      "Epoch 67/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 23.5564\n",
      "Epoch 68/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 22.6927\n",
      "Epoch 69/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 21.5480\n",
      "Epoch 70/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 20.7967\n",
      "Epoch 71/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 19.6646\n",
      "Epoch 72/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 21.1104\n",
      "Epoch 73/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 19.5940\n",
      "Epoch 74/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 20.0130\n",
      "Epoch 75/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 19.4128\n",
      "Epoch 76/2000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 19.3334\n",
      "Epoch 77/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 21.0955\n",
      "Epoch 78/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 18.8139\n",
      "Epoch 79/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 20.4475\n",
      "Epoch 80/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 19.3932\n",
      "Epoch 81/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 20.0326\n",
      "Epoch 82/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 18.7078\n",
      "Epoch 83/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 18.7506\n",
      "Epoch 84/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 18.9975\n",
      "Epoch 85/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 18.4838\n",
      "Epoch 86/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 20.5150\n",
      "Epoch 87/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 19.8332\n",
      "Epoch 88/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 18.4762\n",
      "Epoch 89/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 18.1751\n",
      "Epoch 90/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 17.1228\n",
      "Epoch 91/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 17.6576\n",
      "Epoch 92/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 17.3178\n",
      "Epoch 93/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 17.9356\n",
      "Epoch 94/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 18.0666\n",
      "Epoch 95/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 16.7367\n",
      "Epoch 96/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 18.0549\n",
      "Epoch 97/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 19.0435\n",
      "Epoch 98/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 17.5195\n",
      "Epoch 99/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 17.1896\n",
      "Epoch 100/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 17.1973\n",
      "Epoch 101/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 17.1263\n",
      "Epoch 102/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 18.3989\n",
      "Epoch 103/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 18.0050\n",
      "Epoch 104/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 17.1966\n",
      "Epoch 105/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 17.2085\n",
      "Epoch 106/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 16.7218\n",
      "Epoch 107/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 17.5295\n",
      "Epoch 108/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 16.3687\n",
      "Epoch 109/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 16.7246\n",
      "Epoch 110/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 17.5327\n",
      "Epoch 111/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 15.7298\n",
      "Epoch 112/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 16.8052\n",
      "Epoch 113/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 15.7246\n",
      "Epoch 114/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 16.5653\n",
      "Epoch 115/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 16.3377\n",
      "Epoch 116/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 16.1722\n",
      "Epoch 117/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 17.1880\n",
      "Epoch 118/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 15.6868\n",
      "Epoch 119/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 16.2808\n",
      "Epoch 120/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 15.7172\n",
      "Epoch 121/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 16.5814\n",
      "Epoch 122/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 15.8530\n",
      "Epoch 123/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 16.1629\n",
      "Epoch 124/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 16.5745\n",
      "Epoch 125/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 16.2430\n",
      "Epoch 126/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 16.2778\n",
      "Epoch 127/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 15.7849\n",
      "Epoch 128/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 15.2192\n",
      "Epoch 129/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 16.3625\n",
      "Epoch 130/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 13.7245\n",
      "Epoch 131/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 16.2643\n",
      "Epoch 132/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 14.8666\n",
      "Epoch 133/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 13.7415\n",
      "Epoch 134/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 15.6591\n",
      "Epoch 135/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 14.4860\n",
      "Epoch 136/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 14.0700\n",
      "Epoch 137/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 14.6885\n",
      "Epoch 138/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 14.1439\n",
      "Epoch 139/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 15.8478\n",
      "Epoch 140/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 15.0162\n",
      "Epoch 141/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 14.4978\n",
      "Epoch 142/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 14.7400\n",
      "Epoch 143/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 14.4559\n",
      "Epoch 144/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 14.6119\n",
      "Epoch 145/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 15.3660\n",
      "Epoch 146/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 15.0546\n",
      "Epoch 147/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 14.8781\n",
      "Epoch 148/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 13.9506\n",
      "Epoch 149/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 14.3345\n",
      "Epoch 150/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 13.9727\n",
      "Epoch 151/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 14.3902\n",
      "Epoch 152/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 14.2808\n",
      "Epoch 153/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 14.4558\n",
      "Epoch 154/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 14.1142\n",
      "Epoch 155/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 14.5621\n",
      "Epoch 156/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 13.3243\n",
      "Epoch 157/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 13.7735\n",
      "Epoch 158/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 14.4204\n",
      "Epoch 159/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 14.1999\n",
      "Epoch 160/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 13.3325\n",
      "Epoch 161/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 14.5478\n",
      "Epoch 162/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 14.2797\n",
      "Epoch 163/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 14.4232\n",
      "Epoch 164/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 13.7972\n",
      "Epoch 165/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 12.4098\n",
      "Epoch 166/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 14.4925\n",
      "Epoch 167/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 13.5682\n",
      "Epoch 168/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 14.2602\n",
      "Epoch 169/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 13.6921\n",
      "Epoch 170/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 14.1871\n",
      "Epoch 171/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 13.7779\n",
      "Epoch 172/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 13.8966\n",
      "Epoch 173/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 14.1269\n",
      "Epoch 174/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 14.1735\n",
      "Epoch 175/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 13.8943\n",
      "Epoch 176/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 13.4869\n",
      "Epoch 177/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 13.2388\n",
      "Epoch 178/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 13.5483\n",
      "Epoch 179/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 12.8459\n",
      "Epoch 180/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 13.9133\n",
      "Epoch 181/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.5931\n",
      "Epoch 182/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.4022\n",
      "Epoch 183/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 14.1151\n",
      "Epoch 184/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 13.3650\n",
      "Epoch 185/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 12.7619\n",
      "Epoch 186/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 12.8509\n",
      "Epoch 187/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 13.7814\n",
      "Epoch 188/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.7923\n",
      "Epoch 189/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 13.4620\n",
      "Epoch 190/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 13.6222\n",
      "Epoch 191/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 13.1871\n",
      "Epoch 192/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 13.0380\n",
      "Epoch 193/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 13.2803\n",
      "Epoch 194/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.7234\n",
      "Epoch 195/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 14.2156\n",
      "Epoch 196/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 12.5721\n",
      "Epoch 197/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 13.7160\n",
      "Epoch 198/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 13.9311\n",
      "Epoch 199/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 12.8349\n",
      "Epoch 200/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 12.5451\n",
      "Epoch 201/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 13.1296\n",
      "Epoch 202/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 12.5136\n",
      "Epoch 203/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.4701\n",
      "Epoch 204/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.9414\n",
      "Epoch 205/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 13.1930\n",
      "Epoch 206/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 13.4871\n",
      "Epoch 207/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.6954\n",
      "Epoch 208/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 13.9319\n",
      "Epoch 209/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.2482\n",
      "Epoch 210/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 12.5314\n",
      "Epoch 211/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 12.4672\n",
      "Epoch 212/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.4920\n",
      "Epoch 213/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 12.5743\n",
      "Epoch 214/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 13.3472\n",
      "Epoch 215/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 13.8790\n",
      "Epoch 216/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 12.9416\n",
      "Epoch 217/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 12.1397\n",
      "Epoch 218/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 13.1755\n",
      "Epoch 219/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.9970\n",
      "Epoch 220/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 13.3195\n",
      "Epoch 221/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 14.0117\n",
      "Epoch 222/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.7231\n",
      "Epoch 223/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 12.4121\n",
      "Epoch 224/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 12.1167\n",
      "Epoch 225/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 11.3258\n",
      "Epoch 226/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 12.0676\n",
      "Epoch 227/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.8568\n",
      "Epoch 228/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.0353\n",
      "Epoch 229/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 12.0722\n",
      "Epoch 230/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.2331\n",
      "Epoch 231/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.2462\n",
      "Epoch 232/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.5801\n",
      "Epoch 233/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 12.6950\n",
      "Epoch 234/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.8647\n",
      "Epoch 235/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 13.0081\n",
      "Epoch 236/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.4771\n",
      "Epoch 237/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 12.4755\n",
      "Epoch 238/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.7735\n",
      "Epoch 239/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 12.4349\n",
      "Epoch 240/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 12.3121\n",
      "Epoch 241/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.3503\n",
      "Epoch 242/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.9517\n",
      "Epoch 243/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 14.8343\n",
      "Epoch 244/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.8825\n",
      "Epoch 245/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 12.1034\n",
      "Epoch 246/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.8994\n",
      "Epoch 247/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.6132\n",
      "Epoch 248/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 12.3393\n",
      "Epoch 249/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 13.8048\n",
      "Epoch 250/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.2868\n",
      "Epoch 251/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.3690\n",
      "Epoch 252/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 12.0606\n",
      "Epoch 253/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.2880\n",
      "Epoch 254/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.1530\n",
      "Epoch 255/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.6810\n",
      "Epoch 256/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.5226\n",
      "Epoch 257/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.8127\n",
      "Epoch 258/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 12.3361\n",
      "Epoch 259/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.5081\n",
      "Epoch 260/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.9742\n",
      "Epoch 261/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.0519\n",
      "Epoch 262/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.0204\n",
      "Epoch 263/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.5018\n",
      "Epoch 264/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.4944\n",
      "Epoch 265/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.5599\n",
      "Epoch 266/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.5907\n",
      "Epoch 267/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 12.4292\n",
      "Epoch 268/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.5461\n",
      "Epoch 269/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 12.0064\n",
      "Epoch 270/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.2903\n",
      "Epoch 271/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 12.3779\n",
      "Epoch 272/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.4144\n",
      "Epoch 273/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.1581\n",
      "Epoch 274/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 12.4493\n",
      "Epoch 275/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.4815\n",
      "Epoch 276/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.2464\n",
      "Epoch 277/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.8982\n",
      "Epoch 278/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.7710\n",
      "Epoch 279/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.6807\n",
      "Epoch 280/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 13.0037\n",
      "Epoch 281/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.3123\n",
      "Epoch 282/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 12.0637\n",
      "Epoch 283/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 12.0640\n",
      "Epoch 284/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.1299\n",
      "Epoch 285/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 11.8717\n",
      "Epoch 286/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.2961\n",
      "Epoch 287/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.6715\n",
      "Epoch 288/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.9837\n",
      "Epoch 289/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 12.1608\n",
      "Epoch 290/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.1898\n",
      "Epoch 291/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.8828\n",
      "Epoch 292/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 12.0209\n",
      "Epoch 293/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 12.6942\n",
      "Epoch 294/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.7631\n",
      "Epoch 295/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 12.7128\n",
      "Epoch 296/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.9864\n",
      "Epoch 297/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 12.2306\n",
      "Epoch 298/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.7676\n",
      "Epoch 299/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.6655\n",
      "Epoch 300/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.3572\n",
      "Epoch 301/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.9201\n",
      "Epoch 302/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 12.6798\n",
      "Epoch 303/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.7720\n",
      "Epoch 304/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.8581\n",
      "Epoch 305/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.3005\n",
      "Epoch 306/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.6323\n",
      "Epoch 307/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.3039\n",
      "Epoch 308/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.7660\n",
      "Epoch 309/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.5357\n",
      "Epoch 310/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.3158\n",
      "Epoch 311/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.1674\n",
      "Epoch 312/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.6187\n",
      "Epoch 313/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.3355\n",
      "Epoch 314/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.5425\n",
      "Epoch 315/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.9787\n",
      "Epoch 316/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.7548\n",
      "Epoch 317/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.7023\n",
      "Epoch 318/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.8690\n",
      "Epoch 319/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.0167\n",
      "Epoch 320/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 12.2893\n",
      "Epoch 321/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.5198\n",
      "Epoch 322/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.0613\n",
      "Epoch 323/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.7363\n",
      "Epoch 324/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.5592\n",
      "Epoch 325/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.5889\n",
      "Epoch 326/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.9439\n",
      "Epoch 327/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.0963\n",
      "Epoch 328/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 12.2345\n",
      "Epoch 329/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.4828\n",
      "Epoch 330/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.9475\n",
      "Epoch 331/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.2817\n",
      "Epoch 332/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.5736\n",
      "Epoch 333/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 13.1156\n",
      "Epoch 334/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.8147\n",
      "Epoch 335/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.3375\n",
      "Epoch 336/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.4997\n",
      "Epoch 337/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.5389\n",
      "Epoch 338/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.2048\n",
      "Epoch 339/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.7559\n",
      "Epoch 340/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 11.2181\n",
      "Epoch 341/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 11.8959\n",
      "Epoch 342/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.4179\n",
      "Epoch 343/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 11.5559\n",
      "Epoch 344/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.2252\n",
      "Epoch 345/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 12.1945\n",
      "Epoch 346/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.2168\n",
      "Epoch 347/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 12.6190\n",
      "Epoch 348/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.4585\n",
      "Epoch 349/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 10.3055\n",
      "Epoch 350/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 11.2279\n",
      "Epoch 351/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 11.1268\n",
      "Epoch 352/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 10.8597\n",
      "Epoch 353/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.4456\n",
      "Epoch 354/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 12.1000\n",
      "Epoch 355/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 11.6229\n",
      "Epoch 356/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 10.8381\n",
      "Epoch 357/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 12.5131\n",
      "Epoch 358/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 12.2520\n",
      "Epoch 359/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 11.9261\n",
      "Epoch 360/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.3610\n",
      "Epoch 361/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 10.6597\n",
      "Epoch 362/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.0335\n",
      "Epoch 363/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.1535\n",
      "Epoch 364/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 12.0213\n",
      "Epoch 365/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.2486\n",
      "Epoch 366/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.9509\n",
      "Epoch 367/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.9560\n",
      "Epoch 368/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.3626\n",
      "Epoch 369/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.2547\n",
      "Epoch 370/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.4448\n",
      "Epoch 371/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.7409\n",
      "Epoch 372/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.6133\n",
      "Epoch 373/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.3863\n",
      "Epoch 374/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.1805\n",
      "Epoch 375/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.4604\n",
      "Epoch 376/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.2228\n",
      "Epoch 377/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.1569\n",
      "Epoch 378/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.6764\n",
      "Epoch 379/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.7459\n",
      "Epoch 380/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.4678\n",
      "Epoch 381/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.9018\n",
      "Epoch 382/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.2544\n",
      "Epoch 383/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.1525\n",
      "Epoch 384/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.7389\n",
      "Epoch 385/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.3952\n",
      "Epoch 386/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 13.1278\n",
      "Epoch 387/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.9464\n",
      "Epoch 388/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.7229\n",
      "Epoch 389/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.8193\n",
      "Epoch 390/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.1988\n",
      "Epoch 391/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.7366\n",
      "Epoch 392/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.9839\n",
      "Epoch 393/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.4931\n",
      "Epoch 394/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.5970\n",
      "Epoch 395/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.4999\n",
      "Epoch 396/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.8372\n",
      "Epoch 397/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 12.0421\n",
      "Epoch 398/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.0938\n",
      "Epoch 399/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.5041\n",
      "Epoch 400/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.8353\n",
      "Epoch 401/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.3809\n",
      "Epoch 402/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.0022\n",
      "Epoch 403/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.2410\n",
      "Epoch 404/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.7084\n",
      "Epoch 405/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.9689\n",
      "Epoch 406/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.5379\n",
      "Epoch 407/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.9654\n",
      "Epoch 408/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 13.2493\n",
      "Epoch 409/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.0288\n",
      "Epoch 410/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 12.1854\n",
      "Epoch 411/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.7640\n",
      "Epoch 412/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.0348\n",
      "Epoch 413/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.5645\n",
      "Epoch 414/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 11.9200\n",
      "Epoch 415/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.3634\n",
      "Epoch 416/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.6518\n",
      "Epoch 417/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.2449\n",
      "Epoch 418/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.0451\n",
      "Epoch 419/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.7930\n",
      "Epoch 420/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.9560\n",
      "Epoch 421/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.8704\n",
      "Epoch 422/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 12.1719\n",
      "Epoch 423/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.8954\n",
      "Epoch 424/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.7813\n",
      "Epoch 425/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.3996\n",
      "Epoch 426/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.8250\n",
      "Epoch 427/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.2709\n",
      "Epoch 428/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.1783\n",
      "Epoch 429/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.0309\n",
      "Epoch 430/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.3411\n",
      "Epoch 431/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.3100\n",
      "Epoch 432/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.3336\n",
      "Epoch 433/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.0928\n",
      "Epoch 434/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.5586\n",
      "Epoch 435/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.1366\n",
      "Epoch 436/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.6943\n",
      "Epoch 437/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 12.4952\n",
      "Epoch 438/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.7230\n",
      "Epoch 439/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.2654\n",
      "Epoch 440/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.3542\n",
      "Epoch 441/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.4373\n",
      "Epoch 442/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.7430\n",
      "Epoch 443/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.9854\n",
      "Epoch 444/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.9651\n",
      "Epoch 445/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.8250\n",
      "Epoch 446/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.5897\n",
      "Epoch 447/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.1937\n",
      "Epoch 448/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.9293\n",
      "Epoch 449/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.3212\n",
      "Epoch 450/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.6938\n",
      "Epoch 451/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.8359\n",
      "Epoch 452/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.9759\n",
      "Epoch 453/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.8217\n",
      "Epoch 454/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.4017\n",
      "Epoch 455/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.7911\n",
      "Epoch 456/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.0497\n",
      "Epoch 457/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.3910\n",
      "Epoch 458/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.2678\n",
      "Epoch 459/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.8011\n",
      "Epoch 460/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.8557\n",
      "Epoch 461/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.5541\n",
      "Epoch 462/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.4125\n",
      "Epoch 463/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.7685\n",
      "Epoch 464/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.0147\n",
      "Epoch 465/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.3734\n",
      "Epoch 466/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.4128\n",
      "Epoch 467/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.4527\n",
      "Epoch 468/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.7082\n",
      "Epoch 469/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.2815\n",
      "Epoch 470/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.4448\n",
      "Epoch 471/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.1016\n",
      "Epoch 472/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.0930\n",
      "Epoch 473/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.5278\n",
      "Epoch 474/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.9190\n",
      "Epoch 475/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.2899\n",
      "Epoch 476/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.7982\n",
      "Epoch 477/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.8337\n",
      "Epoch 478/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.6206\n",
      "Epoch 479/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 11.8675\n",
      "Epoch 480/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.4112\n",
      "Epoch 481/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.0129\n",
      "Epoch 482/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 12.5147\n",
      "Epoch 483/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.7205\n",
      "Epoch 484/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.2273\n",
      "Epoch 485/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.9410\n",
      "Epoch 486/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.7198\n",
      "Epoch 487/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.0585\n",
      "Epoch 488/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.3377\n",
      "Epoch 489/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.8285\n",
      "Epoch 490/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.2717\n",
      "Epoch 491/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.6429\n",
      "Epoch 492/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.2887\n",
      "Epoch 493/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.7120\n",
      "Epoch 494/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.6858\n",
      "Epoch 495/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.0671\n",
      "Epoch 496/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.6218\n",
      "Epoch 497/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.3144\n",
      "Epoch 498/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.2835\n",
      "Epoch 499/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.5467\n",
      "Epoch 500/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.2901\n",
      "Epoch 501/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.7836\n",
      "Epoch 502/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.3348\n",
      "Epoch 503/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.3656\n",
      "Epoch 504/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.6125\n",
      "Epoch 505/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.5413\n",
      "Epoch 506/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.6771\n",
      "Epoch 507/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.5765\n",
      "Epoch 508/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.5734\n",
      "Epoch 509/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.2385\n",
      "Epoch 510/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.4391\n",
      "Epoch 511/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.4876\n",
      "Epoch 512/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.1133\n",
      "Epoch 513/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.3567\n",
      "Epoch 514/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.7290\n",
      "Epoch 515/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.1743\n",
      "Epoch 516/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.4134\n",
      "Epoch 517/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.1005\n",
      "Epoch 518/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.8488\n",
      "Epoch 519/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.6460\n",
      "Epoch 520/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.0600\n",
      "Epoch 521/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 12.3725\n",
      "Epoch 522/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 10.7192\n",
      "Epoch 523/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.7087\n",
      "Epoch 524/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.4629\n",
      "Epoch 525/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 11.4980\n",
      "Epoch 526/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.9739\n",
      "Epoch 527/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.9495\n",
      "Epoch 528/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.0127\n",
      "Epoch 529/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.0610\n",
      "Epoch 530/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.4714\n",
      "Epoch 531/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.6037\n",
      "Epoch 532/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.0044\n",
      "Epoch 533/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.0306\n",
      "Epoch 534/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.4813\n",
      "Epoch 535/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.8548\n",
      "Epoch 536/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2572\n",
      "Epoch 537/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.9643\n",
      "Epoch 538/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 12.2448\n",
      "Epoch 539/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.9670\n",
      "Epoch 540/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.6977\n",
      "Epoch 541/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.7509\n",
      "Epoch 542/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.6733\n",
      "Epoch 543/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 11.3134\n",
      "Epoch 544/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.0475\n",
      "Epoch 545/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.2455\n",
      "Epoch 546/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.8253\n",
      "Epoch 547/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.7192\n",
      "Epoch 548/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.7618\n",
      "Epoch 549/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.5299\n",
      "Epoch 550/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.4628\n",
      "Epoch 551/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.1173\n",
      "Epoch 552/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.9196\n",
      "Epoch 553/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2389\n",
      "Epoch 554/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.7261\n",
      "Epoch 555/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.4015\n",
      "Epoch 556/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.6362\n",
      "Epoch 557/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 10.2946\n",
      "Epoch 558/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.1822\n",
      "Epoch 559/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.1776\n",
      "Epoch 560/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 11.2834\n",
      "Epoch 561/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 12.5660\n",
      "Epoch 562/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.2205\n",
      "Epoch 563/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.0398\n",
      "Epoch 564/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.5042\n",
      "Epoch 565/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.5065\n",
      "Epoch 566/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9115\n",
      "Epoch 567/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.6083\n",
      "Epoch 568/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.6727\n",
      "Epoch 569/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.9753\n",
      "Epoch 570/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.1742\n",
      "Epoch 571/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.7547\n",
      "Epoch 572/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.0509\n",
      "Epoch 573/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.2915\n",
      "Epoch 574/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.6467\n",
      "Epoch 575/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.0453\n",
      "Epoch 576/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.6129\n",
      "Epoch 577/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.3346\n",
      "Epoch 578/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.1655\n",
      "Epoch 579/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.5618\n",
      "Epoch 580/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.9396\n",
      "Epoch 581/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.3522\n",
      "Epoch 582/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.4766\n",
      "Epoch 583/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.3469\n",
      "Epoch 584/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.6424\n",
      "Epoch 585/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.2692\n",
      "Epoch 586/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 12.1213\n",
      "Epoch 587/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.8115\n",
      "Epoch 588/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.4601\n",
      "Epoch 589/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.1784\n",
      "Epoch 590/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.7164\n",
      "Epoch 591/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.7615\n",
      "Epoch 592/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 12.2227\n",
      "Epoch 593/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.9899\n",
      "Epoch 594/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.0579\n",
      "Epoch 595/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.4724\n",
      "Epoch 596/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.4189\n",
      "Epoch 597/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.3782\n",
      "Epoch 598/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.8996\n",
      "Epoch 599/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.5186\n",
      "Epoch 600/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.7409\n",
      "Epoch 601/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.0250\n",
      "Epoch 602/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.2059\n",
      "Epoch 603/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.4419\n",
      "Epoch 604/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.2148\n",
      "Epoch 605/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.6297\n",
      "Epoch 606/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.0387\n",
      "Epoch 607/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 11.1914\n",
      "Epoch 608/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.5372\n",
      "Epoch 609/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.7545\n",
      "Epoch 610/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.3280\n",
      "Epoch 611/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.7232\n",
      "Epoch 612/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.2176\n",
      "Epoch 613/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 10.1093\n",
      "Epoch 614/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 11.7937\n",
      "Epoch 615/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.8921\n",
      "Epoch 616/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2947\n",
      "Epoch 617/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.9665\n",
      "Epoch 618/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.2647\n",
      "Epoch 619/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.3101\n",
      "Epoch 620/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 11.8307\n",
      "Epoch 621/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 10.7798\n",
      "Epoch 622/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 10.6493\n",
      "Epoch 623/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 10.2714\n",
      "Epoch 624/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.1263\n",
      "Epoch 625/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.2143\n",
      "Epoch 626/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.7942\n",
      "Epoch 627/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 11.2774\n",
      "Epoch 628/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.9575\n",
      "Epoch 629/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.2958\n",
      "Epoch 630/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.6821\n",
      "Epoch 631/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.6905\n",
      "Epoch 632/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.8920\n",
      "Epoch 633/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.3391\n",
      "Epoch 634/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.5072\n",
      "Epoch 635/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.5283\n",
      "Epoch 636/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.3386\n",
      "Epoch 637/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.8501\n",
      "Epoch 638/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 12.3748\n",
      "Epoch 639/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.6081\n",
      "Epoch 640/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.4424\n",
      "Epoch 641/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.7556\n",
      "Epoch 642/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.5599\n",
      "Epoch 643/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.4651\n",
      "Epoch 644/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.1388\n",
      "Epoch 645/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.2499\n",
      "Epoch 646/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.3523\n",
      "Epoch 647/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.3266\n",
      "Epoch 648/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.6231\n",
      "Epoch 649/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.8156\n",
      "Epoch 650/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.1962\n",
      "Epoch 651/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.6815\n",
      "Epoch 652/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.2246\n",
      "Epoch 653/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.1447\n",
      "Epoch 654/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.4440\n",
      "Epoch 655/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.8613\n",
      "Epoch 656/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.1563\n",
      "Epoch 657/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.8180\n",
      "Epoch 658/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 10.6769\n",
      "Epoch 659/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.1732\n",
      "Epoch 660/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.0231\n",
      "Epoch 661/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.5718\n",
      "Epoch 662/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.5604\n",
      "Epoch 663/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.0334\n",
      "Epoch 664/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.1381\n",
      "Epoch 665/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.7168\n",
      "Epoch 666/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.4072\n",
      "Epoch 667/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.6993\n",
      "Epoch 668/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.2760\n",
      "Epoch 669/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.3678\n",
      "Epoch 670/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.9534\n",
      "Epoch 671/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.2174\n",
      "Epoch 672/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.9675\n",
      "Epoch 673/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.0678\n",
      "Epoch 674/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.2887\n",
      "Epoch 675/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.8272\n",
      "Epoch 676/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.0129\n",
      "Epoch 677/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.4356\n",
      "Epoch 678/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.7709\n",
      "Epoch 679/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.7307\n",
      "Epoch 680/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.3827\n",
      "Epoch 681/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.5429\n",
      "Epoch 682/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 11.1336\n",
      "Epoch 683/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.5424\n",
      "Epoch 684/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 11.0669\n",
      "Epoch 685/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.4882\n",
      "Epoch 686/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.5160\n",
      "Epoch 687/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.4231\n",
      "Epoch 688/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 12.6644\n",
      "Epoch 689/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.6377\n",
      "Epoch 690/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.4244\n",
      "Epoch 691/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.2150\n",
      "Epoch 692/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 11.4201\n",
      "Epoch 693/2000\n",
      "1883/1883 [==============================] - 0s 8us/step - loss: 11.0453\n",
      "Epoch 694/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.8480\n",
      "Epoch 695/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.7717\n",
      "Epoch 696/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.5608\n",
      "Epoch 697/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.9638\n",
      "Epoch 698/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 11.3207\n",
      "Epoch 699/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.7163\n",
      "Epoch 700/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.3209\n",
      "Epoch 701/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.4195\n",
      "Epoch 702/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.6172\n",
      "Epoch 703/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.6009\n",
      "Epoch 704/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.8144\n",
      "Epoch 705/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 12.2548\n",
      "Epoch 706/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.3588\n",
      "Epoch 707/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.4088\n",
      "Epoch 708/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.7980\n",
      "Epoch 709/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.1841\n",
      "Epoch 710/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.6803\n",
      "Epoch 711/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.4077\n",
      "Epoch 712/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.1502\n",
      "Epoch 713/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 12.1889\n",
      "Epoch 714/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 11.2660\n",
      "Epoch 715/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 11.5612\n",
      "Epoch 716/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.3292\n",
      "Epoch 717/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.2473\n",
      "Epoch 718/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.4985\n",
      "Epoch 719/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.2635\n",
      "Epoch 720/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.0750\n",
      "Epoch 721/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.1006\n",
      "Epoch 722/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.2565\n",
      "Epoch 723/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.7928\n",
      "Epoch 724/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.1475\n",
      "Epoch 725/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2893\n",
      "Epoch 726/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 11.7562\n",
      "Epoch 727/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 11.0205\n",
      "Epoch 728/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.7828\n",
      "Epoch 729/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.5407\n",
      "Epoch 730/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 10.4623\n",
      "Epoch 731/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.8823\n",
      "Epoch 732/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.6011\n",
      "Epoch 733/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.7076\n",
      "Epoch 734/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.4021\n",
      "Epoch 735/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.0709\n",
      "Epoch 736/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.4984\n",
      "Epoch 737/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.2780\n",
      "Epoch 738/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.6465\n",
      "Epoch 739/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.7054\n",
      "Epoch 740/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 10.0700\n",
      "Epoch 741/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 12.2734\n",
      "Epoch 742/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.3923\n",
      "Epoch 743/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.7055\n",
      "Epoch 744/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.7501\n",
      "Epoch 745/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 10.5197\n",
      "Epoch 746/2000\n",
      "1883/1883 [==============================] - 0s 19us/step - loss: 10.3236\n",
      "Epoch 747/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 10.8689\n",
      "Epoch 748/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 10.8339\n",
      "Epoch 749/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 10.5309\n",
      "Epoch 750/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.9736\n",
      "Epoch 751/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.6323\n",
      "Epoch 752/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.0200\n",
      "Epoch 753/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.6469\n",
      "Epoch 754/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.9121\n",
      "Epoch 755/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.4837\n",
      "Epoch 756/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.6214\n",
      "Epoch 757/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.2116\n",
      "Epoch 758/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.4516\n",
      "Epoch 759/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.7334\n",
      "Epoch 760/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2340\n",
      "Epoch 761/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.5209\n",
      "Epoch 762/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 11.0698\n",
      "Epoch 763/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.7902\n",
      "Epoch 764/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.8241\n",
      "Epoch 765/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.5513\n",
      "Epoch 766/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.9765\n",
      "Epoch 767/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.0679\n",
      "Epoch 768/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.1701\n",
      "Epoch 769/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.3122\n",
      "Epoch 770/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.1166\n",
      "Epoch 771/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.9543\n",
      "Epoch 772/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.4987\n",
      "Epoch 773/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 12.1593\n",
      "Epoch 774/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.6308\n",
      "Epoch 775/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.7200\n",
      "Epoch 776/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.4573\n",
      "Epoch 777/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.0750\n",
      "Epoch 778/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.4436\n",
      "Epoch 779/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.2391\n",
      "Epoch 780/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.4252\n",
      "Epoch 781/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.3100\n",
      "Epoch 782/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.0236\n",
      "Epoch 783/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.1695\n",
      "Epoch 784/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9548\n",
      "Epoch 785/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2004\n",
      "Epoch 786/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1069\n",
      "Epoch 787/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.8764\n",
      "Epoch 788/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 11.1253\n",
      "Epoch 789/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.8559\n",
      "Epoch 790/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.1516\n",
      "Epoch 791/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.6931\n",
      "Epoch 792/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.1858\n",
      "Epoch 793/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.8568\n",
      "Epoch 794/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.1753\n",
      "Epoch 795/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.5046\n",
      "Epoch 796/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.1086\n",
      "Epoch 797/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.4965\n",
      "Epoch 798/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.8512\n",
      "Epoch 799/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.6194\n",
      "Epoch 800/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 13.0956\n",
      "Epoch 801/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.7364\n",
      "Epoch 802/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.9956\n",
      "Epoch 803/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.9513\n",
      "Epoch 804/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.2882\n",
      "Epoch 805/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.1334\n",
      "Epoch 806/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.7025\n",
      "Epoch 807/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.3587\n",
      "Epoch 808/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.2692\n",
      "Epoch 809/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.7519\n",
      "Epoch 810/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.3974\n",
      "Epoch 811/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.9440\n",
      "Epoch 812/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.4303\n",
      "Epoch 813/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.4052\n",
      "Epoch 814/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.3600\n",
      "Epoch 815/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.7704\n",
      "Epoch 816/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9300\n",
      "Epoch 817/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.7989\n",
      "Epoch 818/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.6598\n",
      "Epoch 819/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1551\n",
      "Epoch 820/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.8410\n",
      "Epoch 821/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.3040\n",
      "Epoch 822/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.3764\n",
      "Epoch 823/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.9316\n",
      "Epoch 824/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.3108\n",
      "Epoch 825/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.4731\n",
      "Epoch 826/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.7004\n",
      "Epoch 827/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.6063\n",
      "Epoch 828/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.5136\n",
      "Epoch 829/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.6322\n",
      "Epoch 830/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.2018\n",
      "Epoch 831/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.0385\n",
      "Epoch 832/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.1106\n",
      "Epoch 833/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.1307\n",
      "Epoch 834/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.6930\n",
      "Epoch 835/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.9695\n",
      "Epoch 836/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.2673\n",
      "Epoch 837/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.9332\n",
      "Epoch 838/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.7438\n",
      "Epoch 839/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 12.4586\n",
      "Epoch 840/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 11.2174\n",
      "Epoch 841/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.7867\n",
      "Epoch 842/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.0836\n",
      "Epoch 843/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.9254\n",
      "Epoch 844/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.0244\n",
      "Epoch 845/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.2865\n",
      "Epoch 846/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.1882\n",
      "Epoch 847/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.4048\n",
      "Epoch 848/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.9243\n",
      "Epoch 849/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 11.0321\n",
      "Epoch 850/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.9799\n",
      "Epoch 851/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 11.4170\n",
      "Epoch 852/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.4968\n",
      "Epoch 853/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.5388\n",
      "Epoch 854/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.5253\n",
      "Epoch 855/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.9909\n",
      "Epoch 856/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.6206\n",
      "Epoch 857/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.1670\n",
      "Epoch 858/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.3062\n",
      "Epoch 859/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.2384\n",
      "Epoch 860/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.9398\n",
      "Epoch 861/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.9037\n",
      "Epoch 862/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7976\n",
      "Epoch 863/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.0826\n",
      "Epoch 864/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.5857\n",
      "Epoch 865/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.5914\n",
      "Epoch 866/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1358\n",
      "Epoch 867/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.6556\n",
      "Epoch 868/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.1363\n",
      "Epoch 869/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.0290\n",
      "Epoch 870/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.1612\n",
      "Epoch 871/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 10.0323\n",
      "Epoch 872/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.0171\n",
      "Epoch 873/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.5516\n",
      "Epoch 874/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.3982\n",
      "Epoch 875/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.6972\n",
      "Epoch 876/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.2502\n",
      "Epoch 877/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2264\n",
      "Epoch 878/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 11.0356\n",
      "Epoch 879/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.5573\n",
      "Epoch 880/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.2363\n",
      "Epoch 881/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.9447\n",
      "Epoch 882/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.3467\n",
      "Epoch 883/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.6445\n",
      "Epoch 884/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6925\n",
      "Epoch 885/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.3530\n",
      "Epoch 886/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.5719\n",
      "Epoch 887/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.5669\n",
      "Epoch 888/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.7507\n",
      "Epoch 889/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.6450\n",
      "Epoch 890/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.1994\n",
      "Epoch 891/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.6480\n",
      "Epoch 892/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.9388\n",
      "Epoch 893/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.7083\n",
      "Epoch 894/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 11.5066\n",
      "Epoch 895/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.2167\n",
      "Epoch 896/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.0170\n",
      "Epoch 897/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.3008\n",
      "Epoch 898/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.6773\n",
      "Epoch 899/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.0801\n",
      "Epoch 900/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.2316\n",
      "Epoch 901/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.3082\n",
      "Epoch 902/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.7168\n",
      "Epoch 903/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.8064\n",
      "Epoch 904/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.1263\n",
      "Epoch 905/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.5371\n",
      "Epoch 906/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.6176\n",
      "Epoch 907/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1766\n",
      "Epoch 908/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4998\n",
      "Epoch 909/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.8531\n",
      "Epoch 910/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 10.9881\n",
      "Epoch 911/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.7958\n",
      "Epoch 912/2000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 10.0084\n",
      "Epoch 913/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 9.8454\n",
      "Epoch 914/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.6758\n",
      "Epoch 915/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.4122\n",
      "Epoch 916/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.4462\n",
      "Epoch 917/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.2554\n",
      "Epoch 918/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.4162\n",
      "Epoch 919/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.1449\n",
      "Epoch 920/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2560\n",
      "Epoch 921/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.9156\n",
      "Epoch 922/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 10.4171\n",
      "Epoch 923/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.1662\n",
      "Epoch 924/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2704\n",
      "Epoch 925/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.2808\n",
      "Epoch 926/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.4677\n",
      "Epoch 927/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.0583\n",
      "Epoch 928/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.8881\n",
      "Epoch 929/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.6787\n",
      "Epoch 930/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.7072\n",
      "Epoch 931/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.2414\n",
      "Epoch 932/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.8621\n",
      "Epoch 933/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.3643\n",
      "Epoch 934/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1406\n",
      "Epoch 935/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.0680\n",
      "Epoch 936/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.4212\n",
      "Epoch 937/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2675\n",
      "Epoch 938/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.3102\n",
      "Epoch 939/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.3254\n",
      "Epoch 940/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.1106\n",
      "Epoch 941/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.5855\n",
      "Epoch 942/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.3093\n",
      "Epoch 943/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.3074\n",
      "Epoch 944/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.2788\n",
      "Epoch 945/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.2323\n",
      "Epoch 946/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.3682\n",
      "Epoch 947/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.8741\n",
      "Epoch 948/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.5185\n",
      "Epoch 949/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.7522\n",
      "Epoch 950/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.7072\n",
      "Epoch 951/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.0335\n",
      "Epoch 952/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5173\n",
      "Epoch 953/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1471\n",
      "Epoch 954/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.2440\n",
      "Epoch 955/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.5556\n",
      "Epoch 956/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3815\n",
      "Epoch 957/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9824\n",
      "Epoch 958/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8684\n",
      "Epoch 959/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7346\n",
      "Epoch 960/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7450\n",
      "Epoch 961/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.2457\n",
      "Epoch 962/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9860\n",
      "Epoch 963/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.8633\n",
      "Epoch 964/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.0187\n",
      "Epoch 965/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.3352\n",
      "Epoch 966/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.5162\n",
      "Epoch 967/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5397\n",
      "Epoch 968/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3421\n",
      "Epoch 969/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.6382\n",
      "Epoch 970/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7986\n",
      "Epoch 971/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.0228\n",
      "Epoch 972/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.4501\n",
      "Epoch 973/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.1835\n",
      "Epoch 974/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2363\n",
      "Epoch 975/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1178\n",
      "Epoch 976/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 10.5943\n",
      "Epoch 977/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.2959\n",
      "Epoch 978/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.8833\n",
      "Epoch 979/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6988\n",
      "Epoch 980/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.0306\n",
      "Epoch 981/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.0580\n",
      "Epoch 982/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.1296\n",
      "Epoch 983/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.3567\n",
      "Epoch 984/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.3010\n",
      "Epoch 985/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.5163\n",
      "Epoch 986/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9367\n",
      "Epoch 987/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.6070\n",
      "Epoch 988/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.3982\n",
      "Epoch 989/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2004\n",
      "Epoch 990/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9781\n",
      "Epoch 991/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5343\n",
      "Epoch 992/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.6797\n",
      "Epoch 993/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.8766\n",
      "Epoch 994/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6230\n",
      "Epoch 995/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2444\n",
      "Epoch 996/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9281\n",
      "Epoch 997/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.7484\n",
      "Epoch 998/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.3235\n",
      "Epoch 999/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.3389\n",
      "Epoch 1000/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 12.0972\n",
      "Epoch 1001/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.8880\n",
      "Epoch 1002/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 11.5081\n",
      "Epoch 1003/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.5679\n",
      "Epoch 1004/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.5487\n",
      "Epoch 1005/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.5787\n",
      "Epoch 1006/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4121\n",
      "Epoch 1007/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2429\n",
      "Epoch 1008/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.1615\n",
      "Epoch 1009/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6448\n",
      "Epoch 1010/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.8813\n",
      "Epoch 1011/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7853\n",
      "Epoch 1012/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.9019\n",
      "Epoch 1013/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.5408\n",
      "Epoch 1014/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2224\n",
      "Epoch 1015/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.7122\n",
      "Epoch 1016/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.1812\n",
      "Epoch 1017/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.5804\n",
      "Epoch 1018/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.1084\n",
      "Epoch 1019/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.7501\n",
      "Epoch 1020/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.6760\n",
      "Epoch 1021/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.5440\n",
      "Epoch 1022/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.3422\n",
      "Epoch 1023/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.7466\n",
      "Epoch 1024/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.7455\n",
      "Epoch 1025/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.8075\n",
      "Epoch 1026/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.8522\n",
      "Epoch 1027/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.8361\n",
      "Epoch 1028/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.7482\n",
      "Epoch 1029/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.5277\n",
      "Epoch 1030/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.2620\n",
      "Epoch 1031/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.3255\n",
      "Epoch 1032/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 10.1692\n",
      "Epoch 1033/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.6223\n",
      "Epoch 1034/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.8372\n",
      "Epoch 1035/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.9450\n",
      "Epoch 1036/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 8.9227\n",
      "Epoch 1037/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.8385\n",
      "Epoch 1038/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.1874\n",
      "Epoch 1039/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3621\n",
      "Epoch 1040/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.6726\n",
      "Epoch 1041/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.7364\n",
      "Epoch 1042/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.1401\n",
      "Epoch 1043/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9883\n",
      "Epoch 1044/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.8038\n",
      "Epoch 1045/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.3674\n",
      "Epoch 1046/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.6086\n",
      "Epoch 1047/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.0187\n",
      "Epoch 1048/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.0734\n",
      "Epoch 1049/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4586\n",
      "Epoch 1050/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.4687\n",
      "Epoch 1051/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.0725\n",
      "Epoch 1052/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.4489\n",
      "Epoch 1053/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9993\n",
      "Epoch 1054/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.3244\n",
      "Epoch 1055/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8270\n",
      "Epoch 1056/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6140\n",
      "Epoch 1057/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.0429\n",
      "Epoch 1058/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.3477\n",
      "Epoch 1059/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9873\n",
      "Epoch 1060/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6558\n",
      "Epoch 1061/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.3239\n",
      "Epoch 1062/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.8176\n",
      "Epoch 1063/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.8537\n",
      "Epoch 1064/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.1672\n",
      "Epoch 1065/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3929\n",
      "Epoch 1066/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.3970\n",
      "Epoch 1067/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.0406\n",
      "Epoch 1068/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8255\n",
      "Epoch 1069/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7025\n",
      "Epoch 1070/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5831\n",
      "Epoch 1071/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.2411\n",
      "Epoch 1072/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8958\n",
      "Epoch 1073/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.5746\n",
      "Epoch 1074/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.9358\n",
      "Epoch 1075/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.0100\n",
      "Epoch 1076/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5608\n",
      "Epoch 1077/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8491\n",
      "Epoch 1078/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.5594\n",
      "Epoch 1079/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.5756\n",
      "Epoch 1080/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3741\n",
      "Epoch 1081/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2451\n",
      "Epoch 1082/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5029\n",
      "Epoch 1083/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5848\n",
      "Epoch 1084/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8750\n",
      "Epoch 1085/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9366\n",
      "Epoch 1086/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.2761\n",
      "Epoch 1087/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8825\n",
      "Epoch 1088/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.3679\n",
      "Epoch 1089/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8059\n",
      "Epoch 1090/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.1344\n",
      "Epoch 1091/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.5200\n",
      "Epoch 1092/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6944\n",
      "Epoch 1093/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9027\n",
      "Epoch 1094/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.3510\n",
      "Epoch 1095/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6294\n",
      "Epoch 1096/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6797\n",
      "Epoch 1097/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6238\n",
      "Epoch 1098/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.1600\n",
      "Epoch 1099/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.1172\n",
      "Epoch 1100/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.4112\n",
      "Epoch 1101/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9240\n",
      "Epoch 1102/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1764\n",
      "Epoch 1103/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.0539\n",
      "Epoch 1104/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4076\n",
      "Epoch 1105/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6761\n",
      "Epoch 1106/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4031\n",
      "Epoch 1107/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.2307\n",
      "Epoch 1108/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2954\n",
      "Epoch 1109/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.5800\n",
      "Epoch 1110/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8572\n",
      "Epoch 1111/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.5459\n",
      "Epoch 1112/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8117\n",
      "Epoch 1113/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.6231\n",
      "Epoch 1114/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.4435\n",
      "Epoch 1115/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0362\n",
      "Epoch 1116/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2466\n",
      "Epoch 1117/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4223\n",
      "Epoch 1118/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9320\n",
      "Epoch 1119/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.8351\n",
      "Epoch 1120/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1036\n",
      "Epoch 1121/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4075\n",
      "Epoch 1122/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7535\n",
      "Epoch 1123/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.8959\n",
      "Epoch 1124/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.7709\n",
      "Epoch 1125/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.2539\n",
      "Epoch 1126/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6240\n",
      "Epoch 1127/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8305\n",
      "Epoch 1128/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.7459\n",
      "Epoch 1129/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.7728\n",
      "Epoch 1130/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9561\n",
      "Epoch 1131/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0306\n",
      "Epoch 1132/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.0216\n",
      "Epoch 1133/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.3426\n",
      "Epoch 1134/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7420\n",
      "Epoch 1135/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6356\n",
      "Epoch 1136/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.2506\n",
      "Epoch 1137/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6378\n",
      "Epoch 1138/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.0419\n",
      "Epoch 1139/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3261\n",
      "Epoch 1140/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.3815\n",
      "Epoch 1141/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3688\n",
      "Epoch 1142/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5048\n",
      "Epoch 1143/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4166\n",
      "Epoch 1144/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.2948\n",
      "Epoch 1145/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1202\n",
      "Epoch 1146/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.7527\n",
      "Epoch 1147/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3323\n",
      "Epoch 1148/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7763\n",
      "Epoch 1149/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.8653\n",
      "Epoch 1150/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6620\n",
      "Epoch 1151/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0557\n",
      "Epoch 1152/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2102\n",
      "Epoch 1153/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.4640\n",
      "Epoch 1154/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.7622\n",
      "Epoch 1155/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.8147\n",
      "Epoch 1156/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.0051\n",
      "Epoch 1157/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1725\n",
      "Epoch 1158/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2619\n",
      "Epoch 1159/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.0116\n",
      "Epoch 1160/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.7194\n",
      "Epoch 1161/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.0469\n",
      "Epoch 1162/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.5614\n",
      "Epoch 1163/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9246\n",
      "Epoch 1164/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1706\n",
      "Epoch 1165/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9303\n",
      "Epoch 1166/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.3444\n",
      "Epoch 1167/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.0079\n",
      "Epoch 1168/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.6201\n",
      "Epoch 1169/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9546\n",
      "Epoch 1170/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6522\n",
      "Epoch 1171/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0599\n",
      "Epoch 1172/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1289\n",
      "Epoch 1173/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1542\n",
      "Epoch 1174/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3432\n",
      "Epoch 1175/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.3524\n",
      "Epoch 1176/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.4037\n",
      "Epoch 1177/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.9731\n",
      "Epoch 1178/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.6112\n",
      "Epoch 1179/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1823\n",
      "Epoch 1180/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.1630\n",
      "Epoch 1181/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.0580\n",
      "Epoch 1182/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.6517\n",
      "Epoch 1183/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.2199\n",
      "Epoch 1184/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0960\n",
      "Epoch 1185/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0407\n",
      "Epoch 1186/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.0825\n",
      "Epoch 1187/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.6233\n",
      "Epoch 1188/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 10.1535\n",
      "Epoch 1189/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7532\n",
      "Epoch 1190/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.0657\n",
      "Epoch 1191/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.9494\n",
      "Epoch 1192/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.0663\n",
      "Epoch 1193/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.4643\n",
      "Epoch 1194/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.1087\n",
      "Epoch 1195/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.8570\n",
      "Epoch 1196/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.2383\n",
      "Epoch 1197/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3344\n",
      "Epoch 1198/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7291\n",
      "Epoch 1199/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1275\n",
      "Epoch 1200/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.7238\n",
      "Epoch 1201/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9023\n",
      "Epoch 1202/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4412\n",
      "Epoch 1203/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.1182\n",
      "Epoch 1204/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6796\n",
      "Epoch 1205/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.3805\n",
      "Epoch 1206/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.2358\n",
      "Epoch 1207/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1687\n",
      "Epoch 1208/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.9673\n",
      "Epoch 1209/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2016\n",
      "Epoch 1210/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.8080\n",
      "Epoch 1211/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.5305\n",
      "Epoch 1212/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.9920\n",
      "Epoch 1213/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2963\n",
      "Epoch 1214/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1523\n",
      "Epoch 1215/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.6731\n",
      "Epoch 1216/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.0187\n",
      "Epoch 1217/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9001\n",
      "Epoch 1218/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9106\n",
      "Epoch 1219/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.3369\n",
      "Epoch 1220/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.9459\n",
      "Epoch 1221/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1320\n",
      "Epoch 1222/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5079\n",
      "Epoch 1223/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.9921\n",
      "Epoch 1224/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7022\n",
      "Epoch 1225/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.6079\n",
      "Epoch 1226/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7956\n",
      "Epoch 1227/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.3549\n",
      "Epoch 1228/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5676\n",
      "Epoch 1229/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.5963\n",
      "Epoch 1230/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5424\n",
      "Epoch 1231/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9774\n",
      "Epoch 1232/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0584\n",
      "Epoch 1233/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6081\n",
      "Epoch 1234/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.7063\n",
      "Epoch 1235/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8138\n",
      "Epoch 1236/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7383\n",
      "Epoch 1237/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.5813\n",
      "Epoch 1238/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5841\n",
      "Epoch 1239/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4815\n",
      "Epoch 1240/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.0569\n",
      "Epoch 1241/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4990\n",
      "Epoch 1242/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2874\n",
      "Epoch 1243/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.5828\n",
      "Epoch 1244/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2743\n",
      "Epoch 1245/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.0614\n",
      "Epoch 1246/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7078\n",
      "Epoch 1247/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6471\n",
      "Epoch 1248/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.0536\n",
      "Epoch 1249/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6932\n",
      "Epoch 1250/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7773\n",
      "Epoch 1251/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.6336\n",
      "Epoch 1252/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3136\n",
      "Epoch 1253/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.9935\n",
      "Epoch 1254/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1221\n",
      "Epoch 1255/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.1687\n",
      "Epoch 1256/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.8514\n",
      "Epoch 1257/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.5621\n",
      "Epoch 1258/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.4476\n",
      "Epoch 1259/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.7311\n",
      "Epoch 1260/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4565\n",
      "Epoch 1261/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8353\n",
      "Epoch 1262/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.7845\n",
      "Epoch 1263/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5845\n",
      "Epoch 1264/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.9007\n",
      "Epoch 1265/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4367\n",
      "Epoch 1266/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.7265\n",
      "Epoch 1267/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.5643\n",
      "Epoch 1268/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.8216\n",
      "Epoch 1269/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.4617\n",
      "Epoch 1270/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 8.9932\n",
      "Epoch 1271/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0292\n",
      "Epoch 1272/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.5648\n",
      "Epoch 1273/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2034\n",
      "Epoch 1274/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.5382\n",
      "Epoch 1275/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.9898\n",
      "Epoch 1276/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.7936\n",
      "Epoch 1277/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5243\n",
      "Epoch 1278/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9370\n",
      "Epoch 1279/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2606\n",
      "Epoch 1280/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1114\n",
      "Epoch 1281/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.7221\n",
      "Epoch 1282/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1155\n",
      "Epoch 1283/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.8397\n",
      "Epoch 1284/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6096\n",
      "Epoch 1285/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4910\n",
      "Epoch 1286/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8212\n",
      "Epoch 1287/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.9570\n",
      "Epoch 1288/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.3866\n",
      "Epoch 1289/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.4763\n",
      "Epoch 1290/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2643\n",
      "Epoch 1291/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9014\n",
      "Epoch 1292/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1087\n",
      "Epoch 1293/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.3195\n",
      "Epoch 1294/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.6253\n",
      "Epoch 1295/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9539\n",
      "Epoch 1296/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3254\n",
      "Epoch 1297/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.0956\n",
      "Epoch 1298/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1548\n",
      "Epoch 1299/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3406\n",
      "Epoch 1300/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5160\n",
      "Epoch 1301/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2017\n",
      "Epoch 1302/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6984\n",
      "Epoch 1303/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5542\n",
      "Epoch 1304/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.9264\n",
      "Epoch 1305/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.0811\n",
      "Epoch 1306/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.4224\n",
      "Epoch 1307/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.3224\n",
      "Epoch 1308/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6118\n",
      "Epoch 1309/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4509\n",
      "Epoch 1310/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7105\n",
      "Epoch 1311/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2734\n",
      "Epoch 1312/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4361\n",
      "Epoch 1313/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4073\n",
      "Epoch 1314/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7561\n",
      "Epoch 1315/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6435\n",
      "Epoch 1316/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.3470\n",
      "Epoch 1317/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2297\n",
      "Epoch 1318/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1433\n",
      "Epoch 1319/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.3491\n",
      "Epoch 1320/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.7280\n",
      "Epoch 1321/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2990\n",
      "Epoch 1322/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0573\n",
      "Epoch 1323/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.8237\n",
      "Epoch 1324/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.8914\n",
      "Epoch 1325/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.6869\n",
      "Epoch 1326/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5852\n",
      "Epoch 1327/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0783\n",
      "Epoch 1328/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.9218\n",
      "Epoch 1329/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.0978\n",
      "Epoch 1330/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 8.9438\n",
      "Epoch 1331/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0902\n",
      "Epoch 1332/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4626\n",
      "Epoch 1333/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.4620\n",
      "Epoch 1334/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0111\n",
      "Epoch 1335/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6901\n",
      "Epoch 1336/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4647\n",
      "Epoch 1337/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.9074\n",
      "Epoch 1338/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7678\n",
      "Epoch 1339/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.3090\n",
      "Epoch 1340/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.4448\n",
      "Epoch 1341/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.5706\n",
      "Epoch 1342/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.2141\n",
      "Epoch 1343/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.1855\n",
      "Epoch 1344/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.3043\n",
      "Epoch 1345/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.6213\n",
      "Epoch 1346/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.1184\n",
      "Epoch 1347/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.1767\n",
      "Epoch 1348/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6058\n",
      "Epoch 1349/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 8.9574\n",
      "Epoch 1350/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.8724\n",
      "Epoch 1351/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.2295\n",
      "Epoch 1352/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0750\n",
      "Epoch 1353/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 8.7877\n",
      "Epoch 1354/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.2330\n",
      "Epoch 1355/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.3649\n",
      "Epoch 1356/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.7849\n",
      "Epoch 1357/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.7948\n",
      "Epoch 1358/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.5436\n",
      "Epoch 1359/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.8164\n",
      "Epoch 1360/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.5490\n",
      "Epoch 1361/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9642\n",
      "Epoch 1362/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.0073\n",
      "Epoch 1363/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6121\n",
      "Epoch 1364/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.8705\n",
      "Epoch 1365/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.0903\n",
      "Epoch 1366/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1031\n",
      "Epoch 1367/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.1046\n",
      "Epoch 1368/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8680\n",
      "Epoch 1369/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.7140\n",
      "Epoch 1370/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3588\n",
      "Epoch 1371/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1967\n",
      "Epoch 1372/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2212\n",
      "Epoch 1373/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.1413\n",
      "Epoch 1374/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.8241\n",
      "Epoch 1375/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6988\n",
      "Epoch 1376/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3119\n",
      "Epoch 1377/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.8632\n",
      "Epoch 1378/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6433\n",
      "Epoch 1379/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6422\n",
      "Epoch 1380/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4784\n",
      "Epoch 1381/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4884\n",
      "Epoch 1382/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.5573\n",
      "Epoch 1383/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1866\n",
      "Epoch 1384/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.6574\n",
      "Epoch 1385/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.2358\n",
      "Epoch 1386/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 8.9578\n",
      "Epoch 1387/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.1293\n",
      "Epoch 1388/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.3330\n",
      "Epoch 1389/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.7120\n",
      "Epoch 1390/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.0418\n",
      "Epoch 1391/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.6192\n",
      "Epoch 1392/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9730\n",
      "Epoch 1393/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.4496\n",
      "Epoch 1394/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.5181\n",
      "Epoch 1395/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9107\n",
      "Epoch 1396/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.5959\n",
      "Epoch 1397/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3353\n",
      "Epoch 1398/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.8023\n",
      "Epoch 1399/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8102\n",
      "Epoch 1400/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9958\n",
      "Epoch 1401/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0171\n",
      "Epoch 1402/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7327\n",
      "Epoch 1403/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2255\n",
      "Epoch 1404/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.7933\n",
      "Epoch 1405/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.9361\n",
      "Epoch 1406/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.5639\n",
      "Epoch 1407/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2006\n",
      "Epoch 1408/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4121\n",
      "Epoch 1409/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1145\n",
      "Epoch 1410/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8445\n",
      "Epoch 1411/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6707\n",
      "Epoch 1412/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3723\n",
      "Epoch 1413/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2184\n",
      "Epoch 1414/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8476\n",
      "Epoch 1415/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2103\n",
      "Epoch 1416/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9571\n",
      "Epoch 1417/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.9213\n",
      "Epoch 1418/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1348\n",
      "Epoch 1419/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5125\n",
      "Epoch 1420/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 8.7148\n",
      "Epoch 1421/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.5659\n",
      "Epoch 1422/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.4112\n",
      "Epoch 1423/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 10.3348\n",
      "Epoch 1424/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.9087\n",
      "Epoch 1425/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.4710\n",
      "Epoch 1426/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.7738\n",
      "Epoch 1427/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 8.9985\n",
      "Epoch 1428/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 8.8059\n",
      "Epoch 1429/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.6714\n",
      "Epoch 1430/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.7589\n",
      "Epoch 1431/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.0169\n",
      "Epoch 1432/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.5876\n",
      "Epoch 1433/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.2619\n",
      "Epoch 1434/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.3217\n",
      "Epoch 1435/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8794\n",
      "Epoch 1436/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3682\n",
      "Epoch 1437/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6462\n",
      "Epoch 1438/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.0809\n",
      "Epoch 1439/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4872\n",
      "Epoch 1440/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9189\n",
      "Epoch 1441/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.6901\n",
      "Epoch 1442/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.6276\n",
      "Epoch 1443/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3862\n",
      "Epoch 1444/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6570\n",
      "Epoch 1445/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.8157\n",
      "Epoch 1446/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 8.9088\n",
      "Epoch 1447/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.5729\n",
      "Epoch 1448/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.9177\n",
      "Epoch 1449/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.6399\n",
      "Epoch 1450/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.6196\n",
      "Epoch 1451/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.2450\n",
      "Epoch 1452/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.7276\n",
      "Epoch 1453/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.7643\n",
      "Epoch 1454/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.9274\n",
      "Epoch 1455/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4196\n",
      "Epoch 1456/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1051\n",
      "Epoch 1457/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5047\n",
      "Epoch 1458/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4315\n",
      "Epoch 1459/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7761\n",
      "Epoch 1460/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4186\n",
      "Epoch 1461/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1885\n",
      "Epoch 1462/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5792\n",
      "Epoch 1463/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6793\n",
      "Epoch 1464/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4528\n",
      "Epoch 1465/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3228\n",
      "Epoch 1466/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.4172\n",
      "Epoch 1467/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2454\n",
      "Epoch 1468/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0376\n",
      "Epoch 1469/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 8.9702\n",
      "Epoch 1470/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2011\n",
      "Epoch 1471/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9324\n",
      "Epoch 1472/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.4611\n",
      "Epoch 1473/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2463\n",
      "Epoch 1474/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1435\n",
      "Epoch 1475/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1592\n",
      "Epoch 1476/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1978\n",
      "Epoch 1477/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6922\n",
      "Epoch 1478/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.8906\n",
      "Epoch 1479/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4244\n",
      "Epoch 1480/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1180\n",
      "Epoch 1481/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1569\n",
      "Epoch 1482/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0378\n",
      "Epoch 1483/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.4636\n",
      "Epoch 1484/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3238\n",
      "Epoch 1485/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4996\n",
      "Epoch 1486/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.0249\n",
      "Epoch 1487/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2679\n",
      "Epoch 1488/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.0344\n",
      "Epoch 1489/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3856\n",
      "Epoch 1490/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6614\n",
      "Epoch 1491/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.0151\n",
      "Epoch 1492/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3081\n",
      "Epoch 1493/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.5980\n",
      "Epoch 1494/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5199\n",
      "Epoch 1495/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.5521\n",
      "Epoch 1496/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 8.9663\n",
      "Epoch 1497/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.9611\n",
      "Epoch 1498/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0453\n",
      "Epoch 1499/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3782\n",
      "Epoch 1500/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3094\n",
      "Epoch 1501/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.8734\n",
      "Epoch 1502/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.8257\n",
      "Epoch 1503/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3457\n",
      "Epoch 1504/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.3056\n",
      "Epoch 1505/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4781\n",
      "Epoch 1506/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3257\n",
      "Epoch 1507/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8162\n",
      "Epoch 1508/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3485\n",
      "Epoch 1509/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7450\n",
      "Epoch 1510/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.8320\n",
      "Epoch 1511/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1736\n",
      "Epoch 1512/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.8493\n",
      "Epoch 1513/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1685\n",
      "Epoch 1514/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6874\n",
      "Epoch 1515/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4260\n",
      "Epoch 1516/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.3164\n",
      "Epoch 1517/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.3835\n",
      "Epoch 1518/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6322\n",
      "Epoch 1519/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.4150\n",
      "Epoch 1520/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.3239\n",
      "Epoch 1521/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 11.2070\n",
      "Epoch 1522/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2002\n",
      "Epoch 1523/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.6710\n",
      "Epoch 1524/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.3739\n",
      "Epoch 1525/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.9377\n",
      "Epoch 1526/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5728\n",
      "Epoch 1527/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.3924\n",
      "Epoch 1528/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3603\n",
      "Epoch 1529/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.3452\n",
      "Epoch 1530/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8498\n",
      "Epoch 1531/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2365\n",
      "Epoch 1532/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4316\n",
      "Epoch 1533/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.9520\n",
      "Epoch 1534/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.0886\n",
      "Epoch 1535/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1992\n",
      "Epoch 1536/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.5218\n",
      "Epoch 1537/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2751\n",
      "Epoch 1538/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2117\n",
      "Epoch 1539/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4999\n",
      "Epoch 1540/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.0116\n",
      "Epoch 1541/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.0853\n",
      "Epoch 1542/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3635\n",
      "Epoch 1543/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.2068\n",
      "Epoch 1544/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.6414\n",
      "Epoch 1545/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1153\n",
      "Epoch 1546/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0548\n",
      "Epoch 1547/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.8886\n",
      "Epoch 1548/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2315\n",
      "Epoch 1549/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.9412\n",
      "Epoch 1550/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1813\n",
      "Epoch 1551/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8199\n",
      "Epoch 1552/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6201\n",
      "Epoch 1553/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2863\n",
      "Epoch 1554/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.0723\n",
      "Epoch 1555/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3487\n",
      "Epoch 1556/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.7725\n",
      "Epoch 1557/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0206\n",
      "Epoch 1558/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 8.6560\n",
      "Epoch 1559/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.6971\n",
      "Epoch 1560/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0249\n",
      "Epoch 1561/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.3543\n",
      "Epoch 1562/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.4454\n",
      "Epoch 1563/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.4830\n",
      "Epoch 1564/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.6166\n",
      "Epoch 1565/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.7157\n",
      "Epoch 1566/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.0780\n",
      "Epoch 1567/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.5111\n",
      "Epoch 1568/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.7790\n",
      "Epoch 1569/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.0780\n",
      "Epoch 1570/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5460\n",
      "Epoch 1571/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.7140\n",
      "Epoch 1572/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.5088\n",
      "Epoch 1573/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.0211\n",
      "Epoch 1574/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7483\n",
      "Epoch 1575/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4111\n",
      "Epoch 1576/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.5254\n",
      "Epoch 1577/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6819\n",
      "Epoch 1578/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2850\n",
      "Epoch 1579/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1369\n",
      "Epoch 1580/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.4412\n",
      "Epoch 1581/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4765\n",
      "Epoch 1582/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.7749\n",
      "Epoch 1583/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1228\n",
      "Epoch 1584/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.7379\n",
      "Epoch 1585/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5470\n",
      "Epoch 1586/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2752\n",
      "Epoch 1587/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.7288\n",
      "Epoch 1588/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6515\n",
      "Epoch 1589/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1450\n",
      "Epoch 1590/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2808\n",
      "Epoch 1591/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.7018\n",
      "Epoch 1592/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 8.8930\n",
      "Epoch 1593/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.1247\n",
      "Epoch 1594/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.5425\n",
      "Epoch 1595/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2965\n",
      "Epoch 1596/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1931\n",
      "Epoch 1597/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.9087\n",
      "Epoch 1598/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.9497\n",
      "Epoch 1599/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.8243\n",
      "Epoch 1600/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8043\n",
      "Epoch 1601/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.8607\n",
      "Epoch 1602/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.8672\n",
      "Epoch 1603/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2055\n",
      "Epoch 1604/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2651\n",
      "Epoch 1605/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4054\n",
      "Epoch 1606/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.8019\n",
      "Epoch 1607/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7906\n",
      "Epoch 1608/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.2727\n",
      "Epoch 1609/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9462\n",
      "Epoch 1610/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.9085\n",
      "Epoch 1611/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.3069\n",
      "Epoch 1612/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6334\n",
      "Epoch 1613/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.7165\n",
      "Epoch 1614/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.7364\n",
      "Epoch 1615/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 8.8974\n",
      "Epoch 1616/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.5846\n",
      "Epoch 1617/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.0996\n",
      "Epoch 1618/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.7975\n",
      "Epoch 1619/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.7151\n",
      "Epoch 1620/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.3063\n",
      "Epoch 1621/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.4689\n",
      "Epoch 1622/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.0878\n",
      "Epoch 1623/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.1876\n",
      "Epoch 1624/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.3772\n",
      "Epoch 1625/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.3710\n",
      "Epoch 1626/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 8.9542\n",
      "Epoch 1627/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.9923\n",
      "Epoch 1628/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 10.6331\n",
      "Epoch 1629/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 10.3647\n",
      "Epoch 1630/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 8.8215\n",
      "Epoch 1631/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.1994\n",
      "Epoch 1632/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.6842\n",
      "Epoch 1633/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.4983\n",
      "Epoch 1634/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.3348\n",
      "Epoch 1635/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.4804\n",
      "Epoch 1636/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.2067\n",
      "Epoch 1637/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.9962\n",
      "Epoch 1638/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4177\n",
      "Epoch 1639/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6763\n",
      "Epoch 1640/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.1432\n",
      "Epoch 1641/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0268\n",
      "Epoch 1642/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.9162\n",
      "Epoch 1643/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7336\n",
      "Epoch 1644/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.1543\n",
      "Epoch 1645/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.4826\n",
      "Epoch 1646/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9970\n",
      "Epoch 1647/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6383\n",
      "Epoch 1648/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2883\n",
      "Epoch 1649/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6701\n",
      "Epoch 1650/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 11.1841\n",
      "Epoch 1651/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6870\n",
      "Epoch 1652/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.7333\n",
      "Epoch 1653/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0051\n",
      "Epoch 1654/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1707\n",
      "Epoch 1655/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.2089\n",
      "Epoch 1656/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6604\n",
      "Epoch 1657/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.5465\n",
      "Epoch 1658/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1888\n",
      "Epoch 1659/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.7267\n",
      "Epoch 1660/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.5102\n",
      "Epoch 1661/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.0981\n",
      "Epoch 1662/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.1462\n",
      "Epoch 1663/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0811\n",
      "Epoch 1664/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7782\n",
      "Epoch 1665/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.0439\n",
      "Epoch 1666/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.2651\n",
      "Epoch 1667/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3823\n",
      "Epoch 1668/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.9086\n",
      "Epoch 1669/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.4884\n",
      "Epoch 1670/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.5818\n",
      "Epoch 1671/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.8033\n",
      "Epoch 1672/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.3646\n",
      "Epoch 1673/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.7746\n",
      "Epoch 1674/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.3368\n",
      "Epoch 1675/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7493\n",
      "Epoch 1676/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.6476\n",
      "Epoch 1677/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3170\n",
      "Epoch 1678/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2712\n",
      "Epoch 1679/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.0878\n",
      "Epoch 1680/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1734\n",
      "Epoch 1681/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9653\n",
      "Epoch 1682/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.5438\n",
      "Epoch 1683/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4644\n",
      "Epoch 1684/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.6394\n",
      "Epoch 1685/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.7102\n",
      "Epoch 1686/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2607\n",
      "Epoch 1687/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1189\n",
      "Epoch 1688/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3083\n",
      "Epoch 1689/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9085\n",
      "Epoch 1690/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3956\n",
      "Epoch 1691/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4518\n",
      "Epoch 1692/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7224\n",
      "Epoch 1693/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.5414\n",
      "Epoch 1694/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.8338\n",
      "Epoch 1695/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.5389\n",
      "Epoch 1696/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8264\n",
      "Epoch 1697/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9629\n",
      "Epoch 1698/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3617\n",
      "Epoch 1699/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7157\n",
      "Epoch 1700/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1160\n",
      "Epoch 1701/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.3315\n",
      "Epoch 1702/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3516\n",
      "Epoch 1703/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.6137\n",
      "Epoch 1704/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.2779\n",
      "Epoch 1705/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3708\n",
      "Epoch 1706/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2344\n",
      "Epoch 1707/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1390\n",
      "Epoch 1708/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0127\n",
      "Epoch 1709/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4846\n",
      "Epoch 1710/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8441\n",
      "Epoch 1711/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9190\n",
      "Epoch 1712/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 11.2764\n",
      "Epoch 1713/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.4609\n",
      "Epoch 1714/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.7332\n",
      "Epoch 1715/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4772\n",
      "Epoch 1716/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 8.9017\n",
      "Epoch 1717/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1438\n",
      "Epoch 1718/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.5044\n",
      "Epoch 1719/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4880\n",
      "Epoch 1720/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3405\n",
      "Epoch 1721/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.9790\n",
      "Epoch 1722/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.1404\n",
      "Epoch 1723/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4067\n",
      "Epoch 1724/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1412\n",
      "Epoch 1725/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1250\n",
      "Epoch 1726/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1712\n",
      "Epoch 1727/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.5476\n",
      "Epoch 1728/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4074\n",
      "Epoch 1729/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.1764\n",
      "Epoch 1730/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 9.3058\n",
      "Epoch 1731/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 9.3453\n",
      "Epoch 1732/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.4722\n",
      "Epoch 1733/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.2166\n",
      "Epoch 1734/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.0687\n",
      "Epoch 1735/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.6872\n",
      "Epoch 1736/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3165\n",
      "Epoch 1737/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.1107\n",
      "Epoch 1738/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5595\n",
      "Epoch 1739/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.9279\n",
      "Epoch 1740/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.3341\n",
      "Epoch 1741/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1347\n",
      "Epoch 1742/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.9809\n",
      "Epoch 1743/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3952\n",
      "Epoch 1744/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.0742\n",
      "Epoch 1745/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1791\n",
      "Epoch 1746/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7251\n",
      "Epoch 1747/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.2486\n",
      "Epoch 1748/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.4265\n",
      "Epoch 1749/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.0066\n",
      "Epoch 1750/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.7457\n",
      "Epoch 1751/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.9379\n",
      "Epoch 1752/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 8.8648\n",
      "Epoch 1753/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 10.2347\n",
      "Epoch 1754/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.7346\n",
      "Epoch 1755/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 10.6489\n",
      "Epoch 1756/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.2882\n",
      "Epoch 1757/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3344\n",
      "Epoch 1758/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.9452\n",
      "Epoch 1759/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2528\n",
      "Epoch 1760/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3352\n",
      "Epoch 1761/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2656\n",
      "Epoch 1762/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.9138\n",
      "Epoch 1763/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.1152\n",
      "Epoch 1764/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.8280\n",
      "Epoch 1765/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.0575\n",
      "Epoch 1766/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2571\n",
      "Epoch 1767/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.0208\n",
      "Epoch 1768/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 8.9564\n",
      "Epoch 1769/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0252\n",
      "Epoch 1770/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3014\n",
      "Epoch 1771/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.6155\n",
      "Epoch 1772/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.9512\n",
      "Epoch 1773/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.0466\n",
      "Epoch 1774/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.7193\n",
      "Epoch 1775/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2702\n",
      "Epoch 1776/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.7248\n",
      "Epoch 1777/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.2938\n",
      "Epoch 1778/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 9.0277\n",
      "Epoch 1779/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.3246\n",
      "Epoch 1780/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.7311\n",
      "Epoch 1781/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.3781\n",
      "Epoch 1782/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.8093\n",
      "Epoch 1783/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.3089\n",
      "Epoch 1784/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.8925\n",
      "Epoch 1785/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6458\n",
      "Epoch 1786/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8780\n",
      "Epoch 1787/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4114\n",
      "Epoch 1788/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.9521\n",
      "Epoch 1789/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.6470\n",
      "Epoch 1790/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.6704\n",
      "Epoch 1791/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.9137\n",
      "Epoch 1792/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.5894\n",
      "Epoch 1793/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4244\n",
      "Epoch 1794/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.1225\n",
      "Epoch 1795/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.7526\n",
      "Epoch 1796/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6644\n",
      "Epoch 1797/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3581\n",
      "Epoch 1798/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.7674\n",
      "Epoch 1799/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0993\n",
      "Epoch 1800/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0507\n",
      "Epoch 1801/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.2268\n",
      "Epoch 1802/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.0986\n",
      "Epoch 1803/2000\n",
      "1883/1883 [==============================] - 0s 9us/step - loss: 9.7402\n",
      "Epoch 1804/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.6352\n",
      "Epoch 1805/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.3187\n",
      "Epoch 1806/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 9.4282\n",
      "Epoch 1807/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.3158\n",
      "Epoch 1808/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0397\n",
      "Epoch 1809/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 8.6504\n",
      "Epoch 1810/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 10.3298\n",
      "Epoch 1811/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.2829\n",
      "Epoch 1812/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.5028\n",
      "Epoch 1813/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.0358\n",
      "Epoch 1814/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 8.8398\n",
      "Epoch 1815/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 8.8771\n",
      "Epoch 1816/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.8965\n",
      "Epoch 1817/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.2140\n",
      "Epoch 1818/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.1094\n",
      "Epoch 1819/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.3818\n",
      "Epoch 1820/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3788\n",
      "Epoch 1821/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3043\n",
      "Epoch 1822/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.9871\n",
      "Epoch 1823/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.6038\n",
      "Epoch 1824/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4523\n",
      "Epoch 1825/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 8.7253\n",
      "Epoch 1826/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.8087\n",
      "Epoch 1827/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1193\n",
      "Epoch 1828/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.0445\n",
      "Epoch 1829/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.8789\n",
      "Epoch 1830/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0994\n",
      "Epoch 1831/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.1789\n",
      "Epoch 1832/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 8.6501\n",
      "Epoch 1833/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.8507\n",
      "Epoch 1834/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.4465\n",
      "Epoch 1835/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 8.7050\n",
      "Epoch 1836/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0147\n",
      "Epoch 1837/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.2786\n",
      "Epoch 1838/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.4877\n",
      "Epoch 1839/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0977\n",
      "Epoch 1840/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6361\n",
      "Epoch 1841/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.6875\n",
      "Epoch 1842/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.4327\n",
      "Epoch 1843/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.1167\n",
      "Epoch 1844/2000\n",
      "1883/1883 [==============================] - 0s 19us/step - loss: 9.3834\n",
      "Epoch 1845/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 9.3081\n",
      "Epoch 1846/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 8.8590\n",
      "Epoch 1847/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 8.8758\n",
      "Epoch 1848/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 8.9680\n",
      "Epoch 1849/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.4091\n",
      "Epoch 1850/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1882\n",
      "Epoch 1851/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.5859\n",
      "Epoch 1852/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3292\n",
      "Epoch 1853/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6014\n",
      "Epoch 1854/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.3408\n",
      "Epoch 1855/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.3666\n",
      "Epoch 1856/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.6677\n",
      "Epoch 1857/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.4728\n",
      "Epoch 1858/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.2760\n",
      "Epoch 1859/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.0889\n",
      "Epoch 1860/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.0071\n",
      "Epoch 1861/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 8.6480\n",
      "Epoch 1862/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3498\n",
      "Epoch 1863/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.7177\n",
      "Epoch 1864/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1910\n",
      "Epoch 1865/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.9239\n",
      "Epoch 1866/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 8.9860\n",
      "Epoch 1867/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3500\n",
      "Epoch 1868/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.7820\n",
      "Epoch 1869/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.2913\n",
      "Epoch 1870/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.1977\n",
      "Epoch 1871/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1350\n",
      "Epoch 1872/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.9520\n",
      "Epoch 1873/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.7403\n",
      "Epoch 1874/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4670\n",
      "Epoch 1875/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3558\n",
      "Epoch 1876/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.3839\n",
      "Epoch 1877/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.1861\n",
      "Epoch 1878/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.2812\n",
      "Epoch 1879/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.5059\n",
      "Epoch 1880/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.6719\n",
      "Epoch 1881/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0031\n",
      "Epoch 1882/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0721\n",
      "Epoch 1883/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.0805\n",
      "Epoch 1884/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9683\n",
      "Epoch 1885/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.4514\n",
      "Epoch 1886/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 8.6959\n",
      "Epoch 1887/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7828\n",
      "Epoch 1888/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.7071\n",
      "Epoch 1889/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 8.9306\n",
      "Epoch 1890/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.8097\n",
      "Epoch 1891/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.0620\n",
      "Epoch 1892/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 9.9150\n",
      "Epoch 1893/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 8.5599\n",
      "Epoch 1894/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 10.9378\n",
      "Epoch 1895/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.8248\n",
      "Epoch 1896/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 8.9712\n",
      "Epoch 1897/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.0639\n",
      "Epoch 1898/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.0094\n",
      "Epoch 1899/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.3608\n",
      "Epoch 1900/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.0897\n",
      "Epoch 1901/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.1423\n",
      "Epoch 1902/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.6773\n",
      "Epoch 1903/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.5841\n",
      "Epoch 1904/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3784\n",
      "Epoch 1905/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.4028\n",
      "Epoch 1906/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0942\n",
      "Epoch 1907/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.2910\n",
      "Epoch 1908/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.5739\n",
      "Epoch 1909/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.6136\n",
      "Epoch 1910/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.3352\n",
      "Epoch 1911/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.1531\n",
      "Epoch 1912/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 9.0478\n",
      "Epoch 1913/2000\n",
      "1883/1883 [==============================] - 0s 19us/step - loss: 9.2877\n",
      "Epoch 1914/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 9.6542\n",
      "Epoch 1915/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 9.3466\n",
      "Epoch 1916/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 9.8083\n",
      "Epoch 1917/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 9.5199\n",
      "Epoch 1918/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 9.5053\n",
      "Epoch 1919/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.5499\n",
      "Epoch 1920/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.6445\n",
      "Epoch 1921/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.5618\n",
      "Epoch 1922/2000\n",
      "1883/1883 [==============================] - 0s 18us/step - loss: 9.3441\n",
      "Epoch 1923/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.0683\n",
      "Epoch 1924/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.1540\n",
      "Epoch 1925/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.4929\n",
      "Epoch 1926/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 10.1093\n",
      "Epoch 1927/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 8.9719\n",
      "Epoch 1928/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.5868\n",
      "Epoch 1929/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1197\n",
      "Epoch 1930/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.5044\n",
      "Epoch 1931/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.0250\n",
      "Epoch 1932/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 8.8515\n",
      "Epoch 1933/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 9.6351\n",
      "Epoch 1934/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.7723\n",
      "Epoch 1935/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 8.8282\n",
      "Epoch 1936/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.5372\n",
      "Epoch 1937/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 10.1174\n",
      "Epoch 1938/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.2658\n",
      "Epoch 1939/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 8.9333\n",
      "Epoch 1940/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7276\n",
      "Epoch 1941/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.7860\n",
      "Epoch 1942/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.3452\n",
      "Epoch 1943/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 8.9679\n",
      "Epoch 1944/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 8.5024\n",
      "Epoch 1945/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.1232\n",
      "Epoch 1946/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.5004\n",
      "Epoch 1947/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 8.6711\n",
      "Epoch 1948/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4052\n",
      "Epoch 1949/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.0898\n",
      "Epoch 1950/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.0563\n",
      "Epoch 1951/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.2494\n",
      "Epoch 1952/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.2797\n",
      "Epoch 1953/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.1498\n",
      "Epoch 1954/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.2844\n",
      "Epoch 1955/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.5849\n",
      "Epoch 1956/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.1924\n",
      "Epoch 1957/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.4735\n",
      "Epoch 1958/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.3566\n",
      "Epoch 1959/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0275\n",
      "Epoch 1960/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.6721\n",
      "Epoch 1961/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 8.8515\n",
      "Epoch 1962/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.0081\n",
      "Epoch 1963/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.1387\n",
      "Epoch 1964/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.6839\n",
      "Epoch 1965/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4111\n",
      "Epoch 1966/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 8.9936\n",
      "Epoch 1967/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.8383\n",
      "Epoch 1968/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.2103\n",
      "Epoch 1969/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0775\n",
      "Epoch 1970/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.4560\n",
      "Epoch 1971/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.8317\n",
      "Epoch 1972/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.3457\n",
      "Epoch 1973/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.0279\n",
      "Epoch 1974/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.7517\n",
      "Epoch 1975/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.6161\n",
      "Epoch 1976/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 10.2696\n",
      "Epoch 1977/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9087\n",
      "Epoch 1978/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.9905\n",
      "Epoch 1979/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 10.0642\n",
      "Epoch 1980/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.3144\n",
      "Epoch 1981/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 9.4687\n",
      "Epoch 1982/2000\n",
      "1883/1883 [==============================] - 0s 17us/step - loss: 9.5586\n",
      "Epoch 1983/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.2065\n",
      "Epoch 1984/2000\n",
      "1883/1883 [==============================] - 0s 15us/step - loss: 8.3978\n",
      "Epoch 1985/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.6667\n",
      "Epoch 1986/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.3179\n",
      "Epoch 1987/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.0962\n",
      "Epoch 1988/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.9537\n",
      "Epoch 1989/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.8112\n",
      "Epoch 1990/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 8.8620\n",
      "Epoch 1991/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.2588\n",
      "Epoch 1992/2000\n",
      "1883/1883 [==============================] - 0s 16us/step - loss: 9.6898\n",
      "Epoch 1993/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 8.8233\n",
      "Epoch 1994/2000\n",
      "1883/1883 [==============================] - 0s 13us/step - loss: 9.4978\n",
      "Epoch 1995/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.7550\n",
      "Epoch 1996/2000\n",
      "1883/1883 [==============================] - 0s 12us/step - loss: 9.0712\n",
      "Epoch 1997/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 10.0425\n",
      "Epoch 1998/2000\n",
      "1883/1883 [==============================] - 0s 14us/step - loss: 9.9102\n",
      "Epoch 1999/2000\n",
      "1883/1883 [==============================] - 0s 11us/step - loss: 9.5259\n",
      "Epoch 2000/2000\n",
      "1883/1883 [==============================] - 0s 10us/step - loss: 9.4702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a21fd02e8>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(np.array(X_train), np.array(y_train), epochs=2000,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.5)\n",
    "gbr.fit(X_train,y_train)\n",
    "gbr_predictions = gbr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "925"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = pd.DataFrame(predictions)\n",
    "testing.columns=['NN_predictions']\n",
    "testing['actual'] = y_test.reset_index()['points']\n",
    "testing['GBR_predictions']=gbr_predictions\n",
    "testing['LY_scoring']=X_test['points_ly'].reset_index()['points_ly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN_predictions</th>\n",
       "      <th>actual</th>\n",
       "      <th>GBR_predictions</th>\n",
       "      <th>LY_scoring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15.283444</td>\n",
       "      <td>15.3</td>\n",
       "      <td>14.516847</td>\n",
       "      <td>14.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14.103240</td>\n",
       "      <td>10.5</td>\n",
       "      <td>14.099980</td>\n",
       "      <td>13.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11.281839</td>\n",
       "      <td>13.9</td>\n",
       "      <td>10.685212</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.453426</td>\n",
       "      <td>18.1</td>\n",
       "      <td>16.879166</td>\n",
       "      <td>14.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12.845493</td>\n",
       "      <td>10.4</td>\n",
       "      <td>10.433422</td>\n",
       "      <td>11.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.046763</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.291565</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>14.779439</td>\n",
       "      <td>16.4</td>\n",
       "      <td>14.648856</td>\n",
       "      <td>11.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>11.931538</td>\n",
       "      <td>10.5</td>\n",
       "      <td>12.772061</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>13.435926</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.681255</td>\n",
       "      <td>16.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.925048</td>\n",
       "      <td>11.3</td>\n",
       "      <td>7.854545</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>8.910604</td>\n",
       "      <td>11.7</td>\n",
       "      <td>9.842944</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>17.523033</td>\n",
       "      <td>14.5</td>\n",
       "      <td>15.890389</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>10.565738</td>\n",
       "      <td>12.7</td>\n",
       "      <td>10.659031</td>\n",
       "      <td>11.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>16.035282</td>\n",
       "      <td>12.4</td>\n",
       "      <td>16.672945</td>\n",
       "      <td>15.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>9.803998</td>\n",
       "      <td>12.7</td>\n",
       "      <td>12.584754</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>25.908287</td>\n",
       "      <td>27.8</td>\n",
       "      <td>23.186448</td>\n",
       "      <td>26.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>22.340355</td>\n",
       "      <td>20.8</td>\n",
       "      <td>24.286563</td>\n",
       "      <td>22.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>17.920033</td>\n",
       "      <td>14.6</td>\n",
       "      <td>16.895189</td>\n",
       "      <td>15.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>10.142896</td>\n",
       "      <td>11.9</td>\n",
       "      <td>13.753258</td>\n",
       "      <td>14.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>13.075540</td>\n",
       "      <td>12.6</td>\n",
       "      <td>11.465363</td>\n",
       "      <td>11.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>11.311777</td>\n",
       "      <td>13.1</td>\n",
       "      <td>12.167192</td>\n",
       "      <td>13.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>15.829757</td>\n",
       "      <td>15.3</td>\n",
       "      <td>17.367826</td>\n",
       "      <td>15.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>16.286255</td>\n",
       "      <td>17.1</td>\n",
       "      <td>15.695024</td>\n",
       "      <td>16.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>7.572212</td>\n",
       "      <td>10.2</td>\n",
       "      <td>6.895618</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>12.045840</td>\n",
       "      <td>12.8</td>\n",
       "      <td>13.036567</td>\n",
       "      <td>12.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>11.553383</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.239090</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>16.152723</td>\n",
       "      <td>13.2</td>\n",
       "      <td>14.517524</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>14.932577</td>\n",
       "      <td>22.3</td>\n",
       "      <td>13.086471</td>\n",
       "      <td>13.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>12.202775</td>\n",
       "      <td>14.9</td>\n",
       "      <td>12.199773</td>\n",
       "      <td>14.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>21.435497</td>\n",
       "      <td>18.7</td>\n",
       "      <td>22.396933</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>28.460144</td>\n",
       "      <td>27.4</td>\n",
       "      <td>23.764332</td>\n",
       "      <td>25.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>20.701866</td>\n",
       "      <td>23.4</td>\n",
       "      <td>21.576183</td>\n",
       "      <td>23.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>33.339657</td>\n",
       "      <td>28.1</td>\n",
       "      <td>25.656534</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>10.005443</td>\n",
       "      <td>11.9</td>\n",
       "      <td>10.782804</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>18.116749</td>\n",
       "      <td>14.6</td>\n",
       "      <td>18.183768</td>\n",
       "      <td>18.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>3.026304</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.055545</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>8.367245</td>\n",
       "      <td>12.2</td>\n",
       "      <td>8.308007</td>\n",
       "      <td>9.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>756</th>\n",
       "      <td>11.824998</td>\n",
       "      <td>12.8</td>\n",
       "      <td>11.105087</td>\n",
       "      <td>13.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>14.050852</td>\n",
       "      <td>12.5</td>\n",
       "      <td>15.478805</td>\n",
       "      <td>15.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>9.036853</td>\n",
       "      <td>12.6</td>\n",
       "      <td>8.383171</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>17.167614</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.563543</td>\n",
       "      <td>17.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>12.499917</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.822861</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>15.968613</td>\n",
       "      <td>15.2</td>\n",
       "      <td>15.406704</td>\n",
       "      <td>15.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>15.381042</td>\n",
       "      <td>19.2</td>\n",
       "      <td>14.875178</td>\n",
       "      <td>14.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>13.535957</td>\n",
       "      <td>14.5</td>\n",
       "      <td>12.936219</td>\n",
       "      <td>11.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>18.421551</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.147993</td>\n",
       "      <td>19.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>18.703278</td>\n",
       "      <td>19.8</td>\n",
       "      <td>17.775089</td>\n",
       "      <td>16.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>14.546153</td>\n",
       "      <td>15.4</td>\n",
       "      <td>12.709203</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>7.178511</td>\n",
       "      <td>10.3</td>\n",
       "      <td>7.084979</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>9.885945</td>\n",
       "      <td>11.4</td>\n",
       "      <td>8.917404</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>21.451355</td>\n",
       "      <td>24.4</td>\n",
       "      <td>23.864063</td>\n",
       "      <td>20.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>10.839400</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9.730935</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>16.047104</td>\n",
       "      <td>19.1</td>\n",
       "      <td>13.790432</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>10.224899</td>\n",
       "      <td>13.3</td>\n",
       "      <td>10.901404</td>\n",
       "      <td>13.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>9.780862</td>\n",
       "      <td>14.1</td>\n",
       "      <td>11.102448</td>\n",
       "      <td>13.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>13.691684</td>\n",
       "      <td>12.6</td>\n",
       "      <td>13.541561</td>\n",
       "      <td>13.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>10.779433</td>\n",
       "      <td>13.9</td>\n",
       "      <td>12.380741</td>\n",
       "      <td>14.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>7.683003</td>\n",
       "      <td>11.8</td>\n",
       "      <td>8.215904</td>\n",
       "      <td>13.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>13.076087</td>\n",
       "      <td>12.3</td>\n",
       "      <td>12.636612</td>\n",
       "      <td>12.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>10.323735</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.421279</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>315 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     NN_predictions  actual  GBR_predictions  LY_scoring\n",
       "7         15.283444    15.3        14.516847        14.2\n",
       "11        14.103240    10.5        14.099980        13.3\n",
       "12        11.281839    13.9        10.685212        11.5\n",
       "14        15.453426    18.1        16.879166        14.3\n",
       "15        12.845493    10.4        10.433422        11.3\n",
       "16         6.046763    14.0         7.291565         7.0\n",
       "20        14.779439    16.4        14.648856        11.7\n",
       "21        11.931538    10.5        12.772061        13.5\n",
       "23        13.435926    15.0        17.681255        16.9\n",
       "24         3.925048    11.3         7.854545         2.0\n",
       "28         8.910604    11.7         9.842944         6.2\n",
       "29        17.523033    14.5        15.890389        18.8\n",
       "32        10.565738    12.7        10.659031        11.7\n",
       "33        16.035282    12.4        16.672945        15.3\n",
       "40         9.803998    12.7        12.584754        14.0\n",
       "41        25.908287    27.8        23.186448        26.9\n",
       "44        22.340355    20.8        24.286563        22.5\n",
       "45        17.920033    14.6        16.895189        15.9\n",
       "48        10.142896    11.9        13.753258        14.2\n",
       "50        13.075540    12.6        11.465363        11.3\n",
       "51        11.311777    13.1        12.167192        13.8\n",
       "53        15.829757    15.3        17.367826        15.9\n",
       "54        16.286255    17.1        15.695024        16.7\n",
       "55         7.572212    10.2         6.895618         9.8\n",
       "56        12.045840    12.8        13.036567        12.7\n",
       "57        11.553383    12.0        11.239090         9.7\n",
       "60        16.152723    13.2        14.517524        14.0\n",
       "61        14.932577    22.3        13.086471        13.8\n",
       "64        12.202775    14.9        12.199773        14.3\n",
       "67        21.435497    18.7        22.396933        24.0\n",
       "..              ...     ...              ...         ...\n",
       "729       28.460144    27.4        23.764332        25.4\n",
       "732       20.701866    23.4        21.576183        23.2\n",
       "734       33.339657    28.1        25.656534        28.0\n",
       "735       10.005443    11.9        10.782804         7.9\n",
       "736       18.116749    14.6        18.183768        18.2\n",
       "740        3.026304    13.0         5.055545         2.6\n",
       "745        8.367245    12.2         8.308007         9.7\n",
       "756       11.824998    12.8        11.105087        13.1\n",
       "757       14.050852    12.5        15.478805        15.9\n",
       "758        9.036853    12.6         8.383171         8.8\n",
       "761       17.167614    16.0        17.563543        17.9\n",
       "765       12.499917    12.0        13.822861         8.8\n",
       "768       15.968613    15.2        15.406704        15.2\n",
       "770       15.381042    19.2        14.875178        14.8\n",
       "771       13.535957    14.5        12.936219        11.7\n",
       "772       18.421551    19.8        19.147993        19.6\n",
       "773       18.703278    19.8        17.775089        16.2\n",
       "774       14.546153    15.4        12.709203        13.0\n",
       "776        7.178511    10.3         7.084979         7.8\n",
       "780        9.885945    11.4         8.917404        11.1\n",
       "782       21.451355    24.4        23.864063        20.8\n",
       "784       10.839400    14.0         9.730935         9.1\n",
       "785       16.047104    19.1        13.790432        14.0\n",
       "789       10.224899    13.3        10.901404        13.9\n",
       "791        9.780862    14.1        11.102448        13.5\n",
       "794       13.691684    12.6        13.541561        13.7\n",
       "799       10.779433    13.9        12.380741        14.9\n",
       "802        7.683003    11.8         8.215904        13.7\n",
       "804       13.076087    12.3        12.636612        12.1\n",
       "805       10.323735    12.0        11.421279        11.9\n",
       "\n",
       "[315 rows x 4 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing[testing['actual']>10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1019    17.8\n",
       "3307     2.9\n",
       "3489     7.3\n",
       "3242     3.1\n",
       "1007     9.4\n",
       "2765     4.7\n",
       "2357    18.8\n",
       "3002     5.9\n",
       "2866    11.0\n",
       "2709    14.0\n",
       "3055     6.3\n",
       "1366     7.5\n",
       "3278    12.8\n",
       "3452     5.9\n",
       "1985    12.2\n",
       "2903    12.7\n",
       "715     17.8\n",
       "754      2.2\n",
       "3450     7.2\n",
       "1322    19.5\n",
       "Name: points_ly, dtype: float64"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['points_ly'][0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17.844143 ],\n",
       "       [ 4.58346  ],\n",
       "       [10.279707 ],\n",
       "       [ 4.779441 ],\n",
       "       [11.738732 ],\n",
       "       [ 4.8977976],\n",
       "       [20.338715 ],\n",
       "       [ 5.509632 ],\n",
       "       [11.4254465],\n",
       "       [13.024121 ],\n",
       "       [ 4.4234757],\n",
       "       [ 5.667042 ],\n",
       "       [13.13639  ],\n",
       "       [ 3.2999768],\n",
       "       [12.733069 ],\n",
       "       [12.993856 ],\n",
       "       [17.7858   ],\n",
       "       [ 3.7786436],\n",
       "       [ 7.8413477],\n",
       "       [16.594303 ]], dtype=float32)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     17.877944\n",
       "1      3.451549\n",
       "2     10.258897\n",
       "3      5.205964\n",
       "4     11.953578\n",
       "5      4.218924\n",
       "6     18.235270\n",
       "7      5.317524\n",
       "8     10.236510\n",
       "9     13.238273\n",
       "10     5.274126\n",
       "11     6.293032\n",
       "12    11.519619\n",
       "13     4.620900\n",
       "14    14.934067\n",
       "15    13.272919\n",
       "16    16.929187\n",
       "17     4.078159\n",
       "18     8.473781\n",
       "19    17.592289\n",
       "dtype: float64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2017points = players[players['season']==2017].drop(['season','team','player','points'],axis=1)\n",
    "points_2017 = model.predict(pred_2017points)\n",
    "test_2 =pd.DataFrame(points_2017)\n",
    "test_3 = pd.merge(players,pred_2017points,left_index=True,right_index=True).reset_index()\n",
    "test_3['predictions']=test_2[0]\n",
    "test_3[['player','points','points_ly_x','predictions']].sort_values(by='points_ly_x',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09999954, 0.18079444, 0.05630521, 0.068424  , 0.00065053,\n",
       "       0.02123672, 0.02468731, 0.00082807, 0.02697013, 0.02809122,\n",
       "       0.02346993, 0.03004118, 0.04160092, 0.0432922 , 0.0426422 ,\n",
       "       0.02623327, 0.04604534, 0.03923624, 0.02557597, 0.03005844,\n",
       "       0.05530913, 0.0830102 , 0.00549783])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbr.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'points_ly', 'change_points_ly', 'starter_change',\n",
       "       'high_usageplayer_added', 'usagemin_opened', 'maxusage_added',\n",
       "       'high_usageplayer_dropped', 'points_opened', 'max_pointsdropped',\n",
       "       'max_pointsadded', 'three_ar_ly', 'change_3ar', 'per_ly', 'change_per',\n",
       "       'usagerank', 'usagerank_ly', 'offensive_winshares',\n",
       "       'offensive_boxplusminus', 'boxplusminus', 'value_overreplacement',\n",
       "       'career_points', 'yearspro'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''next is rebounds'''\n",
    "\n",
    "\n",
    "query= '''\n",
    "        \n",
    "        DROP TABLE IF EXISTS rebounds_pred;\n",
    "        CREATE TABLE rebounds_pred(\n",
    "        season int, --these come from player_stats\n",
    "        player varchar(50),\n",
    "        Age int,\n",
    "        team varchar(50),\n",
    "        rebounds float, -- these come from player_stats\n",
    "        rebounds_ly float,\n",
    "        change_rebounds_ly float,\n",
    "        Games int,\n",
    "        C_PF int,\n",
    "        PG int,\n",
    "        SG_SF int,\n",
    "        starter_change int, \n",
    "        \n",
    "        -- these come from team_changes\n",
    "        high_usageplayer_added int,\n",
    "        usagemin_opened float,\n",
    "        maxusage_added float,\n",
    "        high_usageplayer_dropped int,\n",
    "        rebounds_opened float,\n",
    "        max_reboundsdropped float,\n",
    "        max_reboundsadded float,\n",
    "        \n",
    "        -- from player_advstats\n",
    "        per_ly float,\n",
    "        change_per float,\n",
    "        usagerank float,\n",
    "        usagerank_ly float,\n",
    "        reb_perc_ly float,\n",
    "        change_reb_perc float,\n",
    "        defensive_winshares float,\n",
    "        defensive_boxplusminus float,\n",
    "        boxplusminus float,\n",
    "        value_overreplacement float,\n",
    "        \n",
    "        career_rebounds float,\n",
    "        yearspro int\n",
    "        );\n",
    "        \n",
    "        INSERT INTO rebounds_pred(season,player,age,team,rebounds,rebounds_ly,change_rebounds_ly,Games,starter_change,C_PF,PG,SG_SF)\n",
    "        SELECT season,player,age,startingteam,rebounds,rebounds_ly,change_reb_ly,Games,starter-starter_ly,\n",
    "        case when pos in ('C','PF') then 1 else 0 end,case when pos='PG' then 1 else 0 end,case when pos in('SG','SF') then 1 else 0 end from player_stats;\n",
    "        \n",
    "        update rebounds_pred rp\n",
    "        set high_usageplayer_added = tc.high_usageplayer_added,usagemin_opened=tc.usagemin_opened,\n",
    "        maxusage_added=tc.max_usageadded,high_usageplayer_dropped=tc.high_usageplayer_dropped,rebounds_opened=tc.rebounds_opened,\n",
    "        max_reboundsdropped=tc.max_reboundsdropped,max_reboundsadded=tc.max_reboundsadded\n",
    "        from team_changes tc\n",
    "        where tc.team = rp.team and rp.season=tc.season;\n",
    "        \n",
    "        update rebounds_pred rp\n",
    "        set per_ly=pa.per_ly,change_per=pa.change_per,usagerank=pa.usagerank,usagerank_ly=pa.usagerank_ly\n",
    "        ,reb_perc_ly = pa.reb_perc_ly,change_reb_perc = pa.change_reb_perc,defensive_winshares=pa.defensive_winshares,\n",
    "        defensive_boxplusminus=pa.defensive_boxplusminus,boxplusminus=pa.boxplusminus,value_overreplacement=pa.value_overreplacement\n",
    "        from player_advstats pa\n",
    "        where rp.player = pa.player and rp.season = pa.season and rp.team = pa.startingteam;\n",
    "        \n",
    "        update rebounds_pred rp\n",
    "        set career_rebounds = pc.career_rebounds, yearspro = pc.yearspro\n",
    "        from player_careerstats pc\n",
    "        where rp.player = pc.player and rp.season = pc.season;\n",
    "        \n",
    "        \n",
    "        select * from rebounds_pred where season>2009\n",
    "        '''\n",
    "\n",
    "\n",
    "cur.execute(query)\n",
    "data = cur.fetchall()\n",
    "rebounds_df = pd.DataFrame(np.array(data))\n",
    "rebounds_df.columns = ['season','player','age','team','rebounds','rebounds_ly','change_rebounds_ly','Games','C_PF','PG','SG_SF','starter_change','high_usageplayer_added','usagemin_opened','maxusage_added','high_usageplayer_dropped','rebounds_opened','max_reboundsdropped',\n",
    "                    'max_reboundsadded','per_ly','change_per','usagerank','usagerank_ly','reb_perc_ly','change_reb_perc','defensive_winshares','defensive_boxplusminus','boxplusminus','value_overreplacement','career_rebounds','yearspro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>player</th>\n",
       "      <th>age</th>\n",
       "      <th>team</th>\n",
       "      <th>rebounds</th>\n",
       "      <th>rebounds_ly</th>\n",
       "      <th>change_rebounds_ly</th>\n",
       "      <th>Games</th>\n",
       "      <th>C_PF</th>\n",
       "      <th>PG</th>\n",
       "      <th>...</th>\n",
       "      <th>usagerank_ly</th>\n",
       "      <th>reb_perc_ly</th>\n",
       "      <th>change_reb_perc</th>\n",
       "      <th>defensive_winshares</th>\n",
       "      <th>defensive_boxplusminus</th>\n",
       "      <th>boxplusminus</th>\n",
       "      <th>value_overreplacement</th>\n",
       "      <th>career_rebounds</th>\n",
       "      <th>yearspro</th>\n",
       "      <th>age_squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010</td>\n",
       "      <td>James Anderson</td>\n",
       "      <td>21</td>\n",
       "      <td>SAS</td>\n",
       "      <td>0.9</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>Jameel Warney</td>\n",
       "      <td>24</td>\n",
       "      <td>DAL</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>Jamal Murray</td>\n",
       "      <td>19</td>\n",
       "      <td>DEN</td>\n",
       "      <td>2.6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>Jalen Jones</td>\n",
       "      <td>24</td>\n",
       "      <td>DAL</td>\n",
       "      <td>2.9</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>Jakob Poeltl</td>\n",
       "      <td>21</td>\n",
       "      <td>TOR</td>\n",
       "      <td>3.1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  season          player age team rebounds rebounds_ly change_rebounds_ly  \\\n",
       "0   2010  James Anderson  21  SAS      0.9        None               None   \n",
       "1   2017   Jameel Warney  24  DAL        3        None               None   \n",
       "2   2016    Jamal Murray  19  DEN      2.6        None               None   \n",
       "3   2017     Jalen Jones  24  DAL      2.9        None               None   \n",
       "4   2016    Jakob Poeltl  21  TOR      3.1        None               None   \n",
       "\n",
       "  Games C_PF PG     ...     usagerank_ly reb_perc_ly change_reb_perc  \\\n",
       "0    26    0  0     ...                1        None            None   \n",
       "1     3    1  0     ...                1        None            None   \n",
       "2    82    0  0     ...                1        None            None   \n",
       "3    16    0  0     ...                1        None            None   \n",
       "4    54    1  0     ...                1        None            None   \n",
       "\n",
       "  defensive_winshares defensive_boxplusminus boxplusminus  \\\n",
       "0                None                   None         None   \n",
       "1                None                   None         None   \n",
       "2                None                   None         None   \n",
       "3                None                   None         None   \n",
       "4                None                   None         None   \n",
       "\n",
       "  value_overreplacement career_rebounds yearspro age_squared  \n",
       "0                  None            None     None         441  \n",
       "1                  None            None     None         576  \n",
       "2                  None            None     None         361  \n",
       "3                  None            None     None         576  \n",
       "4                  None            None     None         441  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rebounds_df['age_squared']=rebounds_df['age']*rebounds_df['age']\n",
    "rebounds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "rebounds = rebounds_df[rebounds_df['rebounds_ly'].notna()]\n",
    "for i in rebounds.columns:\n",
    "    if i not in(['player','team']):\n",
    "        rebounds[i]=pd.to_numeric(rebounds[i])\n",
    "rebounds = rebounds.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2157, 28)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = rebounds[(rebounds['season']!=2017) & (rebounds['Games']>30)].drop(['player','team','rebounds','Games'],axis=1)\n",
    "y = rebounds[(rebounds['season']!=2017) & (rebounds['Games']>30)]['rebounds']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1564/1564 [==============================] - 1s 923us/step - loss: 613.6040\n",
      "Epoch 2/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 173.4031\n",
      "Epoch 3/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 75.7023\n",
      "Epoch 4/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 49.9752\n",
      "Epoch 5/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 38.0596\n",
      "Epoch 6/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 30.9769\n",
      "Epoch 7/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 25.4445\n",
      "Epoch 8/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 21.3319\n",
      "Epoch 9/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 18.2191\n",
      "Epoch 10/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 15.8670\n",
      "Epoch 11/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 14.1531\n",
      "Epoch 12/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 12.8729\n",
      "Epoch 13/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 11.8530\n",
      "Epoch 14/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 11.0496\n",
      "Epoch 15/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 10.3943\n",
      "Epoch 16/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 9.8661\n",
      "Epoch 17/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 9.4323\n",
      "Epoch 18/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 8.9810\n",
      "Epoch 19/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 8.6557\n",
      "Epoch 20/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 8.3496\n",
      "Epoch 21/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 8.0863\n",
      "Epoch 22/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 7.8984\n",
      "Epoch 23/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 7.7081\n",
      "Epoch 24/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 7.4832\n",
      "Epoch 25/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 7.3176\n",
      "Epoch 26/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 7.1374\n",
      "Epoch 27/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 6.9859\n",
      "Epoch 28/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 6.8681\n",
      "Epoch 29/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 6.7895\n",
      "Epoch 30/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 6.6025\n",
      "Epoch 31/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 6.4958\n",
      "Epoch 32/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 6.3681\n",
      "Epoch 33/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 6.2506\n",
      "Epoch 34/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 6.1200\n",
      "Epoch 35/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 6.0117\n",
      "Epoch 36/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 5.9834\n",
      "Epoch 37/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 5.7949\n",
      "Epoch 38/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 5.6832\n",
      "Epoch 39/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 5.5599\n",
      "Epoch 40/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 5.4572\n",
      "Epoch 41/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 5.3685\n",
      "Epoch 42/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 5.2660\n",
      "Epoch 43/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 5.1704\n",
      "Epoch 44/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 5.0597\n",
      "Epoch 45/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 4.9744\n",
      "Epoch 46/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 4.9052\n",
      "Epoch 47/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 4.8050\n",
      "Epoch 48/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 4.7321\n",
      "Epoch 49/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 4.6889\n",
      "Epoch 50/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 4.5751\n",
      "Epoch 51/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 4.5218\n",
      "Epoch 52/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 4.4922\n",
      "Epoch 53/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 4.3815\n",
      "Epoch 54/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 4.3231\n",
      "Epoch 55/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 4.2275\n",
      "Epoch 56/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 4.1656\n",
      "Epoch 57/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 4.1244\n",
      "Epoch 58/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 4.0322\n",
      "Epoch 59/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 3.9948\n",
      "Epoch 60/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 3.9165\n",
      "Epoch 61/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 3.8550\n",
      "Epoch 62/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 3.8425\n",
      "Epoch 63/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 3.7463\n",
      "Epoch 64/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 3.7180\n",
      "Epoch 65/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 3.6582\n",
      "Epoch 66/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 3.5847\n",
      "Epoch 67/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 3.5803\n",
      "Epoch 68/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 3.5057\n",
      "Epoch 69/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 3.4925\n",
      "Epoch 70/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 3.4127\n",
      "Epoch 71/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 3.3600\n",
      "Epoch 72/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 3.2946\n",
      "Epoch 73/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 3.2482\n",
      "Epoch 74/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 3.2002\n",
      "Epoch 75/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 3.1925\n",
      "Epoch 76/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 3.1332\n",
      "Epoch 77/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 3.1368\n",
      "Epoch 78/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 3.0551\n",
      "Epoch 79/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 2.9958\n",
      "Epoch 80/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 2.9623\n",
      "Epoch 81/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 2.9325\n",
      "Epoch 82/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 2.9016\n",
      "Epoch 83/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 2.8927\n",
      "Epoch 84/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 2.8274\n",
      "Epoch 85/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 2.7957\n",
      "Epoch 86/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 2.7568\n",
      "Epoch 87/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 2.7685\n",
      "Epoch 88/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 2.7205\n",
      "Epoch 89/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 2.6732\n",
      "Epoch 90/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 2.6408\n",
      "Epoch 91/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 2.6225\n",
      "Epoch 92/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 2.6027\n",
      "Epoch 93/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 2.5945\n",
      "Epoch 94/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 2.6201\n",
      "Epoch 95/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 2.5775\n",
      "Epoch 96/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 2.5227\n",
      "Epoch 97/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 2.4949\n",
      "Epoch 98/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 2.4856\n",
      "Epoch 99/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 2.4590\n",
      "Epoch 100/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 2.4370\n",
      "Epoch 101/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 2.4016\n",
      "Epoch 102/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 2.3953\n",
      "Epoch 103/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 2.3559\n",
      "Epoch 104/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 2.3463\n",
      "Epoch 105/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 2.3153\n",
      "Epoch 106/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 2.3366\n",
      "Epoch 107/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 2.3384\n",
      "Epoch 108/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 2.2933\n",
      "Epoch 109/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 2.2478\n",
      "Epoch 110/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 2.2413\n",
      "Epoch 111/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 2.2594\n",
      "Epoch 112/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 2.2364\n",
      "Epoch 113/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 2.2371\n",
      "Epoch 114/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 2.1837\n",
      "Epoch 115/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 2.2148\n",
      "Epoch 116/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 2.1561\n",
      "Epoch 117/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 2.1613\n",
      "Epoch 118/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 2.1423\n",
      "Epoch 119/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 2.1259\n",
      "Epoch 120/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 2.1406\n",
      "Epoch 121/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 2.0869\n",
      "Epoch 122/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 2.0655\n",
      "Epoch 123/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 2.1453\n",
      "Epoch 124/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 2.0688\n",
      "Epoch 125/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 2.0241\n",
      "Epoch 126/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 2.1046\n",
      "Epoch 127/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 2.0113\n",
      "Epoch 128/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 2.0272\n",
      "Epoch 129/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 2.0026\n",
      "Epoch 130/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 2.0372\n",
      "Epoch 131/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 2.0959\n",
      "Epoch 132/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 2.0539\n",
      "Epoch 133/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 2.0123\n",
      "Epoch 134/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.9937\n",
      "Epoch 135/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.9811\n",
      "Epoch 136/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.9415\n",
      "Epoch 137/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.9381\n",
      "Epoch 138/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.9232\n",
      "Epoch 139/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.9389\n",
      "Epoch 140/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.9353\n",
      "Epoch 141/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 1.9196\n",
      "Epoch 142/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 1.9747\n",
      "Epoch 143/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.9287\n",
      "Epoch 144/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.9195\n",
      "Epoch 145/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.8912\n",
      "Epoch 146/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.9199\n",
      "Epoch 147/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.8753\n",
      "Epoch 148/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.8544\n",
      "Epoch 149/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.8886\n",
      "Epoch 150/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.8670\n",
      "Epoch 151/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.8786\n",
      "Epoch 152/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.9208\n",
      "Epoch 153/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.8328\n",
      "Epoch 154/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.8722\n",
      "Epoch 155/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.8086\n",
      "Epoch 156/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.8562\n",
      "Epoch 157/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.8248\n",
      "Epoch 158/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.8068\n",
      "Epoch 159/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.8025\n",
      "Epoch 160/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.7958\n",
      "Epoch 161/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.7805\n",
      "Epoch 162/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.7857\n",
      "Epoch 163/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.8125\n",
      "Epoch 164/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.8040\n",
      "Epoch 165/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.7768\n",
      "Epoch 166/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.7766\n",
      "Epoch 167/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.8192\n",
      "Epoch 168/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.7575\n",
      "Epoch 169/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.7740\n",
      "Epoch 170/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.7909\n",
      "Epoch 171/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.7479\n",
      "Epoch 172/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.7660\n",
      "Epoch 173/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.7827\n",
      "Epoch 174/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.8359\n",
      "Epoch 175/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.8088\n",
      "Epoch 176/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.7786\n",
      "Epoch 177/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.7900\n",
      "Epoch 178/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.7737\n",
      "Epoch 179/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.6887\n",
      "Epoch 180/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.7052\n",
      "Epoch 181/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.7023\n",
      "Epoch 182/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.6922\n",
      "Epoch 183/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.6788\n",
      "Epoch 184/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.7052\n",
      "Epoch 185/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.7376\n",
      "Epoch 186/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.7098\n",
      "Epoch 187/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.7235\n",
      "Epoch 188/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.6753\n",
      "Epoch 189/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.6618\n",
      "Epoch 190/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.6697\n",
      "Epoch 191/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.6861\n",
      "Epoch 192/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.6560\n",
      "Epoch 193/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.6729\n",
      "Epoch 194/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.7454\n",
      "Epoch 195/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.6480\n",
      "Epoch 196/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.6605\n",
      "Epoch 197/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.6539\n",
      "Epoch 198/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.6293\n",
      "Epoch 199/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.6389\n",
      "Epoch 200/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.6304\n",
      "Epoch 201/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.6286\n",
      "Epoch 202/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.6073\n",
      "Epoch 203/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.7271\n",
      "Epoch 204/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.6505\n",
      "Epoch 205/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.6136\n",
      "Epoch 206/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.6234\n",
      "Epoch 207/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.6195\n",
      "Epoch 208/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.6380\n",
      "Epoch 209/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.5960\n",
      "Epoch 210/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.6015\n",
      "Epoch 211/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.5977\n",
      "Epoch 212/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.5863\n",
      "Epoch 213/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.5850\n",
      "Epoch 214/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.6325\n",
      "Epoch 215/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 1.5699\n",
      "Epoch 216/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.6049\n",
      "Epoch 217/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.6059\n",
      "Epoch 218/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.6018\n",
      "Epoch 219/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.6391\n",
      "Epoch 220/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.5954\n",
      "Epoch 221/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.6102\n",
      "Epoch 222/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.5779\n",
      "Epoch 223/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.5736\n",
      "Epoch 224/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.6018\n",
      "Epoch 225/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.5960\n",
      "Epoch 226/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.5472\n",
      "Epoch 227/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.5391\n",
      "Epoch 228/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.5365\n",
      "Epoch 229/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.5521\n",
      "Epoch 230/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.5878\n",
      "Epoch 231/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.5338\n",
      "Epoch 232/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.5342\n",
      "Epoch 233/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.5300\n",
      "Epoch 234/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.5351\n",
      "Epoch 235/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.6071\n",
      "Epoch 236/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.6844\n",
      "Epoch 237/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.6401\n",
      "Epoch 238/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.5447\n",
      "Epoch 239/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.5290\n",
      "Epoch 240/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.5260\n",
      "Epoch 241/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.5749\n",
      "Epoch 242/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.5130\n",
      "Epoch 243/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.5002\n",
      "Epoch 244/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.5241\n",
      "Epoch 245/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.4959\n",
      "Epoch 246/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.5046\n",
      "Epoch 247/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.4771\n",
      "Epoch 248/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.5242\n",
      "Epoch 249/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.5054\n",
      "Epoch 250/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.5374\n",
      "Epoch 251/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.5397\n",
      "Epoch 252/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 1.4898\n",
      "Epoch 253/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.4879\n",
      "Epoch 254/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.5233\n",
      "Epoch 255/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.6067\n",
      "Epoch 256/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.5341\n",
      "Epoch 257/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.4738\n",
      "Epoch 258/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 1.4662\n",
      "Epoch 259/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.4601\n",
      "Epoch 260/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.4523\n",
      "Epoch 261/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.4860\n",
      "Epoch 262/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.4578\n",
      "Epoch 263/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.5027\n",
      "Epoch 264/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.5286\n",
      "Epoch 265/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.5082\n",
      "Epoch 266/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.5007\n",
      "Epoch 267/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.5661\n",
      "Epoch 268/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.4679\n",
      "Epoch 269/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.4743\n",
      "Epoch 270/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 1.5503\n",
      "Epoch 271/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.6184\n",
      "Epoch 272/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.4444\n",
      "Epoch 273/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.4484\n",
      "Epoch 274/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.5040\n",
      "Epoch 275/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.5439\n",
      "Epoch 276/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.5631\n",
      "Epoch 277/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.6293\n",
      "Epoch 278/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.4568\n",
      "Epoch 279/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.4464\n",
      "Epoch 280/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.4305\n",
      "Epoch 281/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.4318\n",
      "Epoch 282/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.4100\n",
      "Epoch 283/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.4377\n",
      "Epoch 284/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.4961\n",
      "Epoch 285/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.4182\n",
      "Epoch 286/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.4216\n",
      "Epoch 287/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.4102\n",
      "Epoch 288/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.4056\n",
      "Epoch 289/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.4026\n",
      "Epoch 290/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.4032\n",
      "Epoch 291/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.3969\n",
      "Epoch 292/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 1.4710\n",
      "Epoch 293/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.3991\n",
      "Epoch 294/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.4120\n",
      "Epoch 295/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.3954\n",
      "Epoch 296/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.4113\n",
      "Epoch 297/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.4178\n",
      "Epoch 298/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.4655\n",
      "Epoch 299/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.3933\n",
      "Epoch 300/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.4337\n",
      "Epoch 301/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.3730\n",
      "Epoch 302/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.4940\n",
      "Epoch 303/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.3846\n",
      "Epoch 304/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.3824\n",
      "Epoch 305/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.3644\n",
      "Epoch 306/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.4008\n",
      "Epoch 307/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.3991\n",
      "Epoch 308/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.3781\n",
      "Epoch 309/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.5036\n",
      "Epoch 310/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.4571\n",
      "Epoch 311/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.4200\n",
      "Epoch 312/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.4142\n",
      "Epoch 313/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.3846\n",
      "Epoch 314/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.3612\n",
      "Epoch 315/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.3657\n",
      "Epoch 316/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.3364\n",
      "Epoch 317/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.3558\n",
      "Epoch 318/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.3440\n",
      "Epoch 319/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.3979\n",
      "Epoch 320/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.3687\n",
      "Epoch 321/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.4237\n",
      "Epoch 322/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.4148\n",
      "Epoch 323/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.3753\n",
      "Epoch 324/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.3685\n",
      "Epoch 325/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.3836\n",
      "Epoch 326/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.3449\n",
      "Epoch 327/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.3403\n",
      "Epoch 328/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.3736\n",
      "Epoch 329/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.3298\n",
      "Epoch 330/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.3603\n",
      "Epoch 331/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.4359\n",
      "Epoch 332/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.3723\n",
      "Epoch 333/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.3960\n",
      "Epoch 334/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.3369\n",
      "Epoch 335/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.4222\n",
      "Epoch 336/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.3446\n",
      "Epoch 337/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.3421\n",
      "Epoch 338/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.3299\n",
      "Epoch 339/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.4794\n",
      "Epoch 340/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.4659\n",
      "Epoch 341/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.5302\n",
      "Epoch 342/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.6013\n",
      "Epoch 343/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.5017\n",
      "Epoch 344/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.4597\n",
      "Epoch 345/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.3799\n",
      "Epoch 346/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.3330\n",
      "Epoch 347/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.3328\n",
      "Epoch 348/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.3356\n",
      "Epoch 349/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.3919\n",
      "Epoch 350/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.3779\n",
      "Epoch 351/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.3101\n",
      "Epoch 352/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 1.3597\n",
      "Epoch 353/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.3386\n",
      "Epoch 354/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.3397\n",
      "Epoch 355/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.3050\n",
      "Epoch 356/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2991\n",
      "Epoch 357/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.3311\n",
      "Epoch 358/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.3197\n",
      "Epoch 359/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.2982\n",
      "Epoch 360/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.3834\n",
      "Epoch 361/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.4094\n",
      "Epoch 362/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.4123\n",
      "Epoch 363/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.3087\n",
      "Epoch 364/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.3731\n",
      "Epoch 365/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.3120\n",
      "Epoch 366/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.3159\n",
      "Epoch 367/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.3718\n",
      "Epoch 368/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.3681\n",
      "Epoch 369/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.3326\n",
      "Epoch 370/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.5888\n",
      "Epoch 371/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.5398\n",
      "Epoch 372/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.3499\n",
      "Epoch 373/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2915\n",
      "Epoch 374/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.2926\n",
      "Epoch 375/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2764\n",
      "Epoch 376/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2916\n",
      "Epoch 377/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.2829\n",
      "Epoch 378/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.3062\n",
      "Epoch 379/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2853\n",
      "Epoch 380/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.2738\n",
      "Epoch 381/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.3032\n",
      "Epoch 382/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.2943\n",
      "Epoch 383/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.2852\n",
      "Epoch 384/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.2765\n",
      "Epoch 385/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.3200\n",
      "Epoch 386/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2610\n",
      "Epoch 387/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2769\n",
      "Epoch 388/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2661\n",
      "Epoch 389/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.3519\n",
      "Epoch 390/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.3730\n",
      "Epoch 391/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.3399\n",
      "Epoch 392/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2752\n",
      "Epoch 393/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.2920\n",
      "Epoch 394/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2669\n",
      "Epoch 395/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.3459\n",
      "Epoch 396/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.2947\n",
      "Epoch 397/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.3431\n",
      "Epoch 398/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.3010\n",
      "Epoch 399/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.2786\n",
      "Epoch 400/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.3679\n",
      "Epoch 401/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.3252\n",
      "Epoch 402/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.3486\n",
      "Epoch 403/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.4459\n",
      "Epoch 404/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 1.3934\n",
      "Epoch 405/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.3059\n",
      "Epoch 406/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.2654\n",
      "Epoch 407/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2552\n",
      "Epoch 408/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.2707\n",
      "Epoch 409/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2803\n",
      "Epoch 410/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.3367\n",
      "Epoch 411/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.3644\n",
      "Epoch 412/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.3394\n",
      "Epoch 413/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.3224\n",
      "Epoch 414/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.3762\n",
      "Epoch 415/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 1.3395\n",
      "Epoch 416/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.3033\n",
      "Epoch 417/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.3214\n",
      "Epoch 418/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.4073\n",
      "Epoch 419/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.3615\n",
      "Epoch 420/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.3574\n",
      "Epoch 421/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.4091\n",
      "Epoch 422/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.3014\n",
      "Epoch 423/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.3056\n",
      "Epoch 424/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.3040\n",
      "Epoch 425/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.2606\n",
      "Epoch 426/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2537\n",
      "Epoch 427/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2806\n",
      "Epoch 428/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.2487\n",
      "Epoch 429/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.2725\n",
      "Epoch 430/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.3245\n",
      "Epoch 431/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.3055\n",
      "Epoch 432/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.3101\n",
      "Epoch 433/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.2999\n",
      "Epoch 434/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.3108\n",
      "Epoch 435/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.3197\n",
      "Epoch 436/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.3014\n",
      "Epoch 437/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2613\n",
      "Epoch 438/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2734\n",
      "Epoch 439/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.2592\n",
      "Epoch 440/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.2441\n",
      "Epoch 441/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2699\n",
      "Epoch 442/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.3823\n",
      "Epoch 443/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.3175\n",
      "Epoch 444/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.2263\n",
      "Epoch 445/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.3555\n",
      "Epoch 446/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.4331\n",
      "Epoch 447/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.3334\n",
      "Epoch 448/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.2565\n",
      "Epoch 449/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.3704\n",
      "Epoch 450/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.3407\n",
      "Epoch 451/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.2371\n",
      "Epoch 452/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.2318\n",
      "Epoch 453/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.2695\n",
      "Epoch 454/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2318\n",
      "Epoch 455/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2751\n",
      "Epoch 456/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.2630\n",
      "Epoch 457/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.2877\n",
      "Epoch 458/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2778\n",
      "Epoch 459/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.2361\n",
      "Epoch 460/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.2207\n",
      "Epoch 461/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2446\n",
      "Epoch 462/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2657\n",
      "Epoch 463/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.2881\n",
      "Epoch 464/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2379\n",
      "Epoch 465/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2406\n",
      "Epoch 466/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 1.2608\n",
      "Epoch 467/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2623\n",
      "Epoch 468/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.2515\n",
      "Epoch 469/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.3282\n",
      "Epoch 470/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2366\n",
      "Epoch 471/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.2220\n",
      "Epoch 472/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 1.2836\n",
      "Epoch 473/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.2934\n",
      "Epoch 474/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.3631\n",
      "Epoch 475/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 1.2625\n",
      "Epoch 476/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 1.2406\n",
      "Epoch 477/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.2141\n",
      "Epoch 478/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.3277\n",
      "Epoch 479/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.2967\n",
      "Epoch 480/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.2194\n",
      "Epoch 481/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.2186\n",
      "Epoch 482/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2278\n",
      "Epoch 483/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2078\n",
      "Epoch 484/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.2119\n",
      "Epoch 485/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2258\n",
      "Epoch 486/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2346\n",
      "Epoch 487/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.3998\n",
      "Epoch 488/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.4271\n",
      "Epoch 489/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2496\n",
      "Epoch 490/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.3007\n",
      "Epoch 491/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.4304\n",
      "Epoch 492/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2831\n",
      "Epoch 493/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2976\n",
      "Epoch 494/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2088\n",
      "Epoch 495/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2100\n",
      "Epoch 496/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.3383\n",
      "Epoch 497/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.2492\n",
      "Epoch 498/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.2715\n",
      "Epoch 499/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.2462\n",
      "Epoch 500/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2250\n",
      "Epoch 501/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.2310\n",
      "Epoch 502/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.2621\n",
      "Epoch 503/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.2283\n",
      "Epoch 504/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.3182\n",
      "Epoch 505/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2708\n",
      "Epoch 506/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2100\n",
      "Epoch 507/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2538\n",
      "Epoch 508/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.3032\n",
      "Epoch 509/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2212\n",
      "Epoch 510/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2993\n",
      "Epoch 511/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2392\n",
      "Epoch 512/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.3173\n",
      "Epoch 513/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.2209\n",
      "Epoch 514/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.2157\n",
      "Epoch 515/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.1949\n",
      "Epoch 516/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2365\n",
      "Epoch 517/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.2311\n",
      "Epoch 518/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.2868\n",
      "Epoch 519/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.2232\n",
      "Epoch 520/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.3540\n",
      "Epoch 521/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.2903\n",
      "Epoch 522/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2409\n",
      "Epoch 523/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.2294\n",
      "Epoch 524/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.2095\n",
      "Epoch 525/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.2141\n",
      "Epoch 526/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.2312\n",
      "Epoch 527/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2045\n",
      "Epoch 528/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 1.1970\n",
      "Epoch 529/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2637\n",
      "Epoch 530/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.2134\n",
      "Epoch 531/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.3159\n",
      "Epoch 532/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2632\n",
      "Epoch 533/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.2230\n",
      "Epoch 534/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2216\n",
      "Epoch 535/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.2237\n",
      "Epoch 536/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.1962\n",
      "Epoch 537/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2982\n",
      "Epoch 538/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.2840\n",
      "Epoch 539/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.2587\n",
      "Epoch 540/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.2298\n",
      "Epoch 541/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.1997\n",
      "Epoch 542/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2636\n",
      "Epoch 543/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.3719\n",
      "Epoch 544/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.6065\n",
      "Epoch 545/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.6418\n",
      "Epoch 546/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.4494\n",
      "Epoch 547/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.4309\n",
      "Epoch 548/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.4048\n",
      "Epoch 549/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.3163\n",
      "Epoch 550/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.2282\n",
      "Epoch 551/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.2249\n",
      "Epoch 552/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.1930\n",
      "Epoch 553/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.2322\n",
      "Epoch 554/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.2104\n",
      "Epoch 555/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.2347\n",
      "Epoch 556/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.2155\n",
      "Epoch 557/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2379\n",
      "Epoch 558/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.3210\n",
      "Epoch 559/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.3369\n",
      "Epoch 560/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.2288\n",
      "Epoch 561/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2078\n",
      "Epoch 562/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2230\n",
      "Epoch 563/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.1857\n",
      "Epoch 564/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.3617\n",
      "Epoch 565/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1954\n",
      "Epoch 566/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.2492\n",
      "Epoch 567/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.2245\n",
      "Epoch 568/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2559\n",
      "Epoch 569/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.3031\n",
      "Epoch 570/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.2601\n",
      "Epoch 571/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.2333\n",
      "Epoch 572/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.2638\n",
      "Epoch 573/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.1989\n",
      "Epoch 574/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2711\n",
      "Epoch 575/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.2664\n",
      "Epoch 576/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.2432\n",
      "Epoch 577/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.2594\n",
      "Epoch 578/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.2753\n",
      "Epoch 579/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.1762\n",
      "Epoch 580/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.1984\n",
      "Epoch 581/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.2552\n",
      "Epoch 582/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.2137\n",
      "Epoch 583/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.1960\n",
      "Epoch 584/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.2371\n",
      "Epoch 585/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.3498\n",
      "Epoch 586/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.2945\n",
      "Epoch 587/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.1709\n",
      "Epoch 588/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.2253\n",
      "Epoch 589/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.1885\n",
      "Epoch 590/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.2139\n",
      "Epoch 591/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.1672\n",
      "Epoch 592/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2345\n",
      "Epoch 593/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2421\n",
      "Epoch 594/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2067\n",
      "Epoch 595/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.3836\n",
      "Epoch 596/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2628\n",
      "Epoch 597/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.2799\n",
      "Epoch 598/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.1978\n",
      "Epoch 599/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.1959\n",
      "Epoch 600/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.2270\n",
      "Epoch 601/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.2416\n",
      "Epoch 602/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.1900\n",
      "Epoch 603/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.1907\n",
      "Epoch 604/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2238\n",
      "Epoch 605/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1694\n",
      "Epoch 606/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.1801\n",
      "Epoch 607/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.2129\n",
      "Epoch 608/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2120\n",
      "Epoch 609/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.2876\n",
      "Epoch 610/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.4206\n",
      "Epoch 611/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.3018\n",
      "Epoch 612/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.2184\n",
      "Epoch 613/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.2024\n",
      "Epoch 614/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.2766\n",
      "Epoch 615/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1979\n",
      "Epoch 616/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.2374\n",
      "Epoch 617/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.1749\n",
      "Epoch 618/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.1905\n",
      "Epoch 619/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.2212\n",
      "Epoch 620/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.2466\n",
      "Epoch 621/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2204\n",
      "Epoch 622/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.3584\n",
      "Epoch 623/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.2028\n",
      "Epoch 624/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.2178\n",
      "Epoch 625/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.2168\n",
      "Epoch 626/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.1583\n",
      "Epoch 627/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.1645\n",
      "Epoch 628/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 1.1671\n",
      "Epoch 629/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 1.1718\n",
      "Epoch 630/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.1756\n",
      "Epoch 631/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.1694\n",
      "Epoch 632/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 1.2575\n",
      "Epoch 633/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.2324\n",
      "Epoch 634/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.1616\n",
      "Epoch 635/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.2352\n",
      "Epoch 636/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.2073\n",
      "Epoch 637/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.2152\n",
      "Epoch 638/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.1703\n",
      "Epoch 639/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.1949\n",
      "Epoch 640/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.1786\n",
      "Epoch 641/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.2011\n",
      "Epoch 642/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.2085\n",
      "Epoch 643/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.1792\n",
      "Epoch 644/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2041\n",
      "Epoch 645/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.1725\n",
      "Epoch 646/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.2094\n",
      "Epoch 647/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1658\n",
      "Epoch 648/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.1988\n",
      "Epoch 649/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2795\n",
      "Epoch 650/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.2845\n",
      "Epoch 651/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.2036\n",
      "Epoch 652/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.1582\n",
      "Epoch 653/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1583\n",
      "Epoch 654/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.1726\n",
      "Epoch 655/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 1.1735\n",
      "Epoch 656/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.1702\n",
      "Epoch 657/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.1936\n",
      "Epoch 658/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.1530\n",
      "Epoch 659/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 1.1697\n",
      "Epoch 660/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.1562\n",
      "Epoch 661/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.2040\n",
      "Epoch 662/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.2046\n",
      "Epoch 663/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.1846\n",
      "Epoch 664/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.2759\n",
      "Epoch 665/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.1929\n",
      "Epoch 666/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.2061\n",
      "Epoch 667/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.2104\n",
      "Epoch 668/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.1980\n",
      "Epoch 669/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.1987\n",
      "Epoch 670/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.1674\n",
      "Epoch 671/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.1714\n",
      "Epoch 672/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.1565\n",
      "Epoch 673/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.1494\n",
      "Epoch 674/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.1707\n",
      "Epoch 675/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.1773\n",
      "Epoch 676/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.1495\n",
      "Epoch 677/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.1697\n",
      "Epoch 678/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.2479\n",
      "Epoch 679/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.3070\n",
      "Epoch 680/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.1862\n",
      "Epoch 681/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.2158\n",
      "Epoch 682/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.3488\n",
      "Epoch 683/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.2848\n",
      "Epoch 684/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.2378\n",
      "Epoch 685/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.2246\n",
      "Epoch 686/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2597\n",
      "Epoch 687/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.1894\n",
      "Epoch 688/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.1760\n",
      "Epoch 689/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.1670\n",
      "Epoch 690/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1487\n",
      "Epoch 691/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1643\n",
      "Epoch 692/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.2396\n",
      "Epoch 693/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2233\n",
      "Epoch 694/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.1860\n",
      "Epoch 695/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.2149\n",
      "Epoch 696/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.3684\n",
      "Epoch 697/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.2533\n",
      "Epoch 698/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.1867\n",
      "Epoch 699/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2067\n",
      "Epoch 700/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.1769\n",
      "Epoch 701/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.2352\n",
      "Epoch 702/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.1999\n",
      "Epoch 703/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.2225\n",
      "Epoch 704/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.1736\n",
      "Epoch 705/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.1533\n",
      "Epoch 706/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.1665\n",
      "Epoch 707/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.1825\n",
      "Epoch 708/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1518\n",
      "Epoch 709/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1511\n",
      "Epoch 710/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2011\n",
      "Epoch 711/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.2375\n",
      "Epoch 712/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 1.1494\n",
      "Epoch 713/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.1797\n",
      "Epoch 714/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.2259\n",
      "Epoch 715/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.2140\n",
      "Epoch 716/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.1908\n",
      "Epoch 717/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.1940\n",
      "Epoch 718/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1618\n",
      "Epoch 719/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 1.1912\n",
      "Epoch 720/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.2380\n",
      "Epoch 721/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1782\n",
      "Epoch 722/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1759\n",
      "Epoch 723/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.2037\n",
      "Epoch 724/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.1945\n",
      "Epoch 725/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.1789\n",
      "Epoch 726/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 1.2237\n",
      "Epoch 727/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.2280\n",
      "Epoch 728/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.1424\n",
      "Epoch 729/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1837\n",
      "Epoch 730/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.1574\n",
      "Epoch 731/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2075\n",
      "Epoch 732/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.1452\n",
      "Epoch 733/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 1.1870\n",
      "Epoch 734/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 1.1604\n",
      "Epoch 735/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1573\n",
      "Epoch 736/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.1689\n",
      "Epoch 737/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 1.2181\n",
      "Epoch 738/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2338\n",
      "Epoch 739/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2220\n",
      "Epoch 740/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2646\n",
      "Epoch 741/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.2190\n",
      "Epoch 742/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.2322\n",
      "Epoch 743/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.1615\n",
      "Epoch 744/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.1645\n",
      "Epoch 745/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.2145\n",
      "Epoch 746/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.2125\n",
      "Epoch 747/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2271\n",
      "Epoch 748/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2448\n",
      "Epoch 749/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.1447\n",
      "Epoch 750/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.2027\n",
      "Epoch 751/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.1643\n",
      "Epoch 752/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.1952\n",
      "Epoch 753/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1682\n",
      "Epoch 754/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1589\n",
      "Epoch 755/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.1592\n",
      "Epoch 756/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.2667\n",
      "Epoch 757/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.2045\n",
      "Epoch 758/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.1810\n",
      "Epoch 759/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.1788\n",
      "Epoch 760/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1708\n",
      "Epoch 761/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1375\n",
      "Epoch 762/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.1642\n",
      "Epoch 763/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.1521\n",
      "Epoch 764/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.2810\n",
      "Epoch 765/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.2123\n",
      "Epoch 766/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.2124\n",
      "Epoch 767/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.2171\n",
      "Epoch 768/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.3786\n",
      "Epoch 769/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.3037\n",
      "Epoch 770/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.1792\n",
      "Epoch 771/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.1344\n",
      "Epoch 772/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.1380\n",
      "Epoch 773/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1423\n",
      "Epoch 774/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1628\n",
      "Epoch 775/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.1951\n",
      "Epoch 776/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.1802\n",
      "Epoch 777/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1380\n",
      "Epoch 778/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1634\n",
      "Epoch 779/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 1.1589\n",
      "Epoch 780/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1804\n",
      "Epoch 781/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1391\n",
      "Epoch 782/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.2220\n",
      "Epoch 783/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.1685\n",
      "Epoch 784/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.1843\n",
      "Epoch 785/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.1451\n",
      "Epoch 786/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.1592\n",
      "Epoch 787/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.1499\n",
      "Epoch 788/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.1815\n",
      "Epoch 789/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1625\n",
      "Epoch 790/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1564\n",
      "Epoch 791/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.1495\n",
      "Epoch 792/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2194\n",
      "Epoch 793/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.1860\n",
      "Epoch 794/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.1616\n",
      "Epoch 795/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1336\n",
      "Epoch 796/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1312\n",
      "Epoch 797/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.1524\n",
      "Epoch 798/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.1552\n",
      "Epoch 799/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.1656\n",
      "Epoch 800/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.1646\n",
      "Epoch 801/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.1416\n",
      "Epoch 802/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.1949\n",
      "Epoch 803/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1436\n",
      "Epoch 804/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.1430\n",
      "Epoch 805/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2906\n",
      "Epoch 806/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.2725\n",
      "Epoch 807/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2619\n",
      "Epoch 808/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.1519\n",
      "Epoch 809/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1835\n",
      "Epoch 810/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1489\n",
      "Epoch 811/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.1349\n",
      "Epoch 812/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1733\n",
      "Epoch 813/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1440\n",
      "Epoch 814/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 1.1780\n",
      "Epoch 815/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.1885\n",
      "Epoch 816/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.3036\n",
      "Epoch 817/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1523\n",
      "Epoch 818/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1578\n",
      "Epoch 819/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.1916\n",
      "Epoch 820/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2323\n",
      "Epoch 821/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.1610\n",
      "Epoch 822/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 1.2204\n",
      "Epoch 823/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 1.3175\n",
      "Epoch 824/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 1.1212\n",
      "Epoch 825/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1563\n",
      "Epoch 826/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.2268\n",
      "Epoch 827/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.1299\n",
      "Epoch 828/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1326\n",
      "Epoch 829/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.1479\n",
      "Epoch 830/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 1.1970\n",
      "Epoch 831/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 1.1419\n",
      "Epoch 832/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1338\n",
      "Epoch 833/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.1498\n",
      "Epoch 834/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.1326\n",
      "Epoch 835/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1727\n",
      "Epoch 836/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 1.1462\n",
      "Epoch 837/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.1948\n",
      "Epoch 838/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1661\n",
      "Epoch 839/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1431\n",
      "Epoch 840/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.1495\n",
      "Epoch 841/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.1193\n",
      "Epoch 842/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1629\n",
      "Epoch 843/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.1303\n",
      "Epoch 844/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.2151\n",
      "Epoch 845/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.3065\n",
      "Epoch 846/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.2069\n",
      "Epoch 847/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.1546\n",
      "Epoch 848/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.1375\n",
      "Epoch 849/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.1370\n",
      "Epoch 850/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.1906\n",
      "Epoch 851/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1405\n",
      "Epoch 852/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.1353\n",
      "Epoch 853/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.1818\n",
      "Epoch 854/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.1244\n",
      "Epoch 855/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.1548\n",
      "Epoch 856/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2146\n",
      "Epoch 857/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.1387\n",
      "Epoch 858/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1590\n",
      "Epoch 859/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.2134\n",
      "Epoch 860/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.1541\n",
      "Epoch 861/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.1339\n",
      "Epoch 862/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.1150\n",
      "Epoch 863/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.1367\n",
      "Epoch 864/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.1206\n",
      "Epoch 865/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.1239\n",
      "Epoch 866/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.1126\n",
      "Epoch 867/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.1898\n",
      "Epoch 868/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 1.2418\n",
      "Epoch 869/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 1.2254\n",
      "Epoch 870/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.1245\n",
      "Epoch 871/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.1276\n",
      "Epoch 872/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1272\n",
      "Epoch 873/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1222\n",
      "Epoch 874/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.1337\n",
      "Epoch 875/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.1307\n",
      "Epoch 876/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.1561\n",
      "Epoch 877/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.1386\n",
      "Epoch 878/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.1444\n",
      "Epoch 879/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.2743\n",
      "Epoch 880/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1396\n",
      "Epoch 881/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.1584\n",
      "Epoch 882/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.2247\n",
      "Epoch 883/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.1729\n",
      "Epoch 884/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 1.1678\n",
      "Epoch 885/1000\n",
      "1564/1564 [==============================] - 0s 13us/step - loss: 1.1207\n",
      "Epoch 886/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.1253\n",
      "Epoch 887/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1644\n",
      "Epoch 888/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.1291\n",
      "Epoch 889/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.1201\n",
      "Epoch 890/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.1204\n",
      "Epoch 891/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1534\n",
      "Epoch 892/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1289\n",
      "Epoch 893/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 1.2166\n",
      "Epoch 894/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1862\n",
      "Epoch 895/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.1247\n",
      "Epoch 896/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.1867\n",
      "Epoch 897/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.1625\n",
      "Epoch 898/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.1596\n",
      "Epoch 899/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.1981\n",
      "Epoch 900/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.2564\n",
      "Epoch 901/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.1746\n",
      "Epoch 902/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.2497\n",
      "Epoch 903/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.1246\n",
      "Epoch 904/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.1241\n",
      "Epoch 905/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.1244\n",
      "Epoch 906/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.3034\n",
      "Epoch 907/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.1704\n",
      "Epoch 908/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1210\n",
      "Epoch 909/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.2556\n",
      "Epoch 910/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.2158\n",
      "Epoch 911/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1833\n",
      "Epoch 912/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.1268\n",
      "Epoch 913/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.0992\n",
      "Epoch 914/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.1312\n",
      "Epoch 915/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2142\n",
      "Epoch 916/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.1434\n",
      "Epoch 917/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1389\n",
      "Epoch 918/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1791\n",
      "Epoch 919/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.2013\n",
      "Epoch 920/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.1931\n",
      "Epoch 921/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.2041\n",
      "Epoch 922/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.3948\n",
      "Epoch 923/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.3296\n",
      "Epoch 924/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.2434\n",
      "Epoch 925/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 1.2275\n",
      "Epoch 926/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 1.1608\n",
      "Epoch 927/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 1.1453\n",
      "Epoch 928/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1137\n",
      "Epoch 929/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.2091\n",
      "Epoch 930/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.1554\n",
      "Epoch 931/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.1270\n",
      "Epoch 932/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.1395\n",
      "Epoch 933/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 1.1485\n",
      "Epoch 934/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.2971\n",
      "Epoch 935/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1409\n",
      "Epoch 936/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.1412\n",
      "Epoch 937/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.1698\n",
      "Epoch 938/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 1.1892\n",
      "Epoch 939/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.1222\n",
      "Epoch 940/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.1263\n",
      "Epoch 941/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.1106\n",
      "Epoch 942/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.1528\n",
      "Epoch 943/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1382\n",
      "Epoch 944/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1264\n",
      "Epoch 945/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 1.1047\n",
      "Epoch 946/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.1340\n",
      "Epoch 947/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.1039\n",
      "Epoch 948/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.0980\n",
      "Epoch 949/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.1517\n",
      "Epoch 950/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.1056\n",
      "Epoch 951/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.1059\n",
      "Epoch 952/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.1228\n",
      "Epoch 953/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.2189\n",
      "Epoch 954/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1556\n",
      "Epoch 955/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1894\n",
      "Epoch 956/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.2610\n",
      "Epoch 957/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.1482\n",
      "Epoch 958/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.1191\n",
      "Epoch 959/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.1428\n",
      "Epoch 960/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.1283\n",
      "Epoch 961/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.1205\n",
      "Epoch 962/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.1168\n",
      "Epoch 963/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.1116\n",
      "Epoch 964/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1658\n",
      "Epoch 965/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.1293\n",
      "Epoch 966/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.1172\n",
      "Epoch 967/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.1105\n",
      "Epoch 968/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.1637\n",
      "Epoch 969/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.1039\n",
      "Epoch 970/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.1291\n",
      "Epoch 971/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.1372\n",
      "Epoch 972/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.1078\n",
      "Epoch 973/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.1665\n",
      "Epoch 974/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.1330\n",
      "Epoch 975/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.1532\n",
      "Epoch 976/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.1900\n",
      "Epoch 977/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.2112\n",
      "Epoch 978/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.1951\n",
      "Epoch 979/1000\n",
      "1564/1564 [==============================] - 0s 15us/step - loss: 1.1562\n",
      "Epoch 980/1000\n",
      "1564/1564 [==============================] - 0s 14us/step - loss: 1.1342\n",
      "Epoch 981/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.1989\n",
      "Epoch 982/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.1666\n",
      "Epoch 983/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.1064\n",
      "Epoch 984/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 1.1129\n",
      "Epoch 985/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.1629\n",
      "Epoch 986/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.1245\n",
      "Epoch 987/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 1.2589\n",
      "Epoch 988/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1886\n",
      "Epoch 989/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.1669\n",
      "Epoch 990/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.1184\n",
      "Epoch 991/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.1592\n",
      "Epoch 992/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.1887\n",
      "Epoch 993/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.1098\n",
      "Epoch 994/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1112\n",
      "Epoch 995/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 1.1582\n",
      "Epoch 996/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 1.1748\n",
      "Epoch 997/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 1.1807\n",
      "Epoch 998/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 1.1604\n",
      "Epoch 999/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.1324\n",
      "Epoch 1000/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.1247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a37759e10>"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model = Sequential()\n",
    "NN_model.add(Dense(units=16,input_dim= 28,activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_model.add(Dense(units=8, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_model.add(Dense(units=4, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_model.add(Dense(units=1,activation='linear'))\n",
    "NN_model.compile(loss='mse', optimizer='adam')\n",
    "NN_model.fit(np.array(X_train), np.array(y_train), epochs=1000,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a3a6f6390>"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_predictions = NN_model.predict(X_train)\n",
    "training = pd.DataFrame(training_predictions)\n",
    "training['actual'] = y_train.reset_index()['rebounds']\n",
    "plt.scatter(training_predictions,training[0]-training['actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = NN_model.predict(X_test)\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.5)\n",
    "gbr.fit(X_train,y_train)\n",
    "gbr_predictions = gbr.predict(X_test)\n",
    "LR = LinearRegression(fit_intercept=True).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = pd.DataFrame(predictions)\n",
    "testing.columns=['NN_predictions']\n",
    "testing['actual'] = y_test.reset_index()['rebounds']\n",
    "testing['GBR_predictions']=gbr_predictions\n",
    "testing['LY_rebounding']=X_test['rebounds_ly'].reset_index()['rebounds_ly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a38ecf588>]"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(figsize=(16,8))\n",
    "plt.plot(testing[0:100].index,testing['actual'][0:100], color = 'r',alpha = 0.5)\n",
    "plt.plot(testing[0:100].index,testing['NN_predictions'][0:100], color = 'g',alpha = 0.2)\n",
    "#plt.scatter(testing[0:100].index,testing['LY_rebounding'][0:100],color = 'b',alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN_predictions</th>\n",
       "      <th>actual</th>\n",
       "      <th>GBR_predictions</th>\n",
       "      <th>LY_rebounding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>12.765904</td>\n",
       "      <td>13.8</td>\n",
       "      <td>13.489847</td>\n",
       "      <td>14.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>11.916736</td>\n",
       "      <td>12.2</td>\n",
       "      <td>10.849303</td>\n",
       "      <td>12.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>530</th>\n",
       "      <td>10.355140</td>\n",
       "      <td>10.3</td>\n",
       "      <td>9.807479</td>\n",
       "      <td>12.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>10.638011</td>\n",
       "      <td>10.9</td>\n",
       "      <td>11.094418</td>\n",
       "      <td>12.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>10.088206</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.175805</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>12.188785</td>\n",
       "      <td>14.1</td>\n",
       "      <td>11.834806</td>\n",
       "      <td>11.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>9.861157</td>\n",
       "      <td>12.2</td>\n",
       "      <td>9.963722</td>\n",
       "      <td>11.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>10.788072</td>\n",
       "      <td>9.8</td>\n",
       "      <td>10.611417</td>\n",
       "      <td>11.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>9.575421</td>\n",
       "      <td>8.7</td>\n",
       "      <td>10.323050</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>7.563340</td>\n",
       "      <td>4.8</td>\n",
       "      <td>7.630403</td>\n",
       "      <td>11.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>9.951982</td>\n",
       "      <td>10.1</td>\n",
       "      <td>8.714128</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>11.595977</td>\n",
       "      <td>11.3</td>\n",
       "      <td>10.715052</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>9.048032</td>\n",
       "      <td>10.4</td>\n",
       "      <td>10.632928</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>10.198859</td>\n",
       "      <td>10.9</td>\n",
       "      <td>10.688302</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>8.066480</td>\n",
       "      <td>5.6</td>\n",
       "      <td>7.587551</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>12.648248</td>\n",
       "      <td>15.2</td>\n",
       "      <td>11.648853</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>11.183051</td>\n",
       "      <td>8.3</td>\n",
       "      <td>10.708740</td>\n",
       "      <td>10.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>8.405257</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.276048</td>\n",
       "      <td>10.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>8.889251</td>\n",
       "      <td>7.8</td>\n",
       "      <td>9.517446</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>9.638053</td>\n",
       "      <td>9.8</td>\n",
       "      <td>10.448189</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>8.101727</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.892984</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>8.649089</td>\n",
       "      <td>9.2</td>\n",
       "      <td>9.985895</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>9.025359</td>\n",
       "      <td>8.8</td>\n",
       "      <td>10.045945</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>8.076715</td>\n",
       "      <td>8.5</td>\n",
       "      <td>9.106698</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>8.968547</td>\n",
       "      <td>8.2</td>\n",
       "      <td>9.600947</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>9.873603</td>\n",
       "      <td>11.1</td>\n",
       "      <td>10.276407</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>8.620500</td>\n",
       "      <td>10.4</td>\n",
       "      <td>8.972222</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>9.220675</td>\n",
       "      <td>8.7</td>\n",
       "      <td>8.369018</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>8.264550</td>\n",
       "      <td>9.2</td>\n",
       "      <td>10.008025</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>9.130923</td>\n",
       "      <td>9.3</td>\n",
       "      <td>10.535204</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>1.763499</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.696390</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>1.164452</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.902496</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>2.054173</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.438699</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>1.530230</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.343519</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>0.342892</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.251331</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.024091</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.470455</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>0.656089</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.781178</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.900544</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.635007</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>4.305293</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.621447</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1.198834</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.782541</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>2.036885</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.799493</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>1.071078</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.610087</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>1.156375</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.726767</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>1.572934</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.085466</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>2.993815</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.316055</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>1.663247</td>\n",
       "      <td>4.1</td>\n",
       "      <td>2.247415</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>1.947671</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.496951</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1.197238</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.008465</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>1.862683</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.440913</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.984055</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.670981</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>1.299319</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.835118</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>1.540910</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.164285</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>1.710049</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.427616</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>3.119155</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.280306</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>0.948025</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.582836</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>0.134400</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.384847</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1.093983</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.530044</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1.128665</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.108062</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>0.495797</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.843079</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0.348811</td>\n",
       "      <td>10.2</td>\n",
       "      <td>2.810270</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>671 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     NN_predictions  actual  GBR_predictions  LY_rebounding\n",
       "37        12.765904    13.8        13.489847           14.8\n",
       "116       11.916736    12.2        10.849303           12.4\n",
       "530       10.355140    10.3         9.807479           12.1\n",
       "564       10.638011    10.9        11.094418           12.1\n",
       "481       10.088206    11.0        11.175805           11.9\n",
       "441       12.188785    14.1        11.834806           11.8\n",
       "275        9.861157    12.2         9.963722           11.7\n",
       "497       10.788072     9.8        10.611417           11.7\n",
       "439        9.575421     8.7        10.323050           11.5\n",
       "219        7.563340     4.8         7.630403           11.5\n",
       "568        9.951982    10.1         8.714128           11.2\n",
       "316       11.595977    11.3        10.715052           11.1\n",
       "498        9.048032    10.4        10.632928           11.0\n",
       "253       10.198859    10.9        10.688302           11.0\n",
       "60         8.066480     5.6         7.587551           11.0\n",
       "141       12.648248    15.2        11.648853           11.0\n",
       "476       11.183051     8.3        10.708740           10.9\n",
       "326        8.405257     9.6         9.276048           10.7\n",
       "377        8.889251     7.8         9.517446           10.5\n",
       "159        9.638053     9.8        10.448189           10.4\n",
       "398        8.101727     8.6         8.892984           10.4\n",
       "453        8.649089     9.2         9.985895           10.4\n",
       "375        9.025359     8.8        10.045945           10.2\n",
       "88         8.076715     8.5         9.106698           10.2\n",
       "581        8.968547     8.2         9.600947           10.0\n",
       "344        9.873603    11.1        10.276407            9.9\n",
       "526        8.620500    10.4         8.972222            9.9\n",
       "81         9.220675     8.7         8.369018            9.8\n",
       "298        8.264550     9.2        10.008025            9.6\n",
       "437        9.130923     9.3        10.535204            9.6\n",
       "..              ...     ...              ...            ...\n",
       "646        1.763499     0.7         1.696390            1.1\n",
       "558        1.164452     0.8         1.902496            1.1\n",
       "533        2.054173     5.8         2.438699            1.1\n",
       "485        1.530230     2.7         2.343519            1.1\n",
       "418        0.342892     1.0         1.251331            1.1\n",
       "95         1.024091     0.8         1.470455            1.0\n",
       "184        0.656089     0.8         1.781178            1.0\n",
       "25         0.900544     0.6         1.635007            1.0\n",
       "378        4.305293     7.0         3.621447            1.0\n",
       "77         1.198834     1.3         1.782541            1.0\n",
       "659        2.036885     2.4         1.799493            1.0\n",
       "181        1.071078     2.6         1.610087            1.0\n",
       "443        1.156375     1.5         1.726767            0.9\n",
       "133        1.572934     1.7         2.085466            0.9\n",
       "433        2.993815     2.7         3.316055            0.9\n",
       "424        1.663247     4.1         2.247415            0.9\n",
       "325        1.947671     2.9         2.496951            0.9\n",
       "185        1.197238     2.3         2.008465            0.9\n",
       "670        1.862683     1.5         1.440913            0.9\n",
       "68         0.984055     2.4         1.670981            0.8\n",
       "373        1.299319     1.4         1.835118            0.8\n",
       "328        1.540910     2.2         2.164285            0.8\n",
       "602        1.710049     0.9         1.427616            0.8\n",
       "539        3.119155     4.5         3.280306            0.7\n",
       "635        0.948025     1.1         1.582836            0.7\n",
       "212        0.134400     0.6         1.384847            0.7\n",
       "47         1.093983     0.7         1.530044            0.5\n",
       "135        1.128665     1.8         2.108062            0.5\n",
       "638        0.495797     2.8         1.843079            0.3\n",
       "236        0.348811    10.2         2.810270            0.0\n",
       "\n",
       "[671 rows x 4 columns]"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing.sort_values(by='LY_rebounding',ascending=False)#[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>rebounds</th>\n",
       "      <th>rebounds_ly_x</th>\n",
       "      <th>predictions</th>\n",
       "      <th>gbr_pred</th>\n",
       "      <th>LR_pred</th>\n",
       "      <th>mean_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Markieff Morris</td>\n",
       "      <td>5.6</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.630604</td>\n",
       "      <td>5.717301</td>\n",
       "      <td>5.698308</td>\n",
       "      <td>5.682071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>Cody Zeller</td>\n",
       "      <td>5.4</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.502560</td>\n",
       "      <td>4.843199</td>\n",
       "      <td>5.035900</td>\n",
       "      <td>4.793886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Dirk Nowitzki</td>\n",
       "      <td>5.7</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.264424</td>\n",
       "      <td>5.163563</td>\n",
       "      <td>5.804455</td>\n",
       "      <td>5.410814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Dewayne Dedmon</td>\n",
       "      <td>7.9</td>\n",
       "      <td>6.5</td>\n",
       "      <td>7.946820</td>\n",
       "      <td>8.934795</td>\n",
       "      <td>7.677720</td>\n",
       "      <td>8.186445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>Robert Covington</td>\n",
       "      <td>5.4</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.769932</td>\n",
       "      <td>5.641063</td>\n",
       "      <td>6.119539</td>\n",
       "      <td>5.843512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>Robin Lopez</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.4</td>\n",
       "      <td>1.701737</td>\n",
       "      <td>6.060499</td>\n",
       "      <td>6.597710</td>\n",
       "      <td>4.786649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Otto Porter</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.4</td>\n",
       "      <td>5.687191</td>\n",
       "      <td>5.318500</td>\n",
       "      <td>6.085943</td>\n",
       "      <td>5.697212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Rudy Gay</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>4.100277</td>\n",
       "      <td>4.241227</td>\n",
       "      <td>4.529746</td>\n",
       "      <td>4.290417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Dario Saric</td>\n",
       "      <td>6.7</td>\n",
       "      <td>6.3</td>\n",
       "      <td>7.292883</td>\n",
       "      <td>7.154685</td>\n",
       "      <td>7.273493</td>\n",
       "      <td>7.240354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>Marc Gasol</td>\n",
       "      <td>8.1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.733407</td>\n",
       "      <td>6.389506</td>\n",
       "      <td>6.562646</td>\n",
       "      <td>6.561853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Jabari Parker</td>\n",
       "      <td>4.9</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4.690646</td>\n",
       "      <td>5.187480</td>\n",
       "      <td>5.221453</td>\n",
       "      <td>5.033193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>Nicolas Batum</td>\n",
       "      <td>4.8</td>\n",
       "      <td>6.2</td>\n",
       "      <td>4.722104</td>\n",
       "      <td>5.570082</td>\n",
       "      <td>5.271825</td>\n",
       "      <td>5.188003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Jimmy Butler</td>\n",
       "      <td>5.3</td>\n",
       "      <td>6.2</td>\n",
       "      <td>5.443583</td>\n",
       "      <td>5.390890</td>\n",
       "      <td>6.183400</td>\n",
       "      <td>5.672624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Avery Bradley</td>\n",
       "      <td>2.4</td>\n",
       "      <td>6.1</td>\n",
       "      <td>4.290364</td>\n",
       "      <td>5.022227</td>\n",
       "      <td>4.943102</td>\n",
       "      <td>4.751898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Derrick Favors</td>\n",
       "      <td>7.2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>7.189133</td>\n",
       "      <td>6.525818</td>\n",
       "      <td>6.748191</td>\n",
       "      <td>6.821048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>Thaddeus Young</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.1</td>\n",
       "      <td>5.892369</td>\n",
       "      <td>5.956644</td>\n",
       "      <td>6.439155</td>\n",
       "      <td>6.096056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>P.J. Tucker</td>\n",
       "      <td>5.6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.917443</td>\n",
       "      <td>5.486733</td>\n",
       "      <td>5.333840</td>\n",
       "      <td>5.246005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>Larry Nance</td>\n",
       "      <td>6.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5.809662</td>\n",
       "      <td>5.810646</td>\n",
       "      <td>5.954158</td>\n",
       "      <td>5.858155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>Carmelo Anthony</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>4.771859</td>\n",
       "      <td>5.645506</td>\n",
       "      <td>5.411661</td>\n",
       "      <td>5.276342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Ersan Ilyasova</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5.978108</td>\n",
       "      <td>5.832850</td>\n",
       "      <td>5.539695</td>\n",
       "      <td>5.783551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>Zaza Pachulia</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5.975245</td>\n",
       "      <td>5.849122</td>\n",
       "      <td>6.482343</td>\n",
       "      <td>6.102237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>Rondae Hollis-Jefferson</td>\n",
       "      <td>6.8</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6.020258</td>\n",
       "      <td>6.382954</td>\n",
       "      <td>6.210003</td>\n",
       "      <td>6.204405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Jae Crowder</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.8</td>\n",
       "      <td>3.943242</td>\n",
       "      <td>4.207437</td>\n",
       "      <td>4.330580</td>\n",
       "      <td>4.160420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Jusuf Nurkic</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6.411566</td>\n",
       "      <td>6.460987</td>\n",
       "      <td>6.254200</td>\n",
       "      <td>6.375585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>Kosta Koufos</td>\n",
       "      <td>6.6</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4.741206</td>\n",
       "      <td>4.856823</td>\n",
       "      <td>4.808473</td>\n",
       "      <td>4.802167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>Trevor Ariza</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4.608933</td>\n",
       "      <td>4.963951</td>\n",
       "      <td>4.935392</td>\n",
       "      <td>4.836092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>Kyle O'Quinn</td>\n",
       "      <td>6.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5.363965</td>\n",
       "      <td>5.748595</td>\n",
       "      <td>5.876506</td>\n",
       "      <td>5.663022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>Nikola Mirotic</td>\n",
       "      <td>8.2</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.799538</td>\n",
       "      <td>5.258920</td>\n",
       "      <td>5.071637</td>\n",
       "      <td>5.043365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>Richaun Holmes</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.300175</td>\n",
       "      <td>4.948700</td>\n",
       "      <td>5.436471</td>\n",
       "      <td>5.228449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Brook Lopez</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5.496678</td>\n",
       "      <td>5.606606</td>\n",
       "      <td>5.912540</td>\n",
       "      <td>5.671941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ed Davis</td>\n",
       "      <td>7.4</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.948592</td>\n",
       "      <td>5.355304</td>\n",
       "      <td>5.661940</td>\n",
       "      <td>5.655278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>DeMar DeRozan</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5.2</td>\n",
       "      <td>4.786221</td>\n",
       "      <td>4.958907</td>\n",
       "      <td>5.026379</td>\n",
       "      <td>4.923836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Noah Vonleh</td>\n",
       "      <td>5.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.087298</td>\n",
       "      <td>5.292321</td>\n",
       "      <td>5.292951</td>\n",
       "      <td>5.224190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Justise Winslow</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.774810</td>\n",
       "      <td>4.357713</td>\n",
       "      <td>4.123025</td>\n",
       "      <td>4.085183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>Tobias Harris</td>\n",
       "      <td>5.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.427844</td>\n",
       "      <td>6.137799</td>\n",
       "      <td>6.592211</td>\n",
       "      <td>6.385951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>Rajon Rondo</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>4.081555</td>\n",
       "      <td>4.581401</td>\n",
       "      <td>4.493242</td>\n",
       "      <td>4.385399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>Tarik Black</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>4.880917</td>\n",
       "      <td>5.419231</td>\n",
       "      <td>5.233150</td>\n",
       "      <td>5.177766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>T.J. Warren</td>\n",
       "      <td>5.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>4.128762</td>\n",
       "      <td>4.535358</td>\n",
       "      <td>4.894789</td>\n",
       "      <td>4.519636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>John Henson</td>\n",
       "      <td>6.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>5.173062</td>\n",
       "      <td>5.099881</td>\n",
       "      <td>5.465000</td>\n",
       "      <td>5.245981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Andre Roberson</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>4.592907</td>\n",
       "      <td>4.714899</td>\n",
       "      <td>4.616741</td>\n",
       "      <td>4.641516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Aaron Gordon</td>\n",
       "      <td>7.9</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.100205</td>\n",
       "      <td>5.065108</td>\n",
       "      <td>5.864800</td>\n",
       "      <td>5.676704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Chris Paul</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.463986</td>\n",
       "      <td>5.105569</td>\n",
       "      <td>4.964596</td>\n",
       "      <td>4.844717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Harrison Barnes</td>\n",
       "      <td>6.1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.593516</td>\n",
       "      <td>4.686472</td>\n",
       "      <td>4.724805</td>\n",
       "      <td>4.668264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>Skal Labissiere</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5.177332</td>\n",
       "      <td>5.150600</td>\n",
       "      <td>5.786495</td>\n",
       "      <td>5.371476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>James Johnson</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.053494</td>\n",
       "      <td>4.431123</td>\n",
       "      <td>4.343343</td>\n",
       "      <td>4.275987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Damian Lillard</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.572340</td>\n",
       "      <td>4.547379</td>\n",
       "      <td>4.611870</td>\n",
       "      <td>4.577197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>Timofey Mozgov</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.288335</td>\n",
       "      <td>3.785909</td>\n",
       "      <td>3.764335</td>\n",
       "      <td>3.612860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ian Mahinmi</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.454051</td>\n",
       "      <td>4.585691</td>\n",
       "      <td>5.047461</td>\n",
       "      <td>4.695734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Eric Bledsoe</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.003747</td>\n",
       "      <td>4.568103</td>\n",
       "      <td>4.654901</td>\n",
       "      <td>4.408917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Kelly Olynyk</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.816187</td>\n",
       "      <td>4.827772</td>\n",
       "      <td>4.766606</td>\n",
       "      <td>4.803522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      player  rebounds  rebounds_ly_x  predictions  gbr_pred  \\\n",
       "43           Markieff Morris       5.6            6.5     5.630604  5.717301   \n",
       "118              Cody Zeller       5.4            6.5     4.502560  4.843199   \n",
       "14             Dirk Nowitzki       5.7            6.5     5.264424  5.163563   \n",
       "150           Dewayne Dedmon       7.9            6.5     7.946820  8.934795   \n",
       "330         Robert Covington       5.4            6.5     5.769932  5.641063   \n",
       "331              Robin Lopez       4.5            6.4     1.701737  6.060499   \n",
       "50               Otto Porter       6.4            6.4     5.687191  5.318500   \n",
       "56                  Rudy Gay       5.1            6.3     4.100277  4.241227   \n",
       "131              Dario Saric       6.7            6.3     7.292883  7.154685   \n",
       "275               Marc Gasol       8.1            6.3     6.733407  6.389506   \n",
       "194            Jabari Parker       4.9            6.2     4.690646  5.187480   \n",
       "301            Nicolas Batum       4.8            6.2     4.722104  5.570082   \n",
       "218             Jimmy Butler       5.3            6.2     5.443583  5.390890   \n",
       "92             Avery Bradley       2.4            6.1     4.290364  5.022227   \n",
       "146           Derrick Favors       7.2            6.1     7.189133  6.525818   \n",
       "357           Thaddeus Young       6.3            6.1     5.892369  5.956644   \n",
       "310              P.J. Tucker       5.6            6.0     4.917443  5.486733   \n",
       "264              Larry Nance       6.8            5.9     5.809662  5.810646   \n",
       "111          Carmelo Anthony       5.8            5.9     4.771859  5.645506   \n",
       "165           Ersan Ilyasova       5.5            5.9     5.978108  5.832850   \n",
       "391            Zaza Pachulia       4.7            5.9     5.975245  5.849122   \n",
       "333  Rondae Hollis-Jefferson       6.8            5.8     6.020258  6.382954   \n",
       "195              Jae Crowder       3.3            5.8     3.943242  4.207437   \n",
       "35              Jusuf Nurkic       9.0            5.8     6.411566  6.460987   \n",
       "253             Kosta Koufos       6.6            5.7     4.741206  4.856823   \n",
       "367             Trevor Ariza       4.4            5.7     4.608933  4.963951   \n",
       "258             Kyle O'Quinn       6.1            5.6     5.363965  5.748595   \n",
       "305           Nikola Mirotic       8.2            5.5     4.799538  5.258920   \n",
       "328           Richaun Holmes       4.4            5.5     5.300175  4.948700   \n",
       "105              Brook Lopez       4.0            5.4     5.496678  5.606606   \n",
       "17                  Ed Davis       7.4            5.3     5.948592  5.355304   \n",
       "139            DeMar DeRozan       3.9            5.2     4.786221  4.958907   \n",
       "48               Noah Vonleh       5.1            5.2     5.087298  5.292321   \n",
       "34           Justise Winslow       5.4            5.2     3.774810  4.357713   \n",
       "363            Tobias Harris       5.1            5.1     6.427844  6.137799   \n",
       "321              Rajon Rondo       4.0            5.1     4.081555  4.581401   \n",
       "352              Tarik Black       3.2            5.1     4.880917  5.419231   \n",
       "350              T.J. Warren       5.1            5.1     4.128762  4.535358   \n",
       "226              John Henson       6.8            5.1     5.173062  5.099881   \n",
       "82            Andre Roberson       4.7            5.1     4.592907  4.714899   \n",
       "69              Aaron Gordon       7.9            5.1     6.100205  5.065108   \n",
       "116               Chris Paul       5.4            5.0     4.463986  5.105569   \n",
       "20           Harrison Barnes       6.1            5.0     4.593516  4.686472   \n",
       "343          Skal Labissiere       4.8            4.9     5.177332  5.150600   \n",
       "25             James Johnson       4.9            4.9     4.053494  4.431123   \n",
       "6             Damian Lillard       4.5            4.9     4.572340  4.547379   \n",
       "361           Timofey Mozgov       3.2            4.9     3.288335  3.785909   \n",
       "22               Ian Mahinmi       4.1            4.8     4.454051  4.585691   \n",
       "163             Eric Bledsoe       3.9            4.8     4.003747  4.568103   \n",
       "37              Kelly Olynyk       5.7            4.8     4.816187  4.827772   \n",
       "\n",
       "      LR_pred  mean_pred  \n",
       "43   5.698308   5.682071  \n",
       "118  5.035900   4.793886  \n",
       "14   5.804455   5.410814  \n",
       "150  7.677720   8.186445  \n",
       "330  6.119539   5.843512  \n",
       "331  6.597710   4.786649  \n",
       "50   6.085943   5.697212  \n",
       "56   4.529746   4.290417  \n",
       "131  7.273493   7.240354  \n",
       "275  6.562646   6.561853  \n",
       "194  5.221453   5.033193  \n",
       "301  5.271825   5.188003  \n",
       "218  6.183400   5.672624  \n",
       "92   4.943102   4.751898  \n",
       "146  6.748191   6.821048  \n",
       "357  6.439155   6.096056  \n",
       "310  5.333840   5.246005  \n",
       "264  5.954158   5.858155  \n",
       "111  5.411661   5.276342  \n",
       "165  5.539695   5.783551  \n",
       "391  6.482343   6.102237  \n",
       "333  6.210003   6.204405  \n",
       "195  4.330580   4.160420  \n",
       "35   6.254200   6.375585  \n",
       "253  4.808473   4.802167  \n",
       "367  4.935392   4.836092  \n",
       "258  5.876506   5.663022  \n",
       "305  5.071637   5.043365  \n",
       "328  5.436471   5.228449  \n",
       "105  5.912540   5.671941  \n",
       "17   5.661940   5.655278  \n",
       "139  5.026379   4.923836  \n",
       "48   5.292951   5.224190  \n",
       "34   4.123025   4.085183  \n",
       "363  6.592211   6.385951  \n",
       "321  4.493242   4.385399  \n",
       "352  5.233150   5.177766  \n",
       "350  4.894789   4.519636  \n",
       "226  5.465000   5.245981  \n",
       "82   4.616741   4.641516  \n",
       "69   5.864800   5.676704  \n",
       "116  4.964596   4.844717  \n",
       "20   4.724805   4.668264  \n",
       "343  5.786495   5.371476  \n",
       "25   4.343343   4.275987  \n",
       "6    4.611870   4.577197  \n",
       "361  3.764335   3.612860  \n",
       "22   5.047461   4.695734  \n",
       "163  4.654901   4.408917  \n",
       "37   4.766606   4.803522  "
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_2017rebounds = rebounds[rebounds['season']==2017].drop(['team','player','rebounds','Games'],axis=1)\n",
    "rebounds_2017 = NN_model.predict(pred_2017rebounds)\n",
    "test_2 =pd.DataFrame(rebounds_2017)\n",
    "gbr_reb_2017 = pd.DataFrame(gbr.predict(pred_2017rebounds))\n",
    "LR_reb_2017 = pd.DataFrame(LR.predict(pred_2017rebounds))\n",
    "test_3 = pd.merge(rebounds,pred_2017rebounds,left_index=True,right_index=True).reset_index()\n",
    "test_3['predictions']=test_2[0]\n",
    "test_3['gbr_pred'] = gbr_reb_2017[0]\n",
    "test_3['LR_pred'] = LR_reb_2017[0]\n",
    "test_3['mean_pred'] = (test_3['predictions']+test_3['gbr_pred']+test_3['LR_pred'])/3\n",
    "test_3 = test_3[test_3['Games']>30]\n",
    "test_3[['player','rebounds','rebounds_ly_x','predictions','gbr_pred','LR_pred','mean_pred']].sort_values(by='rebounds_ly_x',ascending=False)[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MSE using NN:{}'.format(np.mean((test_3['rebounds']-test_3['predictions'])**2)))\n",
    "print('MSE using mean:{}'.format(np.mean((test_3['rebounds']-np.mean(test_3['rebounds']))**2)))\n",
    "print('MSE using last year stats:{}'.format(np.mean((test_3['rebounds']-test_3['rebounds_ly_x'])**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE using NN:1.5360105666030683\n",
      "MSE using mean:6.292553316074948\n",
      "MSE using last year stats:1.808012820512822\n",
      "MSE using gbr:1.3305627955364254\n",
      "MSE using LR:1.3304784320633838\n",
      "MSE using combo:1.3020509773938502\n"
     ]
    }
   ],
   "source": [
    "print('MSE using NN:{}'.format(np.mean((test_3['rebounds']-test_3['predictions'])**2)))\n",
    "print('MSE using mean:{}'.format(np.mean((test_3['rebounds']-np.mean(test_3['rebounds']))**2)))\n",
    "print('MSE using last year stats:{}'.format(np.mean((test_3['rebounds']-test_3['rebounds_ly_x'])**2)))\n",
    "print('MSE using gbr:{}'.format(np.mean((test_3['rebounds']-test_3['gbr_pred'])**2)))\n",
    "print('MSE using LR:{}'.format(np.mean((test_3['rebounds']-test_3['LR_pred'])**2)))\n",
    "print('MSE using combo:{}'.format(np.mean((test_3['rebounds']-test_3['mean_pred'])**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8111346 , 0.75668588, 0.78079755, 0.72744262, 0.75121757])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.5),X_train,y_train,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(LinearRegression(),X_train,y_train,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''next is assists'''\n",
    "\n",
    "\n",
    "query= '''\n",
    "        \n",
    "        DROP TABLE IF EXISTS assists_pred;\n",
    "        CREATE TABLE assists_pred(\n",
    "        season int, --these come from player_stats\n",
    "        player varchar(50),\n",
    "        Age int,\n",
    "        team varchar(50),\n",
    "        ast float, -- these come from player_stats\n",
    "        ast_ly float,\n",
    "        change_ast_ly float,\n",
    "        Games float,\n",
    "        C_PF int,\n",
    "        PG int,\n",
    "        SG_SF int,\n",
    "        starter_change int, \n",
    "        \n",
    "        -- these come from team_changes\n",
    "        high_usageplayer_added int,\n",
    "        usagemin_opened float,\n",
    "        maxusage_added float,\n",
    "        high_usageplayer_dropped int,\n",
    "        assists_opened float,\n",
    "        max_assistsdropped float,\n",
    "        max_assistsadded float,\n",
    "        points_opened float,\n",
    "        threes_opened float,\n",
    "        \n",
    "        -- from player_advstats\n",
    "        per_ly float,\n",
    "        change_per float,\n",
    "        usagerank float,\n",
    "        usagerank_ly float,\n",
    "        ast_perc_ly float,\n",
    "        change_assist_perc float,\n",
    "        offensive_winshares float,\n",
    "        offensive_boxplusminus float,\n",
    "        boxplusminus float,\n",
    "        value_overreplacement float,\n",
    "        \n",
    "        career_ast float,\n",
    "        yearspro int\n",
    "        );\n",
    "        \n",
    "        INSERT INTO assists_pred(season,player,age,team,ast,ast_ly,change_ast_ly,starter_change,Games,C_PF,PG,SG_SF)\n",
    "        SELECT season,player,age,startingteam,ast,ast_ly,change_ast_ly,starter-starter_ly,Games,\n",
    "        case when pos in ('C','PF') then 1 else 0 end,case when pos='PG' then 1 else 0 end,case when pos in('SG','SF') then 1 else 0 end from player_stats;\n",
    "        \n",
    "        update assists_pred ap\n",
    "        set high_usageplayer_added = tc.high_usageplayer_added,usagemin_opened=tc.usagemin_opened,\n",
    "        maxusage_added=tc.max_usageadded,high_usageplayer_dropped=tc.high_usageplayer_dropped,assists_opened=tc.ast_opened,\n",
    "        max_assistsdropped=tc.max_astdropped,max_assistsadded=tc.max_astadded,points_opened = tc.points_opened,threes_opened = tc.threes_opened\n",
    "        from team_changes tc\n",
    "        where tc.team = ap.team and ap.season=tc.season;\n",
    "        \n",
    "        update assists_pred ap\n",
    "        set per_ly=pa.per_ly,change_per=pa.change_per,usagerank=pa.usagerank,usagerank_ly=pa.usagerank_ly\n",
    "        ,ast_perc_ly = pa.ast_perc_ly,change_assist_perc = pa.change_assist_perc,offensive_winshares=pa.offensive_winshares,\n",
    "        offensive_boxplusminus=pa.offensive_boxplusminus,boxplusminus=pa.boxplusminus,value_overreplacement=pa.value_overreplacement\n",
    "        from player_advstats pa\n",
    "        where ap.player = pa.player and ap.season = pa.season and ap.team = pa.startingteam;\n",
    "        \n",
    "        update assists_pred ap\n",
    "        set career_ast = pc.career_ast, yearspro = pc.yearspro\n",
    "        from player_careerstats pc\n",
    "        where ap.player = pc.player and ap.season = pc.season;\n",
    "        \n",
    "        \n",
    "        select * from assists_pred where season>2009\n",
    "        '''\n",
    "\n",
    "\n",
    "cur.execute(query)\n",
    "data = cur.fetchall()\n",
    "assists_df = pd.DataFrame(np.array(data))\n",
    "assists_df.columns = ['season','player','age','team','assists','assists_ly','change_assists_ly','Games','C_PF','PG','SG_SF','starter_change','high_usageplayer_added','usagemin_opened','maxusage_added','high_usageplayer_dropped','assists_opened','max_assistsdropped',\n",
    "                    'max_assistsadded','points_opened','threes_opened','per_ly','change_per','usagerank','usagerank_ly','ast_perc_ly','change_ast_perc','offensive_winshares','offensive_boxplusminus','boxplusminus','value_overreplacement','career_assists','yearspro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "assists_df['age_squared']=assists_df['age']*assists_df['age']\n",
    "assists = assists_df[assists_df['assists_ly'].notna()]\n",
    "for i in assists.columns:\n",
    "    if i not in(['player','team']):\n",
    "        assists[i]=pd.to_numeric(assists[i])\n",
    "assists = assists.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = assists[(assists['season']!=2017) & (assists['Games']>30)].drop(['player','team','assists','Games'],axis=1)\n",
    "y = assists[(assists['season']!=2017) & (assists['Games']>30)]['assists']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1564/1564 [==============================] - 2s 1ms/step - loss: 8352.1222\n",
      "Epoch 2/1000\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 1536.9714\n",
      "Epoch 3/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 730.5720\n",
      "Epoch 4/1000\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 509.0820\n",
      "Epoch 5/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 380.3260\n",
      "Epoch 6/1000\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 295.6683\n",
      "Epoch 7/1000\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 244.8796\n",
      "Epoch 8/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 208.7038\n",
      "Epoch 9/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 180.3206\n",
      "Epoch 10/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 161.4011\n",
      "Epoch 11/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 144.8289\n",
      "Epoch 12/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 130.3097\n",
      "Epoch 13/1000\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 118.6515\n",
      "Epoch 14/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 108.4529\n",
      "Epoch 15/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 98.7393\n",
      "Epoch 16/1000\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 90.5411\n",
      "Epoch 17/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 84.0754\n",
      "Epoch 18/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 79.6430\n",
      "Epoch 19/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 73.2509\n",
      "Epoch 20/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 67.4306\n",
      "Epoch 21/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 63.8286\n",
      "Epoch 22/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 60.1109\n",
      "Epoch 23/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 57.7458\n",
      "Epoch 24/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 54.5559\n",
      "Epoch 25/1000\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 52.1893\n",
      "Epoch 26/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 50.0881\n",
      "Epoch 27/1000\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 47.5505\n",
      "Epoch 28/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 45.9175\n",
      "Epoch 29/1000\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 43.4499\n",
      "Epoch 30/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 41.2861\n",
      "Epoch 31/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 38.9794\n",
      "Epoch 32/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 37.4222\n",
      "Epoch 33/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 36.0903\n",
      "Epoch 34/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 34.6824\n",
      "Epoch 35/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 33.1786\n",
      "Epoch 36/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 32.0990\n",
      "Epoch 37/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 30.8762\n",
      "Epoch 38/1000\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 30.0595\n",
      "Epoch 39/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 28.1232\n",
      "Epoch 40/1000\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 27.4529\n",
      "Epoch 41/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 26.3755\n",
      "Epoch 42/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 25.3585\n",
      "Epoch 43/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 24.2256\n",
      "Epoch 44/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 23.2282\n",
      "Epoch 45/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 22.5176\n",
      "Epoch 46/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 21.2342\n",
      "Epoch 47/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 20.2938\n",
      "Epoch 48/1000\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 19.5011\n",
      "Epoch 49/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 18.6930\n",
      "Epoch 50/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 17.4715\n",
      "Epoch 51/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 16.5485\n",
      "Epoch 52/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 15.5657\n",
      "Epoch 53/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 14.6483\n",
      "Epoch 54/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 13.8106\n",
      "Epoch 55/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 12.9641\n",
      "Epoch 56/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 12.1545\n",
      "Epoch 57/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 11.5714\n",
      "Epoch 58/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 10.8406\n",
      "Epoch 59/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 10.4111\n",
      "Epoch 60/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 9.9198\n",
      "Epoch 61/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 9.2316\n",
      "Epoch 62/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 8.8024\n",
      "Epoch 63/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 8.2897\n",
      "Epoch 64/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 8.0115\n",
      "Epoch 65/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 7.8377\n",
      "Epoch 66/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 7.3511\n",
      "Epoch 67/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 6.9008\n",
      "Epoch 68/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 6.7367\n",
      "Epoch 69/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 6.5668\n",
      "Epoch 70/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 6.4888\n",
      "Epoch 71/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 6.1455\n",
      "Epoch 72/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 5.7581\n",
      "Epoch 73/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 5.7359\n",
      "Epoch 74/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 5.4100\n",
      "Epoch 75/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 5.1018\n",
      "Epoch 76/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 4.9664\n",
      "Epoch 77/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 4.7975\n",
      "Epoch 78/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 4.5756\n",
      "Epoch 79/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 4.3121\n",
      "Epoch 80/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 4.2005\n",
      "Epoch 81/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 4.1004\n",
      "Epoch 82/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 4.1141\n",
      "Epoch 83/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 3.9498\n",
      "Epoch 84/1000\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 3.7544\n",
      "Epoch 85/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 3.6367\n",
      "Epoch 86/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 3.5519\n",
      "Epoch 87/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 3.4469\n",
      "Epoch 88/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 3.3281\n",
      "Epoch 89/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 3.2426\n",
      "Epoch 90/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 3.1663\n",
      "Epoch 91/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 3.1486\n",
      "Epoch 92/1000\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 3.0715\n",
      "Epoch 93/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 2.9912\n",
      "Epoch 94/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 2.9071\n",
      "Epoch 95/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 2.8405\n",
      "Epoch 96/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 2.7946\n",
      "Epoch 97/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 2.6850\n",
      "Epoch 98/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 2.8123\n",
      "Epoch 99/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 2.6767\n",
      "Epoch 100/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 2.5499\n",
      "Epoch 101/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 2.4745\n",
      "Epoch 102/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 2.4431\n",
      "Epoch 103/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 2.3793\n",
      "Epoch 104/1000\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 2.3663\n",
      "Epoch 105/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 2.2942\n",
      "Epoch 106/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 2.2570\n",
      "Epoch 107/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 2.2091\n",
      "Epoch 108/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 2.3266\n",
      "Epoch 109/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 2.1427\n",
      "Epoch 110/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 2.5817\n",
      "Epoch 111/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 2.2613\n",
      "Epoch 112/1000\n",
      "1564/1564 [==============================] - 0s 73us/step - loss: 2.1773\n",
      "Epoch 113/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 1.9372\n",
      "Epoch 114/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 1.9061\n",
      "Epoch 115/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.9174\n",
      "Epoch 116/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.8984\n",
      "Epoch 117/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.8282\n",
      "Epoch 118/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.8350\n",
      "Epoch 119/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.8807\n",
      "Epoch 120/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.8931\n",
      "Epoch 121/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.7200\n",
      "Epoch 122/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 1.7201\n",
      "Epoch 123/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.6187\n",
      "Epoch 124/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 1.6040\n",
      "Epoch 125/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.6177\n",
      "Epoch 126/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 1.5663\n",
      "Epoch 127/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.5344\n",
      "Epoch 128/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.5257\n",
      "Epoch 129/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 1.5498\n",
      "Epoch 130/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 1.5501\n",
      "Epoch 131/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 1.4637\n",
      "Epoch 132/1000\n",
      "1564/1564 [==============================] - 0s 60us/step - loss: 1.4919\n",
      "Epoch 133/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 1.4590\n",
      "Epoch 134/1000\n",
      "1564/1564 [==============================] - 0s 65us/step - loss: 1.4227\n",
      "Epoch 135/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 1.4068\n",
      "Epoch 136/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 1.4324\n",
      "Epoch 137/1000\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 1.4925\n",
      "Epoch 138/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 1.3686\n",
      "Epoch 139/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.3962\n",
      "Epoch 140/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 1.3652\n",
      "Epoch 141/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 1.3834\n",
      "Epoch 142/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 1.3332\n",
      "Epoch 143/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 1.3833\n",
      "Epoch 144/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 1.2665\n",
      "Epoch 145/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.2392\n",
      "Epoch 146/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 1.2532\n",
      "Epoch 147/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 1.2542\n",
      "Epoch 148/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.3067\n",
      "Epoch 149/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 1.2583\n",
      "Epoch 150/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 1.1770\n",
      "Epoch 151/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 1.2830\n",
      "Epoch 152/1000\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 1.2020\n",
      "Epoch 153/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 1.1724\n",
      "Epoch 154/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 1.2684\n",
      "Epoch 155/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 1.1637\n",
      "Epoch 156/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 1.2003\n",
      "Epoch 157/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 1.1908\n",
      "Epoch 158/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 1.0963\n",
      "Epoch 159/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 1.1424\n",
      "Epoch 160/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 1.0960\n",
      "Epoch 161/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.1555\n",
      "Epoch 162/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 1.1428\n",
      "Epoch 163/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 1.1192\n",
      "Epoch 164/1000\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 1.1992\n",
      "Epoch 165/1000\n",
      "1564/1564 [==============================] - 0s 59us/step - loss: 1.0724\n",
      "Epoch 166/1000\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 1.1249\n",
      "Epoch 167/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 1.1404\n",
      "Epoch 168/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 1.0339\n",
      "Epoch 169/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 1.0356\n",
      "Epoch 170/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 1.1094\n",
      "Epoch 171/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 1.1062\n",
      "Epoch 172/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 1.0004\n",
      "Epoch 173/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.0290\n",
      "Epoch 174/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 1.0276\n",
      "Epoch 175/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 1.0499\n",
      "Epoch 176/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 1.0191\n",
      "Epoch 177/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.9854\n",
      "Epoch 178/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 0.9615\n",
      "Epoch 179/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 0.9646\n",
      "Epoch 180/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 1.0080\n",
      "Epoch 181/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.9500\n",
      "Epoch 182/1000\n",
      "1564/1564 [==============================] - 0s 69us/step - loss: 0.9967\n",
      "Epoch 183/1000\n",
      "1564/1564 [==============================] - 0s 80us/step - loss: 1.0524\n",
      "Epoch 184/1000\n",
      "1564/1564 [==============================] - 0s 75us/step - loss: 1.3367\n",
      "Epoch 185/1000\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 1.0857\n",
      "Epoch 186/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.9567\n",
      "Epoch 187/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 1.1056\n",
      "Epoch 188/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.9816\n",
      "Epoch 189/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.9100\n",
      "Epoch 190/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.9316\n",
      "Epoch 191/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.9418\n",
      "Epoch 192/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.9823\n",
      "Epoch 193/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 1.0182\n",
      "Epoch 194/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.9096\n",
      "Epoch 195/1000\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 1.0289\n",
      "Epoch 196/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 1.0709\n",
      "Epoch 197/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.9630\n",
      "Epoch 198/1000\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 0.9329\n",
      "Epoch 199/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.9160\n",
      "Epoch 200/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.9402\n",
      "Epoch 201/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.9143\n",
      "Epoch 202/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.9026\n",
      "Epoch 203/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.9439\n",
      "Epoch 204/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.9631\n",
      "Epoch 205/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 1.0198\n",
      "Epoch 206/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.9518\n",
      "Epoch 207/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.8945\n",
      "Epoch 208/1000\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 0.9196\n",
      "Epoch 209/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 1.0067\n",
      "Epoch 210/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.8783\n",
      "Epoch 211/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.0655\n",
      "Epoch 212/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.9079\n",
      "Epoch 213/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.9407\n",
      "Epoch 214/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.9329\n",
      "Epoch 215/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.9169\n",
      "Epoch 216/1000\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 0.8604\n",
      "Epoch 217/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 1.0761\n",
      "Epoch 218/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.0242\n",
      "Epoch 219/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 1.1067\n",
      "Epoch 220/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.9265\n",
      "Epoch 221/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.9305\n",
      "Epoch 222/1000\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 0.8579\n",
      "Epoch 223/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.8683\n",
      "Epoch 224/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.8848\n",
      "Epoch 225/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.9218\n",
      "Epoch 226/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.8819\n",
      "Epoch 227/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.9252\n",
      "Epoch 228/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.8827\n",
      "Epoch 229/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.9076\n",
      "Epoch 230/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.9544\n",
      "Epoch 231/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.8514\n",
      "Epoch 232/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.8283\n",
      "Epoch 233/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 1.0332\n",
      "Epoch 234/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.9772\n",
      "Epoch 235/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.9528\n",
      "Epoch 236/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.8904\n",
      "Epoch 237/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.8841\n",
      "Epoch 238/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.0857\n",
      "Epoch 239/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.1191\n",
      "Epoch 240/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.9553\n",
      "Epoch 241/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.9639\n",
      "Epoch 242/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.9953\n",
      "Epoch 243/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.8572\n",
      "Epoch 244/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.9168\n",
      "Epoch 245/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.8040\n",
      "Epoch 246/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.9004\n",
      "Epoch 247/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.8601\n",
      "Epoch 248/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.9549\n",
      "Epoch 249/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.9074\n",
      "Epoch 250/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 1.0628\n",
      "Epoch 251/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.0431\n",
      "Epoch 252/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.8615\n",
      "Epoch 253/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.8831\n",
      "Epoch 254/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.9661\n",
      "Epoch 255/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.9662\n",
      "Epoch 256/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.8976\n",
      "Epoch 257/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.8272\n",
      "Epoch 258/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.8749\n",
      "Epoch 259/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.9784\n",
      "Epoch 260/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 1.2932\n",
      "Epoch 261/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.8366\n",
      "Epoch 262/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 1.0227\n",
      "Epoch 263/1000\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 0.9562\n",
      "Epoch 264/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.8262\n",
      "Epoch 265/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 1.0116\n",
      "Epoch 266/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.9373\n",
      "Epoch 267/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.8940\n",
      "Epoch 268/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.8585\n",
      "Epoch 269/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.9544\n",
      "Epoch 270/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.9237\n",
      "Epoch 271/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.8705\n",
      "Epoch 272/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.8148\n",
      "Epoch 273/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.8748\n",
      "Epoch 274/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.0259\n",
      "Epoch 275/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.8288\n",
      "Epoch 276/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 1.1249\n",
      "Epoch 277/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.8664\n",
      "Epoch 278/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.8397\n",
      "Epoch 279/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.7976\n",
      "Epoch 280/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.8532\n",
      "Epoch 281/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.8521\n",
      "Epoch 282/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.9144\n",
      "Epoch 283/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.9161\n",
      "Epoch 284/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.8346\n",
      "Epoch 285/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.8192\n",
      "Epoch 286/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.9179\n",
      "Epoch 287/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.9713\n",
      "Epoch 288/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.9179\n",
      "Epoch 289/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.8079\n",
      "Epoch 290/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.9562\n",
      "Epoch 291/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.8053\n",
      "Epoch 292/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.8764\n",
      "Epoch 293/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.8277\n",
      "Epoch 294/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.7587\n",
      "Epoch 295/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.8296\n",
      "Epoch 296/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.8993\n",
      "Epoch 297/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.0101\n",
      "Epoch 298/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.9644\n",
      "Epoch 299/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.9326\n",
      "Epoch 300/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.8562\n",
      "Epoch 301/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.8376\n",
      "Epoch 302/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.0702\n",
      "Epoch 303/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.8585\n",
      "Epoch 304/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.8174\n",
      "Epoch 305/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.8800\n",
      "Epoch 306/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.8551\n",
      "Epoch 307/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.9228\n",
      "Epoch 308/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.8734\n",
      "Epoch 309/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.7898\n",
      "Epoch 310/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.7665\n",
      "Epoch 311/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.8105\n",
      "Epoch 312/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.8368\n",
      "Epoch 313/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.8354\n",
      "Epoch 314/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.8128\n",
      "Epoch 315/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.0537\n",
      "Epoch 316/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 1.0304\n",
      "Epoch 317/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.8057\n",
      "Epoch 318/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.7284\n",
      "Epoch 319/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.7641\n",
      "Epoch 320/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.8161\n",
      "Epoch 321/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.7695\n",
      "Epoch 322/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.7566\n",
      "Epoch 323/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.8423\n",
      "Epoch 324/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 1.2469\n",
      "Epoch 325/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.8251\n",
      "Epoch 326/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.8804\n",
      "Epoch 327/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.8959\n",
      "Epoch 328/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.8345\n",
      "Epoch 329/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.7858\n",
      "Epoch 330/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.8322\n",
      "Epoch 331/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.8091\n",
      "Epoch 332/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.8546\n",
      "Epoch 333/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.8849\n",
      "Epoch 334/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.8670\n",
      "Epoch 335/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.8650\n",
      "Epoch 336/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.7838\n",
      "Epoch 337/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.9741\n",
      "Epoch 338/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 1.0766\n",
      "Epoch 339/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.9727\n",
      "Epoch 340/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.9800\n",
      "Epoch 341/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.7771\n",
      "Epoch 342/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.8321\n",
      "Epoch 343/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.7855\n",
      "Epoch 344/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.7650\n",
      "Epoch 345/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.7759\n",
      "Epoch 346/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.8449\n",
      "Epoch 347/1000\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 0.7382\n",
      "Epoch 348/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.8828\n",
      "Epoch 349/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.9426\n",
      "Epoch 350/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 1.2032\n",
      "Epoch 351/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.8013\n",
      "Epoch 352/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 1.0510\n",
      "Epoch 353/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.8412\n",
      "Epoch 354/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.7270\n",
      "Epoch 355/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.7982\n",
      "Epoch 356/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.8666\n",
      "Epoch 357/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.7975\n",
      "Epoch 358/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.8083\n",
      "Epoch 359/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.9116\n",
      "Epoch 360/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.7885\n",
      "Epoch 361/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.9256\n",
      "Epoch 362/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.9135\n",
      "Epoch 363/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.8537\n",
      "Epoch 364/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.7865\n",
      "Epoch 365/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.6815\n",
      "Epoch 366/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.8031\n",
      "Epoch 367/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.9761\n",
      "Epoch 368/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.8212\n",
      "Epoch 369/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.9654\n",
      "Epoch 370/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.9647\n",
      "Epoch 371/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.3597\n",
      "Epoch 372/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.8073\n",
      "Epoch 373/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 1.0066\n",
      "Epoch 374/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.8412\n",
      "Epoch 375/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.8418\n",
      "Epoch 376/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 0.7654\n",
      "Epoch 377/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.7766\n",
      "Epoch 378/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.8555\n",
      "Epoch 379/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.8378\n",
      "Epoch 380/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.8231\n",
      "Epoch 381/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.8852\n",
      "Epoch 382/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.7579\n",
      "Epoch 383/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.7374\n",
      "Epoch 384/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.8157\n",
      "Epoch 385/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.8893\n",
      "Epoch 386/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.9418\n",
      "Epoch 387/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.7663\n",
      "Epoch 388/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.6808\n",
      "Epoch 389/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.7886\n",
      "Epoch 390/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 0.7230\n",
      "Epoch 391/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.8172\n",
      "Epoch 392/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.8517\n",
      "Epoch 393/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.7444\n",
      "Epoch 394/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.9249\n",
      "Epoch 395/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.8500\n",
      "Epoch 396/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.7939\n",
      "Epoch 397/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.7153\n",
      "Epoch 398/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.7239\n",
      "Epoch 399/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.8475\n",
      "Epoch 400/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.0403\n",
      "Epoch 401/1000\n",
      "1564/1564 [==============================] - 0s 62us/step - loss: 1.1216\n",
      "Epoch 402/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 0.8935\n",
      "Epoch 403/1000\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 0.7177\n",
      "Epoch 404/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.7169\n",
      "Epoch 405/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.6838\n",
      "Epoch 406/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.6585\n",
      "Epoch 407/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 0.7208\n",
      "Epoch 408/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 0.8162\n",
      "Epoch 409/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 1.1800\n",
      "Epoch 410/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 1.7236\n",
      "Epoch 411/1000\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 1.0337\n",
      "Epoch 412/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.8003\n",
      "Epoch 413/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.7154\n",
      "Epoch 414/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 0.7433\n",
      "Epoch 415/1000\n",
      "1564/1564 [==============================] - 0s 58us/step - loss: 0.7103\n",
      "Epoch 416/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.7558\n",
      "Epoch 417/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.9630\n",
      "Epoch 418/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.9507\n",
      "Epoch 419/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.7748\n",
      "Epoch 420/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.6793\n",
      "Epoch 421/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.8168\n",
      "Epoch 422/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.7723\n",
      "Epoch 423/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.8454\n",
      "Epoch 424/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.8081\n",
      "Epoch 425/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.7416\n",
      "Epoch 426/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.7171\n",
      "Epoch 427/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.8053\n",
      "Epoch 428/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.7293\n",
      "Epoch 429/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 0.7935\n",
      "Epoch 430/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 1.1487\n",
      "Epoch 431/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 1.0550\n",
      "Epoch 432/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.9706\n",
      "Epoch 433/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.7286\n",
      "Epoch 434/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.6553\n",
      "Epoch 435/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.6628\n",
      "Epoch 436/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 1.0548\n",
      "Epoch 437/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 1.0251\n",
      "Epoch 438/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.7885\n",
      "Epoch 439/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.6894\n",
      "Epoch 440/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.8339\n",
      "Epoch 441/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.7671\n",
      "Epoch 442/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.6837\n",
      "Epoch 443/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.6747\n",
      "Epoch 444/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.6751\n",
      "Epoch 445/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.7639\n",
      "Epoch 446/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.8541\n",
      "Epoch 447/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.8848\n",
      "Epoch 448/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.7728\n",
      "Epoch 449/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.8553\n",
      "Epoch 450/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.8600\n",
      "Epoch 451/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.7321\n",
      "Epoch 452/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.7035\n",
      "Epoch 453/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.8510\n",
      "Epoch 454/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.6898\n",
      "Epoch 455/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 0.8062\n",
      "Epoch 456/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.9614\n",
      "Epoch 457/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.8298\n",
      "Epoch 458/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 1.1045\n",
      "Epoch 459/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.9057\n",
      "Epoch 460/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.7736\n",
      "Epoch 461/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.7118\n",
      "Epoch 462/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7166\n",
      "Epoch 463/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.7475\n",
      "Epoch 464/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.8310\n",
      "Epoch 465/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.6897\n",
      "Epoch 466/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.8024\n",
      "Epoch 467/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.7371\n",
      "Epoch 468/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.6901\n",
      "Epoch 469/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.7740\n",
      "Epoch 470/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.7551\n",
      "Epoch 471/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.7092\n",
      "Epoch 472/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.6318\n",
      "Epoch 473/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.6797\n",
      "Epoch 474/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.7137\n",
      "Epoch 475/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.6510\n",
      "Epoch 476/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.7140\n",
      "Epoch 477/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.7040\n",
      "Epoch 478/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.6745\n",
      "Epoch 479/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.7268\n",
      "Epoch 480/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.7045\n",
      "Epoch 481/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.7901\n",
      "Epoch 482/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.8302\n",
      "Epoch 483/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.8120\n",
      "Epoch 484/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.7702\n",
      "Epoch 485/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.9213\n",
      "Epoch 486/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.2084\n",
      "Epoch 487/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.8996\n",
      "Epoch 488/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.7249\n",
      "Epoch 489/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.6837\n",
      "Epoch 490/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.6565\n",
      "Epoch 491/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.8508\n",
      "Epoch 492/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.9759\n",
      "Epoch 493/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.7301\n",
      "Epoch 494/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.8940\n",
      "Epoch 495/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.7343\n",
      "Epoch 496/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.7064\n",
      "Epoch 497/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.7027\n",
      "Epoch 498/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.7261\n",
      "Epoch 499/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.8455\n",
      "Epoch 500/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.6583\n",
      "Epoch 501/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.6196\n",
      "Epoch 502/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.6967\n",
      "Epoch 503/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.6480\n",
      "Epoch 504/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.6914\n",
      "Epoch 505/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.8046\n",
      "Epoch 506/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.8298\n",
      "Epoch 507/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.7915\n",
      "Epoch 508/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.7448\n",
      "Epoch 509/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.6904\n",
      "Epoch 510/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.7605\n",
      "Epoch 511/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.6415\n",
      "Epoch 512/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.7977\n",
      "Epoch 513/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.7196\n",
      "Epoch 514/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.8990\n",
      "Epoch 515/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 1.0876\n",
      "Epoch 516/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.9344\n",
      "Epoch 517/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 1.2805\n",
      "Epoch 518/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.7748\n",
      "Epoch 519/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.6910\n",
      "Epoch 520/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.7796\n",
      "Epoch 521/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.8687\n",
      "Epoch 522/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.6456\n",
      "Epoch 523/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.7650\n",
      "Epoch 524/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.7306\n",
      "Epoch 525/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.7334\n",
      "Epoch 526/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.7845\n",
      "Epoch 527/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.6824\n",
      "Epoch 528/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.7314\n",
      "Epoch 529/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.6771\n",
      "Epoch 530/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.6839\n",
      "Epoch 531/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.6825\n",
      "Epoch 532/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.6970\n",
      "Epoch 533/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6682\n",
      "Epoch 534/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.6427\n",
      "Epoch 535/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.8493\n",
      "Epoch 536/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6929\n",
      "Epoch 537/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.6842\n",
      "Epoch 538/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.6978\n",
      "Epoch 539/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.6624\n",
      "Epoch 540/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.8707\n",
      "Epoch 541/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.8124\n",
      "Epoch 542/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.7833\n",
      "Epoch 543/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.8577\n",
      "Epoch 544/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.6889\n",
      "Epoch 545/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.7435\n",
      "Epoch 546/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.7728\n",
      "Epoch 547/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.7031\n",
      "Epoch 548/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6616\n",
      "Epoch 549/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.7743\n",
      "Epoch 550/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.6724\n",
      "Epoch 551/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.6241\n",
      "Epoch 552/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.7112\n",
      "Epoch 553/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.9289\n",
      "Epoch 554/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.8248\n",
      "Epoch 555/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.7012\n",
      "Epoch 556/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6839\n",
      "Epoch 557/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.6556\n",
      "Epoch 558/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.6476\n",
      "Epoch 559/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.7306\n",
      "Epoch 560/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.9694\n",
      "Epoch 561/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6333\n",
      "Epoch 562/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.6170\n",
      "Epoch 563/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6428\n",
      "Epoch 564/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.6772\n",
      "Epoch 565/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.6480\n",
      "Epoch 566/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.6374\n",
      "Epoch 567/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.6778\n",
      "Epoch 568/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.6411\n",
      "Epoch 569/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.6399\n",
      "Epoch 570/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.8514\n",
      "Epoch 571/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.7332\n",
      "Epoch 572/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.7664\n",
      "Epoch 573/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.7727\n",
      "Epoch 574/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 0.8906\n",
      "Epoch 575/1000\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 0.7794\n",
      "Epoch 576/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.7632\n",
      "Epoch 577/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.7538\n",
      "Epoch 578/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.7728\n",
      "Epoch 579/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.8233\n",
      "Epoch 580/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.7412\n",
      "Epoch 581/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.7229\n",
      "Epoch 582/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.9914\n",
      "Epoch 583/1000\n",
      "1564/1564 [==============================] - 0s 53us/step - loss: 1.2728\n",
      "Epoch 584/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 1.2837\n",
      "Epoch 585/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.7832\n",
      "Epoch 586/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.6813\n",
      "Epoch 587/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 0.6525\n",
      "Epoch 588/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.7743\n",
      "Epoch 589/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.8401\n",
      "Epoch 590/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.6863\n",
      "Epoch 591/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.6633\n",
      "Epoch 592/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.6538\n",
      "Epoch 593/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.6953\n",
      "Epoch 594/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.7724\n",
      "Epoch 595/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 0.6930\n",
      "Epoch 596/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.9103\n",
      "Epoch 597/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.7049\n",
      "Epoch 598/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.6859\n",
      "Epoch 599/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.7473\n",
      "Epoch 600/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.7051\n",
      "Epoch 601/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.6988\n",
      "Epoch 602/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.6773\n",
      "Epoch 603/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.6476\n",
      "Epoch 604/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.6565\n",
      "Epoch 605/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.7741\n",
      "Epoch 606/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.6530\n",
      "Epoch 607/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.6218\n",
      "Epoch 608/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.6288\n",
      "Epoch 609/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.6358\n",
      "Epoch 610/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6533\n",
      "Epoch 611/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.6420\n",
      "Epoch 612/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.7373\n",
      "Epoch 613/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.7665\n",
      "Epoch 614/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.6220\n",
      "Epoch 615/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.6527\n",
      "Epoch 616/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.8022\n",
      "Epoch 617/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.7483\n",
      "Epoch 618/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.9630\n",
      "Epoch 619/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.9496\n",
      "Epoch 620/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.6611\n",
      "Epoch 621/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.6457\n",
      "Epoch 622/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.6117\n",
      "Epoch 623/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.6605\n",
      "Epoch 624/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6125\n",
      "Epoch 625/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.6669\n",
      "Epoch 626/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.7871\n",
      "Epoch 627/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.7052\n",
      "Epoch 628/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.6233\n",
      "Epoch 629/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.6834\n",
      "Epoch 630/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.6694\n",
      "Epoch 631/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.7346\n",
      "Epoch 632/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6638\n",
      "Epoch 633/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.6338\n",
      "Epoch 634/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.6660\n",
      "Epoch 635/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7008\n",
      "Epoch 636/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.6381\n",
      "Epoch 637/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.6188\n",
      "Epoch 638/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.6996\n",
      "Epoch 639/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6606\n",
      "Epoch 640/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.7719\n",
      "Epoch 641/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.6654\n",
      "Epoch 642/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.6529\n",
      "Epoch 643/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.6424\n",
      "Epoch 644/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.6861\n",
      "Epoch 645/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.7191\n",
      "Epoch 646/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.8109\n",
      "Epoch 647/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 1.5750\n",
      "Epoch 648/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.8483\n",
      "Epoch 649/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.7933\n",
      "Epoch 650/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.7060\n",
      "Epoch 651/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.7803\n",
      "Epoch 652/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.7049\n",
      "Epoch 653/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.7839\n",
      "Epoch 654/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.8379\n",
      "Epoch 655/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.6902\n",
      "Epoch 656/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.7597\n",
      "Epoch 657/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.8034\n",
      "Epoch 658/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.6700\n",
      "Epoch 659/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.7335\n",
      "Epoch 660/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.7144\n",
      "Epoch 661/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.9698\n",
      "Epoch 662/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.7548\n",
      "Epoch 663/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.7759\n",
      "Epoch 664/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.6504\n",
      "Epoch 665/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.6807\n",
      "Epoch 666/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.7809\n",
      "Epoch 667/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.7741\n",
      "Epoch 668/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.7025\n",
      "Epoch 669/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.7176\n",
      "Epoch 670/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.6643\n",
      "Epoch 671/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.6469\n",
      "Epoch 672/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.6668\n",
      "Epoch 673/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6805\n",
      "Epoch 674/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.7390\n",
      "Epoch 675/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.7059\n",
      "Epoch 676/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.6599\n",
      "Epoch 677/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7671\n",
      "Epoch 678/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.6805\n",
      "Epoch 679/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.7668\n",
      "Epoch 680/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.7954\n",
      "Epoch 681/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.7104\n",
      "Epoch 682/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.7224\n",
      "Epoch 683/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.7450\n",
      "Epoch 684/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.7025\n",
      "Epoch 685/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.7939\n",
      "Epoch 686/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6340\n",
      "Epoch 687/1000\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 0.6697\n",
      "Epoch 688/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.5997\n",
      "Epoch 689/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 0.6484\n",
      "Epoch 690/1000\n",
      "1564/1564 [==============================] - 0s 54us/step - loss: 0.6707\n",
      "Epoch 691/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.7398\n",
      "Epoch 692/1000\n",
      "1564/1564 [==============================] - 0s 61us/step - loss: 0.6737\n",
      "Epoch 693/1000\n",
      "1564/1564 [==============================] - 0s 57us/step - loss: 0.7119\n",
      "Epoch 694/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.6745\n",
      "Epoch 695/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.6494\n",
      "Epoch 696/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.6866\n",
      "Epoch 697/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.6268\n",
      "Epoch 698/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.6843\n",
      "Epoch 699/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.8409\n",
      "Epoch 700/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.7478\n",
      "Epoch 701/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.6823\n",
      "Epoch 702/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6717\n",
      "Epoch 703/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.9246\n",
      "Epoch 704/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.7125\n",
      "Epoch 705/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6357\n",
      "Epoch 706/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.8108\n",
      "Epoch 707/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.8119\n",
      "Epoch 708/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.6449\n",
      "Epoch 709/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.7100\n",
      "Epoch 710/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.7287\n",
      "Epoch 711/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.7624\n",
      "Epoch 712/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 1.0007\n",
      "Epoch 713/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.6840\n",
      "Epoch 714/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.6700\n",
      "Epoch 715/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.8547\n",
      "Epoch 716/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.8054\n",
      "Epoch 717/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.7155\n",
      "Epoch 718/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.6934\n",
      "Epoch 719/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.7647\n",
      "Epoch 720/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.7089\n",
      "Epoch 721/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.8627\n",
      "Epoch 722/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.6474\n",
      "Epoch 723/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.6603\n",
      "Epoch 724/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.6120\n",
      "Epoch 725/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6921\n",
      "Epoch 726/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.6997\n",
      "Epoch 727/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.6545\n",
      "Epoch 728/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.6423\n",
      "Epoch 729/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.6614\n",
      "Epoch 730/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.6727\n",
      "Epoch 731/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6657\n",
      "Epoch 732/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.7483\n",
      "Epoch 733/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.7998\n",
      "Epoch 734/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.6597\n",
      "Epoch 735/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.6325\n",
      "Epoch 736/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.7262\n",
      "Epoch 737/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.6483\n",
      "Epoch 738/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6493\n",
      "Epoch 739/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.7662\n",
      "Epoch 740/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7769\n",
      "Epoch 741/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.6663\n",
      "Epoch 742/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6103\n",
      "Epoch 743/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.6385\n",
      "Epoch 744/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.6677\n",
      "Epoch 745/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6176\n",
      "Epoch 746/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.8123\n",
      "Epoch 747/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.8362\n",
      "Epoch 748/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.8240\n",
      "Epoch 749/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.6856\n",
      "Epoch 750/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6536\n",
      "Epoch 751/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.7239\n",
      "Epoch 752/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.8638\n",
      "Epoch 753/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.7712\n",
      "Epoch 754/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.6856\n",
      "Epoch 755/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6727\n",
      "Epoch 756/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.6197\n",
      "Epoch 757/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.5955\n",
      "Epoch 758/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.6372\n",
      "Epoch 759/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.6303\n",
      "Epoch 760/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7013\n",
      "Epoch 761/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7990\n",
      "Epoch 762/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.6824\n",
      "Epoch 763/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.6594\n",
      "Epoch 764/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.8657\n",
      "Epoch 765/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.6802\n",
      "Epoch 766/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6146\n",
      "Epoch 767/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.6440\n",
      "Epoch 768/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.6403\n",
      "Epoch 769/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.6033\n",
      "Epoch 770/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.6468\n",
      "Epoch 771/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.6526\n",
      "Epoch 772/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.6047\n",
      "Epoch 773/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.6884\n",
      "Epoch 774/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.6631\n",
      "Epoch 775/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6506\n",
      "Epoch 776/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.6697\n",
      "Epoch 777/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.6937\n",
      "Epoch 778/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.8151\n",
      "Epoch 779/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.6784\n",
      "Epoch 780/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.6211\n",
      "Epoch 781/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.6658\n",
      "Epoch 782/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.8120\n",
      "Epoch 783/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.7149\n",
      "Epoch 784/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.6990\n",
      "Epoch 785/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.6185\n",
      "Epoch 786/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.7393\n",
      "Epoch 787/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.6393\n",
      "Epoch 788/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.6741\n",
      "Epoch 789/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.6234\n",
      "Epoch 790/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.7461\n",
      "Epoch 791/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.7084\n",
      "Epoch 792/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.6157\n",
      "Epoch 793/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.6508\n",
      "Epoch 794/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6369\n",
      "Epoch 795/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.6876\n",
      "Epoch 796/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6507\n",
      "Epoch 797/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6461\n",
      "Epoch 798/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.7319\n",
      "Epoch 799/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.6084\n",
      "Epoch 800/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.6119\n",
      "Epoch 801/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.8635\n",
      "Epoch 802/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.7994\n",
      "Epoch 803/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.6851\n",
      "Epoch 804/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.6746\n",
      "Epoch 805/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.6024\n",
      "Epoch 806/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.6379\n",
      "Epoch 807/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.6826\n",
      "Epoch 808/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.6540\n",
      "Epoch 809/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6543\n",
      "Epoch 810/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6867\n",
      "Epoch 811/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.6647\n",
      "Epoch 812/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.7136\n",
      "Epoch 813/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.6378\n",
      "Epoch 814/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.6302\n",
      "Epoch 815/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.7003\n",
      "Epoch 816/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.6734\n",
      "Epoch 817/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.6603\n",
      "Epoch 818/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.6617\n",
      "Epoch 819/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.6707\n",
      "Epoch 820/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.6823\n",
      "Epoch 821/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.6213\n",
      "Epoch 822/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5893\n",
      "Epoch 823/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5884\n",
      "Epoch 824/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.6572\n",
      "Epoch 825/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.6823\n",
      "Epoch 826/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.6303\n",
      "Epoch 827/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.6299\n",
      "Epoch 828/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.7756\n",
      "Epoch 829/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.6409\n",
      "Epoch 830/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.6833\n",
      "Epoch 831/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.6677\n",
      "Epoch 832/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.6433\n",
      "Epoch 833/1000\n",
      "1564/1564 [==============================] - 0s 49us/step - loss: 0.7919\n",
      "Epoch 834/1000\n",
      "1564/1564 [==============================] - 0s 55us/step - loss: 0.6112\n",
      "Epoch 835/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.6694\n",
      "Epoch 836/1000\n",
      "1564/1564 [==============================] - 0s 56us/step - loss: 0.6837\n",
      "Epoch 837/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.7833\n",
      "Epoch 838/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.7166\n",
      "Epoch 839/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.8421\n",
      "Epoch 840/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.6924\n",
      "Epoch 841/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.6835\n",
      "Epoch 842/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7627\n",
      "Epoch 843/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.6649\n",
      "Epoch 844/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6163\n",
      "Epoch 845/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.7074\n",
      "Epoch 846/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.7838\n",
      "Epoch 847/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.7877\n",
      "Epoch 848/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.6107\n",
      "Epoch 849/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.6205\n",
      "Epoch 850/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.6176\n",
      "Epoch 851/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.6970\n",
      "Epoch 852/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.8281\n",
      "Epoch 853/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5974\n",
      "Epoch 854/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.6919\n",
      "Epoch 855/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.6462\n",
      "Epoch 856/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.6313\n",
      "Epoch 857/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.6526\n",
      "Epoch 858/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.6189\n",
      "Epoch 859/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6661\n",
      "Epoch 860/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.7662\n",
      "Epoch 861/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.6612\n",
      "Epoch 862/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.7572\n",
      "Epoch 863/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6856\n",
      "Epoch 864/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.8271\n",
      "Epoch 865/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.7045\n",
      "Epoch 866/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.6641\n",
      "Epoch 867/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.6620\n",
      "Epoch 868/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.5914\n",
      "Epoch 869/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.6170\n",
      "Epoch 870/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.6772\n",
      "Epoch 871/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.6507\n",
      "Epoch 872/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.6503\n",
      "Epoch 873/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.6032\n",
      "Epoch 874/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6408\n",
      "Epoch 875/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.6131\n",
      "Epoch 876/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.6358\n",
      "Epoch 877/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.6469\n",
      "Epoch 878/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.6319\n",
      "Epoch 879/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.6289\n",
      "Epoch 880/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.8217\n",
      "Epoch 881/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.7533\n",
      "Epoch 882/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.6622\n",
      "Epoch 883/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5925\n",
      "Epoch 884/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6394\n",
      "Epoch 885/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.7443\n",
      "Epoch 886/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.8061\n",
      "Epoch 887/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6539\n",
      "Epoch 888/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.6598\n",
      "Epoch 889/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.6528\n",
      "Epoch 890/1000\n",
      "1564/1564 [==============================] - 0s 52us/step - loss: 0.6082\n",
      "Epoch 891/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.6374\n",
      "Epoch 892/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.6374\n",
      "Epoch 893/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.6909\n",
      "Epoch 894/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6553\n",
      "Epoch 895/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.7903\n",
      "Epoch 896/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.6550\n",
      "Epoch 897/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.7509\n",
      "Epoch 898/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.7007\n",
      "Epoch 899/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6462\n",
      "Epoch 900/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.6424\n",
      "Epoch 901/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.6287\n",
      "Epoch 902/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.6455\n",
      "Epoch 903/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.6246\n",
      "Epoch 904/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.6448\n",
      "Epoch 905/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.6746\n",
      "Epoch 906/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.6111\n",
      "Epoch 907/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.6444\n",
      "Epoch 908/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.6930\n",
      "Epoch 909/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.6059\n",
      "Epoch 910/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.6985\n",
      "Epoch 911/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.6704\n",
      "Epoch 912/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.6196\n",
      "Epoch 913/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.6541\n",
      "Epoch 914/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.6224\n",
      "Epoch 915/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.6802\n",
      "Epoch 916/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.7079\n",
      "Epoch 917/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.5768\n",
      "Epoch 918/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6434\n",
      "Epoch 919/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.6746\n",
      "Epoch 920/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.6334\n",
      "Epoch 921/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.6502\n",
      "Epoch 922/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.7693\n",
      "Epoch 923/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.6129\n",
      "Epoch 924/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.6904\n",
      "Epoch 925/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.6058\n",
      "Epoch 926/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.6566\n",
      "Epoch 927/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.6491\n",
      "Epoch 928/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.6149\n",
      "Epoch 929/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.5993\n",
      "Epoch 930/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.7048\n",
      "Epoch 931/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6568\n",
      "Epoch 932/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6672\n",
      "Epoch 933/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.6506\n",
      "Epoch 934/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.6595\n",
      "Epoch 935/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.6542\n",
      "Epoch 936/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.6009\n",
      "Epoch 937/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6209\n",
      "Epoch 938/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.7157\n",
      "Epoch 939/1000\n",
      "1564/1564 [==============================] - 0s 50us/step - loss: 0.6926\n",
      "Epoch 940/1000\n",
      "1564/1564 [==============================] - 0s 51us/step - loss: 0.6909\n",
      "Epoch 941/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.6020\n",
      "Epoch 942/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.6217\n",
      "Epoch 943/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6135\n",
      "Epoch 944/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.6991\n",
      "Epoch 945/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.7652\n",
      "Epoch 946/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.6645\n",
      "Epoch 947/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.6441\n",
      "Epoch 948/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.7625\n",
      "Epoch 949/1000\n",
      "1564/1564 [==============================] - 0s 47us/step - loss: 0.6921\n",
      "Epoch 950/1000\n",
      "1564/1564 [==============================] - 0s 48us/step - loss: 0.5936\n",
      "Epoch 951/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.6179\n",
      "Epoch 952/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6150\n",
      "Epoch 953/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.6966\n",
      "Epoch 954/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.9756\n",
      "Epoch 955/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.9246\n",
      "Epoch 956/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.6913\n",
      "Epoch 957/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.6439\n",
      "Epoch 958/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.6045\n",
      "Epoch 959/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.5854\n",
      "Epoch 960/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.6085\n",
      "Epoch 961/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6196\n",
      "Epoch 962/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6479\n",
      "Epoch 963/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.7066\n",
      "Epoch 964/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.7451\n",
      "Epoch 965/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.7489\n",
      "Epoch 966/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.6242\n",
      "Epoch 967/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7345\n",
      "Epoch 968/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.6227\n",
      "Epoch 969/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.6035\n",
      "Epoch 970/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.6437\n",
      "Epoch 971/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.6440\n",
      "Epoch 972/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.7173\n",
      "Epoch 973/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.6348\n",
      "Epoch 974/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.6609\n",
      "Epoch 975/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.6370\n",
      "Epoch 976/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.6397\n",
      "Epoch 977/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.6886\n",
      "Epoch 978/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.6503\n",
      "Epoch 979/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.6188\n",
      "Epoch 980/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6447\n",
      "Epoch 981/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.6593\n",
      "Epoch 982/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.6971\n",
      "Epoch 983/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.6889\n",
      "Epoch 984/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.6866\n",
      "Epoch 985/1000\n",
      "1564/1564 [==============================] - 0s 44us/step - loss: 0.6173\n",
      "Epoch 986/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.6097\n",
      "Epoch 987/1000\n",
      "1564/1564 [==============================] - 0s 43us/step - loss: 0.6144\n",
      "Epoch 988/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.6681\n",
      "Epoch 989/1000\n",
      "1564/1564 [==============================] - 0s 46us/step - loss: 0.6394\n",
      "Epoch 990/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.6286\n",
      "Epoch 991/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.6222\n",
      "Epoch 992/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.6637\n",
      "Epoch 993/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.6239\n",
      "Epoch 994/1000\n",
      "1564/1564 [==============================] - 0s 41us/step - loss: 0.6363\n",
      "Epoch 995/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.7170\n",
      "Epoch 996/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.7154\n",
      "Epoch 997/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.6498\n",
      "Epoch 998/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6692\n",
      "Epoch 999/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.6104\n",
      "Epoch 1000/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.6524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3b81a748>"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_ast = Sequential()\n",
    "NN_ast.add(Dense(units=16,input_dim=30,activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_ast.add(Dense(units=8, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_ast.add(Dense(units=4, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_ast.add(Dense(units=1,activation='linear'))\n",
    "NN_ast.compile(loss='mse', optimizer='adam')\n",
    "NN_ast.fit(np.array(X_train), np.array(y_train), epochs=1000,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = NN_ast.predict(X_test)\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.5)\n",
    "gbr.fit(X_train,y_train)\n",
    "gbr_predictions = gbr.predict(X_test)\n",
    "LR = LinearRegression(fit_intercept=True).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN_predictions</th>\n",
       "      <th>actual</th>\n",
       "      <th>GBR_predictions</th>\n",
       "      <th>LY_assists</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>9.539147</td>\n",
       "      <td>11.7</td>\n",
       "      <td>9.781437</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>9.129800</td>\n",
       "      <td>10.7</td>\n",
       "      <td>9.656808</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>9.831399</td>\n",
       "      <td>9.2</td>\n",
       "      <td>10.403659</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>8.748109</td>\n",
       "      <td>6.5</td>\n",
       "      <td>8.864303</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>9.449506</td>\n",
       "      <td>9.7</td>\n",
       "      <td>9.692736</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>8.366265</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.510544</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>7.496163</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.081874</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>7.738875</td>\n",
       "      <td>5.5</td>\n",
       "      <td>7.433908</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>6.773023</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.185693</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>6.749845</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6.480594</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>7.621202</td>\n",
       "      <td>8.8</td>\n",
       "      <td>8.366975</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>6.289121</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.192670</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>6.872556</td>\n",
       "      <td>4.7</td>\n",
       "      <td>6.621779</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>7.051034</td>\n",
       "      <td>6.8</td>\n",
       "      <td>7.456004</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>7.273114</td>\n",
       "      <td>8.6</td>\n",
       "      <td>7.558017</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>5.837052</td>\n",
       "      <td>6.7</td>\n",
       "      <td>6.220411</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>6.970548</td>\n",
       "      <td>1.2</td>\n",
       "      <td>7.666692</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>3.759534</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.334684</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>5.909532</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.765919</td>\n",
       "      <td>6.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>6.503110</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.806390</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>6.610795</td>\n",
       "      <td>5.9</td>\n",
       "      <td>7.021526</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>5.787278</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.225465</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>6.146722</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6.587076</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>7.805646</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7.184957</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>4.775270</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.955348</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>5.669854</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.367331</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>5.476178</td>\n",
       "      <td>4.6</td>\n",
       "      <td>6.185223</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>6.166879</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.303987</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>6.086007</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.714314</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>5.853406</td>\n",
       "      <td>5.6</td>\n",
       "      <td>6.616853</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.451070</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.416749</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.592111</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.626063</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.251817</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.551529</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>-1.216479</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.200032</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>0.450235</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.648498</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.342195</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.559403</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>0.452916</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.514229</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>0.471841</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.549941</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>0.269220</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.572585</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1.194650</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.215425</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>0.530229</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.928527</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>0.395009</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.473296</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>-0.278361</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.370591</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0.786515</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.636644</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>0.715211</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.778088</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>0.259187</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.610475</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>-0.021998</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.484784</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>-0.367076</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.371536</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.236711</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.653062</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>-0.327842</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.369064</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.524072</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.593632</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.362039</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.435056</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>0.803155</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.873734</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.107141</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.491990</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.667985</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.552739</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0.757058</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.522205</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>-0.352828</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.403114</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>0.303170</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.565157</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.572218</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.901305</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.088712</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.358763</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>671 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     NN_predictions  actual  GBR_predictions  LY_assists\n",
       "167        9.539147    11.7         9.781437        11.2\n",
       "149        9.129800    10.7         9.656808        10.2\n",
       "425        9.831399     9.2        10.403659        10.0\n",
       "462        8.748109     6.5         8.864303         9.8\n",
       "143        9.449506     9.7         9.692736         9.1\n",
       "583        8.366265    10.0         8.510544         8.8\n",
       "469        7.496163     8.0         7.081874         8.3\n",
       "97         7.738875     5.5         7.433908         8.2\n",
       "641        6.773023     7.6         7.185693         7.7\n",
       "201        6.749845     6.6         6.480594         7.6\n",
       "439        7.621202     8.8         8.366975         7.6\n",
       "282        6.289121     5.0         6.192670         7.6\n",
       "541        6.872556     4.7         6.621779         7.4\n",
       "295        7.051034     6.8         7.456004         7.4\n",
       "412        7.273114     8.6         7.558017         7.3\n",
       "492        5.837052     6.7         6.220411         7.2\n",
       "172        6.970548     1.2         7.666692         7.2\n",
       "336        3.759534     5.2         3.334684         7.0\n",
       "665        5.909532     6.0         4.765919         6.9\n",
       "117        6.503110     6.4         6.806390         6.8\n",
       "396        6.610795     5.9         7.021526         6.8\n",
       "249        5.787278     7.0         6.225465         6.7\n",
       "66         6.146722     6.6         6.587076         6.7\n",
       "580        7.805646     6.6         7.184957         6.7\n",
       "154        4.775270     3.5         3.955348         6.6\n",
       "444        5.669854     4.0         4.367331         6.6\n",
       "243        5.476178     4.6         6.185223         6.5\n",
       "390        6.166879     6.4         6.303987         6.5\n",
       "438        6.086007     6.5         6.714314         6.5\n",
       "557        5.853406     5.6         6.616853         6.5\n",
       "..              ...     ...              ...         ...\n",
       "145        0.451070     0.4         0.416749         0.2\n",
       "82         0.592111     0.4         0.626063         0.2\n",
       "155        0.251817     1.3         0.551529         0.2\n",
       "251       -1.216479     0.3         0.200032         0.2\n",
       "510        0.450235     1.2         0.648498         0.2\n",
       "4          0.342195     0.5         0.559403         0.2\n",
       "304        0.452916     0.3         0.514229         0.2\n",
       "650        0.471841     0.8         0.549941         0.2\n",
       "617        0.269220     0.9         0.572585         0.2\n",
       "107        1.194650     0.4         1.215425         0.2\n",
       "626        0.530229     1.0         0.928527         0.2\n",
       "380        0.395009     0.9         0.473296         0.2\n",
       "384       -0.278361     0.1         0.370591         0.2\n",
       "555        0.786515     0.8         0.636644         0.2\n",
       "324        0.715211     0.5         0.778088         0.1\n",
       "457        0.259187     0.2         0.610475         0.1\n",
       "83        -0.021998     0.3         0.484784         0.1\n",
       "160       -0.367076     0.2         0.371536         0.1\n",
       "296        0.236711     0.1         0.653062         0.1\n",
       "87        -0.327842     0.3         0.369064         0.1\n",
       "61         0.524072     0.4         0.593632         0.1\n",
       "84         0.362039     0.7         0.435056         0.1\n",
       "327        0.803155     1.8         0.873734         0.0\n",
       "131        0.107141     0.2         0.491990         0.0\n",
       "148        0.667985     0.3         0.552739         0.0\n",
       "382        0.757058     0.6         0.522205         0.0\n",
       "575       -0.352828     1.8         0.403114         0.0\n",
       "341        0.303170     0.9         0.565157         0.0\n",
       "112        0.572218     1.5         0.901305         0.0\n",
       "398        0.088712     0.5         0.358763         0.0\n",
       "\n",
       "[671 rows x 4 columns]"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing = pd.DataFrame(predictions)\n",
    "testing.columns=['NN_predictions']\n",
    "testing['actual'] = y_test.reset_index()['assists']\n",
    "testing['GBR_predictions']=gbr_predictions\n",
    "testing['LY_assists']=X_test['assists_ly'].reset_index()['assists_ly']\n",
    "testing.sort_values(by='LY_assists',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>assists</th>\n",
       "      <th>predictions</th>\n",
       "      <th>assists_ly_x</th>\n",
       "      <th>gbr_pred</th>\n",
       "      <th>LR_pred</th>\n",
       "      <th>mean_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>James Harden</td>\n",
       "      <td>8.8</td>\n",
       "      <td>9.181874</td>\n",
       "      <td>11.2</td>\n",
       "      <td>8.797185</td>\n",
       "      <td>9.435171</td>\n",
       "      <td>9.138077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>John Wall</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.507752</td>\n",
       "      <td>10.7</td>\n",
       "      <td>9.512599</td>\n",
       "      <td>9.808751</td>\n",
       "      <td>9.609701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>Russell Westbrook</td>\n",
       "      <td>10.3</td>\n",
       "      <td>10.029798</td>\n",
       "      <td>10.4</td>\n",
       "      <td>9.546243</td>\n",
       "      <td>10.562853</td>\n",
       "      <td>10.046298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Chris Paul</td>\n",
       "      <td>7.9</td>\n",
       "      <td>9.120534</td>\n",
       "      <td>9.2</td>\n",
       "      <td>8.761593</td>\n",
       "      <td>8.963949</td>\n",
       "      <td>8.948692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>Ricky Rubio</td>\n",
       "      <td>5.3</td>\n",
       "      <td>7.820031</td>\n",
       "      <td>9.1</td>\n",
       "      <td>7.772140</td>\n",
       "      <td>8.134931</td>\n",
       "      <td>7.909034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>LeBron James</td>\n",
       "      <td>9.1</td>\n",
       "      <td>8.205529</td>\n",
       "      <td>8.7</td>\n",
       "      <td>7.994150</td>\n",
       "      <td>8.026597</td>\n",
       "      <td>8.075426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>Jeff Teague</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.751962</td>\n",
       "      <td>7.8</td>\n",
       "      <td>6.448696</td>\n",
       "      <td>7.029170</td>\n",
       "      <td>6.409943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Jrue Holiday</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.842092</td>\n",
       "      <td>7.3</td>\n",
       "      <td>6.083935</td>\n",
       "      <td>5.703404</td>\n",
       "      <td>5.543143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>Kyle Lowry</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.893334</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.661846</td>\n",
       "      <td>7.073269</td>\n",
       "      <td>7.209483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>Draymond Green</td>\n",
       "      <td>7.3</td>\n",
       "      <td>5.819005</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.191251</td>\n",
       "      <td>6.194833</td>\n",
       "      <td>6.068363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>Rajon Rondo</td>\n",
       "      <td>8.2</td>\n",
       "      <td>5.026944</td>\n",
       "      <td>6.7</td>\n",
       "      <td>8.586593</td>\n",
       "      <td>6.606396</td>\n",
       "      <td>6.739978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>T.J. McConnell</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.558366</td>\n",
       "      <td>6.6</td>\n",
       "      <td>3.963303</td>\n",
       "      <td>5.442488</td>\n",
       "      <td>4.988052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>Stephen Curry</td>\n",
       "      <td>6.1</td>\n",
       "      <td>7.283517</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7.881398</td>\n",
       "      <td>7.161715</td>\n",
       "      <td>7.442210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>Elfrid Payton</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.267373</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.967587</td>\n",
       "      <td>6.417374</td>\n",
       "      <td>6.550778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Eric Bledsoe</td>\n",
       "      <td>5.1</td>\n",
       "      <td>5.774941</td>\n",
       "      <td>6.3</td>\n",
       "      <td>5.928513</td>\n",
       "      <td>5.938009</td>\n",
       "      <td>5.880488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Dennis Schroder</td>\n",
       "      <td>6.2</td>\n",
       "      <td>5.672593</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.043734</td>\n",
       "      <td>5.880849</td>\n",
       "      <td>5.865725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Damian Lillard</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6.321656</td>\n",
       "      <td>5.9</td>\n",
       "      <td>6.411217</td>\n",
       "      <td>6.349333</td>\n",
       "      <td>6.360735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>Nicolas Batum</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.630113</td>\n",
       "      <td>5.9</td>\n",
       "      <td>4.751896</td>\n",
       "      <td>4.936185</td>\n",
       "      <td>4.772731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Isaiah Thomas</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.714890</td>\n",
       "      <td>5.9</td>\n",
       "      <td>6.129673</td>\n",
       "      <td>5.770111</td>\n",
       "      <td>5.871558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Goran Dragic</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5.373307</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.472402</td>\n",
       "      <td>5.685387</td>\n",
       "      <td>5.510365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>Kyrie Irving</td>\n",
       "      <td>5.1</td>\n",
       "      <td>5.779344</td>\n",
       "      <td>5.8</td>\n",
       "      <td>6.052287</td>\n",
       "      <td>5.748726</td>\n",
       "      <td>5.860119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>J.J. Barea</td>\n",
       "      <td>6.3</td>\n",
       "      <td>5.024964</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.738894</td>\n",
       "      <td>4.970834</td>\n",
       "      <td>5.244898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Jimmy Butler</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.880345</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.740186</td>\n",
       "      <td>5.316580</td>\n",
       "      <td>4.979037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>Kemba Walker</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5.817842</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.987155</td>\n",
       "      <td>5.790294</td>\n",
       "      <td>5.865097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>Giannis Antetokounmpo</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5.365495</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5.473560</td>\n",
       "      <td>5.359887</td>\n",
       "      <td>5.399647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>Reggie Jackson</td>\n",
       "      <td>5.3</td>\n",
       "      <td>4.848481</td>\n",
       "      <td>5.2</td>\n",
       "      <td>4.546570</td>\n",
       "      <td>5.081895</td>\n",
       "      <td>4.825649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Ish Smith</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.679147</td>\n",
       "      <td>5.2</td>\n",
       "      <td>4.269153</td>\n",
       "      <td>5.109002</td>\n",
       "      <td>4.685767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Tim Frazier</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.679749</td>\n",
       "      <td>5.2</td>\n",
       "      <td>4.921850</td>\n",
       "      <td>4.590084</td>\n",
       "      <td>4.730561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Jameer Nelson</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.715497</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.802280</td>\n",
       "      <td>4.206065</td>\n",
       "      <td>3.907947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Al Horford</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.719384</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.147061</td>\n",
       "      <td>3.944247</td>\n",
       "      <td>3.936897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Blake Griffin</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5.077714</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5.141634</td>\n",
       "      <td>4.865527</td>\n",
       "      <td>5.028292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>Nikola Jokic</td>\n",
       "      <td>6.1</td>\n",
       "      <td>5.186044</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5.486704</td>\n",
       "      <td>4.829990</td>\n",
       "      <td>5.167579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>D'Angelo Russell</td>\n",
       "      <td>5.2</td>\n",
       "      <td>4.618810</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.397453</td>\n",
       "      <td>4.748584</td>\n",
       "      <td>4.588282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Kevin Durant</td>\n",
       "      <td>5.4</td>\n",
       "      <td>4.965711</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.592255</td>\n",
       "      <td>4.903430</td>\n",
       "      <td>4.820465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>Lance Stephenson</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.910115</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.425893</td>\n",
       "      <td>3.787213</td>\n",
       "      <td>4.041074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>DeMarcus Cousins</td>\n",
       "      <td>5.4</td>\n",
       "      <td>3.184388</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.203201</td>\n",
       "      <td>3.988947</td>\n",
       "      <td>3.792179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Matthew Dellavedova</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.413526</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.321345</td>\n",
       "      <td>3.546935</td>\n",
       "      <td>3.427269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>Marcus Smart</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.699678</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.855459</td>\n",
       "      <td>3.779655</td>\n",
       "      <td>3.778264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Darren Collison</td>\n",
       "      <td>5.3</td>\n",
       "      <td>4.684678</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.125116</td>\n",
       "      <td>4.712685</td>\n",
       "      <td>4.507493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>Marc Gasol</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.355146</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.307381</td>\n",
       "      <td>4.163811</td>\n",
       "      <td>4.275446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Tony Parker</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.118717</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.363968</td>\n",
       "      <td>3.974709</td>\n",
       "      <td>3.819131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Yogi Ferrell</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.312486</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.927315</td>\n",
       "      <td>3.345139</td>\n",
       "      <td>3.194980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Jerryd Bayless</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.517473</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.421445</td>\n",
       "      <td>3.557323</td>\n",
       "      <td>3.498747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>Malcolm Brogdon</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.273412</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3.906637</td>\n",
       "      <td>4.276597</td>\n",
       "      <td>4.152215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>George Hill</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.119907</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.105770</td>\n",
       "      <td>4.545029</td>\n",
       "      <td>4.256902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>Mason Plumlee</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.406736</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.001279</td>\n",
       "      <td>2.903535</td>\n",
       "      <td>2.770517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>DeMar DeRozan</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.725885</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.542619</td>\n",
       "      <td>3.841528</td>\n",
       "      <td>3.703344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Emmanuel Mudiay</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.757917</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.167502</td>\n",
       "      <td>3.780393</td>\n",
       "      <td>3.568604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>Dwyane Wade</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.209501</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.992559</td>\n",
       "      <td>3.210979</td>\n",
       "      <td>3.137679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Paul Millsap</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.255719</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.070364</td>\n",
       "      <td>3.236218</td>\n",
       "      <td>3.187434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    player  assists  predictions  assists_ly_x  gbr_pred  \\\n",
       "202           James Harden      8.8     9.181874          11.2  8.797185   \n",
       "30               John Wall      9.6     9.507752          10.7  9.512599   \n",
       "335      Russell Westbrook     10.3    10.029798          10.4  9.546243   \n",
       "116             Chris Paul      7.9     9.120534           9.2  8.761593   \n",
       "329            Ricky Rubio      5.3     7.820031           9.1  7.772140   \n",
       "265           LeBron James      9.1     8.205529           8.7  7.994150   \n",
       "212            Jeff Teague      7.0     5.751962           7.8  6.448696   \n",
       "237           Jrue Holiday      6.0     4.842092           7.3  6.083935   \n",
       "257             Kyle Lowry      6.9     6.893334           7.0  7.661846   \n",
       "156         Draymond Green      7.3     5.819005           7.0  6.191251   \n",
       "321            Rajon Rondo      8.2     5.026944           6.7  8.586593   \n",
       "349         T.J. McConnell      4.0     5.558366           6.6  3.963303   \n",
       "347          Stephen Curry      6.1     7.283517           6.6  7.881398   \n",
       "160          Elfrid Payton      6.3     6.267373           6.5  6.967587   \n",
       "163           Eric Bledsoe      5.1     5.774941           6.3  5.928513   \n",
       "144        Dennis Schroder      6.2     5.672593           6.3  6.043734   \n",
       "6           Damian Lillard      6.6     6.321656           5.9  6.411217   \n",
       "301          Nicolas Batum      5.5     4.630113           5.9  4.751896   \n",
       "186          Isaiah Thomas      5.0     5.714890           5.9  6.129673   \n",
       "19            Goran Dragic      4.8     5.373307           5.8  5.472402   \n",
       "260           Kyrie Irving      5.1     5.779344           5.8  6.052287   \n",
       "23              J.J. Barea      6.3     5.024964           5.5  5.738894   \n",
       "218           Jimmy Butler      4.9     4.880345           5.5  4.740186   \n",
       "244           Kemba Walker      5.6     5.817842           5.5  5.987155   \n",
       "176  Giannis Antetokounmpo      4.8     5.365495           5.4  5.473560   \n",
       "326         Reggie Jackson      5.3     4.848481           5.2  4.546570   \n",
       "188              Ish Smith      4.4     4.679147           5.2  4.269153   \n",
       "59             Tim Frazier      3.3     4.679749           5.2  4.921850   \n",
       "200          Jameer Nelson      3.6     3.715497           5.1  3.802280   \n",
       "71              Al Horford      4.7     3.719384           5.0  4.147061   \n",
       "95           Blake Griffin      5.4     5.077714           4.9  5.141634   \n",
       "304           Nikola Jokic      6.1     5.186044           4.9  5.486704   \n",
       "124       D'Angelo Russell      5.2     4.618810           4.8  4.397453   \n",
       "248           Kevin Durant      5.4     4.965711           4.8  4.592255   \n",
       "261       Lance Stephenson      2.9     3.910115           4.8  4.425893   \n",
       "140       DeMarcus Cousins      5.4     3.184388           4.8  4.203201   \n",
       "286    Matthew Dellavedova      3.8     3.413526           4.7  3.321345   \n",
       "279           Marcus Smart      4.8     3.699678           4.6  3.855459   \n",
       "133        Darren Collison      5.3     4.684678           4.6  4.125116   \n",
       "275             Marc Gasol      4.2     4.355146           4.6  4.307381   \n",
       "61             Tony Parker      3.5     4.118717           4.5  3.363968   \n",
       "67            Yogi Ferrell      2.5     3.312486           4.3  2.927315   \n",
       "217         Jerryd Bayless      1.4     3.517473           4.3  3.421445   \n",
       "272        Malcolm Brogdon      3.2     4.273412           4.2  3.906637   \n",
       "172            George Hill      2.8     4.119907           4.2  4.105770   \n",
       "285          Mason Plumlee      1.9     2.406736           4.0  3.001279   \n",
       "139          DeMar DeRozan      5.2     3.725885           3.9  3.542619   \n",
       "161        Emmanuel Mudiay      2.9     3.757917           3.9  3.167502   \n",
       "158            Dwyane Wade      3.5     3.209501           3.8  2.992559   \n",
       "316           Paul Millsap      2.8     3.255719           3.7  3.070364   \n",
       "\n",
       "       LR_pred  mean_pred  \n",
       "202   9.435171   9.138077  \n",
       "30    9.808751   9.609701  \n",
       "335  10.562853  10.046298  \n",
       "116   8.963949   8.948692  \n",
       "329   8.134931   7.909034  \n",
       "265   8.026597   8.075426  \n",
       "212   7.029170   6.409943  \n",
       "237   5.703404   5.543143  \n",
       "257   7.073269   7.209483  \n",
       "156   6.194833   6.068363  \n",
       "321   6.606396   6.739978  \n",
       "349   5.442488   4.988052  \n",
       "347   7.161715   7.442210  \n",
       "160   6.417374   6.550778  \n",
       "163   5.938009   5.880488  \n",
       "144   5.880849   5.865725  \n",
       "6     6.349333   6.360735  \n",
       "301   4.936185   4.772731  \n",
       "186   5.770111   5.871558  \n",
       "19    5.685387   5.510365  \n",
       "260   5.748726   5.860119  \n",
       "23    4.970834   5.244898  \n",
       "218   5.316580   4.979037  \n",
       "244   5.790294   5.865097  \n",
       "176   5.359887   5.399647  \n",
       "326   5.081895   4.825649  \n",
       "188   5.109002   4.685767  \n",
       "59    4.590084   4.730561  \n",
       "200   4.206065   3.907947  \n",
       "71    3.944247   3.936897  \n",
       "95    4.865527   5.028292  \n",
       "304   4.829990   5.167579  \n",
       "124   4.748584   4.588282  \n",
       "248   4.903430   4.820465  \n",
       "261   3.787213   4.041074  \n",
       "140   3.988947   3.792179  \n",
       "286   3.546935   3.427269  \n",
       "279   3.779655   3.778264  \n",
       "133   4.712685   4.507493  \n",
       "275   4.163811   4.275446  \n",
       "61    3.974709   3.819131  \n",
       "67    3.345139   3.194980  \n",
       "217   3.557323   3.498747  \n",
       "272   4.276597   4.152215  \n",
       "172   4.545029   4.256902  \n",
       "285   2.903535   2.770517  \n",
       "139   3.841528   3.703344  \n",
       "161   3.780393   3.568604  \n",
       "158   3.210979   3.137679  \n",
       "316   3.236218   3.187434  "
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_2017assists = assists[assists['season']==2017].drop(['team','player','assists','Games'],axis=1)\n",
    "assists_2017 = NN_ast.predict(pred_2017assists)\n",
    "gbr_ast_2017 = pd.DataFrame(gbr.predict(pred_2017assists))\n",
    "LR_ast_2017 = pd.DataFrame(LR.predict(pred_2017assists))\n",
    "test_2 =pd.DataFrame(assists_2017)\n",
    "test_3 = pd.merge(assists,pred_2017assists,left_index=True,right_index=True).reset_index()\n",
    "test_3['predictions']=test_2[0]\n",
    "test_3['gbr_pred'] = gbr_ast_2017[0]\n",
    "test_3['LR_pred'] = LR_ast_2017[0]\n",
    "test_3['mean_pred'] = (test_3['predictions']+test_3['gbr_pred']+test_3['LR_pred'])/3\n",
    "test_3 = test_3[test_3['Games']>30]\n",
    "test_3[['player','assists','predictions','assists_ly_x','gbr_pred','LR_pred','mean_pred']].sort_values(by='assists_ly_x',ascending=False)[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE using NN:0.7428029483598435\n",
      "MSE using mean:3.3617587113740988\n",
      "MSE using last year stats:0.850384615384615\n",
      "MSE using LR:0.5360204938681716\n",
      "MSE using GB:0.5081943911208421\n",
      "MSE using combo:0.5386291140274688\n"
     ]
    }
   ],
   "source": [
    "print('MSE using NN:{}'.format(np.mean((test_3['assists']-test_3['predictions'])**2)))\n",
    "print('MSE using mean:{}'.format(np.mean((test_3['assists']-np.mean(test_3['assists']))**2)))\n",
    "print('MSE using last year stats:{}'.format(np.mean((test_3['assists']-test_3['assists_ly_x'])**2)))\n",
    "print('MSE using LR:{}'.format(np.mean((test_3['assists']-test_3['LR_pred'])**2)))\n",
    "print('MSE using GB:{}'.format(np.mean((test_3['assists']-test_3['gbr_pred'])**2)))\n",
    "print('MSE using combo:{}'.format(np.mean((test_3['assists']-test_3['mean_pred'])**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''next is steals.  In the future, may want to add minutes from last season?'''\n",
    "\n",
    "\n",
    "query= '''\n",
    "        \n",
    "        DROP TABLE IF EXISTS steals_pred;\n",
    "        CREATE TABLE steals_pred(\n",
    "        season int, --these come from player_stats\n",
    "        player varchar(50),\n",
    "        Age int,\n",
    "        team varchar(50),\n",
    "        stl float, -- these come from player_stats\n",
    "        stl_ly float,\n",
    "        change_stl_ly float,\n",
    "        Games float,\n",
    "        C_PF int,\n",
    "        PG int,\n",
    "        SG_SF int,\n",
    "        starter_change int, \n",
    "        \n",
    "\n",
    "        -- from player_advstats\n",
    "        per_ly float,\n",
    "        change_per float,\n",
    "        stl_perc_ly float,\n",
    "        change_stl_perc_ly float,\n",
    "        defensive_winshares float,\n",
    "        defensive_boxplusminus float,\n",
    "        boxplusminus float,\n",
    "        value_overreplacement float,\n",
    "        \n",
    "        career_stl float,\n",
    "        yearspro int\n",
    "        );\n",
    "        \n",
    "        INSERT INTO steals_pred(season,player,age,team,stl,stl_ly,change_stl_ly,starter_change,Games,C_PF,PG,SG_SF)\n",
    "        SELECT season,player,age,startingteam,stl,stl_ly,change_stl_ly,starter-starter_ly,Games,\n",
    "        case when pos in ('C','PF') then 1 else 0 end,case when pos='PG' then 1 else 0 end,case when pos in('SG','SF') then 1 else 0 end from player_stats;\n",
    "        \n",
    "        \n",
    "        update steals_pred sp\n",
    "        set per_ly=pa.per_ly,change_per=pa.change_per,stl_perc_ly = pa.stl_perc_ly,change_stl_perc_ly = pa.change_stl_perc_ly\n",
    "        ,defensive_winshares=pa.defensive_winshares,defensive_boxplusminus=pa.defensive_boxplusminus\n",
    "        ,boxplusminus=pa.boxplusminus,value_overreplacement=pa.value_overreplacement\n",
    "        from player_advstats pa\n",
    "        where sp.player = pa.player and sp.season = pa.season and sp.team = pa.startingteam;\n",
    "        \n",
    "        update steals_pred sp\n",
    "        set career_stl = pc.career_stl, yearspro = pc.yearspro\n",
    "        from player_careerstats pc\n",
    "        where sp.player = pc.player and sp.season = pc.season;\n",
    "        \n",
    "        \n",
    "        select * from steals_pred where season>2009\n",
    "        '''\n",
    "\n",
    "\n",
    "cur.execute(query)\n",
    "data = cur.fetchall()\n",
    "steals_df = pd.DataFrame(np.array(data))\n",
    "steals_df.columns = ['season','player','age','team','steals','steals_ly','change_steals_ly','Games','C_PF','PG','SG_SF','starter_change'\n",
    "                    ,'per_ly','change_per','stl_perc_ly','change_stl_perc','defensive_winshares','defensive_boxplusminus','boxplusminus','value_overreplacement','career_steals','yearspro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "steals_df['age_squared']=steals_df['age']*steals_df['age']\n",
    "steals = steals_df[steals_df['steals_ly'].notna()]\n",
    "for i in steals.columns:\n",
    "    if i not in(['player','team']):\n",
    "        steals[i]=pd.to_numeric(steals[i])\n",
    "steals = steals.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = steals[(steals['season']!=2017) & (steals['Games']>30)].drop(['player','team','steals','Games'],axis=1)\n",
    "y = steals[(steals['season']!=2017) & (steals['Games']>30)]['steals']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1564/1564 [==============================] - 2s 1ms/step - loss: 518214.8728\n",
      "Epoch 2/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 279058.1391\n",
      "Epoch 3/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 139750.0776\n",
      "Epoch 4/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 65175.8204\n",
      "Epoch 5/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 29759.3468\n",
      "Epoch 6/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 15249.9335\n",
      "Epoch 7/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 8344.6012\n",
      "Epoch 8/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 4291.8988\n",
      "Epoch 9/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1677.7571\n",
      "Epoch 10/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 481.5773\n",
      "Epoch 11/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 245.7537\n",
      "Epoch 12/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 239.9885\n",
      "Epoch 13/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 216.6592\n",
      "Epoch 14/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 203.1315\n",
      "Epoch 15/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 196.1215\n",
      "Epoch 16/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 189.3720\n",
      "Epoch 17/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 183.0987\n",
      "Epoch 18/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 177.3540\n",
      "Epoch 19/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 171.7347\n",
      "Epoch 20/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 166.1587\n",
      "Epoch 21/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 161.7813\n",
      "Epoch 22/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 157.9791\n",
      "Epoch 23/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 154.7358\n",
      "Epoch 24/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 151.5018\n",
      "Epoch 25/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 148.2894\n",
      "Epoch 26/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 144.9962\n",
      "Epoch 27/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 141.8631\n",
      "Epoch 28/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 138.8371\n",
      "Epoch 29/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 135.7785\n",
      "Epoch 30/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 132.9424\n",
      "Epoch 31/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 130.0829\n",
      "Epoch 32/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 127.2608\n",
      "Epoch 33/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 124.5843\n",
      "Epoch 34/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 121.9692\n",
      "Epoch 35/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 119.5873\n",
      "Epoch 36/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 117.4592\n",
      "Epoch 37/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 115.3049\n",
      "Epoch 38/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 113.2276\n",
      "Epoch 39/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 111.1600\n",
      "Epoch 40/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 108.9841\n",
      "Epoch 41/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 106.8956\n",
      "Epoch 42/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 104.7155\n",
      "Epoch 43/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 102.7894\n",
      "Epoch 44/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 100.7945\n",
      "Epoch 45/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 98.6221\n",
      "Epoch 46/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 96.6002\n",
      "Epoch 47/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 94.5929\n",
      "Epoch 48/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 92.6390\n",
      "Epoch 49/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 90.7186\n",
      "Epoch 50/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 88.9265\n",
      "Epoch 51/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 86.9574\n",
      "Epoch 52/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 85.1682\n",
      "Epoch 53/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 83.2692\n",
      "Epoch 54/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 81.5550\n",
      "Epoch 55/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 79.7133\n",
      "Epoch 56/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 77.9530\n",
      "Epoch 57/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 76.1231\n",
      "Epoch 58/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 74.4363\n",
      "Epoch 59/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 72.8063\n",
      "Epoch 60/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 71.1879\n",
      "Epoch 61/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 69.3296\n",
      "Epoch 62/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 67.7621\n",
      "Epoch 63/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 66.1013\n",
      "Epoch 64/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 64.3822\n",
      "Epoch 65/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 62.6847\n",
      "Epoch 66/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 60.9476\n",
      "Epoch 67/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 59.3777\n",
      "Epoch 68/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 57.6323\n",
      "Epoch 69/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 56.0502\n",
      "Epoch 70/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 54.2981\n",
      "Epoch 71/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 52.7358\n",
      "Epoch 72/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 51.0693\n",
      "Epoch 73/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 49.4024\n",
      "Epoch 74/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 47.6979\n",
      "Epoch 75/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 46.1633\n",
      "Epoch 76/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 44.4483\n",
      "Epoch 77/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 42.9225\n",
      "Epoch 78/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 41.3741\n",
      "Epoch 79/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 39.8014\n",
      "Epoch 80/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 38.2046\n",
      "Epoch 81/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 36.6336\n",
      "Epoch 82/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 35.0411\n",
      "Epoch 83/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 33.5219\n",
      "Epoch 84/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 31.9772\n",
      "Epoch 85/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 30.4783\n",
      "Epoch 86/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 29.0193\n",
      "Epoch 87/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 27.4831\n",
      "Epoch 88/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 25.9850\n",
      "Epoch 89/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 24.5891\n",
      "Epoch 90/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 23.2370\n",
      "Epoch 91/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 21.9340\n",
      "Epoch 92/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 20.6026\n",
      "Epoch 93/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 19.3559\n",
      "Epoch 94/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 18.1773\n",
      "Epoch 95/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 17.0054\n",
      "Epoch 96/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 15.9850\n",
      "Epoch 97/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 14.8944\n",
      "Epoch 98/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 13.8824\n",
      "Epoch 99/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 12.9275\n",
      "Epoch 100/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 12.0261\n",
      "Epoch 101/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 11.1626\n",
      "Epoch 102/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 10.3871\n",
      "Epoch 103/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 9.6666\n",
      "Epoch 104/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 9.0056\n",
      "Epoch 105/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 8.3842\n",
      "Epoch 106/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 7.7764\n",
      "Epoch 107/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 7.2360\n",
      "Epoch 108/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 6.7307\n",
      "Epoch 109/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 6.2925\n",
      "Epoch 110/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 5.8868\n",
      "Epoch 111/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 5.4698\n",
      "Epoch 112/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 5.1394\n",
      "Epoch 113/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 4.8291\n",
      "Epoch 114/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 4.5356\n",
      "Epoch 115/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 4.2453\n",
      "Epoch 116/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 3.9940\n",
      "Epoch 117/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 3.7629\n",
      "Epoch 118/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 3.5595\n",
      "Epoch 119/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 3.3740\n",
      "Epoch 120/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 3.2123\n",
      "Epoch 121/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 3.0676\n",
      "Epoch 122/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 2.9308\n",
      "Epoch 123/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 2.8189\n",
      "Epoch 124/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 2.7054\n",
      "Epoch 125/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 2.5885\n",
      "Epoch 126/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 2.4891\n",
      "Epoch 127/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 2.3992\n",
      "Epoch 128/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 2.3079\n",
      "Epoch 129/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 2.2212\n",
      "Epoch 130/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 2.1441\n",
      "Epoch 131/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 2.0736\n",
      "Epoch 132/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 2.0116\n",
      "Epoch 133/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.9451\n",
      "Epoch 134/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.8900\n",
      "Epoch 135/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.8403\n",
      "Epoch 136/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.7871\n",
      "Epoch 137/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 1.7367\n",
      "Epoch 138/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 1.6954\n",
      "Epoch 139/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 1.6519\n",
      "Epoch 140/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 1.6174\n",
      "Epoch 141/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.5770\n",
      "Epoch 142/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.5408\n",
      "Epoch 143/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 1.5058\n",
      "Epoch 144/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 1.4732\n",
      "Epoch 145/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 1.4400\n",
      "Epoch 146/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 1.4100\n",
      "Epoch 147/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 1.3835\n",
      "Epoch 148/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.3541\n",
      "Epoch 149/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 1.3179\n",
      "Epoch 150/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.2899\n",
      "Epoch 151/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 1.2688\n",
      "Epoch 152/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.2399\n",
      "Epoch 153/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 1.2135\n",
      "Epoch 154/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.1903\n",
      "Epoch 155/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.1600\n",
      "Epoch 156/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.1411\n",
      "Epoch 157/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.1221\n",
      "Epoch 158/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 1.0999\n",
      "Epoch 159/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.0779\n",
      "Epoch 160/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 1.0590\n",
      "Epoch 161/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 1.0383\n",
      "Epoch 162/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 1.0219\n",
      "Epoch 163/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 1.0038\n",
      "Epoch 164/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.9891\n",
      "Epoch 165/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.9715\n",
      "Epoch 166/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.9550\n",
      "Epoch 167/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.9413\n",
      "Epoch 168/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.9234\n",
      "Epoch 169/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.9066\n",
      "Epoch 170/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.8920\n",
      "Epoch 171/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.8765\n",
      "Epoch 172/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.8625\n",
      "Epoch 173/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.8478\n",
      "Epoch 174/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.8344\n",
      "Epoch 175/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.8237\n",
      "Epoch 176/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.8071\n",
      "Epoch 177/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.7969\n",
      "Epoch 178/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.7818\n",
      "Epoch 179/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.7683\n",
      "Epoch 180/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.7597\n",
      "Epoch 181/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.7456\n",
      "Epoch 182/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.7316\n",
      "Epoch 183/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.7211\n",
      "Epoch 184/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.7121\n",
      "Epoch 185/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.7026\n",
      "Epoch 186/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.6895\n",
      "Epoch 187/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.6775\n",
      "Epoch 188/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.6658\n",
      "Epoch 189/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.6561\n",
      "Epoch 190/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.6486\n",
      "Epoch 191/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.6368\n",
      "Epoch 192/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.6280\n",
      "Epoch 193/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.6223\n",
      "Epoch 194/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.6084\n",
      "Epoch 195/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.5984\n",
      "Epoch 196/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.5891\n",
      "Epoch 197/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.5799\n",
      "Epoch 198/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.5718\n",
      "Epoch 199/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.5660\n",
      "Epoch 200/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.5553\n",
      "Epoch 201/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5473\n",
      "Epoch 202/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.5390\n",
      "Epoch 203/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.5311\n",
      "Epoch 204/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.5252\n",
      "Epoch 205/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.5186\n",
      "Epoch 206/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.5122\n",
      "Epoch 207/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.5076\n",
      "Epoch 208/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.5030\n",
      "Epoch 209/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.4962\n",
      "Epoch 210/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.4911\n",
      "Epoch 211/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.4879\n",
      "Epoch 212/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.4825\n",
      "Epoch 213/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.4787\n",
      "Epoch 214/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.4741\n",
      "Epoch 215/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.4713\n",
      "Epoch 216/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.4662\n",
      "Epoch 217/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4617\n",
      "Epoch 218/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.4592\n",
      "Epoch 219/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.4555\n",
      "Epoch 220/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4496\n",
      "Epoch 221/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4461\n",
      "Epoch 222/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.4455\n",
      "Epoch 223/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.4407\n",
      "Epoch 224/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.4370\n",
      "Epoch 225/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.4308\n",
      "Epoch 226/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.4279\n",
      "Epoch 227/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.4238\n",
      "Epoch 228/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.4194\n",
      "Epoch 229/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.4148\n",
      "Epoch 230/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.4113\n",
      "Epoch 231/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.4078\n",
      "Epoch 232/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4074\n",
      "Epoch 233/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.4006\n",
      "Epoch 234/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3984\n",
      "Epoch 235/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.3930\n",
      "Epoch 236/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.3898\n",
      "Epoch 237/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.3892\n",
      "Epoch 238/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.3815\n",
      "Epoch 239/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.3797\n",
      "Epoch 240/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.3769\n",
      "Epoch 241/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.3747\n",
      "Epoch 242/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.3697\n",
      "Epoch 243/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.3661\n",
      "Epoch 244/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.3654\n",
      "Epoch 245/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.3623\n",
      "Epoch 246/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.3577\n",
      "Epoch 247/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.3554\n",
      "Epoch 248/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.3516\n",
      "Epoch 249/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.3523\n",
      "Epoch 250/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.3460\n",
      "Epoch 251/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.3423\n",
      "Epoch 252/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.3402\n",
      "Epoch 253/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.3364\n",
      "Epoch 254/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.3347\n",
      "Epoch 255/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.3331\n",
      "Epoch 256/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.3285\n",
      "Epoch 257/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.3267\n",
      "Epoch 258/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3228\n",
      "Epoch 259/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3230\n",
      "Epoch 260/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.3183\n",
      "Epoch 261/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.3182\n",
      "Epoch 262/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.3146\n",
      "Epoch 263/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.3110\n",
      "Epoch 264/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.3079\n",
      "Epoch 265/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3059\n",
      "Epoch 266/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.3031\n",
      "Epoch 267/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.3019\n",
      "Epoch 268/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.3032\n",
      "Epoch 269/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.2967\n",
      "Epoch 270/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.2951\n",
      "Epoch 271/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.2944\n",
      "Epoch 272/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.2911\n",
      "Epoch 273/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.2953\n",
      "Epoch 274/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.2905\n",
      "Epoch 275/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.2871\n",
      "Epoch 276/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.2876\n",
      "Epoch 277/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.2828\n",
      "Epoch 278/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.2831\n",
      "Epoch 279/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.2801\n",
      "Epoch 280/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.2786\n",
      "Epoch 281/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.2788\n",
      "Epoch 282/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2782\n",
      "Epoch 283/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.2773\n",
      "Epoch 284/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.2732\n",
      "Epoch 285/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.2747\n",
      "Epoch 286/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.2721\n",
      "Epoch 287/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.2701\n",
      "Epoch 288/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.2688\n",
      "Epoch 289/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.2684\n",
      "Epoch 290/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.2657\n",
      "Epoch 291/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.2668\n",
      "Epoch 292/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.2631\n",
      "Epoch 293/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.2620\n",
      "Epoch 294/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.2610\n",
      "Epoch 295/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.2606\n",
      "Epoch 296/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.2583\n",
      "Epoch 297/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.2575\n",
      "Epoch 298/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.2558\n",
      "Epoch 299/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.2558\n",
      "Epoch 300/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.2591\n",
      "Epoch 301/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.2541\n",
      "Epoch 302/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.2529\n",
      "Epoch 303/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.2526\n",
      "Epoch 304/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.2498\n",
      "Epoch 305/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.2491\n",
      "Epoch 306/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.2508\n",
      "Epoch 307/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.2486\n",
      "Epoch 308/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.2493\n",
      "Epoch 309/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.2446\n",
      "Epoch 310/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.2440\n",
      "Epoch 311/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.2474\n",
      "Epoch 312/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.2432\n",
      "Epoch 313/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.2432\n",
      "Epoch 314/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.2400\n",
      "Epoch 315/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.2461\n",
      "Epoch 316/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.2391\n",
      "Epoch 317/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.2363\n",
      "Epoch 318/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.2360\n",
      "Epoch 319/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.2350\n",
      "Epoch 320/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.2345\n",
      "Epoch 321/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.2344\n",
      "Epoch 322/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.2338\n",
      "Epoch 323/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.2319\n",
      "Epoch 324/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.2317\n",
      "Epoch 325/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.2314\n",
      "Epoch 326/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.2311\n",
      "Epoch 327/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.2312\n",
      "Epoch 328/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.2281\n",
      "Epoch 329/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.2279\n",
      "Epoch 330/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.2258\n",
      "Epoch 331/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2248\n",
      "Epoch 332/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.2266\n",
      "Epoch 333/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.2222\n",
      "Epoch 334/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.2231\n",
      "Epoch 335/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.2245\n",
      "Epoch 336/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.2208\n",
      "Epoch 337/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.2212\n",
      "Epoch 338/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2181\n",
      "Epoch 339/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.2201\n",
      "Epoch 340/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.2158\n",
      "Epoch 341/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.2208\n",
      "Epoch 342/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.2176\n",
      "Epoch 343/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.2143\n",
      "Epoch 344/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.2148\n",
      "Epoch 345/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.2134\n",
      "Epoch 346/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.2151\n",
      "Epoch 347/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.2125\n",
      "Epoch 348/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.2108\n",
      "Epoch 349/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.2114\n",
      "Epoch 350/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.2172\n",
      "Epoch 351/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.2115\n",
      "Epoch 352/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.2103\n",
      "Epoch 353/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.2076\n",
      "Epoch 354/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.2053\n",
      "Epoch 355/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2069\n",
      "Epoch 356/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.2052\n",
      "Epoch 357/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.2043\n",
      "Epoch 358/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.2077\n",
      "Epoch 359/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.2045\n",
      "Epoch 360/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.2036\n",
      "Epoch 361/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.2053\n",
      "Epoch 362/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.2001\n",
      "Epoch 363/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.2005\n",
      "Epoch 364/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.2015\n",
      "Epoch 365/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.2000\n",
      "Epoch 366/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1982\n",
      "Epoch 367/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1964\n",
      "Epoch 368/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1961\n",
      "Epoch 369/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1983\n",
      "Epoch 370/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1993\n",
      "Epoch 371/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1962\n",
      "Epoch 372/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1937\n",
      "Epoch 373/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.1955\n",
      "Epoch 374/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.1982\n",
      "Epoch 375/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1939\n",
      "Epoch 376/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1905\n",
      "Epoch 377/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1905\n",
      "Epoch 378/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.1905\n",
      "Epoch 379/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1888\n",
      "Epoch 380/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1880\n",
      "Epoch 381/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1887\n",
      "Epoch 382/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1870\n",
      "Epoch 383/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.1873\n",
      "Epoch 384/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1859\n",
      "Epoch 385/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1854\n",
      "Epoch 386/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1856\n",
      "Epoch 387/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1863\n",
      "Epoch 388/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1838\n",
      "Epoch 389/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1832\n",
      "Epoch 390/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1826\n",
      "Epoch 391/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1822\n",
      "Epoch 392/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1828\n",
      "Epoch 393/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1836\n",
      "Epoch 394/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.1823\n",
      "Epoch 395/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.1877\n",
      "Epoch 396/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1855\n",
      "Epoch 397/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1831\n",
      "Epoch 398/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1814\n",
      "Epoch 399/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1775\n",
      "Epoch 400/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1772\n",
      "Epoch 401/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1766\n",
      "Epoch 402/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1758\n",
      "Epoch 403/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1765\n",
      "Epoch 404/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1754\n",
      "Epoch 405/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.1763\n",
      "Epoch 406/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1771\n",
      "Epoch 407/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1788\n",
      "Epoch 408/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1725\n",
      "Epoch 409/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1724\n",
      "Epoch 410/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1740\n",
      "Epoch 411/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1721\n",
      "Epoch 412/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.1702\n",
      "Epoch 413/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.1718\n",
      "Epoch 414/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.1743\n",
      "Epoch 415/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.1704\n",
      "Epoch 416/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.1690\n",
      "Epoch 417/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.1684\n",
      "Epoch 418/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.1695\n",
      "Epoch 419/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1676\n",
      "Epoch 420/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1698\n",
      "Epoch 421/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.1666\n",
      "Epoch 422/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1668\n",
      "Epoch 423/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1671\n",
      "Epoch 424/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1664\n",
      "Epoch 425/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1647\n",
      "Epoch 426/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1649\n",
      "Epoch 427/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1655\n",
      "Epoch 428/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1670\n",
      "Epoch 429/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1675\n",
      "Epoch 430/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.1739\n",
      "Epoch 431/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.1695\n",
      "Epoch 432/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1664\n",
      "Epoch 433/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1690\n",
      "Epoch 434/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1655\n",
      "Epoch 435/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1646\n",
      "Epoch 436/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1720\n",
      "Epoch 437/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1652\n",
      "Epoch 438/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1595\n",
      "Epoch 439/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.1593\n",
      "Epoch 440/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.1588\n",
      "Epoch 441/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.1599\n",
      "Epoch 442/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.1612\n",
      "Epoch 443/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1684\n",
      "Epoch 444/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.1612\n",
      "Epoch 445/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.1609\n",
      "Epoch 446/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1586\n",
      "Epoch 447/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1563\n",
      "Epoch 448/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1582\n",
      "Epoch 449/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1598\n",
      "Epoch 450/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1576\n",
      "Epoch 451/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1608\n",
      "Epoch 452/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1557\n",
      "Epoch 453/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1569\n",
      "Epoch 454/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1548\n",
      "Epoch 455/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1531\n",
      "Epoch 456/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1563\n",
      "Epoch 457/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1586\n",
      "Epoch 458/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1520\n",
      "Epoch 459/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1535\n",
      "Epoch 460/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1533\n",
      "Epoch 461/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1564\n",
      "Epoch 462/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1515\n",
      "Epoch 463/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1516\n",
      "Epoch 464/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1541\n",
      "Epoch 465/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.1508\n",
      "Epoch 466/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.1519\n",
      "Epoch 467/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1553\n",
      "Epoch 468/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.1493\n",
      "Epoch 469/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.1502\n",
      "Epoch 470/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1513\n",
      "Epoch 471/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1500\n",
      "Epoch 472/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.1511\n",
      "Epoch 473/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.1500\n",
      "Epoch 474/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1493\n",
      "Epoch 475/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1494\n",
      "Epoch 476/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1526\n",
      "Epoch 477/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1471\n",
      "Epoch 478/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1462\n",
      "Epoch 479/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1463\n",
      "Epoch 480/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1461\n",
      "Epoch 481/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1466\n",
      "Epoch 482/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1456\n",
      "Epoch 483/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1466\n",
      "Epoch 484/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1465\n",
      "Epoch 485/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1445\n",
      "Epoch 486/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1457\n",
      "Epoch 487/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1459\n",
      "Epoch 488/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1458\n",
      "Epoch 489/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1449\n",
      "Epoch 490/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1426\n",
      "Epoch 491/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1413\n",
      "Epoch 492/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.1424\n",
      "Epoch 493/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1417\n",
      "Epoch 494/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1437\n",
      "Epoch 495/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1413\n",
      "Epoch 496/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.1404\n",
      "Epoch 497/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.1419\n",
      "Epoch 498/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.1399\n",
      "Epoch 499/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1396\n",
      "Epoch 500/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1406\n",
      "Epoch 501/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1419\n",
      "Epoch 502/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1394\n",
      "Epoch 503/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1387\n",
      "Epoch 504/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1397\n",
      "Epoch 505/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1373\n",
      "Epoch 506/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1371\n",
      "Epoch 507/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1370\n",
      "Epoch 508/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1367\n",
      "Epoch 509/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1400\n",
      "Epoch 510/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1406\n",
      "Epoch 511/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1400\n",
      "Epoch 512/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1394\n",
      "Epoch 513/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1381\n",
      "Epoch 514/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.1458\n",
      "Epoch 515/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.1387\n",
      "Epoch 516/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1379\n",
      "Epoch 517/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1364\n",
      "Epoch 518/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.1362\n",
      "Epoch 519/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1333\n",
      "Epoch 520/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1353\n",
      "Epoch 521/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.1337\n",
      "Epoch 522/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1332\n",
      "Epoch 523/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1331\n",
      "Epoch 524/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1318\n",
      "Epoch 525/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1320\n",
      "Epoch 526/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1310\n",
      "Epoch 527/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1314\n",
      "Epoch 528/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1306\n",
      "Epoch 529/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1303\n",
      "Epoch 530/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1302\n",
      "Epoch 531/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1334\n",
      "Epoch 532/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1295\n",
      "Epoch 533/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1368\n",
      "Epoch 534/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1293\n",
      "Epoch 535/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1303\n",
      "Epoch 536/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1301\n",
      "Epoch 537/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1318\n",
      "Epoch 538/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1302\n",
      "Epoch 539/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1429\n",
      "Epoch 540/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1295\n",
      "Epoch 541/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1265\n",
      "Epoch 542/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.1299\n",
      "Epoch 543/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.1297\n",
      "Epoch 544/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.1268\n",
      "Epoch 545/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1304\n",
      "Epoch 546/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.1293\n",
      "Epoch 547/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.1255\n",
      "Epoch 548/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1257\n",
      "Epoch 549/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1248\n",
      "Epoch 550/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1245\n",
      "Epoch 551/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1304\n",
      "Epoch 552/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1340\n",
      "Epoch 553/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1265\n",
      "Epoch 554/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1221\n",
      "Epoch 555/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1256\n",
      "Epoch 556/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1282\n",
      "Epoch 557/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.1234\n",
      "Epoch 558/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1233\n",
      "Epoch 559/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1245\n",
      "Epoch 560/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1429\n",
      "Epoch 561/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.1286\n",
      "Epoch 562/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1206\n",
      "Epoch 563/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1201\n",
      "Epoch 564/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.1213\n",
      "Epoch 565/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.1207\n",
      "Epoch 566/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.1181\n",
      "Epoch 567/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1267\n",
      "Epoch 568/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.1195\n",
      "Epoch 569/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.1220\n",
      "Epoch 570/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.1187\n",
      "Epoch 571/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1242\n",
      "Epoch 572/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.1174\n",
      "Epoch 573/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.1171\n",
      "Epoch 574/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.1224\n",
      "Epoch 575/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1205\n",
      "Epoch 576/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.1155\n",
      "Epoch 577/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1194\n",
      "Epoch 578/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1164\n",
      "Epoch 579/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1181\n",
      "Epoch 580/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1164\n",
      "Epoch 581/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1139\n",
      "Epoch 582/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1144\n",
      "Epoch 583/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1164\n",
      "Epoch 584/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1187\n",
      "Epoch 585/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1168\n",
      "Epoch 586/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1160\n",
      "Epoch 587/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1186\n",
      "Epoch 588/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1190\n",
      "Epoch 589/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1111\n",
      "Epoch 590/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.1134\n",
      "Epoch 591/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.1241\n",
      "Epoch 592/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.1230\n",
      "Epoch 593/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1144\n",
      "Epoch 594/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.1389\n",
      "Epoch 595/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.1302\n",
      "Epoch 596/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.1205\n",
      "Epoch 597/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1169\n",
      "Epoch 598/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.1098\n",
      "Epoch 599/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.1087\n",
      "Epoch 600/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1092\n",
      "Epoch 601/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1098\n",
      "Epoch 602/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1099\n",
      "Epoch 603/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1134\n",
      "Epoch 604/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1115\n",
      "Epoch 605/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1158\n",
      "Epoch 606/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1122\n",
      "Epoch 607/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1112\n",
      "Epoch 608/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1087\n",
      "Epoch 609/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1083\n",
      "Epoch 610/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.1063\n",
      "Epoch 611/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1077\n",
      "Epoch 612/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1184\n",
      "Epoch 613/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1077\n",
      "Epoch 614/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1095\n",
      "Epoch 615/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1087\n",
      "Epoch 616/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1240\n",
      "Epoch 617/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1238\n",
      "Epoch 618/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.1163\n",
      "Epoch 619/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.1185\n",
      "Epoch 620/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.1035\n",
      "Epoch 621/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1039\n",
      "Epoch 622/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.1046\n",
      "Epoch 623/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.1090\n",
      "Epoch 624/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.1074\n",
      "Epoch 625/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1090\n",
      "Epoch 626/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1098\n",
      "Epoch 627/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1079\n",
      "Epoch 628/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1068\n",
      "Epoch 629/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1054\n",
      "Epoch 630/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1007\n",
      "Epoch 631/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1021\n",
      "Epoch 632/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1053\n",
      "Epoch 633/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1044\n",
      "Epoch 634/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1054\n",
      "Epoch 635/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0998\n",
      "Epoch 636/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1006\n",
      "Epoch 637/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0985\n",
      "Epoch 638/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0997\n",
      "Epoch 639/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0975\n",
      "Epoch 640/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0978\n",
      "Epoch 641/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.1019\n",
      "Epoch 642/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1021\n",
      "Epoch 643/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0981\n",
      "Epoch 644/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0962\n",
      "Epoch 645/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1142\n",
      "Epoch 646/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0996\n",
      "Epoch 647/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0963\n",
      "Epoch 648/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0999\n",
      "Epoch 649/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0960\n",
      "Epoch 650/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0956\n",
      "Epoch 651/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1014\n",
      "Epoch 652/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1042\n",
      "Epoch 653/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0982\n",
      "Epoch 654/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0928\n",
      "Epoch 655/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0933\n",
      "Epoch 656/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0989\n",
      "Epoch 657/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1011\n",
      "Epoch 658/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1060\n",
      "Epoch 659/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0941\n",
      "Epoch 660/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1016\n",
      "Epoch 661/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.0929\n",
      "Epoch 662/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.0906\n",
      "Epoch 663/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0907\n",
      "Epoch 664/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.0905\n",
      "Epoch 665/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.0936\n",
      "Epoch 666/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0906\n",
      "Epoch 667/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0921\n",
      "Epoch 668/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.0907\n",
      "Epoch 669/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.0950\n",
      "Epoch 670/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0907\n",
      "Epoch 671/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0909\n",
      "Epoch 672/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0969\n",
      "Epoch 673/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0941\n",
      "Epoch 674/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0900\n",
      "Epoch 675/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0919\n",
      "Epoch 676/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0921\n",
      "Epoch 677/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0893\n",
      "Epoch 678/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0955\n",
      "Epoch 679/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0870\n",
      "Epoch 680/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0893\n",
      "Epoch 681/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0998\n",
      "Epoch 682/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0986\n",
      "Epoch 683/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0889\n",
      "Epoch 684/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0871\n",
      "Epoch 685/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.0881\n",
      "Epoch 686/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.0860\n",
      "Epoch 687/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0956\n",
      "Epoch 688/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0875\n",
      "Epoch 689/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0867\n",
      "Epoch 690/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.0886\n",
      "Epoch 691/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0839\n",
      "Epoch 692/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0858\n",
      "Epoch 693/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0922\n",
      "Epoch 694/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0847\n",
      "Epoch 695/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0835\n",
      "Epoch 696/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0826\n",
      "Epoch 697/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0835\n",
      "Epoch 698/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0829\n",
      "Epoch 699/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0829\n",
      "Epoch 700/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0843\n",
      "Epoch 701/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0829\n",
      "Epoch 702/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0811\n",
      "Epoch 703/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0879\n",
      "Epoch 704/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0905\n",
      "Epoch 705/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0908\n",
      "Epoch 706/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0895\n",
      "Epoch 707/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0909\n",
      "Epoch 708/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0795\n",
      "Epoch 709/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0840\n",
      "Epoch 710/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0821\n",
      "Epoch 711/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0793\n",
      "Epoch 712/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.0789\n",
      "Epoch 713/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.0791\n",
      "Epoch 714/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.0824\n",
      "Epoch 715/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0877\n",
      "Epoch 716/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0938\n",
      "Epoch 717/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0955\n",
      "Epoch 718/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0851\n",
      "Epoch 719/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1149\n",
      "Epoch 720/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0871\n",
      "Epoch 721/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0783\n",
      "Epoch 722/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0775\n",
      "Epoch 723/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0786\n",
      "Epoch 724/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0833\n",
      "Epoch 725/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0813\n",
      "Epoch 726/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0759\n",
      "Epoch 727/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0763\n",
      "Epoch 728/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0758\n",
      "Epoch 729/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0769\n",
      "Epoch 730/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0801\n",
      "Epoch 731/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.0764\n",
      "Epoch 732/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.0821\n",
      "Epoch 733/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0883\n",
      "Epoch 734/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0851\n",
      "Epoch 735/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0854\n",
      "Epoch 736/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0777\n",
      "Epoch 737/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.0793\n",
      "Epoch 738/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.0859\n",
      "Epoch 739/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0808\n",
      "Epoch 740/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0805\n",
      "Epoch 741/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0789\n",
      "Epoch 742/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0759\n",
      "Epoch 743/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0753\n",
      "Epoch 744/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0805\n",
      "Epoch 745/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0747\n",
      "Epoch 746/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0779\n",
      "Epoch 747/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0798\n",
      "Epoch 748/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0737\n",
      "Epoch 749/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0819\n",
      "Epoch 750/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0855\n",
      "Epoch 751/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0815\n",
      "Epoch 752/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0791\n",
      "Epoch 753/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0853\n",
      "Epoch 754/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0782\n",
      "Epoch 755/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0734\n",
      "Epoch 756/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0735\n",
      "Epoch 757/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0743\n",
      "Epoch 758/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0721\n",
      "Epoch 759/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0785\n",
      "Epoch 760/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0878\n",
      "Epoch 761/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0762\n",
      "Epoch 762/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0689\n",
      "Epoch 763/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0683\n",
      "Epoch 764/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0698\n",
      "Epoch 765/1000\n",
      "1564/1564 [==============================] - 0s 42us/step - loss: 0.0747\n",
      "Epoch 766/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0702\n",
      "Epoch 767/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0705\n",
      "Epoch 768/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0674\n",
      "Epoch 769/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0727\n",
      "Epoch 770/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0965\n",
      "Epoch 771/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1119\n",
      "Epoch 772/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0864\n",
      "Epoch 773/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.0830\n",
      "Epoch 774/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0913\n",
      "Epoch 775/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0926\n",
      "Epoch 776/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0715\n",
      "Epoch 777/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.0797\n",
      "Epoch 778/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.0855\n",
      "Epoch 779/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.0912\n",
      "Epoch 780/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.0678\n",
      "Epoch 781/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.0722\n",
      "Epoch 782/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0743\n",
      "Epoch 783/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0750\n",
      "Epoch 784/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.0818\n",
      "Epoch 785/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.0653\n",
      "Epoch 786/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.0713\n",
      "Epoch 787/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0704\n",
      "Epoch 788/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0670\n",
      "Epoch 789/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.0648\n",
      "Epoch 790/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.0731\n",
      "Epoch 791/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1139\n",
      "Epoch 792/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0710\n",
      "Epoch 793/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0670\n",
      "Epoch 794/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0644\n",
      "Epoch 795/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.0680\n",
      "Epoch 796/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0839\n",
      "Epoch 797/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0659\n",
      "Epoch 798/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0633\n",
      "Epoch 799/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0669\n",
      "Epoch 800/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0714\n",
      "Epoch 801/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0669\n",
      "Epoch 802/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0694\n",
      "Epoch 803/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0672\n",
      "Epoch 804/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.0703\n",
      "Epoch 805/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.0687\n",
      "Epoch 806/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.0658\n",
      "Epoch 807/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.0640\n",
      "Epoch 808/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0776\n",
      "Epoch 809/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0787\n",
      "Epoch 810/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.0686\n",
      "Epoch 811/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.0737\n",
      "Epoch 812/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.0643\n",
      "Epoch 813/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0858\n",
      "Epoch 814/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0761\n",
      "Epoch 815/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0843\n",
      "Epoch 816/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0951\n",
      "Epoch 817/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0849\n",
      "Epoch 818/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0649\n",
      "Epoch 819/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0668\n",
      "Epoch 820/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0727\n",
      "Epoch 821/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0623\n",
      "Epoch 822/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0746\n",
      "Epoch 823/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0712\n",
      "Epoch 824/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0831\n",
      "Epoch 825/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0695\n",
      "Epoch 826/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0613\n",
      "Epoch 827/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.0669\n",
      "Epoch 828/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.0684\n",
      "Epoch 829/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0603\n",
      "Epoch 830/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0611\n",
      "Epoch 831/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0612\n",
      "Epoch 832/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.0658\n",
      "Epoch 833/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.0728\n",
      "Epoch 834/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.0844\n",
      "Epoch 835/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.0630\n",
      "Epoch 836/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0590\n",
      "Epoch 837/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.0588\n",
      "Epoch 838/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.0580\n",
      "Epoch 839/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.0603\n",
      "Epoch 840/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.1175\n",
      "Epoch 841/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0894\n",
      "Epoch 842/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0791\n",
      "Epoch 843/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0837\n",
      "Epoch 844/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0793\n",
      "Epoch 845/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0864\n",
      "Epoch 846/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0620\n",
      "Epoch 847/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0629\n",
      "Epoch 848/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0649\n",
      "Epoch 849/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0612\n",
      "Epoch 850/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0727\n",
      "Epoch 851/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0582\n",
      "Epoch 852/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0589\n",
      "Epoch 853/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0654\n",
      "Epoch 854/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0591\n",
      "Epoch 855/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0578\n",
      "Epoch 856/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0644\n",
      "Epoch 857/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0591\n",
      "Epoch 858/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0623\n",
      "Epoch 859/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.0714\n",
      "Epoch 860/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0590\n",
      "Epoch 861/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0673\n",
      "Epoch 862/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0921\n",
      "Epoch 863/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0720\n",
      "Epoch 864/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.0568\n",
      "Epoch 865/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.0616\n",
      "Epoch 866/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.0719\n",
      "Epoch 867/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0637\n",
      "Epoch 868/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0924\n",
      "Epoch 869/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1459\n",
      "Epoch 870/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0746\n",
      "Epoch 871/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0577\n",
      "Epoch 872/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0631\n",
      "Epoch 873/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0569\n",
      "Epoch 874/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0636\n",
      "Epoch 875/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0779\n",
      "Epoch 876/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0803\n",
      "Epoch 877/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1179\n",
      "Epoch 878/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0953\n",
      "Epoch 879/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0929\n",
      "Epoch 880/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0648\n",
      "Epoch 881/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0712\n",
      "Epoch 882/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0908\n",
      "Epoch 883/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0830\n",
      "Epoch 884/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0916\n",
      "Epoch 885/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0643\n",
      "Epoch 886/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0605\n",
      "Epoch 887/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.0562\n",
      "Epoch 888/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0676\n",
      "Epoch 889/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0581\n",
      "Epoch 890/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0667\n",
      "Epoch 891/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0564\n",
      "Epoch 892/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0602\n",
      "Epoch 893/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0703\n",
      "Epoch 894/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1168\n",
      "Epoch 895/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0576\n",
      "Epoch 896/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0548\n",
      "Epoch 897/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0658\n",
      "Epoch 898/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.0632\n",
      "Epoch 899/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.0709\n",
      "Epoch 900/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0696\n",
      "Epoch 901/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0625\n",
      "Epoch 902/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0647\n",
      "Epoch 903/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0866\n",
      "Epoch 904/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0639\n",
      "Epoch 905/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0917\n",
      "Epoch 906/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1361\n",
      "Epoch 907/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.1318\n",
      "Epoch 908/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.0865\n",
      "Epoch 909/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.0872\n",
      "Epoch 910/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.0685\n",
      "Epoch 911/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0640\n",
      "Epoch 912/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0742\n",
      "Epoch 913/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0730\n",
      "Epoch 914/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0667\n",
      "Epoch 915/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.0705\n",
      "Epoch 916/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.0668\n",
      "Epoch 917/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0655\n",
      "Epoch 918/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0793\n",
      "Epoch 919/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1068\n",
      "Epoch 920/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.0679\n",
      "Epoch 921/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.0899\n",
      "Epoch 922/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.0728\n",
      "Epoch 923/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.1658\n",
      "Epoch 924/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0926\n",
      "Epoch 925/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0592\n",
      "Epoch 926/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1003\n",
      "Epoch 927/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0886\n",
      "Epoch 928/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0610\n",
      "Epoch 929/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0853\n",
      "Epoch 930/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1076\n",
      "Epoch 931/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0860\n",
      "Epoch 932/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0894\n",
      "Epoch 933/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1179\n",
      "Epoch 934/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.0656\n",
      "Epoch 935/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1115\n",
      "Epoch 936/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.0672\n",
      "Epoch 937/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.0744\n",
      "Epoch 938/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.0626\n",
      "Epoch 939/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.0653\n",
      "Epoch 940/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.0763\n",
      "Epoch 941/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.0966\n",
      "Epoch 942/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0745\n",
      "Epoch 943/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.1265\n",
      "Epoch 944/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0536\n",
      "Epoch 945/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.0964\n",
      "Epoch 946/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.1845\n",
      "Epoch 947/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0893\n",
      "Epoch 948/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0713\n",
      "Epoch 949/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0991\n",
      "Epoch 950/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.1431\n",
      "Epoch 951/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.0832\n",
      "Epoch 952/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.0596\n",
      "Epoch 953/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.0680\n",
      "Epoch 954/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1786\n",
      "Epoch 955/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0753\n",
      "Epoch 956/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1052\n",
      "Epoch 957/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0722\n",
      "Epoch 958/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1146\n",
      "Epoch 959/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0900\n",
      "Epoch 960/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1071\n",
      "Epoch 961/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.1995\n",
      "Epoch 962/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.0715\n",
      "Epoch 963/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0900\n",
      "Epoch 964/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0942\n",
      "Epoch 965/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0692\n",
      "Epoch 966/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1456\n",
      "Epoch 967/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.1134\n",
      "Epoch 968/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.1352\n",
      "Epoch 969/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.0617\n",
      "Epoch 970/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1501\n",
      "Epoch 971/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0904\n",
      "Epoch 972/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1427\n",
      "Epoch 973/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0917\n",
      "Epoch 974/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1422\n",
      "Epoch 975/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1074\n",
      "Epoch 976/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1655\n",
      "Epoch 977/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0829\n",
      "Epoch 978/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0914\n",
      "Epoch 979/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.3321\n",
      "Epoch 980/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1977\n",
      "Epoch 981/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1705\n",
      "Epoch 982/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0684\n",
      "Epoch 983/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0918\n",
      "Epoch 984/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0684\n",
      "Epoch 985/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.0543\n",
      "Epoch 986/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.0514\n",
      "Epoch 987/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.0527\n",
      "Epoch 988/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.0926\n",
      "Epoch 989/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.0908\n",
      "Epoch 990/1000\n",
      "1564/1564 [==============================] - 0s 19us/step - loss: 0.1252\n",
      "Epoch 991/1000\n",
      "1564/1564 [==============================] - 0s 17us/step - loss: 0.1136\n",
      "Epoch 992/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.0730\n",
      "Epoch 993/1000\n",
      "1564/1564 [==============================] - 0s 16us/step - loss: 0.1397\n",
      "Epoch 994/1000\n",
      "1564/1564 [==============================] - 0s 18us/step - loss: 0.1866\n",
      "Epoch 995/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.0699\n",
      "Epoch 996/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0721\n",
      "Epoch 997/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0910\n",
      "Epoch 998/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0782\n",
      "Epoch 999/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1452\n",
      "Epoch 1000/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0572\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a3a6e45c0>"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_stl = Sequential()\n",
    "NN_stl.add(Dense(units=16,input_dim=19,activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_stl.add(Dense(units=8, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_stl.add(Dense(units=4, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_stl.add(Dense(units=1,activation='linear'))\n",
    "NN_stl.compile(loss='mse', optimizer='adam')\n",
    "NN_stl.fit(np.array(X_train), np.array(y_train), epochs=1000,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN_predictions</th>\n",
       "      <th>actual</th>\n",
       "      <th>GBR_predictions</th>\n",
       "      <th>LY_steals</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>1.358141</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.438233</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>1.397292</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.491734</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>1.168331</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.292477</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>1.488063</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.526214</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>1.477453</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.526288</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1.422665</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.366565</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>1.364403</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.474882</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1.326980</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.395218</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>1.290931</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.279994</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>1.175832</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.132050</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>1.508530</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.415498</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>1.232133</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.402935</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>1.137083</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.163684</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.230867</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.212195</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>1.583236</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.610689</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.849515</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.012416</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>1.062478</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.064284</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>1.164530</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.115097</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>1.118471</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.166937</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>1.244291</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.172244</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1.301358</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.303947</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>1.223650</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.175351</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>1.499334</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.352627</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.963352</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.075733</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>1.266396</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.332053</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>1.144847</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.097607</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1.094683</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.098564</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>1.261232</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.247648</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>1.070604</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.057515</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>1.206235</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.472163</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>1.336431</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.273849</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>1.222559</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.341997</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>0.909345</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.899503</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>1.103224</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.178330</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>1.302338</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.286416</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.138562</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.091403</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>1.425360</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.335777</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1.247270</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.247104</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1.343136</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.282664</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>1.198382</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.198600</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>0.771003</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.870717</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>1.250646</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.308957</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>1.090105</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.286399</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1.102409</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.100642</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.194384</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.009710</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>1.146930</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.222391</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>1.202818</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.319879</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>1.333978</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.446687</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>1.242161</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.229498</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.785069</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.049364</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     NN_predictions  actual  GBR_predictions  LY_steals\n",
       "172        1.358141     1.3         1.438233        1.5\n",
       "491        1.397292     1.5         1.491734        1.5\n",
       "266        1.168331     0.8         1.292477        1.5\n",
       "597        1.488063     1.6         1.526214        1.5\n",
       "175        1.477453     1.3         1.526288        1.5\n",
       "128        1.422665     2.0         1.366565        1.5\n",
       "243        1.364403     1.6         1.474882        1.5\n",
       "99         1.326980     1.3         1.395218        1.5\n",
       "150        1.290931     1.7         1.279994        1.5\n",
       "433        1.175832     1.2         1.132050        1.5\n",
       "425        1.508530     1.5         1.415498        1.5\n",
       "447        1.232133     0.7         1.402935        1.5\n",
       "475        1.137083     1.3         1.163684        1.5\n",
       "27         1.230867     1.6         1.212195        1.5\n",
       "305        1.583236     1.7         1.610689        1.5\n",
       "50         0.849515     1.1         1.012416        1.5\n",
       "595        1.062478     1.1         1.064284        1.4\n",
       "309        1.164530     1.6         1.115097        1.4\n",
       "234        1.118471     1.4         1.166937        1.4\n",
       "123        1.244291     1.0         1.172244        1.4\n",
       "390        1.301358     1.2         1.303947        1.4\n",
       "391        1.223650     1.8         1.175351        1.4\n",
       "265        1.499334     1.2         1.352627        1.4\n",
       "116        0.963352     1.0         1.075733        1.4\n",
       "571        1.266396     1.5         1.332053        1.4\n",
       "321        1.144847     1.1         1.097607        1.4\n",
       "195        1.094683     1.8         1.098564        1.4\n",
       "386        1.261232     1.5         1.247648        1.4\n",
       "619        1.070604     1.4         1.057515        1.4\n",
       "359        1.206235     1.3         1.472163        1.4\n",
       "154        1.336431     1.5         1.273849        1.4\n",
       "198        1.222559     1.3         1.341997        1.3\n",
       "229        0.909345     1.5         0.899503        1.3\n",
       "212        1.103224     1.0         1.178330        1.3\n",
       "360        1.302338     1.3         1.286416        1.3\n",
       "29         1.138562     1.5         1.091403        1.3\n",
       "529        1.425360     1.5         1.335777        1.3\n",
       "42         1.247270     0.9         1.247104        1.3\n",
       "406        1.343136     1.5         1.282664        1.3\n",
       "561        1.198382     1.0         1.198600        1.3\n",
       "622        0.771003     0.8         0.870717        1.3\n",
       "295        1.250646     1.7         1.308957        1.3\n",
       "158        1.090105     1.0         1.286399        1.3\n",
       "145        1.102409     1.0         1.100642        1.2\n",
       "2          1.194384     0.7         1.009710        1.2\n",
       "142        1.146930     1.0         1.222391        1.2\n",
       "141        1.202818     1.5         1.319879        1.2\n",
       "403        1.333978     1.3         1.446687        1.2\n",
       "420        1.242161     1.2         1.229498        1.2\n",
       "173        0.785069     0.6         1.049364        1.2"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = NN_stl.predict(X_test)\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = 3,max_features=0.5)\n",
    "gbr.fit(X_train,y_train)\n",
    "gbr_predictions = gbr.predict(X_test)\n",
    "LR = LinearRegression(fit_intercept=True).fit(X_train,y_train)\n",
    "\n",
    "testing = pd.DataFrame(predictions)\n",
    "testing.columns=['NN_predictions']\n",
    "testing['actual'] = y_test.reset_index()['steals']\n",
    "testing['GBR_predictions']=gbr_predictions\n",
    "testing['LY_steals']=X_test['steals_ly'].reset_index()['steals_ly']\n",
    "testing.sort_values(by='LY_steals',ascending=False)[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>steals</th>\n",
       "      <th>predictions</th>\n",
       "      <th>LR_pred</th>\n",
       "      <th>gbr_pred</th>\n",
       "      <th>mean_pred</th>\n",
       "      <th>steals_ly_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>John Wall</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.679314</td>\n",
       "      <td>1.778605</td>\n",
       "      <td>1.739955</td>\n",
       "      <td>1.732625</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Draymond Green</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.568552</td>\n",
       "      <td>1.566244</td>\n",
       "      <td>1.624291</td>\n",
       "      <td>1.586362</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Chris Paul</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.866328</td>\n",
       "      <td>1.954337</td>\n",
       "      <td>2.036539</td>\n",
       "      <td>1.952401</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>Jimmy Butler</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.614456</td>\n",
       "      <td>1.676836</td>\n",
       "      <td>1.750813</td>\n",
       "      <td>1.680702</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>Robert Covington</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.448184</td>\n",
       "      <td>1.507417</td>\n",
       "      <td>1.615496</td>\n",
       "      <td>1.523699</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>Stephen Curry</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.783131</td>\n",
       "      <td>1.752388</td>\n",
       "      <td>1.838558</td>\n",
       "      <td>1.791359</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>Trevor Ariza</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.521492</td>\n",
       "      <td>1.578091</td>\n",
       "      <td>1.603565</td>\n",
       "      <td>1.567716</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>T.J. McConnell</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.251057</td>\n",
       "      <td>1.286076</td>\n",
       "      <td>1.510351</td>\n",
       "      <td>1.349161</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>Ricky Rubio</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.630803</td>\n",
       "      <td>1.734700</td>\n",
       "      <td>1.811957</td>\n",
       "      <td>1.725820</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>Russell Westbrook</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.880314</td>\n",
       "      <td>1.922384</td>\n",
       "      <td>1.616153</td>\n",
       "      <td>1.806284</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>Paul George</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.476139</td>\n",
       "      <td>1.523187</td>\n",
       "      <td>1.591068</td>\n",
       "      <td>1.530131</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Giannis Antetokounmpo</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.481407</td>\n",
       "      <td>1.509887</td>\n",
       "      <td>1.425450</td>\n",
       "      <td>1.472248</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>Marcus Smart</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.467372</td>\n",
       "      <td>1.511802</td>\n",
       "      <td>1.534884</td>\n",
       "      <td>1.504686</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>Rudy Gay</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.895564</td>\n",
       "      <td>1.016376</td>\n",
       "      <td>1.038458</td>\n",
       "      <td>0.983466</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>Thabo Sefolosha</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.987510</td>\n",
       "      <td>1.001614</td>\n",
       "      <td>1.186581</td>\n",
       "      <td>1.058568</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>Thaddeus Young</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.264267</td>\n",
       "      <td>1.289896</td>\n",
       "      <td>1.440982</td>\n",
       "      <td>1.331715</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>James Harden</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.582826</td>\n",
       "      <td>1.631493</td>\n",
       "      <td>1.514837</td>\n",
       "      <td>1.576385</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>P.J. Tucker</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.123042</td>\n",
       "      <td>1.172659</td>\n",
       "      <td>1.244140</td>\n",
       "      <td>1.179947</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Andre Drummond</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.357725</td>\n",
       "      <td>1.335519</td>\n",
       "      <td>1.341536</td>\n",
       "      <td>1.344927</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>Kyle Lowry</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.450518</td>\n",
       "      <td>1.486763</td>\n",
       "      <td>1.450581</td>\n",
       "      <td>1.462621</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Jrue Holiday</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.327482</td>\n",
       "      <td>1.386638</td>\n",
       "      <td>1.426532</td>\n",
       "      <td>1.380217</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>Otto Porter</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.330174</td>\n",
       "      <td>1.334085</td>\n",
       "      <td>1.272332</td>\n",
       "      <td>1.312197</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>D'Angelo Russell</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.313979</td>\n",
       "      <td>1.354433</td>\n",
       "      <td>1.260150</td>\n",
       "      <td>1.309521</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>DeMarcus Cousins</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.363036</td>\n",
       "      <td>1.420599</td>\n",
       "      <td>1.360522</td>\n",
       "      <td>1.381385</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>Rajon Rondo</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.350575</td>\n",
       "      <td>1.404030</td>\n",
       "      <td>1.326221</td>\n",
       "      <td>1.360275</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Dwyane Wade</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.011186</td>\n",
       "      <td>1.071025</td>\n",
       "      <td>1.102292</td>\n",
       "      <td>1.061501</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>Eric Bledsoe</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.313596</td>\n",
       "      <td>1.410573</td>\n",
       "      <td>1.388710</td>\n",
       "      <td>1.370960</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>Khris Middleton</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.136124</td>\n",
       "      <td>1.232085</td>\n",
       "      <td>1.140902</td>\n",
       "      <td>1.169704</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>Justise Winslow</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.920387</td>\n",
       "      <td>1.009323</td>\n",
       "      <td>1.064699</td>\n",
       "      <td>0.998136</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Garrett Temple</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.920788</td>\n",
       "      <td>0.960709</td>\n",
       "      <td>0.883989</td>\n",
       "      <td>0.921829</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Larry Nance</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.075789</td>\n",
       "      <td>1.127288</td>\n",
       "      <td>1.084957</td>\n",
       "      <td>1.096012</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Anthony Davis</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.310935</td>\n",
       "      <td>1.353553</td>\n",
       "      <td>1.272220</td>\n",
       "      <td>1.312236</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>Paul Millsap</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.232890</td>\n",
       "      <td>1.252330</td>\n",
       "      <td>1.202904</td>\n",
       "      <td>1.229375</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>Kyrie Irving</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.193881</td>\n",
       "      <td>1.262707</td>\n",
       "      <td>1.237764</td>\n",
       "      <td>1.231450</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Jeff Teague</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.133004</td>\n",
       "      <td>1.167244</td>\n",
       "      <td>1.132794</td>\n",
       "      <td>1.144347</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>Manu Ginobili</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.243535</td>\n",
       "      <td>1.076739</td>\n",
       "      <td>1.177876</td>\n",
       "      <td>1.166050</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>Kentavious Caldwell-Pope</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.186813</td>\n",
       "      <td>1.201078</td>\n",
       "      <td>1.126528</td>\n",
       "      <td>1.171473</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>Victor Oladipo</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.221171</td>\n",
       "      <td>1.284417</td>\n",
       "      <td>1.193164</td>\n",
       "      <td>1.232917</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>Tyler Johnson</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.056248</td>\n",
       "      <td>1.091416</td>\n",
       "      <td>1.029694</td>\n",
       "      <td>1.059119</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Gary Harris</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.130781</td>\n",
       "      <td>1.183002</td>\n",
       "      <td>1.094250</td>\n",
       "      <td>1.136011</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Goran Dragic</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.056290</td>\n",
       "      <td>1.076896</td>\n",
       "      <td>0.984754</td>\n",
       "      <td>1.039313</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>Kent Bazemore</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.982246</td>\n",
       "      <td>0.980111</td>\n",
       "      <td>0.908443</td>\n",
       "      <td>0.956934</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Andre Roberson</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.985491</td>\n",
       "      <td>1.007149</td>\n",
       "      <td>0.952429</td>\n",
       "      <td>0.981690</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Joe Ingles</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.237603</td>\n",
       "      <td>1.221732</td>\n",
       "      <td>1.298839</td>\n",
       "      <td>1.252725</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Avery Bradley</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.037545</td>\n",
       "      <td>1.089266</td>\n",
       "      <td>1.031959</td>\n",
       "      <td>1.052923</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>LeBron James</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.303220</td>\n",
       "      <td>1.372525</td>\n",
       "      <td>1.204068</td>\n",
       "      <td>1.293271</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>T.J. Warren</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.953719</td>\n",
       "      <td>1.034474</td>\n",
       "      <td>0.934427</td>\n",
       "      <td>0.974207</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>Ian Mahinmi</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.695916</td>\n",
       "      <td>0.716142</td>\n",
       "      <td>0.667093</td>\n",
       "      <td>0.693050</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>Maurice Harkless</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.014852</td>\n",
       "      <td>1.039726</td>\n",
       "      <td>1.030073</td>\n",
       "      <td>1.028217</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>Kevin Durant</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.101220</td>\n",
       "      <td>1.122446</td>\n",
       "      <td>1.122848</td>\n",
       "      <td>1.115505</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       player  steals  predictions   LR_pred  gbr_pred  \\\n",
       "189                 John Wall     1.4     1.679314  1.778605  1.739955   \n",
       "104            Draymond Green     1.4     1.568552  1.566244  1.624291   \n",
       "54                 Chris Paul     1.7     1.866328  1.954337  2.036539   \n",
       "178              Jimmy Butler     2.0     1.614456  1.676836  1.750813   \n",
       "317          Robert Covington     1.7     1.448184  1.507417  1.615496   \n",
       "338             Stephen Curry     1.6     1.783131  1.752388  1.838558   \n",
       "361              Trevor Ariza     1.5     1.521492  1.578091  1.603565   \n",
       "340            T.J. McConnell     1.2     1.251057  1.286076  1.510351   \n",
       "316               Ricky Rubio     1.6     1.630803  1.734700  1.811957   \n",
       "324         Russell Westbrook     1.8     1.880314  1.922384  1.616153   \n",
       "301               Paul George     2.0     1.476139  1.523187  1.591068   \n",
       "127     Giannis Antetokounmpo     1.5     1.481407  1.509887  1.425450   \n",
       "254              Marcus Smart     1.3     1.467372  1.511802  1.534884   \n",
       "322                  Rudy Gay     0.8     0.895564  1.016376  1.038458   \n",
       "347           Thabo Sefolosha     1.4     0.987510  1.001614  1.186581   \n",
       "348            Thaddeus Young     1.7     1.264267  1.289896  1.440982   \n",
       "159              James Harden     1.8     1.582826  1.631493  1.514837   \n",
       "293               P.J. Tucker     1.0     1.123042  1.172659  1.244140   \n",
       "14             Andre Drummond     1.5     1.357725  1.335519  1.341536   \n",
       "229                Kyle Lowry     1.1     1.450518  1.486763  1.450581   \n",
       "203              Jrue Holiday     1.5     1.327482  1.386638  1.426532   \n",
       "292               Otto Porter     1.5     1.330174  1.334085  1.272332   \n",
       "62           D'Angelo Russell     0.8     1.313979  1.354433  1.260150   \n",
       "82           DeMarcus Cousins     1.6     1.363036  1.420599  1.360522   \n",
       "307               Rajon Rondo     1.1     1.350575  1.404030  1.326221   \n",
       "107               Dwyane Wade     0.9     1.011186  1.071025  1.102292   \n",
       "113              Eric Bledsoe     2.0     1.313596  1.410573  1.388710   \n",
       "222           Khris Middleton     1.5     1.136124  1.232085  1.140902   \n",
       "208           Justise Winslow     0.8     0.920387  1.009323  1.064699   \n",
       "120            Garrett Temple     0.9     0.920788  0.960709  0.883989   \n",
       "237               Larry Nance     1.4     1.075789  1.127288  1.084957   \n",
       "21              Anthony Davis     1.5     1.310935  1.353553  1.272220   \n",
       "302              Paul Millsap     1.0     1.232890  1.252330  1.202904   \n",
       "232              Kyrie Irving     1.1     1.193881  1.262707  1.237764   \n",
       "171               Jeff Teague     1.5     1.133004  1.167244  1.132794   \n",
       "248             Manu Ginobili     0.7     1.243535  1.076739  1.177876   \n",
       "218  Kentavious Caldwell-Pope     1.4     1.186813  1.201078  1.126528   \n",
       "376            Victor Oladipo     2.4     1.221171  1.284417  1.193164   \n",
       "369             Tyler Johnson     0.8     1.056248  1.091416  1.029694   \n",
       "121               Gary Harris     1.8     1.130781  1.183002  1.094250   \n",
       "129              Goran Dragic     0.8     1.056290  1.076896  0.984754   \n",
       "217             Kent Bazemore     1.5     0.982246  0.980111  0.908443   \n",
       "16             Andre Roberson     1.2     0.985491  1.007149  0.952429   \n",
       "182                Joe Ingles     1.1     1.237603  1.221732  1.298839   \n",
       "26              Avery Bradley     1.2     1.037545  1.089266  1.031959   \n",
       "238              LeBron James     1.4     1.303220  1.372525  1.204068   \n",
       "341               T.J. Warren     1.0     0.953719  1.034474  0.934427   \n",
       "137               Ian Mahinmi     0.5     0.695916  0.716142  0.667093   \n",
       "263          Maurice Harkless     0.8     1.014852  1.039726  1.030073   \n",
       "219              Kevin Durant     0.7     1.101220  1.122446  1.122848   \n",
       "\n",
       "     mean_pred  steals_ly_x  \n",
       "189   1.732625          2.0  \n",
       "104   1.586362          2.0  \n",
       "54    1.952401          2.0  \n",
       "178   1.680702          1.9  \n",
       "317   1.523699          1.9  \n",
       "338   1.791359          1.8  \n",
       "361   1.567716          1.8  \n",
       "340   1.349161          1.7  \n",
       "316   1.725820          1.7  \n",
       "324   1.806284          1.6  \n",
       "301   1.530131          1.6  \n",
       "127   1.472248          1.6  \n",
       "254   1.504686          1.6  \n",
       "322   0.983466          1.5  \n",
       "347   1.058568          1.5  \n",
       "348   1.331715          1.5  \n",
       "159   1.576385          1.5  \n",
       "293   1.179947          1.5  \n",
       "14    1.344927          1.5  \n",
       "229   1.462621          1.5  \n",
       "203   1.380217          1.5  \n",
       "292   1.312197          1.5  \n",
       "62    1.309521          1.4  \n",
       "82    1.381385          1.4  \n",
       "307   1.360275          1.4  \n",
       "107   1.061501          1.4  \n",
       "113   1.370960          1.4  \n",
       "222   1.169704          1.4  \n",
       "208   0.998136          1.4  \n",
       "120   0.921829          1.3  \n",
       "237   1.096012          1.3  \n",
       "21    1.312236          1.3  \n",
       "302   1.229375          1.3  \n",
       "232   1.231450          1.2  \n",
       "171   1.144347          1.2  \n",
       "248   1.166050          1.2  \n",
       "218   1.171473          1.2  \n",
       "376   1.232917          1.2  \n",
       "369   1.059119          1.2  \n",
       "121   1.136011          1.2  \n",
       "129   1.039313          1.2  \n",
       "217   0.956934          1.2  \n",
       "16    0.981690          1.2  \n",
       "182   1.252725          1.2  \n",
       "26    1.052923          1.2  \n",
       "238   1.293271          1.2  \n",
       "341   0.974207          1.2  \n",
       "137   0.693050          1.1  \n",
       "263   1.028217          1.1  \n",
       "219   1.115505          1.1  "
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_2017steals = steals[steals['season']==2017].drop(['team','player','steals','Games'],axis=1)\n",
    "steals_2017 = NN_stl.predict(pred_2017steals)\n",
    "gbr_stl_2017 = pd.DataFrame(gbr.predict(pred_2017steals))\n",
    "LR_stl_2017 = pd.DataFrame(LR.predict(pred_2017steals))\n",
    "test_2 =pd.DataFrame(steals_2017)\n",
    "test_3 = pd.merge(steals,pred_2017steals,left_index=True,right_index=True).reset_index()\n",
    "test_3['predictions']=test_2[0]\n",
    "test_3['gbr_pred'] = gbr_stl_2017[0]\n",
    "test_3['LR_pred'] = LR_stl_2017[0]\n",
    "test_3['mean_pred'] = (test_3['predictions']+test_3['gbr_pred']+test_3['LR_pred'])/3\n",
    "test_3 = test_3[test_3['Games']>30]\n",
    "test_3[['player','steals','predictions','LR_pred','gbr_pred','mean_pred','steals_ly_x']].sort_values(by='steals_ly_x',ascending=False)[0:50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE using LR:0.05558796722155904\n",
      "MSE using GB:0.05758201819927772\n",
      "MSE using NN:0.06117266689151495\n",
      "MSE using combo:0.05569501924904028\n",
      "MSE using mean:0.17097129766600938\n",
      "MSE using last year stats:0.08067307692307688\n"
     ]
    }
   ],
   "source": [
    "print('MSE using LR:{}'.format(np.mean((test_3['steals']-test_3['LR_pred'])**2)))\n",
    "print('MSE using GB:{}'.format(np.mean((test_3['steals']-test_3['gbr_pred'])**2)))\n",
    "print('MSE using NN:{}'.format(np.mean((test_3['steals']-test_3['predictions'])**2)))\n",
    "print('MSE using combo:{}'.format(np.mean((test_3['steals']-test_3['mean_pred'])**2)))\n",
    "print('MSE using mean:{}'.format(np.mean((test_3['steals']-np.mean(test_3['steals']))**2)))\n",
    "print('MSE using last year stats:{}'.format(np.mean((test_3['steals']-test_3['steals_ly_x'])**2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01125328 0.04008531 0.10639288 0.04426043 0.02392808 0.00408012\n",
      " 0.0016119  0.0723225  0.04320477 0.05824298 0.0763244  0.08581513\n",
      " 0.04672878 0.07181035 0.06675481 0.04345141 0.15460267 0.01074619\n",
      " 0.03838401]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['season', 'age', 'steals_ly', 'change_steals_ly', 'C_PF', 'PG', 'SG_SF',\n",
       "       'starter_change', 'per_ly', 'change_per', 'stl_perc_ly',\n",
       "       'change_stl_perc', 'defensive_winshares', 'defensive_boxplusminus',\n",
       "       'boxplusminus', 'value_overreplacement', 'career_steals', 'yearspro',\n",
       "       'age_squared'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(gbr.feature_importances_)\n",
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''next is blocks.  In the future, may want to add minutes from last season?'''\n",
    "\n",
    "\n",
    "query= '''\n",
    "        \n",
    "        DROP TABLE IF EXISTS blocks_pred;\n",
    "        CREATE TABLE blocks_pred(\n",
    "        season int, --these come from player_stats\n",
    "        player varchar(50),\n",
    "        Age int,\n",
    "        team varchar(50),\n",
    "        blk float, -- these come from player_stats\n",
    "        blk_ly float,\n",
    "        change_blk_ly float,\n",
    "        Games float,\n",
    "        C_PF int,\n",
    "        PG int,\n",
    "        SG_SF int,\n",
    "        starter_change int, \n",
    "        \n",
    "\n",
    "        -- from player_advstats\n",
    "        per_ly float,\n",
    "        change_per float,\n",
    "        blk_perc_ly float,\n",
    "        change_blk_perc_ly float,\n",
    "        defensive_winshares float,\n",
    "        defensive_boxplusminus float,\n",
    "        boxplusminus float,\n",
    "        value_overreplacement float,\n",
    "        \n",
    "        career_blk float,\n",
    "        yearspro int\n",
    "        );\n",
    "        \n",
    "        INSERT INTO blocks_pred(season,player,age,team,blk,blk_ly,change_blk_ly,starter_change,Games,C_PF,PG,SG_SF)\n",
    "        SELECT season,player,age,startingteam,blk,blk_ly,change_blk_ly,starter-starter_ly,Games,\n",
    "        case when pos in ('C','PF') then 1 else 0 end,case when pos='PG' then 1 else 0 end,case when pos in('SG','SF') then 1 else 0 end from player_stats;\n",
    "        \n",
    "        \n",
    "        update blocks_pred bp\n",
    "        set per_ly=pa.per_ly,change_per=pa.change_per,blk_perc_ly = pa.blk_perc_ly,change_blk_perc_ly = pa.change_blk_perc_ly\n",
    "        ,defensive_winshares=pa.defensive_winshares,defensive_boxplusminus=pa.defensive_boxplusminus\n",
    "        ,boxplusminus=pa.boxplusminus,value_overreplacement=pa.value_overreplacement\n",
    "        from player_advstats pa\n",
    "        where bp.player = pa.player and bp.season = pa.season and bp.team = pa.startingteam;\n",
    "        \n",
    "        update blocks_pred bp\n",
    "        set career_blk = pc.career_blk, yearspro = pc.yearspro\n",
    "        from player_careerstats pc\n",
    "        where bp.player = pc.player and bp.season = pc.season;\n",
    "        \n",
    "        \n",
    "        select * from blocks_pred where season>2009\n",
    "        '''\n",
    "\n",
    "\n",
    "cur.execute(query)\n",
    "data = cur.fetchall()\n",
    "blocks_df = pd.DataFrame(np.array(data))\n",
    "blocks_df.columns = ['season','player','age','team','blocks','blocks_ly','change_blocks_ly','Games','C_PF','PG','SG_SF','starter_change'\n",
    "                    ,'per_ly','change_per','blk_perc_ly','change_blk_perc','defensive_winshares','defensive_boxplusminus','boxplusminus','value_overreplacement','career_blocks','yearspro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "blocks_df['age_squared']=blocks_df['age']*blocks_df['age']\n",
    "blocks = blocks_df[blocks_df['blocks_ly'].notna()]\n",
    "for i in blocks.columns:\n",
    "    if i not in(['player','team']):\n",
    "        blocks[i]=pd.to_numeric(blocks[i])\n",
    "blocks = blocks.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = blocks[(blocks['season']!=2017) & (blocks['Games']>30)].drop(['player','team','blocks','Games'],axis=1)\n",
    "#X = blocks[(blocks['season']!=2017) & (blocks['Games']>30)][['blocks_ly','career_blocks','starter_change']]\n",
    "y = blocks[(blocks['season']!=2017) & (blocks['Games']>30)]['blocks']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1564/1564 [==============================] - 2s 1ms/step - loss: 169.0718\n",
      "Epoch 2/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 54.7393\n",
      "Epoch 3/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 40.0995\n",
      "Epoch 4/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 32.4636\n",
      "Epoch 5/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 27.7551\n",
      "Epoch 6/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 23.8176\n",
      "Epoch 7/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 21.0157\n",
      "Epoch 8/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 17.1252\n",
      "Epoch 9/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 15.2152\n",
      "Epoch 10/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 11.8473\n",
      "Epoch 11/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 9.2615\n",
      "Epoch 12/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 7.1209\n",
      "Epoch 13/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 5.2539\n",
      "Epoch 14/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 3.7883\n",
      "Epoch 15/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 2.8800\n",
      "Epoch 16/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 2.2412\n",
      "Epoch 17/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 1.4738\n",
      "Epoch 18/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 1.1206\n",
      "Epoch 19/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.9072\n",
      "Epoch 20/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.7162\n",
      "Epoch 21/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.5844\n",
      "Epoch 22/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.5084\n",
      "Epoch 23/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.4506\n",
      "Epoch 24/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.3869\n",
      "Epoch 25/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.3426\n",
      "Epoch 26/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.3154\n",
      "Epoch 27/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.2830\n",
      "Epoch 28/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.2523\n",
      "Epoch 29/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2403\n",
      "Epoch 30/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.2148\n",
      "Epoch 31/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.2086\n",
      "Epoch 32/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1991\n",
      "Epoch 33/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.2100\n",
      "Epoch 34/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1791\n",
      "Epoch 35/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1684\n",
      "Epoch 36/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1579\n",
      "Epoch 37/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1560\n",
      "Epoch 38/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.1600\n",
      "Epoch 39/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1482\n",
      "Epoch 40/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1392\n",
      "Epoch 41/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1300\n",
      "Epoch 42/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1251\n",
      "Epoch 43/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1220\n",
      "Epoch 44/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1239\n",
      "Epoch 45/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1303\n",
      "Epoch 46/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1181\n",
      "Epoch 47/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1076\n",
      "Epoch 48/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1047\n",
      "Epoch 49/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1091\n",
      "Epoch 50/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1122\n",
      "Epoch 51/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1014\n",
      "Epoch 52/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1055\n",
      "Epoch 53/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0978\n",
      "Epoch 54/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1005\n",
      "Epoch 55/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1043\n",
      "Epoch 56/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0980\n",
      "Epoch 57/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0899\n",
      "Epoch 58/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0927\n",
      "Epoch 59/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1081\n",
      "Epoch 60/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0935\n",
      "Epoch 61/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0896\n",
      "Epoch 62/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1003\n",
      "Epoch 63/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0822\n",
      "Epoch 64/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0823\n",
      "Epoch 65/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0834\n",
      "Epoch 66/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0923\n",
      "Epoch 67/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0911\n",
      "Epoch 68/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0794\n",
      "Epoch 69/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0781\n",
      "Epoch 70/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0832\n",
      "Epoch 71/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0740\n",
      "Epoch 72/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0735\n",
      "Epoch 73/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0762\n",
      "Epoch 74/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0746\n",
      "Epoch 75/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0706\n",
      "Epoch 76/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0711\n",
      "Epoch 77/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0735\n",
      "Epoch 78/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0760\n",
      "Epoch 79/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0727\n",
      "Epoch 80/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0708\n",
      "Epoch 81/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0705\n",
      "Epoch 82/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0703\n",
      "Epoch 83/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0663\n",
      "Epoch 84/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0705\n",
      "Epoch 85/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0737\n",
      "Epoch 86/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0886\n",
      "Epoch 87/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0791\n",
      "Epoch 88/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0747\n",
      "Epoch 89/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0650\n",
      "Epoch 90/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0639\n",
      "Epoch 91/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0744\n",
      "Epoch 92/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0835\n",
      "Epoch 93/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0697\n",
      "Epoch 94/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0639\n",
      "Epoch 95/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0786\n",
      "Epoch 96/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0689\n",
      "Epoch 97/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0680\n",
      "Epoch 98/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0633\n",
      "Epoch 99/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0686\n",
      "Epoch 100/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0665\n",
      "Epoch 101/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0823\n",
      "Epoch 102/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0769\n",
      "Epoch 103/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0885\n",
      "Epoch 104/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0715\n",
      "Epoch 105/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0663\n",
      "Epoch 106/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0655\n",
      "Epoch 107/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0610\n",
      "Epoch 108/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0973\n",
      "Epoch 109/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0897\n",
      "Epoch 110/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0743\n",
      "Epoch 111/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0727\n",
      "Epoch 112/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0607\n",
      "Epoch 113/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0620\n",
      "Epoch 114/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0596\n",
      "Epoch 115/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0661\n",
      "Epoch 116/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0602\n",
      "Epoch 117/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0571\n",
      "Epoch 118/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0604\n",
      "Epoch 119/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0574\n",
      "Epoch 120/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0576\n",
      "Epoch 121/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0620\n",
      "Epoch 122/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0665\n",
      "Epoch 123/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0842\n",
      "Epoch 124/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0755\n",
      "Epoch 125/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0932\n",
      "Epoch 126/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0698\n",
      "Epoch 127/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0714\n",
      "Epoch 128/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0694\n",
      "Epoch 129/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0602\n",
      "Epoch 130/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0712\n",
      "Epoch 131/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0567\n",
      "Epoch 132/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0632\n",
      "Epoch 133/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0576\n",
      "Epoch 134/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0852\n",
      "Epoch 135/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0642\n",
      "Epoch 136/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0601\n",
      "Epoch 137/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0652\n",
      "Epoch 138/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0768\n",
      "Epoch 139/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0547\n",
      "Epoch 140/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0575\n",
      "Epoch 141/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0598\n",
      "Epoch 142/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0565\n",
      "Epoch 143/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0597\n",
      "Epoch 144/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0627\n",
      "Epoch 145/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0590\n",
      "Epoch 146/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0619\n",
      "Epoch 147/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0942\n",
      "Epoch 148/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0772\n",
      "Epoch 149/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0578\n",
      "Epoch 150/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0582\n",
      "Epoch 151/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0596\n",
      "Epoch 152/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0537\n",
      "Epoch 153/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0785\n",
      "Epoch 154/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0968\n",
      "Epoch 155/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0622\n",
      "Epoch 156/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0937\n",
      "Epoch 157/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0692\n",
      "Epoch 158/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0609\n",
      "Epoch 159/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0589\n",
      "Epoch 160/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0605\n",
      "Epoch 161/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0592\n",
      "Epoch 162/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0577\n",
      "Epoch 163/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0655\n",
      "Epoch 164/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0853\n",
      "Epoch 165/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0835\n",
      "Epoch 166/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0587\n",
      "Epoch 167/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0683\n",
      "Epoch 168/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0684\n",
      "Epoch 169/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0823\n",
      "Epoch 170/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0936\n",
      "Epoch 171/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0627\n",
      "Epoch 172/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0700\n",
      "Epoch 173/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0805\n",
      "Epoch 174/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0618\n",
      "Epoch 175/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0654\n",
      "Epoch 176/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1188\n",
      "Epoch 177/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0626\n",
      "Epoch 178/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0586\n",
      "Epoch 179/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0613\n",
      "Epoch 180/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0792\n",
      "Epoch 181/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0553\n",
      "Epoch 182/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0700\n",
      "Epoch 183/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0625\n",
      "Epoch 184/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0596\n",
      "Epoch 185/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0602\n",
      "Epoch 186/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0893\n",
      "Epoch 187/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0827\n",
      "Epoch 188/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0803\n",
      "Epoch 189/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0739\n",
      "Epoch 190/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0728\n",
      "Epoch 191/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0805\n",
      "Epoch 192/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0621\n",
      "Epoch 193/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1023\n",
      "Epoch 194/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0972\n",
      "Epoch 195/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0903\n",
      "Epoch 196/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0714\n",
      "Epoch 197/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0721\n",
      "Epoch 198/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0920\n",
      "Epoch 199/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1103\n",
      "Epoch 200/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0953\n",
      "Epoch 201/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0596\n",
      "Epoch 202/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0834\n",
      "Epoch 203/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0616\n",
      "Epoch 204/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0903\n",
      "Epoch 205/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1863\n",
      "Epoch 206/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0866\n",
      "Epoch 207/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0591\n",
      "Epoch 208/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1020\n",
      "Epoch 209/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1079\n",
      "Epoch 210/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0634\n",
      "Epoch 211/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1018\n",
      "Epoch 212/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1549\n",
      "Epoch 213/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0770\n",
      "Epoch 214/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0897\n",
      "Epoch 215/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0676\n",
      "Epoch 216/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0524\n",
      "Epoch 217/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0530\n",
      "Epoch 218/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0548\n",
      "Epoch 219/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0564\n",
      "Epoch 220/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1238\n",
      "Epoch 221/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0867\n",
      "Epoch 222/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0640\n",
      "Epoch 223/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0890\n",
      "Epoch 224/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0766\n",
      "Epoch 225/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0754\n",
      "Epoch 226/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0511\n",
      "Epoch 227/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0519\n",
      "Epoch 228/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0605\n",
      "Epoch 229/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0724\n",
      "Epoch 230/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0613\n",
      "Epoch 231/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0866\n",
      "Epoch 232/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0688\n",
      "Epoch 233/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0529\n",
      "Epoch 234/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0655\n",
      "Epoch 235/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0762\n",
      "Epoch 236/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0642\n",
      "Epoch 237/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1030\n",
      "Epoch 238/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0835\n",
      "Epoch 239/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0993\n",
      "Epoch 240/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1147\n",
      "Epoch 241/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0780\n",
      "Epoch 242/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0544\n",
      "Epoch 243/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0636\n",
      "Epoch 244/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1234\n",
      "Epoch 245/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0929\n",
      "Epoch 246/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0678\n",
      "Epoch 247/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1214\n",
      "Epoch 248/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0991\n",
      "Epoch 249/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0707\n",
      "Epoch 250/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0577\n",
      "Epoch 251/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0620\n",
      "Epoch 252/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1000\n",
      "Epoch 253/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0519\n",
      "Epoch 254/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0791\n",
      "Epoch 255/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0671\n",
      "Epoch 256/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0677\n",
      "Epoch 257/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0761\n",
      "Epoch 258/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1024\n",
      "Epoch 259/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0850\n",
      "Epoch 260/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0744\n",
      "Epoch 261/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1169\n",
      "Epoch 262/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0903\n",
      "Epoch 263/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0961\n",
      "Epoch 264/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0679\n",
      "Epoch 265/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0637\n",
      "Epoch 266/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0654\n",
      "Epoch 267/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0711\n",
      "Epoch 268/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0743\n",
      "Epoch 269/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0757\n",
      "Epoch 270/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0682\n",
      "Epoch 271/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0711\n",
      "Epoch 272/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0971\n",
      "Epoch 273/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1843\n",
      "Epoch 274/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0652\n",
      "Epoch 275/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0526\n",
      "Epoch 276/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0652\n",
      "Epoch 277/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0733\n",
      "Epoch 278/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0863\n",
      "Epoch 279/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0786\n",
      "Epoch 280/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0853\n",
      "Epoch 281/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0887\n",
      "Epoch 282/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0851\n",
      "Epoch 283/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0795\n",
      "Epoch 284/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0754\n",
      "Epoch 285/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0966\n",
      "Epoch 286/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1397\n",
      "Epoch 287/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1188\n",
      "Epoch 288/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0628\n",
      "Epoch 289/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0950\n",
      "Epoch 290/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0718\n",
      "Epoch 291/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0945\n",
      "Epoch 292/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0748\n",
      "Epoch 293/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0965\n",
      "Epoch 294/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1032\n",
      "Epoch 295/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1141\n",
      "Epoch 296/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0667\n",
      "Epoch 297/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0700\n",
      "Epoch 298/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0669\n",
      "Epoch 299/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0625\n",
      "Epoch 300/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0714\n",
      "Epoch 301/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0508\n",
      "Epoch 302/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1017\n",
      "Epoch 303/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0994\n",
      "Epoch 304/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0971\n",
      "Epoch 305/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0583\n",
      "Epoch 306/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0844\n",
      "Epoch 307/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0693\n",
      "Epoch 308/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0671\n",
      "Epoch 309/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0808\n",
      "Epoch 310/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0822\n",
      "Epoch 311/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0575\n",
      "Epoch 312/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0721\n",
      "Epoch 313/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0920\n",
      "Epoch 314/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0592\n",
      "Epoch 315/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0598\n",
      "Epoch 316/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0723\n",
      "Epoch 317/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0568\n",
      "Epoch 318/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0574\n",
      "Epoch 319/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0971\n",
      "Epoch 320/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0747\n",
      "Epoch 321/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0617\n",
      "Epoch 322/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0802\n",
      "Epoch 323/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0609\n",
      "Epoch 324/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0550\n",
      "Epoch 325/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0730\n",
      "Epoch 326/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0602\n",
      "Epoch 327/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0524\n",
      "Epoch 328/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0757\n",
      "Epoch 329/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1421\n",
      "Epoch 330/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1848\n",
      "Epoch 331/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1423\n",
      "Epoch 332/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1401\n",
      "Epoch 333/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1085\n",
      "Epoch 334/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0522\n",
      "Epoch 335/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0557\n",
      "Epoch 336/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0774\n",
      "Epoch 337/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0858\n",
      "Epoch 338/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0854\n",
      "Epoch 339/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0523\n",
      "Epoch 340/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0988\n",
      "Epoch 341/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1320\n",
      "Epoch 342/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0901\n",
      "Epoch 343/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0702\n",
      "Epoch 344/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0641\n",
      "Epoch 345/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0760\n",
      "Epoch 346/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0730\n",
      "Epoch 347/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1356\n",
      "Epoch 348/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0894\n",
      "Epoch 349/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0526\n",
      "Epoch 350/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1009\n",
      "Epoch 351/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0608\n",
      "Epoch 352/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0602\n",
      "Epoch 353/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0766\n",
      "Epoch 354/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.0541\n",
      "Epoch 355/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0569\n",
      "Epoch 356/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0707\n",
      "Epoch 357/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0535\n",
      "Epoch 358/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0686\n",
      "Epoch 359/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0613\n",
      "Epoch 360/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0622\n",
      "Epoch 361/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0756\n",
      "Epoch 362/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0770\n",
      "Epoch 363/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0701\n",
      "Epoch 364/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1475\n",
      "Epoch 365/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1147\n",
      "Epoch 366/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.0862\n",
      "Epoch 367/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0904\n",
      "Epoch 368/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0618\n",
      "Epoch 369/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0660\n",
      "Epoch 370/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0783\n",
      "Epoch 371/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0533\n",
      "Epoch 372/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0627\n",
      "Epoch 373/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0641\n",
      "Epoch 374/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1239\n",
      "Epoch 375/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.1116\n",
      "Epoch 376/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0901\n",
      "Epoch 377/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0859\n",
      "Epoch 378/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0763\n",
      "Epoch 379/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0561\n",
      "Epoch 380/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0803\n",
      "Epoch 381/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0874\n",
      "Epoch 382/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0537\n",
      "Epoch 383/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0943\n",
      "Epoch 384/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0669\n",
      "Epoch 385/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0779\n",
      "Epoch 386/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0560\n",
      "Epoch 387/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0580\n",
      "Epoch 388/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0926\n",
      "Epoch 389/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0633\n",
      "Epoch 390/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1100\n",
      "Epoch 391/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0968\n",
      "Epoch 392/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0819\n",
      "Epoch 393/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0868\n",
      "Epoch 394/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1091\n",
      "Epoch 395/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0827\n",
      "Epoch 396/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0645\n",
      "Epoch 397/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0686\n",
      "Epoch 398/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0856\n",
      "Epoch 399/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1554\n",
      "Epoch 400/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0658\n",
      "Epoch 401/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0618\n",
      "Epoch 402/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0906\n",
      "Epoch 403/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1254\n",
      "Epoch 404/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0600\n",
      "Epoch 405/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0907\n",
      "Epoch 406/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0684\n",
      "Epoch 407/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0644\n",
      "Epoch 408/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0642\n",
      "Epoch 409/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0646\n",
      "Epoch 410/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0829\n",
      "Epoch 411/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0636\n",
      "Epoch 412/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0693\n",
      "Epoch 413/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0905\n",
      "Epoch 414/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0873\n",
      "Epoch 415/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0873\n",
      "Epoch 416/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0584\n",
      "Epoch 417/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0705\n",
      "Epoch 418/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0827\n",
      "Epoch 419/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1467\n",
      "Epoch 420/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0647\n",
      "Epoch 421/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0737\n",
      "Epoch 422/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0756\n",
      "Epoch 423/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0728\n",
      "Epoch 424/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0732\n",
      "Epoch 425/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0619\n",
      "Epoch 426/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1192\n",
      "Epoch 427/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1371\n",
      "Epoch 428/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1157\n",
      "Epoch 429/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0793\n",
      "Epoch 430/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0868\n",
      "Epoch 431/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.0884\n",
      "Epoch 432/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0509\n",
      "Epoch 433/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0709\n",
      "Epoch 434/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0687\n",
      "Epoch 435/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0976\n",
      "Epoch 436/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1729\n",
      "Epoch 437/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1570\n",
      "Epoch 438/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1077\n",
      "Epoch 439/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0737\n",
      "Epoch 440/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0852\n",
      "Epoch 441/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0619\n",
      "Epoch 442/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0882\n",
      "Epoch 443/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0534\n",
      "Epoch 444/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0557\n",
      "Epoch 445/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0616\n",
      "Epoch 446/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0521\n",
      "Epoch 447/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1129\n",
      "Epoch 448/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0509\n",
      "Epoch 449/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0591\n",
      "Epoch 450/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0582\n",
      "Epoch 451/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0690\n",
      "Epoch 452/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0915\n",
      "Epoch 453/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0562\n",
      "Epoch 454/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0680\n",
      "Epoch 455/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0839\n",
      "Epoch 456/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0571\n",
      "Epoch 457/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0505\n",
      "Epoch 458/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0607\n",
      "Epoch 459/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0685\n",
      "Epoch 460/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0663\n",
      "Epoch 461/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0603\n",
      "Epoch 462/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0922\n",
      "Epoch 463/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.1185\n",
      "Epoch 464/1000\n",
      "1564/1564 [==============================] - 0s 40us/step - loss: 0.0579\n",
      "Epoch 465/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0696\n",
      "Epoch 466/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0592\n",
      "Epoch 467/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0928\n",
      "Epoch 468/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0624\n",
      "Epoch 469/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0857\n",
      "Epoch 470/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0734\n",
      "Epoch 471/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0603\n",
      "Epoch 472/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1196\n",
      "Epoch 473/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1013\n",
      "Epoch 474/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0543\n",
      "Epoch 475/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0664\n",
      "Epoch 476/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0580\n",
      "Epoch 477/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0671\n",
      "Epoch 478/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0648\n",
      "Epoch 479/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0720\n",
      "Epoch 480/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1352\n",
      "Epoch 481/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0661\n",
      "Epoch 482/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0665\n",
      "Epoch 483/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0989\n",
      "Epoch 484/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0545\n",
      "Epoch 485/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0550\n",
      "Epoch 486/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1209\n",
      "Epoch 487/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1009\n",
      "Epoch 488/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1773\n",
      "Epoch 489/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1558\n",
      "Epoch 490/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0698\n",
      "Epoch 491/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0612\n",
      "Epoch 492/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0612\n",
      "Epoch 493/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0699\n",
      "Epoch 494/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0550\n",
      "Epoch 495/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0562\n",
      "Epoch 496/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0627\n",
      "Epoch 497/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0626\n",
      "Epoch 498/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0678\n",
      "Epoch 499/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0761\n",
      "Epoch 500/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0498\n",
      "Epoch 501/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0642\n",
      "Epoch 502/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0935\n",
      "Epoch 503/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0575\n",
      "Epoch 504/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0657\n",
      "Epoch 505/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0567\n",
      "Epoch 506/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0885\n",
      "Epoch 507/1000\n",
      "1564/1564 [==============================] - 0s 36us/step - loss: 0.0802\n",
      "Epoch 508/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0515\n",
      "Epoch 509/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1045\n",
      "Epoch 510/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0952\n",
      "Epoch 511/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0515\n",
      "Epoch 512/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0521\n",
      "Epoch 513/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0863\n",
      "Epoch 514/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1100\n",
      "Epoch 515/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0724\n",
      "Epoch 516/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0554\n",
      "Epoch 517/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0666\n",
      "Epoch 518/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0543\n",
      "Epoch 519/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0582\n",
      "Epoch 520/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0736\n",
      "Epoch 521/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0550\n",
      "Epoch 522/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0612\n",
      "Epoch 523/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0817\n",
      "Epoch 524/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0643\n",
      "Epoch 525/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0658\n",
      "Epoch 526/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0631\n",
      "Epoch 527/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0629\n",
      "Epoch 528/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0823\n",
      "Epoch 529/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0747\n",
      "Epoch 530/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0571\n",
      "Epoch 531/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1032\n",
      "Epoch 532/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1137\n",
      "Epoch 533/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0641\n",
      "Epoch 534/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0542\n",
      "Epoch 535/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1234\n",
      "Epoch 536/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0919\n",
      "Epoch 537/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0671\n",
      "Epoch 538/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0611\n",
      "Epoch 539/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1140\n",
      "Epoch 540/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0673\n",
      "Epoch 541/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0781\n",
      "Epoch 542/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0683\n",
      "Epoch 543/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0596\n",
      "Epoch 544/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0570\n",
      "Epoch 545/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1282\n",
      "Epoch 546/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0750\n",
      "Epoch 547/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0868\n",
      "Epoch 548/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0806\n",
      "Epoch 549/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0896\n",
      "Epoch 550/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1157\n",
      "Epoch 551/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1232\n",
      "Epoch 552/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0846\n",
      "Epoch 553/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0584\n",
      "Epoch 554/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0752\n",
      "Epoch 555/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0878\n",
      "Epoch 556/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0535\n",
      "Epoch 557/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0535\n",
      "Epoch 558/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0624\n",
      "Epoch 559/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1392\n",
      "Epoch 560/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1233\n",
      "Epoch 561/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1030\n",
      "Epoch 562/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0811\n",
      "Epoch 563/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0696\n",
      "Epoch 564/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0833\n",
      "Epoch 565/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0716\n",
      "Epoch 566/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1746\n",
      "Epoch 567/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1047\n",
      "Epoch 568/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0644\n",
      "Epoch 569/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0652\n",
      "Epoch 570/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0702\n",
      "Epoch 571/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0885\n",
      "Epoch 572/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0908\n",
      "Epoch 573/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0825\n",
      "Epoch 574/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.1371\n",
      "Epoch 575/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0658\n",
      "Epoch 576/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0777\n",
      "Epoch 577/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0666\n",
      "Epoch 578/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0967\n",
      "Epoch 579/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0766\n",
      "Epoch 580/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0604\n",
      "Epoch 581/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0628\n",
      "Epoch 582/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0661\n",
      "Epoch 583/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0508\n",
      "Epoch 584/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0511\n",
      "Epoch 585/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0550\n",
      "Epoch 586/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0665\n",
      "Epoch 587/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1070\n",
      "Epoch 588/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0983\n",
      "Epoch 589/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0778\n",
      "Epoch 590/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0544\n",
      "Epoch 591/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0539\n",
      "Epoch 592/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0615\n",
      "Epoch 593/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0555\n",
      "Epoch 594/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0753\n",
      "Epoch 595/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0659\n",
      "Epoch 596/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0852\n",
      "Epoch 597/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0805\n",
      "Epoch 598/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1730\n",
      "Epoch 599/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1313\n",
      "Epoch 600/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0898\n",
      "Epoch 601/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0559\n",
      "Epoch 602/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0764\n",
      "Epoch 603/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0779\n",
      "Epoch 604/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0798\n",
      "Epoch 605/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0927\n",
      "Epoch 606/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0842\n",
      "Epoch 607/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0569\n",
      "Epoch 608/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.0497\n",
      "Epoch 609/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0701\n",
      "Epoch 610/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0502\n",
      "Epoch 611/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0494\n",
      "Epoch 612/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0542\n",
      "Epoch 613/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0564\n",
      "Epoch 614/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0552\n",
      "Epoch 615/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0597\n",
      "Epoch 616/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0548\n",
      "Epoch 617/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0521\n",
      "Epoch 618/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0567\n",
      "Epoch 619/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0558\n",
      "Epoch 620/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0614\n",
      "Epoch 621/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0542\n",
      "Epoch 622/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0575\n",
      "Epoch 623/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0930\n",
      "Epoch 624/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0697\n",
      "Epoch 625/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0608\n",
      "Epoch 626/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0954\n",
      "Epoch 627/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0775\n",
      "Epoch 628/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0972\n",
      "Epoch 629/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0861\n",
      "Epoch 630/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0635\n",
      "Epoch 631/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1071\n",
      "Epoch 632/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0790\n",
      "Epoch 633/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0684\n",
      "Epoch 634/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0816\n",
      "Epoch 635/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0810\n",
      "Epoch 636/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0851\n",
      "Epoch 637/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0859\n",
      "Epoch 638/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0690\n",
      "Epoch 639/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0627\n",
      "Epoch 640/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0883\n",
      "Epoch 641/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0716\n",
      "Epoch 642/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0989\n",
      "Epoch 643/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0659\n",
      "Epoch 644/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0586\n",
      "Epoch 645/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0528\n",
      "Epoch 646/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0536\n",
      "Epoch 647/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0622\n",
      "Epoch 648/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0627\n",
      "Epoch 649/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0742\n",
      "Epoch 650/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0832\n",
      "Epoch 651/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1035\n",
      "Epoch 652/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0813\n",
      "Epoch 653/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0825\n",
      "Epoch 654/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0674\n",
      "Epoch 655/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0658\n",
      "Epoch 656/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0525\n",
      "Epoch 657/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0724\n",
      "Epoch 658/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1010\n",
      "Epoch 659/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0508\n",
      "Epoch 660/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0607\n",
      "Epoch 661/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0565\n",
      "Epoch 662/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0537\n",
      "Epoch 663/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0687\n",
      "Epoch 664/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0711\n",
      "Epoch 665/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0733\n",
      "Epoch 666/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0516\n",
      "Epoch 667/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0554\n",
      "Epoch 668/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0767\n",
      "Epoch 669/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0700\n",
      "Epoch 670/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0611\n",
      "Epoch 671/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0645\n",
      "Epoch 672/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0538\n",
      "Epoch 673/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0586\n",
      "Epoch 674/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0585\n",
      "Epoch 675/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0719\n",
      "Epoch 676/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0948\n",
      "Epoch 677/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0829\n",
      "Epoch 678/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0706\n",
      "Epoch 679/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0708\n",
      "Epoch 680/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0834\n",
      "Epoch 681/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0876\n",
      "Epoch 682/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1136\n",
      "Epoch 683/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0839\n",
      "Epoch 684/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1424\n",
      "Epoch 685/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0867\n",
      "Epoch 686/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0590\n",
      "Epoch 687/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0726\n",
      "Epoch 688/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0816\n",
      "Epoch 689/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0626\n",
      "Epoch 690/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0717\n",
      "Epoch 691/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0526\n",
      "Epoch 692/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0569\n",
      "Epoch 693/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0729\n",
      "Epoch 694/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0587\n",
      "Epoch 695/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0718\n",
      "Epoch 696/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.0627\n",
      "Epoch 697/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0620\n",
      "Epoch 698/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0768\n",
      "Epoch 699/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0650\n",
      "Epoch 700/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.0551\n",
      "Epoch 701/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0790\n",
      "Epoch 702/1000\n",
      "1564/1564 [==============================] - 0s 38us/step - loss: 0.0509\n",
      "Epoch 703/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0509\n",
      "Epoch 704/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.0787\n",
      "Epoch 705/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0718\n",
      "Epoch 706/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0658\n",
      "Epoch 707/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0784\n",
      "Epoch 708/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0530\n",
      "Epoch 709/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1059\n",
      "Epoch 710/1000\n",
      "1564/1564 [==============================] - 0s 37us/step - loss: 0.0882\n",
      "Epoch 711/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0572\n",
      "Epoch 712/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0630\n",
      "Epoch 713/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0587\n",
      "Epoch 714/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0536\n",
      "Epoch 715/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0765\n",
      "Epoch 716/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0793\n",
      "Epoch 717/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0525\n",
      "Epoch 718/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.0499\n",
      "Epoch 719/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0651\n",
      "Epoch 720/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1074\n",
      "Epoch 721/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0883\n",
      "Epoch 722/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.1205\n",
      "Epoch 723/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0568\n",
      "Epoch 724/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0616\n",
      "Epoch 725/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0524\n",
      "Epoch 726/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.0532\n",
      "Epoch 727/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.0561\n",
      "Epoch 728/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0689\n",
      "Epoch 729/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0553\n",
      "Epoch 730/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0607\n",
      "Epoch 731/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.0629\n",
      "Epoch 732/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0909\n",
      "Epoch 733/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0600\n",
      "Epoch 734/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0756\n",
      "Epoch 735/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.1089\n",
      "Epoch 736/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1735\n",
      "Epoch 737/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0583\n",
      "Epoch 738/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0597\n",
      "Epoch 739/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.0784\n",
      "Epoch 740/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0847\n",
      "Epoch 741/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0561\n",
      "Epoch 742/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0921\n",
      "Epoch 743/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0551\n",
      "Epoch 744/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0695\n",
      "Epoch 745/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0771\n",
      "Epoch 746/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0941\n",
      "Epoch 747/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0590\n",
      "Epoch 748/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0604\n",
      "Epoch 749/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0583\n",
      "Epoch 750/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0907\n",
      "Epoch 751/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0692\n",
      "Epoch 752/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0603\n",
      "Epoch 753/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0826\n",
      "Epoch 754/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.1329\n",
      "Epoch 755/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0610\n",
      "Epoch 756/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.0557\n",
      "Epoch 757/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0838\n",
      "Epoch 758/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0733\n",
      "Epoch 759/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0683\n",
      "Epoch 760/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0667\n",
      "Epoch 761/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0687\n",
      "Epoch 762/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0518\n",
      "Epoch 763/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0539\n",
      "Epoch 764/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0547\n",
      "Epoch 765/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0672\n",
      "Epoch 766/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0818\n",
      "Epoch 767/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0674\n",
      "Epoch 768/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0512\n",
      "Epoch 769/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0680\n",
      "Epoch 770/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0567\n",
      "Epoch 771/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0658\n",
      "Epoch 772/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0567\n",
      "Epoch 773/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0822\n",
      "Epoch 774/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0545\n",
      "Epoch 775/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0563\n",
      "Epoch 776/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0817\n",
      "Epoch 777/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0620\n",
      "Epoch 778/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0709\n",
      "Epoch 779/1000\n",
      "1564/1564 [==============================] - 0s 45us/step - loss: 0.0662\n",
      "Epoch 780/1000\n",
      "1564/1564 [==============================] - 0s 39us/step - loss: 0.0659\n",
      "Epoch 781/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0661\n",
      "Epoch 782/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0858\n",
      "Epoch 783/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0843\n",
      "Epoch 784/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0603\n",
      "Epoch 785/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0580\n",
      "Epoch 786/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0536\n",
      "Epoch 787/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0569\n",
      "Epoch 788/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0510\n",
      "Epoch 789/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0607\n",
      "Epoch 790/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0971\n",
      "Epoch 791/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0589\n",
      "Epoch 792/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0639\n",
      "Epoch 793/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0584\n",
      "Epoch 794/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.1024\n",
      "Epoch 795/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0759\n",
      "Epoch 796/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1216\n",
      "Epoch 797/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1370\n",
      "Epoch 798/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0702\n",
      "Epoch 799/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0932\n",
      "Epoch 800/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0777\n",
      "Epoch 801/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0650\n",
      "Epoch 802/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0888\n",
      "Epoch 803/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0625\n",
      "Epoch 804/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0744\n",
      "Epoch 805/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0814\n",
      "Epoch 806/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0561\n",
      "Epoch 807/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0779\n",
      "Epoch 808/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0925\n",
      "Epoch 809/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.2547\n",
      "Epoch 810/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.1170\n",
      "Epoch 811/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0738\n",
      "Epoch 812/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0641\n",
      "Epoch 813/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0589\n",
      "Epoch 814/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0950\n",
      "Epoch 815/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0526\n",
      "Epoch 816/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0533\n",
      "Epoch 817/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0580\n",
      "Epoch 818/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0602\n",
      "Epoch 819/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0616\n",
      "Epoch 820/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0711\n",
      "Epoch 821/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0807\n",
      "Epoch 822/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0728\n",
      "Epoch 823/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0551\n",
      "Epoch 824/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0631\n",
      "Epoch 825/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0635\n",
      "Epoch 826/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0859\n",
      "Epoch 827/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1690\n",
      "Epoch 828/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0983\n",
      "Epoch 829/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.1266\n",
      "Epoch 830/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0723\n",
      "Epoch 831/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0538\n",
      "Epoch 832/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0761\n",
      "Epoch 833/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0648\n",
      "Epoch 834/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0800\n",
      "Epoch 835/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0582\n",
      "Epoch 836/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0691\n",
      "Epoch 837/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0532\n",
      "Epoch 838/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0495\n",
      "Epoch 839/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0539\n",
      "Epoch 840/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0595\n",
      "Epoch 841/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0497\n",
      "Epoch 842/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0676\n",
      "Epoch 843/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0888\n",
      "Epoch 844/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0577\n",
      "Epoch 845/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0695\n",
      "Epoch 846/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0847\n",
      "Epoch 847/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0531\n",
      "Epoch 848/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0544\n",
      "Epoch 849/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.0672\n",
      "Epoch 850/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0721\n",
      "Epoch 851/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.1114\n",
      "Epoch 852/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.2433\n",
      "Epoch 853/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1838\n",
      "Epoch 854/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0939\n",
      "Epoch 855/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0704\n",
      "Epoch 856/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0601\n",
      "Epoch 857/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0604\n",
      "Epoch 858/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0667\n",
      "Epoch 859/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0659\n",
      "Epoch 860/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.0822\n",
      "Epoch 861/1000\n",
      "1564/1564 [==============================] - 0s 24us/step - loss: 0.0780\n",
      "Epoch 862/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0608\n",
      "Epoch 863/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0711\n",
      "Epoch 864/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0532\n",
      "Epoch 865/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.0809\n",
      "Epoch 866/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0562\n",
      "Epoch 867/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0592\n",
      "Epoch 868/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0512\n",
      "Epoch 869/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0520\n",
      "Epoch 870/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0504\n",
      "Epoch 871/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0498\n",
      "Epoch 872/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0538\n",
      "Epoch 873/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0733\n",
      "Epoch 874/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.0506\n",
      "Epoch 875/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.0509\n",
      "Epoch 876/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0538\n",
      "Epoch 877/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0695\n",
      "Epoch 878/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0583\n",
      "Epoch 879/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.0502\n",
      "Epoch 880/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.0574\n",
      "Epoch 881/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0670\n",
      "Epoch 882/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0588\n",
      "Epoch 883/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0828\n",
      "Epoch 884/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0691\n",
      "Epoch 885/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.1200\n",
      "Epoch 886/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0882\n",
      "Epoch 887/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0675\n",
      "Epoch 888/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0562\n",
      "Epoch 889/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0551\n",
      "Epoch 890/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0543\n",
      "Epoch 891/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0518\n",
      "Epoch 892/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0539\n",
      "Epoch 893/1000\n",
      "1564/1564 [==============================] - 0s 35us/step - loss: 0.0586\n",
      "Epoch 894/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0568\n",
      "Epoch 895/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0660\n",
      "Epoch 896/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0494\n",
      "Epoch 897/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0497\n",
      "Epoch 898/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0540\n",
      "Epoch 899/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0653\n",
      "Epoch 900/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0544\n",
      "Epoch 901/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0781\n",
      "Epoch 902/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0544\n",
      "Epoch 903/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0521\n",
      "Epoch 904/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0540\n",
      "Epoch 905/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0805\n",
      "Epoch 906/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0543\n",
      "Epoch 907/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0610\n",
      "Epoch 908/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0687\n",
      "Epoch 909/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0714\n",
      "Epoch 910/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0954\n",
      "Epoch 911/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0685\n",
      "Epoch 912/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0561\n",
      "Epoch 913/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.0527\n",
      "Epoch 914/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0544\n",
      "Epoch 915/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0550\n",
      "Epoch 916/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0661\n",
      "Epoch 917/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0583\n",
      "Epoch 918/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0567\n",
      "Epoch 919/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0544\n",
      "Epoch 920/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0858\n",
      "Epoch 921/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0596\n",
      "Epoch 922/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0685\n",
      "Epoch 923/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0604\n",
      "Epoch 924/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0733\n",
      "Epoch 925/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0878\n",
      "Epoch 926/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1346\n",
      "Epoch 927/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.1040\n",
      "Epoch 928/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.1103\n",
      "Epoch 929/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0630\n",
      "Epoch 930/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0799\n",
      "Epoch 931/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0619\n",
      "Epoch 932/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0683\n",
      "Epoch 933/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0591\n",
      "Epoch 934/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0531\n",
      "Epoch 935/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0535\n",
      "Epoch 936/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0517\n",
      "Epoch 937/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0786\n",
      "Epoch 938/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0894\n",
      "Epoch 939/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0541\n",
      "Epoch 940/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0588\n",
      "Epoch 941/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0593\n",
      "Epoch 942/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.0845\n",
      "Epoch 943/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0797\n",
      "Epoch 944/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.1152\n",
      "Epoch 945/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0587\n",
      "Epoch 946/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0587\n",
      "Epoch 947/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0654\n",
      "Epoch 948/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0744\n",
      "Epoch 949/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0520\n",
      "Epoch 950/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0507\n",
      "Epoch 951/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0521\n",
      "Epoch 952/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0563\n",
      "Epoch 953/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0613\n",
      "Epoch 954/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0520\n",
      "Epoch 955/1000\n",
      "1564/1564 [==============================] - 0s 34us/step - loss: 0.0758\n",
      "Epoch 956/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0820\n",
      "Epoch 957/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0563\n",
      "Epoch 958/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0682\n",
      "Epoch 959/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1027\n",
      "Epoch 960/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0699\n",
      "Epoch 961/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0652\n",
      "Epoch 962/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.0548\n",
      "Epoch 963/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.0605\n",
      "Epoch 964/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0559\n",
      "Epoch 965/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0715\n",
      "Epoch 966/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0661\n",
      "Epoch 967/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.0745\n",
      "Epoch 968/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.0682\n",
      "Epoch 969/1000\n",
      "1564/1564 [==============================] - 0s 23us/step - loss: 0.0658\n",
      "Epoch 970/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.1060\n",
      "Epoch 971/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.1456\n",
      "Epoch 972/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0678\n",
      "Epoch 973/1000\n",
      "1564/1564 [==============================] - 0s 22us/step - loss: 0.0627\n",
      "Epoch 974/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.0601\n",
      "Epoch 975/1000\n",
      "1564/1564 [==============================] - 0s 20us/step - loss: 0.0560\n",
      "Epoch 976/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0768\n",
      "Epoch 977/1000\n",
      "1564/1564 [==============================] - 0s 32us/step - loss: 0.0976\n",
      "Epoch 978/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0657\n",
      "Epoch 979/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0549\n",
      "Epoch 980/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.0533\n",
      "Epoch 981/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0771\n",
      "Epoch 982/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.1305\n",
      "Epoch 983/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0823\n",
      "Epoch 984/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0733\n",
      "Epoch 985/1000\n",
      "1564/1564 [==============================] - 0s 21us/step - loss: 0.0710\n",
      "Epoch 986/1000\n",
      "1564/1564 [==============================] - 0s 25us/step - loss: 0.0569\n",
      "Epoch 987/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0746\n",
      "Epoch 988/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0551\n",
      "Epoch 989/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0576\n",
      "Epoch 990/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0503\n",
      "Epoch 991/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0786\n",
      "Epoch 992/1000\n",
      "1564/1564 [==============================] - 0s 31us/step - loss: 0.0622\n",
      "Epoch 993/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0638\n",
      "Epoch 994/1000\n",
      "1564/1564 [==============================] - 0s 27us/step - loss: 0.0739\n",
      "Epoch 995/1000\n",
      "1564/1564 [==============================] - 0s 28us/step - loss: 0.0583\n",
      "Epoch 996/1000\n",
      "1564/1564 [==============================] - 0s 29us/step - loss: 0.0597\n",
      "Epoch 997/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0592\n",
      "Epoch 998/1000\n",
      "1564/1564 [==============================] - 0s 30us/step - loss: 0.0711\n",
      "Epoch 999/1000\n",
      "1564/1564 [==============================] - 0s 26us/step - loss: 0.0706\n",
      "Epoch 1000/1000\n",
      "1564/1564 [==============================] - 0s 33us/step - loss: 0.0961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a40f727f0>"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_blk = Sequential()\n",
    "NN_blk.add(Dense(units=16,input_dim=X_train.shape[1],activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_blk.add(Dense(units=8, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_blk.add(Dense(units=8, activation='relu'))\n",
    "#NN_model.add(Dropout(rate=0.5))\n",
    "NN_blk.add(Dense(units=1,activation='linear'))\n",
    "NN_blk.compile(loss='mse', optimizer='adam')\n",
    "NN_blk.fit(np.array(X_train), np.array(y_train), epochs=1000,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NN_predictions</th>\n",
       "      <th>actual</th>\n",
       "      <th>GBR_predictions</th>\n",
       "      <th>LY_blocks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>1.473373</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.239849</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>1.381236</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.099172</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>1.429256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.263199</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>1.277068</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.039512</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>1.370475</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.934486</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>1.517829</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.099204</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>1.576911</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.047491</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1.441978</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.108170</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>1.303337</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.072781</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>1.313171</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.076979</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>1.306636</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.047811</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>1.454131</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.020849</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>1.590835</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.033429</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589</th>\n",
       "      <td>1.289983</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.005632</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>1.173965</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.764655</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>1.301933</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.147720</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1.309821</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.168110</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>1.412578</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.055888</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>1.081386</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.787405</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>1.223709</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.903822</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>1.255679</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.946308</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>1.209472</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.843197</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1.121452</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.861293</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>1.122486</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.912533</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>1.358146</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.863069</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1.294357</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.894418</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>1.285297</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.895857</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>1.091941</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.765722</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>670</th>\n",
       "      <td>1.184112</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.890717</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>1.302375</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.918773</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>1.285007</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.885227</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>1.292121</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.973685</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>1.159633</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.726984</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>1.296375</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.007974</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>1.342639</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.101441</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>1.476024</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.373288</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>1.316070</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.824708</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.300844</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.932993</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>1.124877</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.857383</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1.214971</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.995750</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1.210103</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.887288</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1.322494</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.280077</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>1.210063</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.094978</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>1.196437</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.915239</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>1.061649</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.726224</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>1.249229</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.954650</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1.278621</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.976569</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>1.206642</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.848726</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>1.031295</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.696722</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>1.189659</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.966558</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     NN_predictions  actual  GBR_predictions  LY_blocks\n",
       "128        1.473373     1.3         1.239849        1.3\n",
       "327        1.381236     0.8         1.099172        1.3\n",
       "244        1.429256     0.2         1.263199        1.3\n",
       "460        1.277068     1.1         1.039512        1.3\n",
       "656        1.370475     0.7         0.934486        1.3\n",
       "419        1.517829     1.5         1.099204        1.2\n",
       "630        1.576911     1.1         1.047491        1.2\n",
       "72         1.441978     1.2         1.108170        1.2\n",
       "423        1.303337     1.6         1.072781        1.2\n",
       "489        1.313171     0.7         1.076979        1.2\n",
       "258        1.306636     0.9         1.047811        1.2\n",
       "620        1.454131     1.1         1.020849        1.2\n",
       "234        1.590835     1.0         1.033429        1.2\n",
       "589        1.289983     1.1         1.005632        1.2\n",
       "182        1.173965     0.5         0.764655        1.2\n",
       "120        1.301933     1.2         1.147720        1.2\n",
       "52         1.309821     1.5         1.168110        1.2\n",
       "646        1.412578     0.9         1.055888        1.2\n",
       "223        1.081386     0.8         0.787405        1.1\n",
       "455        1.223709     0.8         0.903822        1.1\n",
       "159        1.255679     1.2         0.946308        1.1\n",
       "240        1.209472     1.4         0.843197        1.1\n",
       "95         1.121452     0.8         0.861293        1.1\n",
       "337        1.122486     1.4         0.912533        1.1\n",
       "259        1.358146     1.1         0.863069        1.1\n",
       "148        1.294357     1.2         0.894418        1.1\n",
       "296        1.285297     1.2         0.895857        1.1\n",
       "139        1.091941     0.7         0.765722        1.1\n",
       "670        1.184112     1.0         0.890717        1.1\n",
       "431        1.302375     0.9         0.918773        1.1\n",
       "650        1.285007     1.1         0.885227        1.1\n",
       "541        1.292121     1.1         0.973685        1.1\n",
       "67         1.159633     1.2         0.726984        1.1\n",
       "657        1.296375     0.5         1.007974        1.1\n",
       "66         1.342639     1.3         1.101441        1.1\n",
       "631        1.476024     1.5         1.373288        1.1\n",
       "168        1.316070     0.9         0.824708        1.0\n",
       "12         1.300844     1.7         0.932993        1.0\n",
       "649        1.124877     0.4         0.857383        1.0\n",
       "65         1.214971     0.6         0.995750        1.0\n",
       "56         1.210103     0.8         0.887288        1.0\n",
       "57         1.322494     0.9         1.280077        1.0\n",
       "523        1.210063     1.0         1.094978        1.0\n",
       "63         1.196437     0.9         0.915239        1.0\n",
       "421        1.061649     1.1         0.726224        1.0\n",
       "131        1.249229     0.8         0.954650        1.0\n",
       "178        1.278621     0.6         0.976569        1.0\n",
       "456        1.206642     1.9         0.848726        1.0\n",
       "452        1.031295     0.5         0.696722        1.0\n",
       "488        1.189659     0.8         0.966558        1.0"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = NN_blk.predict(X_test)\n",
    "gbr = GradientBoostingRegressor(learning_rate=0.01,n_estimators=1000,max_depth = None,max_features=0.3)\n",
    "gbr.fit(X_train,y_train)\n",
    "gbr_predictions = gbr.predict(X_test)\n",
    "LR = LinearRegression(fit_intercept=True).fit(X_train,y_train)\n",
    "\n",
    "testing = pd.DataFrame(predictions)\n",
    "testing.columns=['NN_predictions']\n",
    "testing['actual'] = y_test.reset_index()['blocks']\n",
    "testing['GBR_predictions']=gbr_predictions\n",
    "testing['LY_blocks']=X_test['blocks_ly'].reset_index()['blocks_ly']\n",
    "testing.sort_values(by='LY_blocks',ascending=False)[50:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>blocks</th>\n",
       "      <th>predictions</th>\n",
       "      <th>LR_pred</th>\n",
       "      <th>gbr_pred</th>\n",
       "      <th>mean_pred</th>\n",
       "      <th>blocks_ly_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>Rudy Gobert</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.384002</td>\n",
       "      <td>2.164193</td>\n",
       "      <td>2.136520</td>\n",
       "      <td>2.228238</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Joel Embiid</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.456306</td>\n",
       "      <td>2.210025</td>\n",
       "      <td>2.248079</td>\n",
       "      <td>2.304804</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Anthony Davis</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.267372</td>\n",
       "      <td>1.982206</td>\n",
       "      <td>2.241989</td>\n",
       "      <td>2.163855</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>Myles Turner</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.080682</td>\n",
       "      <td>1.831949</td>\n",
       "      <td>1.746683</td>\n",
       "      <td>1.886438</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>Hassan Whiteside</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.161163</td>\n",
       "      <td>2.014637</td>\n",
       "      <td>1.580400</td>\n",
       "      <td>1.918734</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>Kristaps Porzingis</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.990268</td>\n",
       "      <td>1.763285</td>\n",
       "      <td>1.493095</td>\n",
       "      <td>1.748883</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Giannis Antetokounmpo</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.774188</td>\n",
       "      <td>1.581997</td>\n",
       "      <td>1.547266</td>\n",
       "      <td>1.634484</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Brook Lopez</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.705501</td>\n",
       "      <td>1.432882</td>\n",
       "      <td>1.523154</td>\n",
       "      <td>1.553846</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>DeAndre Jordan</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.798225</td>\n",
       "      <td>1.542816</td>\n",
       "      <td>1.329975</td>\n",
       "      <td>1.557005</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>Kevin Durant</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.505576</td>\n",
       "      <td>1.253495</td>\n",
       "      <td>1.357542</td>\n",
       "      <td>1.372205</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>Lucas Nogueira</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.457607</td>\n",
       "      <td>1.189799</td>\n",
       "      <td>1.264563</td>\n",
       "      <td>1.303990</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>Serge Ibaka</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.855575</td>\n",
       "      <td>1.497177</td>\n",
       "      <td>1.377140</td>\n",
       "      <td>1.576631</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Josh Huestis</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.400813</td>\n",
       "      <td>1.090500</td>\n",
       "      <td>1.604936</td>\n",
       "      <td>1.365416</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>Robin Lopez</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.455016</td>\n",
       "      <td>1.203451</td>\n",
       "      <td>1.170197</td>\n",
       "      <td>1.276222</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Draymond Green</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.399448</td>\n",
       "      <td>1.154126</td>\n",
       "      <td>1.249224</td>\n",
       "      <td>1.267599</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Alex Len</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.352729</td>\n",
       "      <td>1.096672</td>\n",
       "      <td>0.910571</td>\n",
       "      <td>1.119991</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Al Horford</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.401641</td>\n",
       "      <td>1.106244</td>\n",
       "      <td>1.180704</td>\n",
       "      <td>1.229530</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Marc Gasol</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.550964</td>\n",
       "      <td>1.159482</td>\n",
       "      <td>1.242107</td>\n",
       "      <td>1.317518</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>DeMarcus Cousins</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.411933</td>\n",
       "      <td>1.155303</td>\n",
       "      <td>1.315720</td>\n",
       "      <td>1.294319</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Karl-Anthony Towns</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.552413</td>\n",
       "      <td>1.320454</td>\n",
       "      <td>1.591931</td>\n",
       "      <td>1.488266</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>John Henson</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.706142</td>\n",
       "      <td>1.392152</td>\n",
       "      <td>1.135536</td>\n",
       "      <td>1.411277</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>Kyle O'Quinn</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.424110</td>\n",
       "      <td>1.111495</td>\n",
       "      <td>0.969843</td>\n",
       "      <td>1.168482</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Gorgui Dieng</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.252010</td>\n",
       "      <td>0.940336</td>\n",
       "      <td>0.970313</td>\n",
       "      <td>1.054220</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>LaMarcus Aldridge</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.348689</td>\n",
       "      <td>1.017953</td>\n",
       "      <td>0.906764</td>\n",
       "      <td>1.091136</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Dwight Howard</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.672290</td>\n",
       "      <td>1.230159</td>\n",
       "      <td>1.188240</td>\n",
       "      <td>1.363563</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>Mason Plumlee</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.184966</td>\n",
       "      <td>0.908262</td>\n",
       "      <td>0.928502</td>\n",
       "      <td>1.007244</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Clint Capela</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.427225</td>\n",
       "      <td>1.182235</td>\n",
       "      <td>1.090683</td>\n",
       "      <td>1.233381</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Bismack Biyombo</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.448844</td>\n",
       "      <td>1.166671</td>\n",
       "      <td>1.009192</td>\n",
       "      <td>1.208236</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>Tristan Thompson</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.041088</td>\n",
       "      <td>0.774354</td>\n",
       "      <td>0.733342</td>\n",
       "      <td>0.849594</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>Pau Gasol</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.516738</td>\n",
       "      <td>1.104900</td>\n",
       "      <td>1.143019</td>\n",
       "      <td>1.254886</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Andre Drummond</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.457515</td>\n",
       "      <td>1.156170</td>\n",
       "      <td>1.306836</td>\n",
       "      <td>1.306840</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>James Johnson</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.264236</td>\n",
       "      <td>0.914446</td>\n",
       "      <td>0.974736</td>\n",
       "      <td>1.051139</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>Robert Covington</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.984069</td>\n",
       "      <td>0.725279</td>\n",
       "      <td>0.667797</td>\n",
       "      <td>0.792382</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>Michael Kidd-Gilchrist</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.068797</td>\n",
       "      <td>0.803211</td>\n",
       "      <td>0.796375</td>\n",
       "      <td>0.889461</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Jerami Grant</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.260034</td>\n",
       "      <td>1.026879</td>\n",
       "      <td>0.904691</td>\n",
       "      <td>1.063868</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>Nikola Vucevic</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.163368</td>\n",
       "      <td>0.905469</td>\n",
       "      <td>0.772081</td>\n",
       "      <td>0.946973</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>Richaun Holmes</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.228179</td>\n",
       "      <td>0.948455</td>\n",
       "      <td>0.967315</td>\n",
       "      <td>1.047983</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>Steven Adams</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.209762</td>\n",
       "      <td>0.959476</td>\n",
       "      <td>0.903788</td>\n",
       "      <td>1.024342</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Andre Roberson</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.008228</td>\n",
       "      <td>0.750740</td>\n",
       "      <td>0.698442</td>\n",
       "      <td>0.819137</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Ivica Zubac</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.246690</td>\n",
       "      <td>1.007213</td>\n",
       "      <td>1.255936</td>\n",
       "      <td>1.169946</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>Maurice Harkless</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.964902</td>\n",
       "      <td>0.716878</td>\n",
       "      <td>0.541945</td>\n",
       "      <td>0.741242</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>JaVale McGee</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.507739</td>\n",
       "      <td>1.035292</td>\n",
       "      <td>1.144971</td>\n",
       "      <td>1.229334</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>Taj Gibson</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.236957</td>\n",
       "      <td>0.858840</td>\n",
       "      <td>0.704278</td>\n",
       "      <td>0.933358</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>Paul Millsap</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.196342</td>\n",
       "      <td>0.891517</td>\n",
       "      <td>0.771770</td>\n",
       "      <td>0.953209</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>Marquese Chriss</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.159133</td>\n",
       "      <td>0.929302</td>\n",
       "      <td>0.996345</td>\n",
       "      <td>1.028260</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Cody Zeller</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.970584</td>\n",
       "      <td>0.714003</td>\n",
       "      <td>0.755002</td>\n",
       "      <td>0.813196</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>Rudy Gay</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.922515</td>\n",
       "      <td>0.612272</td>\n",
       "      <td>0.445264</td>\n",
       "      <td>0.660017</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Amir Johnson</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.995994</td>\n",
       "      <td>0.664225</td>\n",
       "      <td>0.808553</td>\n",
       "      <td>0.822924</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>Salah Mejri</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.321723</td>\n",
       "      <td>0.904937</td>\n",
       "      <td>0.912406</td>\n",
       "      <td>1.046355</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>Nikola Mirotic</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.988498</td>\n",
       "      <td>0.698003</td>\n",
       "      <td>0.733778</td>\n",
       "      <td>0.806760</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     player  blocks  predictions   LR_pred  gbr_pred  \\\n",
       "323             Rudy Gobert     2.3     2.384002  2.164193  2.136520   \n",
       "186             Joel Embiid     1.8     2.456306  2.210025  2.248079   \n",
       "21            Anthony Davis     2.6     2.267372  1.982206  2.241989   \n",
       "275            Myles Turner     1.8     2.080682  1.831949  1.746683   \n",
       "134        Hassan Whiteside     1.7     2.161163  2.014637  1.580400   \n",
       "226      Kristaps Porzingis     2.4     1.990268  1.763285  1.493095   \n",
       "127   Giannis Antetokounmpo     1.4     1.774188  1.581997  1.547266   \n",
       "40              Brook Lopez     1.3     1.705501  1.432882  1.523154   \n",
       "78           DeAndre Jordan     0.9     1.798225  1.542816  1.329975   \n",
       "219            Kevin Durant     1.8     1.505576  1.253495  1.357542   \n",
       "241          Lucas Nogueira     0.9     1.457607  1.189799  1.264563   \n",
       "329             Serge Ibaka     1.3     1.855575  1.497177  1.377140   \n",
       "200            Josh Huestis     0.6     1.400813  1.090500  1.604936   \n",
       "318             Robin Lopez     0.8     1.455016  1.203451  1.170197   \n",
       "104          Draymond Green     1.3     1.399448  1.154126  1.249224   \n",
       "10                 Alex Len     0.9     1.352729  1.096672  0.910571   \n",
       "4                Al Horford     1.1     1.401641  1.106244  1.180704   \n",
       "249              Marc Gasol     1.4     1.550964  1.159482  1.242107   \n",
       "82         DeMarcus Cousins     1.6     1.411933  1.155303  1.315720   \n",
       "210      Karl-Anthony Towns     1.4     1.552413  1.320454  1.591931   \n",
       "188             John Henson     1.4     1.706142  1.392152  1.135536   \n",
       "230            Kyle O'Quinn     1.3     1.424110  1.111495  0.969843   \n",
       "131            Gorgui Dieng     0.5     1.252010  0.940336  0.970313   \n",
       "233       LaMarcus Aldridge     1.2     1.348689  1.017953  0.906764   \n",
       "105           Dwight Howard     1.6     1.672290  1.230159  1.188240   \n",
       "261           Mason Plumlee     1.1     1.184966  0.908262  0.928502   \n",
       "55             Clint Capela     1.9     1.427225  1.182235  1.090683   \n",
       "28          Bismack Biyombo     1.2     1.448844  1.166671  1.009192   \n",
       "365        Tristan Thompson     0.3     1.041088  0.774354  0.733342   \n",
       "300               Pau Gasol     1.0     1.516738  1.104900  1.143019   \n",
       "14           Andre Drummond     1.6     1.457515  1.156170  1.306836   \n",
       "160           James Johnson     0.7     1.264236  0.914446  0.974736   \n",
       "317        Robert Covington     0.9     0.984069  0.725279  0.667797   \n",
       "267  Michael Kidd-Gilchrist     0.4     1.068797  0.803211  0.796375   \n",
       "173            Jerami Grant     1.0     1.260034  1.026879  0.904691   \n",
       "286          Nikola Vucevic     1.1     1.163368  0.905469  0.772081   \n",
       "315          Richaun Holmes     0.6     1.228179  0.948455  0.967315   \n",
       "339            Steven Adams     1.0     1.209762  0.959476  0.903788   \n",
       "16           Andre Roberson     0.9     1.008228  0.750740  0.698442   \n",
       "144             Ivica Zubac     0.3     1.246690  1.007213  1.255936   \n",
       "263        Maurice Harkless     0.7     0.964902  0.716878  0.541945   \n",
       "149            JaVale McGee     0.9     1.507739  1.035292  1.144971   \n",
       "342              Taj Gibson     0.7     1.236957  0.858840  0.704278   \n",
       "302            Paul Millsap     1.2     1.196342  0.891517  0.771770   \n",
       "257         Marquese Chriss     1.0     1.159133  0.929302  0.996345   \n",
       "56              Cody Zeller     0.6     0.970584  0.714003  0.755002   \n",
       "322                Rudy Gay     0.7     0.922515  0.612272  0.445264   \n",
       "13             Amir Johnson     0.6     0.995994  0.664225  0.808553   \n",
       "326             Salah Mejri     1.1     1.321723  0.904937  0.912406   \n",
       "285          Nikola Mirotic     0.9     0.988498  0.698003  0.733778   \n",
       "\n",
       "     mean_pred  blocks_ly_x  \n",
       "323   2.228238          2.6  \n",
       "186   2.304804          2.5  \n",
       "21    2.163855          2.2  \n",
       "275   1.886438          2.1  \n",
       "134   1.918734          2.1  \n",
       "226   1.748883          2.0  \n",
       "127   1.634484          1.9  \n",
       "40    1.553846          1.7  \n",
       "78    1.557005          1.7  \n",
       "219   1.372205          1.6  \n",
       "241   1.303990          1.6  \n",
       "329   1.576631          1.6  \n",
       "200   1.365416          1.5  \n",
       "318   1.276222          1.4  \n",
       "104   1.267599          1.4  \n",
       "10    1.119991          1.3  \n",
       "4     1.229530          1.3  \n",
       "249   1.317518          1.3  \n",
       "82    1.294319          1.3  \n",
       "210   1.488266          1.3  \n",
       "188   1.411277          1.3  \n",
       "230   1.168482          1.3  \n",
       "131   1.054220          1.2  \n",
       "233   1.091136          1.2  \n",
       "105   1.363563          1.2  \n",
       "261   1.007244          1.2  \n",
       "55    1.233381          1.2  \n",
       "28    1.208236          1.1  \n",
       "365   0.849594          1.1  \n",
       "300   1.254886          1.1  \n",
       "14    1.306840          1.1  \n",
       "160   1.051139          1.1  \n",
       "317   0.792382          1.0  \n",
       "267   0.889461          1.0  \n",
       "173   1.063868          1.0  \n",
       "286   0.946973          1.0  \n",
       "315   1.047983          1.0  \n",
       "339   1.024342          1.0  \n",
       "16    0.819137          1.0  \n",
       "144   1.169946          0.9  \n",
       "263   0.741242          0.9  \n",
       "149   1.229334          0.9  \n",
       "342   0.933358          0.9  \n",
       "302   0.953209          0.9  \n",
       "257   1.028260          0.9  \n",
       "56    0.813196          0.9  \n",
       "322   0.660017          0.9  \n",
       "13    0.822924          0.8  \n",
       "326   1.046355          0.8  \n",
       "285   0.806760          0.8  "
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_2017blocks = blocks[blocks['season']==2017].drop(['team','player','blocks','Games'],axis=1)\n",
    "#pred_2017blocks = blocks[blocks['season']==2017][['blocks_ly','career_blocks','starter_change']]\n",
    "blocks_2017 = NN_blk.predict(pred_2017blocks)\n",
    "gbr_blk_2017 = pd.DataFrame(gbr.predict(pred_2017blocks))\n",
    "LR_blk_2017 = pd.DataFrame(LR.predict(pred_2017blocks))\n",
    "test_2 =pd.DataFrame(blocks_2017)\n",
    "test_3 = pd.merge(blocks,pred_2017blocks,left_index=True,right_index=True).reset_index()\n",
    "test_3['predictions']=test_2[0]\n",
    "test_3['gbr_pred'] = gbr_blk_2017[0]\n",
    "test_3['LR_pred'] = LR_blk_2017[0]\n",
    "test_3['mean_pred'] = (test_3['predictions']+test_3['gbr_pred']+test_3['LR_pred'])/3\n",
    "test_3 = test_3[test_3['Games']>30]\n",
    "test_3[['player','blocks','predictions','LR_pred','gbr_pred','mean_pred','blocks_ly_x']].sort_values(by='blocks_ly_x',ascending=False)[0:50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE using LR:0.03722589949460395\n",
      "MSE using GB:0.04058784592984654\n",
      "MSE using NN:0.12255816610021561\n",
      "MSE using combo:0.04392197487777133\n",
      "MSE using mean:0.18036817882971726\n",
      "MSE using last year stats:0.04798076923076909\n"
     ]
    }
   ],
   "source": [
    "print('MSE using LR:{}'.format(np.mean((test_3['blocks']-test_3['LR_pred'])**2)))\n",
    "print('MSE using GB:{}'.format(np.mean((test_3['blocks']-test_3['gbr_pred'])**2)))\n",
    "print('MSE using NN:{}'.format(np.mean((test_3['blocks']-test_3['predictions'])**2)))\n",
    "print('MSE using combo:{}'.format(np.mean((test_3['blocks']-test_3['mean_pred'])**2)))\n",
    "print('MSE using mean:{}'.format(np.mean((test_3['blocks']-np.mean(test_3['blocks']))**2)))\n",
    "print('MSE using last year stats:{}'.format(np.mean((test_3['blocks']-test_3['blocks_ly_x'])**2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " query= '''\n",
    "        \n",
    "        DROP TABLE IF EXISTS threes_pred;\n",
    "        CREATE TABLE threes_pred(\n",
    "        season int, --these come from player_stats\n",
    "        player varchar(50),\n",
    "        Age int,\n",
    "        team varchar(50),\n",
    "        threes_made float, -- these come from player_stats\n",
    "        threes_ly float,\n",
    "        change_threes float\n",
    "        points_ly float,\n",
    "        change_points_ly float,\n",
    "        starter_change int,\n",
    "        C_PF int,\n",
    "        PG int,\n",
    "        SG_SF int,\n",
    "        \n",
    "         -- these come from team_changes\n",
    "        high_usageplayer_added int,\n",
    "        usagemin_opened float,\n",
    "        maxusage_added float,\n",
    "        high_usageplayer_dropped int,\n",
    "        points_opened float,\n",
    "        max_pointsdropped float,\n",
    "        max_pointsadded float,\n",
    "        \n",
    "        three_ar_ly float, -- from player_advstats\n",
    "        change_3ar float,\n",
    "        per_ly float,\n",
    "        change_per float,\n",
    "        usagerank float,\n",
    "        usagerank_ly float,\n",
    "        offensive_winshares float,\n",
    "        offensive_boxplusminus float,\n",
    "        boxplusminus float,\n",
    "        value_overreplacement float,\n",
    "        \n",
    "        career_threes float,\n",
    "        yearspro int\n",
    "        );\n",
    "        \n",
    "        INSERT INTO threes_pred(season,player,age,team,threes_made,threes_ly,change_threes,points_ly,change_points_ly,starter_change,C_PF,PG,SG_SF)\n",
    "        SELECT season,player,age,startingteam,threes_made,threes_ly,change_threes,points_ly,change_points_ly,starter-starter_ly,\n",
    "        case when pos in ('C','PF') then 1 else 0 end,case when pos='PG' then 1 else 0 end,case when pos in('SG','SF') then 1 else 0 end from player_stats;\n",
    "        \n",
    "        update threes_pred tp\n",
    "        set high_usageplayer_added = tc.high_usageplayer_added,usagemin_opened=tc.usagemin_opened,\n",
    "        maxusage_added=tc.max_usageadded,high_usageplayer_dropped=tc.high_usageplayer_dropped,points_opened=tc.points_opened,\n",
    "        max_pointsdropped=tc.max_pointsdropped,max_pointsadded=tc.max_pointsadded\n",
    "        from team_changes tc\n",
    "        where tc.team = tp.team and tp.season=tc.season;\n",
    "        \n",
    "        update threes_pred tp\n",
    "        set three_ar_ly = pa.threear_ly,change_3ar=pa.change_3ar,per_ly=pa.per_ly,change_per=pa.change_per,\n",
    "        usagerank=pa.usagerank,usagerank_ly=pa.usagerank_ly,offensive_winshares=pa.offensive_winshares,\n",
    "        offensive_boxplusminus=pa.offensive_boxplusminus,boxplusminus=pa.boxplusminus,value_overreplacement=pa.value_overreplacement\n",
    "        from player_advstats pa\n",
    "        where tp.player = pa.player and tp.season = pa.season and tp.team = pa.startingteam;\n",
    "        \n",
    "        update threes_pred pp\n",
    "        set career_threes = pc.career_threes, yearspro = pc.yearspro\n",
    "        from player_careerstats pc\n",
    "        where tp.player = pc.player and tp.season = pc.season;\n",
    "        \n",
    "        \n",
    "        select * from threes_pred where season>2009\n",
    "        '''\n",
    "\n",
    "\n",
    "cur.execute(query)\n",
    "data = cur.fetchall()\n",
    "points_df = pd.DataFrame(np.array(data))\n",
    "points_df.columns = ['season','player','age','team','points','points_ly','change_points_ly','starter_change','C_PF','PG','SG_SF','high_usageplayer_added','usagemin_opened','maxusage_added','high_usageplayer_dropped','points_opened','max_pointsdropped',\n",
    "                    'max_pointsadded','three_ar_ly','change_3ar','per_ly','change_per','usagerank','usagerank_ly','offensive_winshares','offensive_boxplusminus','boxplusminus','value_overreplacement','career_points','yearspro']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
